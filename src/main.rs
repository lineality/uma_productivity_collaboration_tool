/*
Uma
2024.09-11
RUST_BACKTRACE=full cargo run

# Uma: Coordination, Productivity, Hygiene
```
4_|
/ \
```
A distributed project graph database MCU (Multipoint Conferencing Unit) with cli TUI, instant messenger, Kanban Task Manager, and other Agile Kahneman-Tversky project, productivity, coordination, collaboration features

Uma Productivity Collaboration Tools for Project-Alignment
~ "Read the old books."
- MIT license
- https://github.com/lineality/uma_productivity_collaboration_tool
- https://github.com/lineality/definition_behavior_studies
- https://github.com/lineality/Online_Voting_Using_One_Time_Pads
- https://github.com/lineality/object_relationship_spaces_ai_ml
In memory of Eleanor Th. Vadala 1923-2023: aviator, astronomer, engineer, pioneer, leader, friend.

cargo.toml ->

[package]
name = "uma"
version = "0.1.0"
edition = "2021"

[dependencies]
walkdir = "2.5.0"
toml = "0.8.19"
serde = { version = "1.0.210", features = ["derive"] }
rand = "0.8.5"
getifaddrs = "0.1.4"

https://docs.rs/getifaddrs/latest/getifaddrs/

// tiny_tui_module.rs

pub mod tiny_tui {
    use std::path::Path;
    use std::time::{
        Duration,
        UNIX_EPOCH
        };
    use crate::{ // Import from the main module
        DEBUG_FLAG,
        debug_log,
        OpenOptions,
        Write,
        };

    pub fn render_list(
        list: &Vec<String>,
        current_path: &Path,
        agenda_process: &str,
        goals_features: &str,
        scope: &str,
        pa2_schedule: &Vec<u64>,
    ) {
        // 1. Get the path components
        let path_components: Vec<_> = current_path.components().collect();

        // 2. Display the path, skipping the first two components
        if path_components.len() > 2 {
            let relevant_path = path_components[2..].iter()
                .map(|c| c.as_os_str().to_string_lossy())
                .collect::<Vec<_>>()
                .join("/");
            println!("Current Path: /{}", relevant_path);
        } else {
            println!("Select a Team-Channel (by number):");
        }

        // 2b. Display added core node fields
        println!("Agenda/Process: {}", agenda_process);
        println!("Goals/Features: {}", goals_features);
        println!("Scope: {}", scope);

        if pa2_schedule.len() == 2 {
            let start_time = pa2_schedule[0];
            let end_time = pa2_schedule[1];
            let duration_days = (end_time - start_time) / (60 * 60 * 24);

            let start_date = format_timestamp_to_date(start_time);
            let end_date = format_timestamp_to_date(end_time);
            println!("Schedule: {} - {} ({} days)", start_date, end_date, duration_days);

        }
        else {
            println!("Schedule: (no schedule)");
        }

        // 3. Display the list items as before
        for (i, item) in list.iter().enumerate() {
            println!("{}. {}", i + 1, item);
        }
    }

    pub fn simple_render_list(list: &Vec<String>, current_path: &Path) {

        // 1. Get the path components
        let path_components: Vec<_> = current_path.components().collect();

        // 2. Display the path, skipping the first two components
        if path_components.len() > 2 {
            let relevant_path = path_components[2..].iter()
                .map(|c| c.as_os_str().to_string_lossy())
                .collect::<Vec<_>>()
                .join("/");
            println!("Current Path: /{}", relevant_path);
        } else {
            println!("Select a Team-Channel (by number):");
        }

        // 3. Display the list items as before
        for (i, item) in list.iter().enumerate() {
            println!("{}. {}", i + 1, item);
        }
    }



/// Converts a Unix timestamp (seconds since 1970-01-01 00:00:00 UTC) to a YYYY-MM-DD formatted date string
///
/// # Arguments
/// * `timestamp` - Unix timestamp in seconds
///
/// # Returns
/// * `String` - Date in "YYYY-MM-DD" format, or "Invalid Date" if the timestamp cannot be converted
///
/// # Examples
/// ```
/// let timestamp = 1672531200; // 2023-01-01 00:00:00 UTC
/// assert_eq!(format_timestamp_to_date(timestamp), "2023-01-01");
/// ```
/// use -> use std::time::{Duration, UNIX_EPOCH};
fn format_timestamp_to_date(timestamp: u64) -> String {
    UNIX_EPOCH
        .checked_add(Duration::from_secs(timestamp))
        .and_then(|datetime| datetime.duration_since(UNIX_EPOCH).ok())
        .map(|duration| {
            let secs = duration.as_secs();
            let year = 1970 + (secs / 31_557_600); // Approximate years (365.25 days)
            let remaining_secs = secs % 31_557_600;
            let month = 1 + (remaining_secs / 2_629_800); // Approximate months (30.44 days)
            let day = 1 + ((remaining_secs % 2_629_800) / 86_400); // Days (24 hours)

            format!("{:04}-{:02}-{:02}", year, month, day)
        })
        .unwrap_or_else(|| "Invalid Date".to_string())
}


    pub fn render_tasks_table(headers: &[String], data: &[Vec<String>], current_path: &Path) {
        debug_log("starting: render_tasks_table");
        // 1. Display Current Path
        print!("\x1B[2J\x1B[1;1H"); // Clear the screen
        println!("Current Path: {}", current_path.display());

        // 2. Display Table (reuse display_table from tiny_tui_module)
        display_table(headers, data);

        // 3. (Optional) Display any other task-specific information or instructions.
        println!("Select a Task (by number):");
    }



    // pub fn render_list(list: &Vec<String>, current_path: &Path) {
    //     println!("Current Path: {}", current_path.display());
    //     for (i, item) in list.iter().enumerate() {
    //         println!("{}. {}", i + 1, item);
    //     }
    // }

    pub fn get_input() -> Result<String, std::io::Error> {
        let mut input = String::new();
        std::io::stdin().read_line(&mut input)?;
        Ok(input.trim().to_string())
    }

    pub fn display_table(headers: &[String], data: &[Vec<String>]) {  // Changed header type
        debug_log("tui module: task-mode: start: display_table()");
        debug_log!(
            "tui module: display_table(): headers -> {:?} data -> {:?}",
            headers,
            data,
        );

        // Print headers
        for header in headers {
            print!("{:<15} ", header);
        }
        println!();

        // Print separator (optional)
        println!("{}", "-".repeat(headers.len() * 15));


        // Print rows:  Handle potentially uneven row lengths
        // Find the maximum number of columns for formatting:
        let max_columns = headers.len();

        for row in data {
            for (i, item) in row.iter().enumerate() {
                if i < max_columns { // Ensure we don't exceed the header count.
                    print!("{:<15} ", item);
                }
            }
            println!();
        }
    }

    // pub fn display_table(headers: &[&str], data: &[Vec<&str>]) {
    //     // Print headers
    //     for header in headers {
    //         print!("{:<15} ", header); // Left-align with padding
    //     }
    //     println!();

    //     // Print separator
    //     println!("{}", "-".repeat(headers.len() * 15));

    //     // Print data rows
    //     for row in data {
    //         for item in row {
    //             print!("{:<15} ", item);
    //         }
    //         println!();
    //     }
    // }
    // // fn main() {
    // //     let headers = vec!["Column 1", "Column 2", "Column 3"];
    // //     let data = vec![
    // //         vec!["Data A", "Data B", "Data C"],
    // //         vec!["Data D", "Data E", "Data F"],
    // //     ];
    // //     display_table(&headers, &data);
    // // }

    // Helper function to transpose the table data
    pub fn transpose_table_data(data: &[Vec<String>]) -> Vec<Vec<String>> {
        debug_log("tui module: task-mode: start: transpose_table_data()");
        if data.is_empty() {
            return Vec::new();
        }

        let num_rows = data.iter().map(|col| col.len()).max().unwrap_or(0);  // Or 0 for an empty table
        let num_cols = data.len();
        let mut transposed_data = vec![vec![String::new(); num_cols]; num_rows];

        for (j, col) in data.iter().enumerate() {
            for (i, item) in col.iter().enumerate() {
                transposed_data[i][j] = item.clone();
            }
        }

        transposed_data
    }

}


# See:
src/manage_absolute_executable_directory_relative_paths.rs
src/read_toml_field.rs
src/read_toml_field.rs

*/

/*

// Get armored public key, using key-id (full fingerprint in)
let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
    Ok(fingerprint) => fingerprint,
    Err(e) => {
        // Since the function returns Result<CoreNode, String>, we need to return a String error
        return Err(format!(
            "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
            e
        ).into());
    }
};

// code from load_core_node...()
// Get the UME temp directory path with proper GpgError conversion
let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
    .map_err(|io_err| GpgError::ValidationError(
        format!("Failed to get UME temp directory path: {}", io_err)
    ))?;

// Using Debug trait for more detailed error information
let node_readcopy_path = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
    &node_toml_path,
    &gpg_full_fingerprint_key_id_string,
    &base_uma_temp_directory_path,
).map_err(|e| format!("Failed to get temporary read copy of TOML file: {:?}", e))?;

or

// Using Debug trait for more detailed error information
let node_readcopy_path = get_pathstring_to_temp_plaintoml_verified_extracted(
    &node_toml_path,
    &gpg_full_fingerprint_key_id_string,
    &base_uma_temp_directory_path,
).map_err(|e| format!("Failed to get temporary read copy of TOML file: {:?}", e))?;

*/

// Set debug flag (future: add time stamp with 24 check)
const DEBUG_FLAG: bool = true;
const MAX_NETWORK_TYPE_LENGTH: usize = 1024; // Example: 1KB limit

const EMPTY_IPV_4: Ipv4Addr = Ipv4Addr::new(127, 0, 0, 1); // == = 127.0.0.1
const EMPTY_IPV_6: Ipv6Addr = Ipv6Addr::UNSPECIFIED; // Correct way to represent an unspecified IPv6 address

use std::env;
use std::hash::{
    Hash,
    DefaultHasher,
    Hasher,
};
use std::io::{
    self,
    Error,
    ErrorKind,
    Write,
    BufRead,
    BufReader,
    Read,
};

// use std::str::FromStr;
use std::process::{
    self,
    Command as StdCommand,
    Stdio,
};
use std::error::Error as StdError;
use walkdir::WalkDir;
use std::path::Path;
use std::path::{
    PathBuf,
};
use std::time::{
    SystemTime,
    UNIX_EPOCH,
    // Instant,
};

use std::fs;
use std::fs::{
    File,
    remove_file,
    create_dir_all,
    OpenOptions,
    read_to_string,
    write,
    remove_dir_all,
    read_dir,
    // DirEntry,
};
use toml;
use toml::Value;
use serde::{
    Deserialize,
    Serialize,

};

use std::ffi::OsStr;
use std::collections::HashMap;
use std::collections::HashSet;

// For Sync
use rand::prelude::{
    // SliceRandom,
    // IteratorRandom,
    Rng,
};
use std::thread;
use std::num::ParseIntError;
use std::time::Duration;
use std::net::{
    IpAddr,
    Ipv4Addr,
    Ipv6Addr,
    TcpListener,
    // TcpStream,
    SocketAddr,
    UdpSocket,
};
// https://docs.rs/getifaddrs/latest/getifaddrs/
use getifaddrs::{getifaddrs, InterfaceFlags};





/*
To eventually replace any 3rd party
toml crates
*/
// For toml and clearsigntoml
mod clearsign_toml_module;
use crate::clearsign_toml_module::{
    GpgError,
    read_string_array_field_from_toml,
    convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace,
    verify_clearsign,
    convert_toml_filewithkeyid_into_clearsigntoml_inplace,
    q_and_a_user_selects_gpg_key_full_fingerprint,
    read_single_line_string_field_from_toml,
    read_u8_field_from_toml,
    read_u64_field_from_toml,
    read_float_f32_field_from_toml,
    read_singleline_string_from_clearsigntoml,
    read_multiline_string_from_clearsigntoml,
    read_str_array_field_clearsigntoml,
    extract_verify_store_gpg_encrypted_clearsign_toml,
    verify_clearsigned_file_and_extract_content_to_output,
    clearsign_and_encrypt_file_for_recipient,
    gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck,
    decrypt_gpgfile_to_output,
    read_all_collaborator_port_assignments_clearsigntoml_optimized,
    read_abstract_collaborator_portassignments_from_clearsigntoml_withoutkeyid,
    read_teamchannel_collaborators_with_access_from_clearsigntoml,
    read_singleline_string_from_clearsigntoml_without_publicgpgkey,
    read_u8_array_from_clearsigntoml_without_publicgpgkey,
    read_pathbuf_from_clearsigntoml_without_publicgpgkey,
    read_u64_from_clearsigntoml_without_publicgpgkey,
    read_stringarray_from_clearsigntoml_without_publicgpgkey,
    read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey,
    read_option_usize_from_clearsigntoml_without_publicgpgkey,
    read_option_bool_from_clearsigntoml_without_publicgpgkey,
    read_bool_from_clearsigntoml_without_publicgpgkey,
    read_abstract_ports_from_clearsigntoml_without_publicgpgkey,
    read_option_i64_from_clearsigntoml_without_publicgpgkey,
    read_teamchannel_collaborator_ports_clearsigntoml_without_keyid,
    read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml,
    get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml,
    get_pathstring_to_temp_plaintoml_verified_extracted,
    get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml,
    cleanup_collaborator_temp_file,
    read_u64_array_from_clearsigntoml_without_publicgpgkey,
};


/// for managing file paths
mod manage_absolute_executable_directory_relative_paths;
use manage_absolute_executable_directory_relative_paths::{
    make_input_path_name_abs_executabledirectoryrelative_nocheck,
    make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error,
    make_file_path_abs_executabledirectoryrelative_canonicalized_or_error,
    get_absolute_path_to_executable_parentdirectory,
    abs_executable_directory_relative_exists,
    prepare_file_parent_directories_abs_executabledirectoryrelative,
    make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path,
    // count_subdirectories_executabledirectoryrelative_default_zero,
};


// For TUI
#[macro_use]
mod tiny_tui_module;
use tiny_tui_module::tiny_tui;


const FILE_READWRITE_N_RETRIES: u64 = 5;
const FILE_READWRITE_RETRY_SEC_PAUSE: u64 = 2;
const FILE_READWRITE_RETRY_SEC_PAUSE_MIN: u64 = 1;
const FILE_READWRITE_RETRY_SEC_PAUSE_MAX: u64 = 6;

/*
Path constants will later be converted
to executible-parent-relative-aboslute paths
*/
const UMA_TOML_CONFIGFILE_PATH_STR: &str = "uma.toml";

/// use:
/// "project_graph_data/collaborator_files_address_book/{}__collaborator.toml";
/// "project_graph_data/collaborator_files_address_book/{}__collaborator.gpgtoml";
const COLLABORATOR_ADDRESSBOOK_PATH_STR: &str = "project_graph_data/collaborator_files_address_book";

const TEAM_CHANNELS_HOMEBASE_PATH_STR: &str = "project_graph_data/team_channels/";


/// temp file to clean regularly
const TEMP_DIR_BASE_UMA_PATH_STR: &str = "uma_temp_dir";

const CONTINUE_UMA_PATH_STR: &str = "project_graph_data/session_state_items/continue_uma.txt";
const HARD_RESTART_FLAG_PATH_STR: &str = "project_graph_data/session_state_items/yes_hard_restart_flag.txt";
const SYNC_START_OK_FLAG_PATH_STR: &str = "project_graph_data/session_state_items/ok_to_start_sync_flag.txt";
const INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR: &str = "invites_updates/incoming/key.asc";
const UMA_SESSION_STATE_ITEMS_DIR_PATH_STR: &str = "project_graph_data/session_state_items";

const UMA_CURRENT_NODE_PATH_STR: &str = "project_graph_data/session_state_items/current_node_directory_path.txt";



/*
# Use Example:
```
let absolute_path = match get_team_channels_homebase_directory_path() {
    Ok(path) => path,
    Err(e) => {
        debug_log!("Failed to get absolute path: {}", e);
        return None;
    }
};
```
*/

/// Gets the absolute path to temp directory
/// executible-parent-relative-aboslute path
pub fn get_addressbook_directory_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        COLLABORATOR_ADDRESSBOOK_PATH_STR
    )
}

/// Gets the absolute path to temp directory
/// executible-parent-relative-aboslute path
pub fn get_team_channels_homebase_directory_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        TEAM_CHANNELS_HOMEBASE_PATH_STR
    )
}

/// Gets the absolute path to temp directory
/// executible-parent-relative-aboslute path
pub fn get_base_uma_temp_directory_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        TEMP_DIR_BASE_UMA_PATH_STR
    )
}

/// Gets the absolute path to the hard restart flag file.
/// executible-parent-relative-aboslute path
pub fn get_hard_restart_flag_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        HARD_RESTART_FLAG_PATH_STR
    )
}

/// Gets the absolute path to the sync start OK flag file.
/// executible-parent-relative-aboslute path
pub fn get_sync_start_ok_flag_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        SYNC_START_OK_FLAG_PATH_STR
    )
}

/// Gets the absolute path to the incoming public GPG key file.
/// executible-parent-relative-aboslute path
pub fn get_incoming_publicgpg_keyasc_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR
    )
}

pub fn get_continue_uma_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        CONTINUE_UMA_PATH_STR
    )
}

pub fn get_sessionstateitems_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        UMA_SESSION_STATE_ITEMS_DIR_PATH_STR
    )
}

pub fn get_current_node_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        UMA_CURRENT_NODE_PATH_STR
    )
}


/// Determines if UMA should halt based on the continue_uma.txt file.
///
/// Reads the content of the continue_uma.txt file from its executable-relative
/// absolute path, and checks if the content is "0".
///
/// # Returns
///
/// * `bool` - true if UMA should halt (file contains "0"), false otherwise.
///
/// # Behavior
///
/// - Returns true if the file exists and contains "0"
/// - Returns false if:
///   - The path to the file cannot be resolved
///   - The file does not exist
///   - The file cannot be read
///   - The file contains any value other than "0"
pub fn should_halt_uma() -> bool {
    // 1. Get the absolute path to the continue_uma.txt file
    let file_path = match get_continue_uma_path() {
        Ok(path) => path,
        Err(e) => {
            eprintln!("Error resolving path to continue_uma.txt: {:?}", e);
            return false; // Don't halt if we can't even find the path
        }
    };

    // 2. Read the file content
    let file_content = match fs::read_to_string(&file_path) {
        Ok(content) => content,
        Err(e) => {
            eprintln!("Error reading continue_uma.txt at {:?}: {:?}", file_path, e);

            // Optional: attempt to create the file if it doesn't exist
            if e.kind() == io::ErrorKind::NotFound {
                println!("continue_uma.txt not found, creating with default value '1'");
                if let Some(parent) = file_path.parent() {
                    if let Err(e) = fs::create_dir_all(parent) {
                        eprintln!("Failed to create parent directories: {:?}", e);
                    }
                }

                if let Err(e) = fs::write(&file_path, "1") {
                    eprintln!("Failed to create continue_uma.txt file: {:?}", e);
                }
            }

            return false; // Don't halt on error reading the file
        }
    };

    // 3. Check if the file content is "0"
    file_content.trim() == "0"
}

// use std::fs;
// use std::io::{self, Write};
// use std::path::{Path, PathBuf};
// use crate::manage_absolute_executable_directory_relative_paths::{
//     make_file_path_abs_executabledirectoryrelative_canonicalized_or_error,
//     prepare_file_parent_directories_abs_executabledirectoryrelative,
// };

// /// optional
// /// Gets the absolute path to the continue_uma.txt file, creating it with default content "1"
// /// if it doesn't exist.
// ///
// /// # Returns
// ///
// /// * `io::Result<PathBuf>` - The absolute canonicalized path to the continue_uma.txt file
// ///
// /// # Errors
// ///
// /// This function will return an error if:
// /// * The parent directory cannot be created
// /// * The file cannot be created when it doesn't exist
// /// * Path canonicalization fails for any reason
// fn get_continue_uma_path() -> io::Result<PathBuf> {
//     let relative_path = CONTINUE_UMA_PATH_STR;

//     // First try to get the path if it already exists
//     match make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_path) {
//         Ok(path) => {
//             // File exists, return its canonicalized path
//             println!("Continue UMA file found at: {:?}", path);
//             Ok(path)
//         },
//         Err(_) => {
//             // File doesn't exist or other error - create it with default content "1"
//             println!("Continue UMA file not found, creating it with default value '1'");

//             // Prepare the parent directories
//             let path = prepare_file_parent_directories_abs_executabledirectoryrelative(relative_path)?;

//             // Create the file with default content
//             let mut file = fs::File::create(&path)?;
//             file.write_all(b"1")?;

//             // Return the canonicalized path
//             let canonicalized = path.canonicalize()?;
//             println!("Created continue UMA file at: {:?}", canonicalized);
//             Ok(canonicalized)
//         }
//     }
// }

// /// Reads the content of the continue_uma.txt file, creating it with default value "1"
// /// if it doesn't exist or there's an error reading it.
// ///
// /// # Returns
// ///
// /// * `String` - The content of the continue_uma.txt file ("0" or "1"), defaults to "1" on errors
// fn read_continue_uma_file() -> String {
//     // First get the path, which creates the file if needed
//     let continue_path = match get_continue_uma_path() {
//         Ok(path) => path,
//         Err(e) => {
//             eprintln!("Error ensuring continue_uma.txt path: {}", e);
//             return "1".to_string(); // Default to "continue" on path resolution error
//         }
//     };

//     // Then read the file content
//     match fs::read_to_string(&continue_path) {
//         Ok(content) => {
//             let trimmed = content.trim().to_string();
//             // Validate content - if not "0" or "1", default to "1"
//             if trimmed != "0" && trimmed != "1" {
//                 eprintln!("Invalid content in continue_uma.txt: '{}', defaulting to '1'", trimmed);
//                 // Try to fix the file with correct content
//                 let _ = fs::write(&continue_path, "1");
//                 "1".to_string()
//             } else {
//                 trimmed
//             }
//         },
//         Err(e) => {
//             eprintln!("Error reading continue_uma.txt: {}", e);

//             // Try to recreate the file with default content
//             match fs::write(&continue_path, "1") {
//                 Ok(_) => "1".to_string(),
//                 Err(e2) => {
//                     eprintln!("Error creating continue_uma.txt after read failed: {}", e2);
//                     "1".to_string() // Default to "continue" on write error
//                 }
//             }
//         }
//     }
// }

pub enum SyncError {
    ConnectionError(std::io::Error),
    ChecksumMismatch,
    Timeout,
    FileReadError(std::io::Error),
    FileWriteError(std::io::Error),
    // ... other potential errors ...
}

// #[derive(Debug, Deserialize, Serialize, Clone)]
// struct CollaboratorPairPorts {
//     collaborator_ports: Vec<ReadTeamchannelCollaboratorPortsToml>,
// }

#[derive(Debug)]
enum MyCustomError {
    /// IO errors from file operations
    IoError(std::io::Error),
    /// TOML parsing and deserialization errors
    TomlDeserializationError(toml::de::Error),
    /// Invalid data format or content errors
    InvalidData(String),
    /// Port collision errors when ports are already in use
    PortCollision(String),
    /// Custom error messages for general purpose errors
    Custom(String),
}


// Implement From<ThisProjectError> for MyCustomError
impl From<ThisProjectError> for MyCustomError {
    fn from(error: ThisProjectError) -> Self {
        match error {
            ThisProjectError::IoError(e) => MyCustomError::IoError(e),
            ThisProjectError::TomlDeserializationError(e) => MyCustomError::TomlDeserializationError(e),
            ThisProjectError::InvalidData(msg) => MyCustomError::InvalidData(msg),
            ThisProjectError::InvalidInput(msg) => MyCustomError::InvalidData(msg),
            ThisProjectError::PortCollision(msg) => MyCustomError::PortCollision(msg),
            // ... add other conversions for your variants ...
            _ => MyCustomError::InvalidData("Unknown error".to_string()), // Default case
        }
    }
}

impl From<String> for MyCustomError {
    /// Converts a String into a MyCustomError::Custom variant
    fn from(error_message: String) -> Self {
        MyCustomError::Custom(error_message)
    }
}

impl From<&str> for MyCustomError {
    /// Converts a &str into a MyCustomError::Custom variant
    fn from(error_message: &str) -> Self {
        MyCustomError::Custom(error_message.to_string())
    }
}

// Optional: implement Display trait for better error messages
impl std::fmt::Display for MyCustomError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            MyCustomError::IoError(e) => write!(f, "IO Error: {}", e),
            MyCustomError::TomlDeserializationError(e) => write!(f, "TOML Error: {}", e),
            MyCustomError::InvalidData(msg) => write!(f, "Invalid Data: {}", msg),
            MyCustomError::PortCollision(msg) => write!(f, "Port Collision: {}", msg),
            MyCustomError::Custom(msg) => write!(f, "Error: {}", msg),
        }
    }
}
// Implement PartialEq manually:
impl PartialEq for MyCustomError {
    fn eq(&self, other: &Self) -> bool {
        match (self, other) {
            // (MyCustomError::IoError(ref e1), MyCustomError::IoError(ref e2)) => {
            (MyCustomError::IoError(e1), MyCustomError::IoError(e2)) => {
                e1.kind() == e2.kind() // Compare the ErrorKind
                // Or you can use:
                // e1.to_string() == e2.to_string()
            },
            (MyCustomError::TomlDeserializationError(e1), MyCustomError::TomlDeserializationError(e2)) => e1 == e2,
            // Add other arms for your variants as needed
            _ => false, // Different variants are never equal
        }
    }
}

// Implement the std::error::Error trait
impl StdError for MyCustomError {
    fn source(&self) -> Option<&(dyn StdError + 'static)> {
        match *self {
            MyCustomError::IoError(ref err) => Some(err),
            MyCustomError::TomlDeserializationError(ref err) => Some(err),
            _ => None, // No underlying source for these variants
        }
    }
}

// impl std::fmt::Display for MyCustomError {
//     fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
//         match self {
//             MyCustomError::IoError(err) => write!(f, "IO Error: {}", err),
//             // MyCustomError::TomlDeserializationError(err) => write!(f, "TOML Error: {}", err),
//             MyCustomError::TomlDeserializationError(err) => write!(f, "TOML Error: {}", err),
//             // &MyCustomError::InvalidData(_) => todo!(),
//             &MyCustomError::InvalidData(_) => todo!(),
//             &MyCustomError::PortCollision(_) => todo!(),
//         }
//     }
// }

// Implement the From trait for easy conversion from io::Error and toml::de::Error:
impl From<io::Error> for MyCustomError {
    fn from(error: io::Error) -> Self {
        MyCustomError::IoError(error)
    }
}

impl From<toml::de::Error> for MyCustomError {
    fn from(error: toml::de::Error) -> Self {
        MyCustomError::TomlDeserializationError(error)
    }
}

#[derive(Debug)]
pub enum ThisProjectError {
    IoError(std::io::Error),
    TomlDeserializationError(toml::de::Error), // May be depricated along with serde-crate
    TomlVanillaDeserialStrError(String), // use without serede crate (good)
    InvalidInput(String),
    InvalidData(String),
    PortCollision(String),
    NetworkError(String),
    WalkDirError(walkdir::Error),
    ParseIntError(ParseIntError),
    GpgError(String),  // GPG-specific error type
    ParseError(std::num::ParseIntError),
    // Add new variant for String errors
    StringError(String),
    // Other variants...
}

impl From<GpgError> for ThisProjectError {
    fn from(err: GpgError) -> Self {
        ThisProjectError::GpgError(format!("GPG operation failed: {:?}", err))
    }
}

// Implement From<walkdir::Error> for ThisProjectError
impl From<walkdir::Error> for ThisProjectError {
    fn from(err: walkdir::Error) -> Self {
        ThisProjectError::WalkDirError(err)
    }
}

// Implement From<ParseIntError> for ThisProjectError
impl From<ParseIntError> for ThisProjectError {
    fn from(err: ParseIntError) -> Self {
        ThisProjectError::ParseIntError(err)
    }
}

// Implement From<toml::de::Error> for ThisProjectError
impl From<toml::de::Error> for ThisProjectError {
    fn from(err: toml::de::Error) -> Self {
        ThisProjectError::TomlDeserializationError(err)
    }
}

// Implement the std::error::Error trait for ThisProjectError
impl std::error::Error for ThisProjectError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        match *self {
            ThisProjectError::IoError(ref err) => Some(err),
            ThisProjectError::TomlDeserializationError(ref err) => Some(err),
            _ => None,
        }
    }
}

// Implement the Display trait for ThisProjectError for easy printing
impl std::fmt::Display for ThisProjectError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match *self {
            ThisProjectError::IoError(ref err) => write!(f, "IO Error: {}", err),
            ThisProjectError::TomlDeserializationError(ref err) => write!(f, "TOML TomlDeserializationError  Error: {}", err),
            ThisProjectError::TomlVanillaDeserialStrError(ref err) => write!(f, "TomlVanillaDeserialStrError TOML Error: {}", err),
            ThisProjectError::InvalidData(ref msg) => write!(f, "Invalid Data: {}", msg),
            ThisProjectError::InvalidInput(ref msg) => write!(f, "Invalid Input: {}", msg),
            ThisProjectError::PortCollision(ref msg) => write!(f, "Port Collision: {}", msg),
            ThisProjectError::NetworkError(ref msg) => write!(f, "Network Error: {}", msg),
            ThisProjectError::WalkDirError(ref err) => write!(f, "WalkDir Error: {}", err),
            ThisProjectError::ParseIntError(ref err) => write!(f, "ParseInt Error: {}", err),
            ThisProjectError::ParseIntError(ref err) => write!(f, "ParseInt Error: {}", err),
            ThisProjectError::GpgError(ref err) => write!(f, "GPG Error: {}", err),
            ThisProjectError::ParseError(ref err) => write!(f, "Parse Error: {}", err),
            ThisProjectError::StringError(ref msg) => write!(f, "Error: {}", msg),
            // ... add formatting for other error types
        }
    }
}

/// Implements conversion from String to ThisProjectError
///
/// This allows using .into() to convert string error messages directly to
/// the project's error type, simplifying error propagation when the error
/// source is a formatted message.
impl From<String> for ThisProjectError {
    fn from(message: String) -> Self {
        // Create a ThisProjectError from a String
        // Assuming ThisProjectError has a variant for string errors
        // Update this to match your actual error type structure
        ThisProjectError::StringError(message)
    }
}

/// Implements conversion from &str to ThisProjectError for convenience
///
/// This allows using string literals as errors without explicit conversion
impl From<&str> for ThisProjectError {
    fn from(message: &str) -> Self {
        // Convert &str to String and then use the String implementation
        ThisProjectError::from(message.to_string())
    }
}



fn remove_duplicates_from_path_array(vec: Vec<PathBuf>) -> Vec<PathBuf> {
    let mut seen = HashSet::new();
    let mut unique_vec = Vec::new();

    for item in vec {
        if seen.insert(item.clone()) {
            unique_vec.push(item);
        }
    }

    unique_vec
}

// Implement the From trait to easily convert from other error types into ThisProjectError
impl From<io::Error> for ThisProjectError {
    fn from(err: io::Error) -> ThisProjectError {
        ThisProjectError::IoError(err)
    }
}

/// utility: Gets a list of all IPv4 and IPv6 addresses associated with the current system's network interfaces.
///
/// Returns:
/// - `Ok(Vec<IpAddr>)`: A vector of IP addresses on success.
/// - `Err(io::Error)`: An error if obtaining network interface information fails.
/// From: https://docs.rs/getifaddrs/latest/getifaddrs/
/// use getifaddrs::{getifaddrs, InterfaceFlags};
fn get_local_ip_addresses() -> Result<Vec<IpAddr>, std::io::Error> {
    // https://docs.rs/getifaddrs/latest/getifaddrs/

    // Test Print in Debug Log
    for interface in getifaddrs()? {
        debug_log("fn get_local_ip_addresses() -> std::io::Result<()> {");
        debug_log!("Interface: {}", interface.name);
        debug_log!("  Address: {}", interface.address);
        if let Some(netmask) = interface.netmask {
            debug_log!("  Netmask: {}", netmask);
        }
        debug_log!("  Flags: {:?}", interface.flags);
        if interface.flags.contains(InterfaceFlags::UP) {
            debug_log!("  Status: Up");
        } else {
            debug_log!("  Status: Down");
        }
        debug_log!();
    }

    let mut addresses = Vec::new();

    for interface in getifaddrs()? {
        if interface.flags.contains(InterfaceFlags::UP) && // Interface is up
           !interface.flags.contains(InterfaceFlags::LOOPBACK) { // Not a loopback interface
               match interface.address {
                   IpAddr::V4(addr) => addresses.push(IpAddr::V4(addr)),
                   IpAddr::V6(addr) => addresses.push(IpAddr::V6(addr)),
               }
           }
    }

    Ok(addresses)
}

// /*
// TODO:
// in the nearterm and long term
// there needs to be a way of selecting and coordinating about working ip addresses
// e.g. once an address works, the number of that address in the shared list may be
// transmitted in the ReadySignal to say which ip is being used (e.g. when
//     there are several possible 'campuses' that might be used)

// The primary task is testing what local IP for the local owner user out of the list
// in their file works (and which listen item that is).

// another later task may be using a intranet mode.
// */

/// Get Band: Network config data
/// The function is called during initialization bootstrapping
/// so there are few pre-existing values to put in,
/// this function must bootstrap itself.
/// Note: this is before any team_channel has been entered
///
/// Get Band: Network config data
/// Returns the first valid IP address and its type ("ipv6" or "ipv4") found for the local user,
/// along with its index in the respective list.
///
/// This function is called during initialization bootstrapping to determine a valid network configuration
/// before any team channel is entered. It reads the local user's IP address lists from their collaborator
/// TOML file and attempts to bind a UDP socket to each address to verify its validity.
///
/// Args:
///     uma_local_owner_user: The username of the local UMA user.
///
/// Returns:
///     (String, u8): A tuple containing the network type ("ipv6" or "ipv4") and the index of the valid IP address.
///     Returns ("none", 0) if no valid IP address is found.
fn get_band__find_valid_network_index_and_type(
    uma_local_owner_user: &str,
    full_fingerprint_key_id_string: &str,
) -> (
    bool, // network_found_ok flag
    String, // network_type
    u8, // network_index
    Ipv4Addr,
    Ipv6Addr,
    ) {
    /*
    General Steps
    1. get name of local owner
        paremeter
    2. get local owner file (or fields)
    COLLABORATOR_ADDRESSBOOK_PATH_STR
    "/project_graph_data/collaborator_files_address_book/{}__collaborator.toml", uma_local_owner_user
    3. look for valid ipv6
        find_valid_local_owner_ipv6_address
    4. (if not found) look for valid ivp4
        find_valid_local_owner_ipv4_address
    5. (pending) look for other network band types e.g. CB radio, optical, audio, etc.
    6. return (network_type, network_index) tuple (e.g. ('ipv6', 0)
    */

    // 2. Load IP lists from the collaborator file
    let (ipv4_addresses, ipv6_addresses) = match load_local_ip_lists_to_ipvec(
        uma_local_owner_user,
        &full_fingerprint_key_id_string,
        ) {
        Ok(lists) => lists,
        Err(e) => {
            debug_log!("Error loading IP lists: {}. Returning filler values.", e);
            return (
                false,
                "none".to_string(),
                0,
                EMPTY_IPV_4,  // Filler value
                EMPTY_IPV_6,  // Filler value
            );
        }
    };

    // println!("ipv4_addresses: {:?}", ipv4_addresses);
    // println!("ipv6_addresses: {:?}", ipv6_addresses);


    let (ipv4_addresses_string, ipv6_addresses_string) = match load_local_iplists_as_stringtype(
        uma_local_owner_user,
        &full_fingerprint_key_id_string,
        ) {
        Ok(lists) => lists,
        Err(e) => {
            debug_log!("Error loading IP lists as strings: {}", e);
            // Return "none" with default IP addresses
            return (false, "none".to_string(), 0, Ipv4Addr::UNSPECIFIED, Ipv6Addr::UNSPECIFIED);
        }
    };

    // println!("ipv4_addresses_string: {:?}", ipv4_addresses_string);
    // println!("ipv6_addresses_string: {:?}", ipv6_addresses_string);


    // 3. Try IPv6 addresses first
    if let Some(valid_ipv6) = find_valid_local_owner_ipv6_address(&ipv6_addresses) {
        // Get index
        debug_log!("Found valid ipv6 address: {:?}", valid_ipv6);

        if let Some(index) = get_index_byof_ip(
            &ipv4_addresses_string,
            &ipv6_addresses_string,
            &valid_ipv6.to_string()
        ) {
            return (true, "ipv6".to_string(), index, EMPTY_IPV_4, valid_ipv6);
        } else {
            debug_log!("Valid IPv6 address not found in the list.");
        }
    }

    // 4. If no valid IPv6, then try IPv4
    if let Some(valid_ipv4) = find_valid_local_owner_ipv4_address(&ipv4_addresses) {
        if let Some(index) = get_index_byof_ip(
            &ipv4_addresses_string,
            &ipv6_addresses_string,
            &valid_ipv4.to_string()
        ) {
            return (true, "ipv4".to_string(), index, valid_ipv4, EMPTY_IPV_6);
        } else {
            debug_log!("Valid IPv4 address not found in the list.");
        }
    }

    // 5. No valid IP found
    debug_log!("No valid IPv4 or IPv6 address found.");
    (false, "none".to_string(), 0, EMPTY_IPV_4, EMPTY_IPV_6) // Return a default value
}

/// Attempts to bind a UDP socket to each address in the provided list.
///
/// This function iterates through the `ip_addresses` slice. For each address, it attempts to bind a UDP
/// socket to the address on a designated test port (55555). If successful, the function immediately
/// returns the bindable address. If binding fails for all addresses in the list, the function returns `None`.
///
/// This function is used during initialization to determine a valid local IP address that UMA can use
/// for communication.
///
/// Args:
///     ip_addresses (&[Ipv6Addr]): A slice of IPv6 addresses to test.
///
/// Returns:
///     Option<Ipv6Addr>: The first IPv6 address in the list to which a UDP socket can be successfully bound, or `None` if no address is bindable.
///
fn find_valid_local_owner_ipv6_address(ipv6_addresses: &[Ipv6Addr]) -> Option<Ipv6Addr> {
    for &address in ipv6_addresses {
        if !address.is_loopback() && !address.is_unspecified() { // Use short-circuit &&
            let test_port = 55555;
            let socket_addr = SocketAddr::new(IpAddr::V6(address), test_port);
            if UdpSocket::bind(socket_addr).is_ok() { // Simplified check
                return Some(address);
            } else {
                debug_log!("Could not bind to {:?}. Trying next address...", socket_addr);
            }
        }
    }
    None
}

// Analogous function for IPv4
fn find_valid_local_owner_ipv4_address(ipv4_addresses: &[Ipv4Addr]) -> Option<Ipv4Addr> {
    // ... (Implementation is analogous to the IPv6 version)
    for &address in ipv4_addresses {
        if !address.is_loopback() && !address.is_unspecified() {
            let test_port = 55555;
            let socket_addr = SocketAddr::new(IpAddr::V4(address), test_port);
            if UdpSocket::bind(socket_addr).is_ok() {
                return Some(address);
            } else {
                debug_log!("Could not bind to {:?}. Trying next address...", socket_addr);
            }
        }
    }
    None
}

/// Securely extracts a GPG-encrypted clearsigned TOML file to a temporary location.
///
/// This function decrypts a GPG-encrypted file using the specified key fingerprint and
/// writes the decrypted content to a temporary file with restricted permissions. The
/// temporary file path is returned for further processing.
///
/// # Security
/// - Creates temporary files with restricted permissions (owner-only access)
/// - Uses unique filenames to prevent race conditions
/// - Ensures cross-platform compatibility for file permissions
/// - Caller is responsible for deleting the temporary file
///
/// # Arguments
/// * `gpg_encrypted_path` - Absolute path to the GPG-encrypted file
/// * `full_fingerprint_key_id_string` - Full GPG key fingerprint for decryption
/// * `owner` - Username for generating unique temp filename
///
/// # Returns
/// * `Result<PathBuf, ThisProjectError>` - Path to the temporary decrypted file
fn decrypt_gpgtoml_to_temp_file_secure(
    gpg_encrypted_path: &str,
    full_fingerprint_key_id_string: &str,
    owner: &str,
) -> Result<PathBuf, ThisProjectError> {
    // Verify the encrypted file exists
    if !Path::new(gpg_encrypted_path).exists() {
        return Err(ThisProjectError::IoError(
            io::Error::new(
                io::ErrorKind::NotFound,
                format!("GPG encrypted file not found: {}", gpg_encrypted_path)
            )
        ));
    }

    // Generate a unique temporary filename
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map_err(|e| ThisProjectError::IoError(
            io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e))
        ))?
        .as_nanos();

    let temp_filename = format!("gpg_decrypt_{}_{}.toml", owner, timestamp);
    let temp_dir = std::env::temp_dir();
    let temp_path = temp_dir.join(&temp_filename);

    // Decrypt the GPG file using the gpg command
    let output = std::process::Command::new("gpg")
        .arg("--quiet")
        .arg("--batch")
        .arg("--yes")
        .arg("--local-user")
        .arg(full_fingerprint_key_id_string)
        .arg("--decrypt")
        .arg(gpg_encrypted_path)
        .output()
        .map_err(|e| ThisProjectError::GpgError(
            format!("Failed to execute GPG decrypt command: {}", e)
        ))?;

    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        return Err(ThisProjectError::GpgError(
            format!("GPG decryption failed: {}", stderr)
        ));
    }

    // Create the temporary file with restricted permissions
    #[cfg(unix)]
    {
        use std::os::unix::fs::OpenOptionsExt;
        let mut file = std::fs::OpenOptions::new()
            .create(true)
            .write(true)
            .truncate(true)
            .mode(0o600) // Owner read/write only
            .open(&temp_path)
            .map_err(|e| ThisProjectError::IoError(
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("Failed to create secure temp file: {}", e)
                )
            ))?;

        file.write_all(&output.stdout)
            .map_err(|e| ThisProjectError::IoError(
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("Failed to write decrypted content: {}", e)
                )
            ))?;
    }

    #[cfg(not(unix))]
    {
        // On Windows, files in temp directory are typically user-restricted by default
        fs::write(&temp_path, &output.stdout)
            .map_err(|e| ThisProjectError::IoError(
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("Failed to write decrypted content: {}", e)
                )
            ))?;
    }

    Ok(temp_path)
}

/// Attempts to read IP addresses from a GPG-encrypted clearsigned TOML file.
///
/// This function tries to decrypt and read a .gpgtoml file if it exists. It handles
/// the entire process including decryption, reading, and cleanup of temporary files.
///
/// # Security
/// - Decrypts to a temporary file with restricted permissions
/// - Ensures temporary file cleanup even on error
/// - Validates clearsigned content after decryption
///
/// # Arguments
/// * `owner` - Username to locate the collaborator file
/// * `full_fingerprint_key_id_string` - GPG key fingerprint for decryption
///
/// # Returns
/// * `Result<Option<(Vec<String>, Vec<String>)>, ThisProjectError>` - IP addresses if successful,
///   None if .gpgtoml doesn't exist
fn try_read_iplists_from_gpg_encrypted_collaborator_file(
    owner: &str,
    full_fingerprint_key_id_string: &str,
) -> Result<Option<(Vec<String>, Vec<String>)>, ThisProjectError> {
    // Construct path to GPG encrypted file
    let gpg_relative_path = format!(
        "{}/{}__collaborator.gpgtoml",
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        owner,
    );

    // Convert to absolute path
    let gpg_absolute_path = match gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(&gpg_relative_path) {
        Ok(path) => path.to_string_lossy().to_string(),
        Err(_) => return Ok(None), // GPG file doesn't exist, return None
    };

    // Check if GPG encrypted file exists
    if !Path::new(&gpg_absolute_path).exists() {
        return Ok(None); // No GPG file, will fall back to regular clearsign
    }

    // Decrypt to temporary file
    let temp_path = match decrypt_gpgtoml_to_temp_file_secure(
        &gpg_absolute_path,
        full_fingerprint_key_id_string,
        owner
    ) {
        Ok(path) => path,
        Err(e) => {
            // Log the error but return None to allow fallback
            eprintln!("Warning: Failed to decrypt GPG file for {}: {}", owner, e);
            return Ok(None);
        }
    };

    // Ensure cleanup happens regardless of success or failure
    let cleanup_temp_file = |path: &Path| {
        if let Err(e) = fs::remove_file(path) {
            eprintln!("Warning: Failed to remove temporary file {}: {}", path.display(), e);
        }
    };

    // Read from the decrypted clearsigned TOML file
    let temp_path_str = temp_path.to_string_lossy().to_string();

    let ipv4_addresses = match read_str_array_field_clearsigntoml(&temp_path_str, "ipv4_addresses") {
        Ok(addrs) => addrs,
        Err(e) => {
            cleanup_temp_file(&temp_path);
            return Err(ThisProjectError::GpgError(
                format!("Failed to read IPv4 addresses from decrypted file: {}", e)
            ));
        }
    };

    let ipv6_addresses = match read_str_array_field_clearsigntoml(&temp_path_str, "ipv6_addresses") {
        Ok(addrs) => addrs,
        Err(e) => {
            cleanup_temp_file(&temp_path);
            return Err(ThisProjectError::GpgError(
                format!("Failed to read IPv6 addresses from decrypted file: {}", e)
            ));
        }
    };

    // Clean up temporary file
    cleanup_temp_file(&temp_path);

    Ok(Some((ipv4_addresses, ipv6_addresses)))
}

/// Loads the local user's IPv4 and IPv6 addresses from their collaborator TOML file.
///
/// This function reads the collaborator file for the given `owner` and extracts the
/// `ipv4_addresses` and `ipv6_addresses` fields as strings. It ensures security by requiring
/// clearsigned validation of the TOML file.
///
/// # Security
/// - REQUIRES cryptographically verified clearsigned TOML files
/// - Will REJECT files that fail signature verification
/// - Maintains the integrity of configuration data
/// - Attempts to use GPG-encrypted files first for enhanced security
/// - Falls back to regular clearsigned files if GPG version unavailable
///
/// # Process
/// 1. First attempts to read from a GPG-encrypted clearsigned file (.gpgtoml)
/// 2. If .gpgtoml doesn't exist or fails, falls back to regular clearsigned file (.toml)
/// 3. All files must be cryptographically verified (clearsigned)
///
/// # Arguments
/// * `owner` - The username of the local user
/// * `full_fingerprint_key_id_string` - GPG key fingerprint for decrypting .gpgtoml files
///
/// # Returns
/// * `Result<(Vec<String>, Vec<String>), ThisProjectError>` - A tuple containing the IPv4 and IPv6
///   address lists as strings, or a `ThisProjectError` if an error occurs
fn load_local_iplists_as_stringtype(
    owner: &str,
    full_fingerprint_key_id_string: &str,
) -> Result<(Vec<String>, Vec<String>), ThisProjectError> {
    // First, try to read from GPG encrypted file
    match try_read_iplists_from_gpg_encrypted_collaborator_file(owner, full_fingerprint_key_id_string)? {
        Some(ip_lists) => return Ok(ip_lists),
        None => {
            // GPG file doesn't exist or failed, proceed with regular clearsigned file
        }
    }

    // Fall back to regular clearsigned TOML file
    let relative_path = format!(
        "{}/{}__collaborator.toml",
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        owner,
    );

    // Convert to an absolute path based on executable location
    let absolute_path = match gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(&relative_path) {
        Ok(path) => path.to_string_lossy().to_string(),
        Err(e) => {
            return Err(ThisProjectError::IoError(
                std::io::Error::new(
                    std::io::ErrorKind::NotFound,
                    format!("Failed to resolve path for collaborator '{}': {}", owner, e)
                )
            ));
        }
    };

    // Check if the file exists
    if !std::path::Path::new(&absolute_path).exists() {
        return Err(ThisProjectError::IoError(
            std::io::Error::new(
                std::io::ErrorKind::NotFound,
                format!("No collaborator file found for '{}'. Checked both .gpgtoml and .toml", owner)
            )
        ));
    }

    // Read IP addresses as strings from the clearsigned TOML file
    // We use our secure verification function that will fail if verification fails
    let ipv4_addresses = match read_str_array_field_clearsigntoml(&absolute_path, "ipv4_addresses") {
        Ok(strings) => strings,
        Err(e) => {
            return Err(ThisProjectError::GpgError(
                format!("Failed to securely read IPv4 addresses from clearsigned file: {}", e)
            ));
        }
    };

    let ipv6_addresses = match read_str_array_field_clearsigntoml(&absolute_path, "ipv6_addresses") {
        Ok(strings) => strings,
        Err(e) => {
            return Err(ThisProjectError::GpgError(
                format!("Failed to securely read IPv6 addresses from clearsigned file: {}", e)
            ));
        }
    };

    // Return the string representations of the IP addresses directly
    Ok((ipv4_addresses, ipv6_addresses))
}

/// Loads the local user's IPv4 and IPv6 addresses from their collaborator TOML file.
///
/// This function reads the collaborator file for the given `owner` and extracts the
/// `ipv4_addresses` and `ipv6_addresses` fields. It ensures security by requiring
/// clearsigned validation of the TOML file.
///
/// # Security
/// - REQUIRES cryptographically verified clearsigned TOML files
/// - Will REJECT files that fail signature verification
/// - Will NOT fall back to reading unsigned files
/// - Attempts to use GPG-encrypted files first for enhanced security
/// - Falls back to regular clearsigned files if GPG version unavailable
///
/// # Process
/// 1. First attempts to read from a GPG-encrypted clearsigned file (.gpgtoml)
/// 2. If .gpgtoml doesn't exist or fails, falls back to regular clearsigned file (.toml)
/// 3. Parses string IP addresses into strongly-typed Ipv4Addr and Ipv6Addr
/// 4. Invalid IP addresses are logged as warnings but don't fail the operation
///
/// # Arguments
/// * `owner` - The username of the local user
/// * `full_fingerprint_key_id_string` - GPG key fingerprint for decrypting .gpgtoml files
///
/// # Returns
/// * `Result<(Vec<Ipv4Addr>, Vec<Ipv6Addr>), ThisProjectError>` - A tuple containing the IPv4 and IPv6
///   address lists, or a `ThisProjectError` if an error occurs
fn load_local_ip_lists_to_ipvec(
    owner: &str,
    full_fingerprint_key_id_string: &str,
) -> Result<(Vec<Ipv4Addr>, Vec<Ipv6Addr>), ThisProjectError> {
    // Get IP addresses as strings (handles GPG decryption and fallback internally)
    let (ipv4_strings, ipv6_strings) = load_local_iplists_as_stringtype(owner, full_fingerprint_key_id_string)?;

    // Parse the string values into IP address types
    let mut ipv4_addresses = Vec::new();
    for ip_str in ipv4_strings {
        match ip_str.parse::<Ipv4Addr>() {
            Ok(addr) => ipv4_addresses.push(addr),
            Err(e) => {
                println!("Warning: Invalid IPv4 address '{}' for user '{}': {}", ip_str, owner, e);
            }
        }
    }

    let mut ipv6_addresses = Vec::new();
    for ip_str in ipv6_strings {
        match ip_str.parse::<Ipv6Addr>() {
            Ok(addr) => ipv6_addresses.push(addr),
            Err(e) => {
                println!("Warning: Invalid IPv6 address '{}' for user '{}': {}", ip_str, owner, e);
            }
        }
    }

    // Return the collected IP addresses
    Ok((ipv4_addresses, ipv6_addresses))
}

/// This converts between the u8 sent by uma over network and usize that Rust uses for array-indices.
fn get_ip_by_index(
    index: u8,
    ipv4_list: &[Ipv4Addr],
    ipv6_list: &[Ipv6Addr],
) -> Option<(IpAddr, u8)> {
    if index < ipv4_list.len() as u8 {
        Some((IpAddr::V4(ipv4_list[index as usize]), index))
    } else if index < (ipv4_list.len() + ipv6_list.len()) as u8 {
        let ipv6_index = index - ipv4_list.len() as u8;
        Some((IpAddr::V6(ipv6_list[ipv6_index as usize]), index))
    } else {
        None
    }
}

/// Saves the combined network option index to a file.
/// @ /sync_data/network_option_index.txt
/// This function saves the given `combined_index` to "sync_data/{team_channel_name}/network_option_index.txt".
/// It creates the necessary directories if they don't exist and handles file I/O errors.
///
/// # Arguments
///
/// * `combined_index`: The combined network option index.
/// * `team_channel_name`: The name of the team channel.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`:  `Ok(())` on success, or an error if an I/O operation fails.
fn save_network_option_index_statefile(
    combined_index: u8,
) -> Result<(), ThisProjectError> {
    let mut file_path = PathBuf::from("sync_data");
    file_path.push("network_option_index.txt");

    if let Some(parent_dir) = file_path.parent() {
        create_dir_all(parent_dir)?;
    }

    let mut file = File::create(&file_path)?;
    write!(file, "{}", combined_index)?;
    Ok(())
}

/// Finds the the index in either along, not combined.
/// This converts between the u8 sent by uma over network and usize that Rust uses for array-indices.
///
/// This function searches for the given `ip_address`
/// each list alone.
/// It returns the index found.
///
/// # Arguments
///
/// * `ipv4_list`: The list of IPv4 addresses as strings.
/// * `ipv6_list`: The list of IPv6 addresses as strings.
/// * `ip_address`: The IP address to search for as a string.
///
/// # Returns
///
/// * `Option<u8>`:  The combined index, or `None` if the IP address is not found.
fn get_index_byof_ip(
    ipv4_list: &[String],
    ipv6_list: &[String],
    ip_address: &str,
) -> Option<u8> {
    let ip_addr: IpAddr = ip_address.parse().ok()?;

    debug_log!("get_index_byof_ip ipv4_list{:?}",ipv4_list);
    debug_log!("get_index_byof_ip ipv6_list{:?}",ipv6_list);
    debug_log!("get_index_byof_ip ip_address{:?}",ip_address);
    debug_log!("get_index_byof_ip ip_addr{:?}",ip_addr);

    let result = match ip_addr {
        IpAddr::V4(ipv4) => {
            ipv4_list.iter().position(|ip| ip == &ipv4.to_string()).map(|index| index as u8)
        }
        IpAddr::V6(ipv6) => {
            ipv6_list.iter().position(|ip| ip == &ipv6.to_string()).map(|index| index as u8)
        }
    };

    debug_log!("get_index_byof_ip result {:?}", result);

    result

}

/// Saves the local user's network band config data
/// to sync_data text files
/// As this is done only once during startup, retry is likely not needed
///
fn write_local_band__save_network_band__type_index(
    network_type: String,
    network_index: u8,
    this_ipv4: Ipv4Addr,
    this_ipv6: Ipv6Addr,
) -> Result<(), ThisProjectError> {
    // 1. Construct Path:
    let base_path = PathBuf::from("sync_data");

    // 2. Create Directory (if doesn't exist)
    create_dir_all(&base_path)?;

    // 3. Construct Absolute File Paths
    let type_path = base_path.join("network_type.txt");
    let index_path = base_path.join("network_index.txt");
    let ipv4_path = base_path.join("ipv4.txt");
    let ipv6_path = base_path.join("ipv6.txt");

    // 4. Write to Files (handling potential errors):
    let mut type_file = File::create(&type_path)?; // Note the & for borrowing
    writeln!(type_file, "{}", network_type)?;

    let mut index_file = File::create(&index_path)?;
    writeln!(index_file, "{}", network_index)?;

     // 4. Write to Files (handling potential errors):
     // working now?
     // TODO this is not working, it is writing "sync_data/ipv6.txt" as the file text
     // the path to the file should not be the file content...
    let mut ip4_file = File::create(&ipv4_path)?; // Note the & for borrowing
    writeln!(ip4_file, "{}", this_ipv4.to_string())?;  // Write IP string

    let mut ip6_file = File::create(&ipv6_path)?;
    writeln!(ip6_file, "{}", this_ipv6.to_string())?;  // Write IP string

    Ok(())
}

/// Saves the local user's network band config data
/// to sync_data text files
/// as this is done only once during startup, retry is likely not needed
///
fn write_save_rc_bandnetwork_type_index(
    remote_collaborator_name: String,
    team_channel_name: String,
    network_type: String,
    network_index: u8,
    this_ipv4: Ipv4Addr,
    this_ipv6: Ipv6Addr,
) -> Result<(), ThisProjectError> {
    /* ?
    Wait random time in A to B range, N times
    FILE_READWRITE_N_RETRIES
    FILE_READWRITE_RETRY_SEC_PAUSE_MIN
    FILE_READWRITE_RETRY_SEC_PAUSE_max
    */


    debug_log("write_save_rc_bandnetwork_type_index(), starting");

    // 1. Construct Path:
    let mut base_path = PathBuf::from("sync_data");
    base_path.push(team_channel_name);
    base_path.push("network_band");
    base_path.push(remote_collaborator_name);

    // Create directory structure if it doesn't exist
    create_dir_all(&base_path)?;

    debug_log!("write_save_rc_bandnetwork_type_index(), base_path {:?}", base_path);

    // 3. Construct Absolute File Paths
    let type_path = base_path.join("network_type.txt");
    let index_path = base_path.join("network_index.txt");
    let ipv4_path = base_path.join("ipv4.txt");
    let ipv6_path = base_path.join("ipv6.txt");

    debug_log!("write_save_rc_bandnetwork_type_index(), type_path {:?}", type_path);
    debug_log!("write_save_rc_bandnetwork_type_index(), index_path {:?}", index_path);
    debug_log!("write_save_rc_bandnetwork_type_index(), ipv4_path {:?}", ipv4_path);
    debug_log!("write_save_rc_bandnetwork_type_index(), ipv6_path {:?}", ipv6_path);

    // 4.1 Write to Files (handling potential errors):
    let mut type_file = File::create(&type_path)?; // Note the & for borrowing
    writeln!(type_file, "{}", network_type)?;

    debug_log!("write_save_rc_bandnetwork_type_index(), type_file {:?}", type_file);

    let mut index_file = File::create(&index_path)?;
    writeln!(index_file, "{}", network_index)?;

    debug_log!("write_save_rc_bandnetwork_type_index(), index_file {:?}", index_file);

    // 4.2 Write to Files (handling potential errors):
    let mut ip4_file = File::create(&ipv4_path)?; // Note the & for borrowing
    writeln!(ip4_file, "{}", this_ipv4.to_string())?;  // Write IP string
    debug_log!("write_save_rc_bandnetwork_type_index(), ip4_file {:?}", ip4_file);

    let mut ip6_file = File::create(&ipv6_path)?;
    writeln!(ip6_file, "{}", this_ipv6.to_string())?;  // Write IP string
    debug_log!("write_save_rc_bandnetwork_type_index(), ip6_file {:?}", ip6_file);

    Ok(())
}

// TODO: maybe use a parameter in team-channel instead of hard-coding ~10 sec
/// hlod_udp_handshake__rc_network_type_rc_ip_addr(): returns (rc_network_type, rc_ip_addr) as (String, String) loop until satisfied:
/// every 10-60 sec: (lite-weight is the goal, not expensive-brute-force)
/// 1. check for hault-uma (if not more often check somehow)
/// 2. check for received ready-signal in /sync_data/ (if so, exit handshake) see below: with this you can get the rc_ip-data read_rc_bandnetwork_type_index()
/// 3. if not the above options: send a ready signal (iterating) to each listed collaborator ip
///   ipv4 and ipv6 (until (step 2) there has been logged a ready-signal from one of them)
///
fn hlod_udp_handshake__rc_network_type_rc_ip_addr(
    local_owner_desk_setup_data: &ForLocalOwnerDeskThread,
    band_local_network_type: &str,
    band_local_user_ipv4_address: &Ipv4Addr,
    band_local_user_ipv6_address: &Ipv6Addr,
    band_local_network_index: u8,
) -> Result<(String, String), ThisProjectError> {
    debug_log("inHLOD: Start hlod_udp_handshake__rc_network_type_rc_ip_addr()");

    // --- 1. Extract Data from Setup Data ---
    let local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip = local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip;


    // --- Select IP Address and Create SocketAddr for Local Listening ---
    let listen_ip_addr = match band_local_network_type {
        "ipv6" => IpAddr::V6(*band_local_user_ipv6_address),
        "ipv4" => IpAddr::V4(*band_local_user_ipv4_address),
        _ => return Err(ThisProjectError::NetworkError(
            "Invalid network type in hlod_udp_handshake__rc_network_type_rc_ip_addr".into()
            )
        ),
    };

    let local_listen_addr = SocketAddr::new(
        listen_ip_addr,
        local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
    );

    // --- Prepare ReadySignal ---
    let timestamp_for_rt = match get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl(
        &local_owner_desk_setup_data.remote_collaborator_name,
    ) {
        Ok(timestamp) => timestamp,
        Err(e) => {
            debug_log!("hlod_udp_handshake__rc_network_type_rc_ip_addr(): Error getting timestamp: {}", e);
            0
        }
    };
    debug_log!(
        "hlod_udp_handshake: .rt, timestamp_for_rt, from get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl -> {:?}",
        timestamp_for_rt,
    );


    // setup: Get Team Channel Name
    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

    // setup: Construct Path to check for a ready signal received from the rc (remote collaborator)
    let mut got_signal_check_base_path = PathBuf::from("sync_data");
    got_signal_check_base_path.push(team_channel_name.clone());
    got_signal_check_base_path.push("network_band");
    got_signal_check_base_path.push(&local_owner_desk_setup_data.remote_collaborator_name);

    loop { // hlod_udp_handshake__rc_network_type_rc_ip_addr() Main loop starts here
        debug_log("hlod_udp_handshake__rc_network_type_rc_ip_addr() main loop (re)starting from the top...");

        // 1. Check for Halt Signal and Team Channel Name (as before)
        if should_halt_uma() { // 1. check for halt-uma
            return Err(ThisProjectError::NetworkError("UMA halt signal received (not an error)".into())); // or log the exit?
        }

        // --- 2. Check for Received Ready Signal ---
        // hlod_udp_handshake__rc_network_type_rc_ip_addr() Main loop starts here
        if got_signal_check_base_path.exists() {
            // The path exists...

            // --- The purpose of this block is to use existing band data if it exists in sync_data
            if let Ok(Some((rc_network_type, _, rc_ip_addr_string))) = read_rc_bandnetwork_type_index(
                &local_owner_desk_setup_data.remote_collaborator_name, // Correct collaborator name
                &team_channel_name, // Use correctly retrieved team channel name
            ) {
                debug_log!(
                    "hlod_udp_handshake__rc_network_type_rc_ip_addr(): Ready signal information found in sync_data for {}. rc_network_type: {}, rc_ip: {:?}",
                    local_owner_desk_setup_data.remote_collaborator_name,
                    rc_network_type,
                    rc_ip_addr_string,
                );

                return Ok((rc_network_type, rc_ip_addr_string)); // Return address, breaking loop
            } else {
                // ... (No ready signal yet, continue sending your own)
                debug_log("hlod_udp_handshake path but no files");
            }
        } else {
                // ... (No ready signal yet, continue sending your own)
                debug_log("hlod_udp_handshake no path yet");
        } // End of if got_signal_check_base_path.exists()

        // --- 3. Send Ready Signal ---
        // ... [Iterate remote IP addresses *only* if no ReadySignal received]

        // Send to each IPv6 address in rc_ipv6_list
        debug_log("hlod_udp_handshake__rc_network_type_rc_ip_addr() Sending Handshake ready signals!");
        for ipv6_addr_string in &local_owner_desk_setup_data.remote_collaborator_ipv6_addr_list {
            send_ready_signal(
                &local_owner_desk_setup_data.local_user_salt_list,
                "ipv6".to_string(),                            // Correct: Always "ipv6" here
                ipv6_addr_string.to_string(),                  //Correct: Use remote IPv6 address
                local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,  // Use provided port
                timestamp_for_rt,                              // Use calculated timestamp
                band_local_network_type,                       // band_local_network_type
                band_local_network_index,                      // Use band index
            )?;
            debug_log!(
                "ReadySignal sent to IPv6: {}:{}",
                ipv6_addr_string,
                local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
            );
        }

        // Send to each IPv4 address in rc_ipv4_list
        for ipv4_addr_string in &local_owner_desk_setup_data.remote_collaborator_ipv4_addr_list {  // Iterate IPv4 list
            send_ready_signal(
                &local_owner_desk_setup_data.local_user_salt_list,
                "ipv4".to_string(),                           // Correct: Always "ipv4" here
                ipv4_addr_string.to_string(),                   // Correct: Use remote IPv4 address
                local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip, // Use port number
                timestamp_for_rt,                           // Use calculated timestamp // Correct: Consistent order
                band_local_network_type,
                band_local_network_index,                           // Use consistent type for band index. // Correct: Consistent order
            )?;
            debug_log!(
                "ReadySignal sent to IPv4: {}:{}",
                ipv4_addr_string,
                local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
            );
        }

        // 1.1 Wait (and check for exit Uma)  this waits and checks N times: for i in 0..N {
        for i in 0..5 {
            // break for loop ?
            if should_halt_uma() {
                debug_log!("hold_udp_handshake: should_halt_uma(), exiting Uma in handle_local_owner_desk()");
                break; // break this for-loop
            }
            thread::sleep(Duration::from_secs(3));
        }
        // Then break out of this function main loop
        if should_halt_uma() {
            debug_log!("hold_udp_handshake: should_halt_uma(). Exiting hlod_upd_handshake()");
            break Ok((Default::default(), Default::default()));
        }

    } // loop end
}


// HEREHERE todo TODO fix this, not checking for likely duely noneexistant files
/// Reads the remote collaborator's band data (network type, index, IP address). -> (network_type, network_index, rc_ip)
///
/// This function reads the remote collaborator's network band information, which was previously
/// saved by the `write_save_rc_bandnetwork_type_index` function. The data is read from files
/// within the following directory structure:
/// sync_data/{team_channel_name}/network_band/{remote_collaborator_name}/
///
/// It returns a tuple containing the remote collaborator's network type (e.g., "ipv4" or "ipv6"),
/// network index (as a u8), and IP address (as an IpAddr).
///
/// # Arguments
///
/// * `remote_collaborator_name`: The remote collaborator's username.
/// * `team_channel_name`: The name of the active team channel.
///
/// # Returns
///
/// * `Result<(String, u8, IpAddr), ThisProjectError>`: A tuple containing the network type,
///   network index, and IP address on success, or a `ThisProjectError` if reading or parsing fails.
///
fn read_rc_bandnetwork_type_index(
    remote_collaborator_name: &str,
    team_channel_name: &str,
) -> Result<Option<(String, u8, String)>, ThisProjectError> { // Returns Option

    let mut base_path = PathBuf::from("sync_data");
    base_path.push(team_channel_name);
    base_path.push("network_band");
    base_path.push(remote_collaborator_name);

    // Check if the directory for the collaborator's band data exists
    if !base_path.exists() {
        debug_log!("read_rc_bandnetwork_type_index: Directory for collaborator '{}' not found.  No ready signal received yet.", remote_collaborator_name);
        return Ok(None); // Return None, not an error
    }


    let network_type_path = base_path.join("network_type.txt");
    let network_index_path = base_path.join("network_index.txt");
    let ipv4_path = base_path.join("ipv4.txt");
    let ipv6_path = base_path.join("ipv6.txt");

    // Use a match statement to handle potential file not found errors
    let network_type = match fs::read_to_string(&network_type_path) {
        Ok(content) => content.trim().to_string(),
        Err(e) if e.kind() == ErrorKind::NotFound => {
            debug_log!("read_rc_bandnetwork_type_index: network_type.txt not found for collaborator '{}'.", remote_collaborator_name);
            return Ok(None); // Return None
        }
        Err(e) => return Err(ThisProjectError::IoError(e)), // Return other IO errors
    };

    let network_index: u8 = match fs::read_to_string(&network_index_path) {  //Similar handling
        Ok(content) => content.trim().parse().map_err(ThisProjectError::ParseIntError)?,
        Err(e) if e.kind() == ErrorKind::NotFound => {
             debug_log!("read_rc_bandnetwork_type_index:  network_index.txt not found for collaborator '{}'.", remote_collaborator_name);
            return Ok(None);
        }
        Err(e) => return Err(ThisProjectError::IoError(e)),
    };


    let ip_address_string = match network_type.as_str() { // ... (as before)
        "ipv4" => match fs::read_to_string(&ipv4_path) { //Handle potential file not found error here as well:
                Ok(s) => s.trim().to_string(),
                Err(e) if e.kind() == ErrorKind::NotFound => {
                    debug_log!("read_rc_bandnetwork_type_index: ipv4.txt not found for collaborator '{}'.", remote_collaborator_name);
                    return Ok(None);
                }
                Err(e) => return Err(ThisProjectError::IoError(e)),
            },
        "ipv6" => match fs::read_to_string(&ipv6_path) {  // And here.
                Ok(s) => s.trim().to_string(),
                Err(e) if e.kind() == ErrorKind::NotFound => {
                     debug_log!("read_rc_bandnetwork_type_index: ipv6.txt not found for collaborator '{}'.", remote_collaborator_name);
                    return Ok(None);
                }
                Err(e) => return Err(ThisProjectError::IoError(e)),
            },
        _ => return Err(ThisProjectError::NetworkError("Invalid network type".into())),
    };

    Ok(Some((network_type, network_index, ip_address_string)))  // Wrap the result in Some()
}

/// Reads the local user's network band configuration data from files in the sync_data directory.
/// Uses absolute paths and handles file I/O and parsing errors.
///
/// Returns:
///     Result<(String, u8, Ipv4Addr, Ipv6Addr), ThisProjectError>: A tuple containing the network type, index, IPv4 address, and IPv6 address on success, or a ThisProjectError on failure.
fn read_band__network_config_type_index_specs() -> Result<(String, u8, Ipv4Addr, Ipv6Addr), ThisProjectError> {
    // 1. Construct Absolute Paths (get current absolute working directory)
    let mut base_path = std::env::current_dir()?; // Start with absolute current directory. Handle potential errors.
    base_path.push("sync_data");
    let type_path = base_path.join("network_type.txt");
    let index_path = base_path.join("network_index.txt");
    let ipv4_path = base_path.join("ipv4.txt");
    let ipv6_path = base_path.join("ipv6.txt");

    // 2. Read Values From Files
    let network_type_result = read_to_string(&type_path);
    let network_index_result = read_to_string(&index_path);
    let ipv4_result = read_to_string(&ipv4_path);
    let ipv6_result = read_to_string(&ipv6_path);

    // 3. Handle File Reading Errors: Return early if *any* file read fails
    let network_type = network_type_result?.trim().to_string();
    let network_index_str = network_index_result?.trim().to_string();
    let ipv4_str = ipv4_result?.trim().to_string();
    let ipv6_str = ipv6_result?.trim().to_string();


    // 4. Parse network_index (u8), Handling Errors
    let network_index: u8 = network_index_str
        .parse()
        .map_err(|e| ThisProjectError::InvalidData(format!("Invalid network index: {}", e)))?;


    // 5. Parse IPv4 and IPv6, Handling Errors
    let ipv4: Ipv4Addr = ipv4_str
        .parse()
        .map_err(|e| ThisProjectError::InvalidData(format!("Invalid IPv4 address: {}", e)))?;
    let ipv6: Ipv6Addr = ipv6_str
        .parse()
        .map_err(|e| ThisProjectError::InvalidData(format!("Invalid IPv6 address: {}", e)))?;


    Ok((network_type, network_index, ipv4, ipv6))
}


enum IpAddrKind { V4, V6 }

// impl From<toml::de::Error> for ThisProjectError {
//     fn from(err: toml::de::Error) -> ThisProjectError {
//         ThisProjectError::TomlDeserializationError(err)
//     }
// }


/*
Seri_Deseri Serialize To Start
*/



/// Serialize struct to .toml file
/// Serializes a `CollaboratorTomlData` struct into a TOML-formatted string.
///
/// This function takes a `CollaboratorTomlData` struct and manually constructs
/// a TOML-formatted string representation of the data.
///
/// # No `serde` Crate
///
/// This function implements TOML serialization *without* using the `serde`
/// crate. It manually formats each field of the `CollaboratorTomlData` struct
/// into the TOML syntax.
///
/// This approach is taken to avoid the dependency on the `serde` crate
/// while still providing a way to generate TOML output.
///
/// # TOML Format
///
/// The function generates a TOML string with the following structure:
///
/// ```toml
/// user_name = "value"
/// user_salt_list = [
///     "0xhex_value",
///     "0xhex_value",
///     ...
/// ]
/// ipv4_addresses = [
///     "ip_address",
///     "ip_address",
///     ...
/// ]
/// ipv6_addresses = [
///     "ip_address",
///     "ip_address",
///     ...
/// ]
/// gpg_key_public = "value"
/// sync_interval = value
/// updated_at_timestamp = value
/// ```
///
/// # Helper Function
///
/// The `serialize_ip_addresses` helper function is used to format the
/// `ipv4_addresses` and `ipv6_addresses` fields into TOML array syntax.
///
/// # Parameters
///
/// - `collaborator`: A reference to the `CollaboratorTomlData` struct to be serialized.
///
/// # Returns
///
/// Returns a `Result` containing:
/// - `Ok`: The TOML-formatted string representation of the `CollaboratorTomlData`.
/// - `Err`: A `ThisProjectError` if an error occurs during serialization (although
///           errors are unlikely in this simplified implementation).
///
/// # use with
/// // Serialize the collaborator data to a TOML string
/// match serialize_collaborator_to_toml(&collaborator) {
///     Ok(toml_string) => {
///         println!("Serialized TOML:\n{}", toml_string);
///
///         // Write the TOML string to a file (example file path)
///         match write_toml_to_file("collaborator_data.toml", &toml_string) {
///             Ok(_) => println!("TOML data written to file successfully."),
///             Err(e) => println!("Error writing to file: {}", e),
///         }
///     }
///     Err(e) => println!("Error serializing to TOML: {}", e),
/// }
fn serialize_collaborator_to_toml(collaborator: &CollaboratorTomlData) -> Result<String, ThisProjectError> {
    let mut toml_string = String::new();

    // Add user_name
    toml_string.push_str(&format!("user_name = \"{}\"\n", collaborator.user_name));

    // Add user_salt_list
    toml_string.push_str("user_salt_list = [\n");
    for salt in &collaborator.user_salt_list {
        toml_string.push_str(&format!("    \"0x{:x}\",\n", salt));
    }
    toml_string.push_str("]\n");

    // Add ipv4_addresses
    serialize_ip_addresses(&mut toml_string, "ipv4_addresses", &collaborator.ipv4_addresses)?;

    // Add ipv6_addresses
    serialize_ip_addresses(&mut toml_string, "ipv6_addresses", &collaborator.ipv6_addresses)?;

    // Add gpg_publickey_id
    toml_string.push_str(&format!("gpg_publickey_id = \"{}\"\n", collaborator.gpg_publickey_id));

    // Add gpg_key_public
    toml_string.push_str(&format!("gpg_key_public = \"\"\"{}\"\"\"\n", collaborator.gpg_key_public));

    // Add sync_interval
    toml_string.push_str(&format!("sync_interval = {}\n", collaborator.sync_interval));

    // Add updated_at_timestamp
    toml_string.push_str(&format!("updated_at_timestamp = {}\n", collaborator.updated_at_timestamp));

    Ok(toml_string)
}

// Helper function to serialize IP addresses to TOML array format
fn serialize_ip_addresses<T: std::fmt::Display>(
    toml_string: &mut String,
    key: &str,
    addresses: &Option<Vec<T>>
) -> Result<(), ThisProjectError> {
    if let Some(addr_vec) = addresses {
        toml_string.push_str(&format!("{} = [\n", key));
        for addr in addr_vec {
            toml_string.push_str(&format!("    \"{}\",\n", addr));
        }
        toml_string.push_str("]\n");
    }
    Ok(()) // Return Ok(()) if the addresses field is None
}

// Function to write a TOML string to a file
// Function to write a TOML string to a file
fn write_toml_to_file(file_path: &str, toml_string: &str) -> Result<(), ThisProjectError> {
    /* ?
    Wait random time in A to B range, N times
    FILE_READWRITE_N_RETRIES
    FILE_READWRITE_RETRY_SEC_PAUSE_MIN
    FILE_READWRITE_RETRY_SEC_PAUSE_max
    */

    // Attempt to create the file.
    let mut file = match File::create(file_path) {
        Ok(file) => file,
        Err(e) => return Err(ThisProjectError::IoError(e)),
    };

    // Attempt to write to the file.
    if let Err(e) = file.write_all(toml_string.as_bytes()) {
        return Err(ThisProjectError::IoError(e));
    }

    // Everything successful!
    Ok(())
}
/*
Seri_Deseri Serialize To TOml File End
*/

/*
Seri_Deseri Deserialize From .toml Start
*/

/// TODO: warning - any error should delete the temp file
/// Reads and parses collaborator setup data from a clearsigned TOML file.
///
/// This function securely reads collaborator data from a clearsigned TOML file by:
/// 1. Extracting the GPG public key from the file itself
/// 2. Verifying the clearsign signature to ensure integrity and authenticity
/// 3. If verification succeeds, parsing the TOML data within the clearsigned content
/// 4. Extracting all required fields into a CollaboratorTomlData structure
///
/// # Security Model
/// This function implements a self-verifying approach where each collaborator file
/// contains its own GPG public key and is clearsigned with the corresponding private key.
/// This ensures that:
/// - The data has not been tampered with (integrity)
/// - The data comes from the claimed source (authenticity)
/// - No external key management is required for basic verification
///
/// # File Format Expected
/// The input file should be a clearsigned TOML file with the following structure:
/// ```
/// -----BEGIN PGP SIGNED MESSAGE-----
/// Hash: SHA256
///
/// user_name = "alice"
/// user_salt_list = ["0x11111111111111111111111111111111", "0x11111111111111111111111111111112"]
/// ipv4_addresses = ["192.168.1.1", "10.0.0.1"]
/// ipv6_addresses = ["fe80::1", "::1"]
/// gpg_publickey_id = "3AA5C34371567BD2"
/// gpg_key_public = """-----BEGIN PGP PUBLIC KEY BLOCK-----
/// ...
/// -----END PGP PUBLIC KEY BLOCK-----"""
/// sync_interval = 60
/// updated_at_timestamp = 1728307160
/// -----BEGIN PGP SIGNATURE-----
/// ...
/// -----END PGP SIGNATURE-----
/// ```
///
/// # Arguments
/// * `collaborator_name` - The username/identifier of the collaborator whose data to read
///
/// # Returns
/// * `Ok(CollaboratorTomlData)` - Successfully parsed and verified collaborator data
/// * `Err(ThisProjectError)` - If verification fails, file is missing, or data is malformed
///
/// # Errors
/// This function may return errors for several reasons:
/// * File not found or unreadable
/// * GPG signature verification failure
/// * Missing or invalid GPG public key in the file
/// * Missing required TOML fields
/// * Invalid data formats (e.g., malformed IP addresses, invalid timestamps)
///
/// # Example Usage
/// ```rust
/// match read_one_collaborator_addressbook_toml("alice") {
///     Ok(collaborator_data) => {
///         println!("Successfully loaded data for: {}", collaborator_data.user_name);
///         println!("IP addresses: {:?}", collaborator_data.ipv4_addresses);
///     },
///     Err(e) => {
///         eprintln!("Failed to load collaborator data: {}", e);
///     }
/// }
/// ```
///
/// # Implementation Notes
/// - Uses line-by-line reading instead of loading entire file into memory
/// - Does not use any third-party crates like `serde` or `toml`
/// - Implements manual TOML field extraction for security and control
/// - Performs cryptographic verification before any data extraction
/// - Handles both IPv4 and IPv6 address parsing with proper error handling
///
/// # Related Functions
/// This function uses several helper functions from the clearsign_toml_module:
/// - `read_singleline_string_from_clearsigntoml()` - For single-line string fields
/// - `read_stringarray_field_clearsigntoml()` - For string arrays
/// - `read_u64_field_from_toml()` - For numeric fields (after verification)
/// This function loads collaborator data from either a clearsigned TOML file (.toml)
/// or a GPG-encrypted clearsigned TOML file (.gpgtoml). It ensures data integrity
/// through cryptographic verification and handles both file formats transparently.
///
/// # File Format Support
/// - **Clearsigned TOML (.toml)**: Plain text TOML file with GPG clearsign signature
/// - **GPG Encrypted TOML (.gpgtoml)**: Encrypted version of the clearsigned TOML
///
/// # File Selection Logic
/// 1. Checks for both `{collaborator_name}__collaborator.toml` and `.gpgtoml` files
/// 2. If BOTH exist: prefers the `.toml` file (no decryption needed)
/// 3. If only `.gpgtoml` exists: decrypts it to a temporary file for processing
/// 4. If only `.toml` exists: uses it directly
/// 5. If neither exists: returns an error
///
/// # GPG Decryption Process (for .gpgtoml files)
/// - Uses the specified GPG key from the local keyring for decryption
/// - Creates a secure temporary file with restricted permissions (0600 on Unix)
/// - Decrypts the content to the temporary file
/// - Processes the decrypted clearsigned TOML
/// - Automatically cleans up the temporary file after processing
///
/// # Security Features
/// - All files must be cryptographically clearsigned (signature verification)
/// - Temporary decrypted files have restricted permissions
/// - Temporary files are always cleaned up, even on error paths
/// - Original `.gpgtoml` files are never modified or deleted
///
/// # Error Handling
/// - If GPG decryption fails (wrong key, corrupted file, etc.):
///   - Displays detailed error message to the user
///   - Waits for user to press Enter (for visibility in multi-threaded context)
///   - Returns an error to the caller
/// - This approach ensures users see decryption failures without crashing the application
///
/// # Arguments
/// * `collaborator_name` - The username of the collaborator whose data to read
/// * `full_fingerprint_key_id_string` - The GPG key fingerprint to use for decrypting
///   .gpgtoml files. This must be a private key available in the local keyring.
///
/// # Returns
/// * `Ok(CollaboratorTomlData)` - Successfully parsed collaborator configuration
/// * `Err(ThisProjectError)` - Various errors:
///   - File not found (neither .toml nor .gpgtoml exists)
///   - GPG decryption failure
///   - Clearsign verification failure
///   - TOML parsing errors
///   - IO errors
///
/// # Example
/// ```no_run
/// let collaborator_data = read_one_collaborator_addressbook_toml(
///     "alice",
///     "1234567890ABCDEF1234567890ABCDEF12345678"
/// )?;
/// ```
///
/// # Debug Logging
/// - Logs which file type was selected (.toml vs .gpgtoml)
/// - Logs file paths being processed
/// - Logs GPG operations and any errors encountered
fn read_one_collaborator_addressbook_toml(
    collaborator_name: &str,
    full_fingerprint_key_id_string: &str,
    ) -> Result<CollaboratorTomlData, ThisProjectError> {
    debug_log("Starting ROCST: read_one_collaborator_addressbook_toml()");

    // 1. File Paths
    // Check for both .toml and .gpgtoml files
    let toml_relative = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
        .join(format!("{}__collaborator.toml", collaborator_name));
    let gpgtoml_relative = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
        .join(format!("{}__collaborator.gpgtoml", collaborator_name));

    // Get absolute paths
    let toml_abs = make_input_path_name_abs_executabledirectoryrelative_nocheck(&toml_relative)?;
    let gpgtoml_abs = make_input_path_name_abs_executabledirectoryrelative_nocheck(&gpgtoml_relative)?;

    // Determine which file to use and prepare the path
    let (abs_file_path, temp_file_to_cleanup) = if toml_abs.exists() {
        // Prefer .toml if it exists
        debug_log!("ROCST: Using clearsigned .toml file for collaborator '{}'", collaborator_name);
        (toml_abs, None)
    } else if gpgtoml_abs.exists() {
        // Use .gpgtoml and decrypt it
        debug_log!("ROCST: Using GPG encrypted .gpgtoml file for collaborator '{}'", collaborator_name);

        // Create secure temp file for decrypted content
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| ThisProjectError::IoError(
                std::io::Error::new(std::io::ErrorKind::Other, format!("Time error: {}", e))
            ))?
            .as_nanos();

        let temp_filename = format!("decrypt_collab_{}_{}.toml", collaborator_name, timestamp);
        let temp_path = std::env::temp_dir().join(&temp_filename);

        // Decrypt the .gpgtoml file
        let output = std::process::Command::new("gpg")
            .arg("--quiet")
            .arg("--batch")
            .arg("--yes")
            .arg("--local-user")
            .arg(full_fingerprint_key_id_string)
            .arg("--decrypt")
            .arg("--output")
            .arg(&temp_path)
            .arg(&gpgtoml_abs)
            .output()
            .map_err(|e| {
                let error_msg = format!("Failed to execute GPG decrypt for collaborator '{}': {}", collaborator_name, e);
                eprintln!("\nERROR: {}", error_msg);
                eprintln!("Press Enter to continue...");
                let _ = std::io::stdin().read_line(&mut String::new());
                ThisProjectError::GpgError(error_msg)
            })?;

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            let error_msg = format!("GPG decryption failed for collaborator '{}': {}", collaborator_name, stderr);
            eprintln!("\nERROR: {}", error_msg);
            eprintln!("Press Enter to continue...");
            let _ = std::io::stdin().read_line(&mut String::new());
            return Err(ThisProjectError::GpgError(error_msg));
        }

        // Set restricted permissions on temp file (Unix only)
        #[cfg(unix)]
        {
            use std::os::unix::fs::PermissionsExt;
            std::fs::set_permissions(&temp_path, std::fs::Permissions::from_mode(0o600))
                .map_err(|e| ThisProjectError::IoError(
                    std::io::Error::new(std::io::ErrorKind::Other,
                        format!("Failed to set temp file permissions: {}", e))
                ))?;
        }

        (temp_path.clone(), Some(temp_path))
    } else {
        return Err(ThisProjectError::IoError(
            std::io::Error::new(
                std::io::ErrorKind::NotFound,
                format!("No collaborator file found for '{}' (checked both .toml and .gpgtoml)", collaborator_name)
            )
        ));
    };

    debug_log!("ROCST: read_one_collaborator_addressbook_toml(), abs_file_path -> {:?}", abs_file_path);


    /////


    debug_log!("ROCST: read_one_collaborator_addressbook_toml(), abs_file_path (executable-relative) -> {:?}", abs_file_path);

    // Convert path to string for clearsign functions
    let file_path_str = abs_file_path.to_str()
        .ok_or_else(|| ThisProjectError::TomlVanillaDeserialStrError(
            "Failed to convert file path to string".to_string()
        ))?;

    // 2. Read and verify all fields from the clearsigned TOML file
    // Each read operation includes signature verification

    // Extract user_name
    let user_name = read_singleline_string_from_clearsigntoml(file_path_str, "user_name")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read user_name: {}", e)
        ))?;

    // Extract gpg_publickey_id
    let gpg_publickey_id = read_singleline_string_from_clearsigntoml(file_path_str, "gpg_publickey_id")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read gpg_publickey_id: {}", e)
        ))?;

    // Extract gpg_key_public
    let gpg_key_public = read_multiline_string_from_clearsigntoml(file_path_str, "gpg_key_public")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read gpg_key_public: {}", e)
        ))?;

    // Extract user_salt_list (array of hex strings that need to be converted to u128)
    let salt_strings = read_str_array_field_clearsigntoml(file_path_str, "user_salt_list")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read user_salt_list: {}", e)
        ))?;

    // Convert hex strings to u128 values
    let user_salt_list: Result<Vec<u128>, ThisProjectError> = salt_strings
        .iter()
        .map(|hex_str| {
            // Remove "0x" prefix if present
            let clean_hex = hex_str.trim_start_matches("0x");
            u128::from_str_radix(clean_hex, 16)
                .map_err(|e| ThisProjectError::ParseIntError(e))
        })
        .collect();
    let user_salt_list = user_salt_list?;

    // Extract IPv4 addresses (optional)
    let ipv4_addresses = match read_str_array_field_clearsigntoml(file_path_str, "ipv4_addresses") {
        Ok(addr_strings) => {
            let parsed_addrs: Result<Vec<std::net::Ipv4Addr>, ThisProjectError> = addr_strings
                .iter()
                .map(|addr_str| {
                    addr_str.parse::<std::net::Ipv4Addr>()
                        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
                            format!("Invalid IPv4 address '{}': {}", addr_str, e)
                        ))
                })
                .collect();
            Some(parsed_addrs?)
        },
        Err(_) => None, // Field is optional
    };

    // Extract IPv6 addresses (optional)
    let ipv6_addresses = match read_str_array_field_clearsigntoml(file_path_str, "ipv6_addresses") {
        Ok(addr_strings) => {
            let parsed_addrs: Result<Vec<std::net::Ipv6Addr>, ThisProjectError> = addr_strings
                .iter()
                .map(|addr_str| {
                    addr_str.parse::<std::net::Ipv6Addr>()
                        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
                            format!("Invalid IPv6 address '{}': {}", addr_str, e)
                        ))
                })
                .collect();
            Some(parsed_addrs?)
        },
        Err(_) => None, // Field is optional
    };

    // For numeric fields, we need to read them as strings first (since they're in a clearsigned file)
    // then parse them manually

    // Extract sync_interval
    let sync_interval_str = read_singleline_string_from_clearsigntoml(file_path_str, "sync_interval")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read sync_interval: {}", e)
        ))?;
    let sync_interval = sync_interval_str.parse::<u64>()
        .map_err(|e| ThisProjectError::ParseIntError(e))?;

    // Extract updated_at_timestamp
    let timestamp_str = read_singleline_string_from_clearsigntoml(file_path_str, "updated_at_timestamp")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read updated_at_timestamp: {}", e)
        ))?;
    let updated_at_timestamp = timestamp_str.parse::<u64>()
        .map_err(|e| ThisProjectError::ParseIntError(e))?;

    // remove temp file
    // At the very end of the function, clean up temp file if we created one
    if let Some(temp_path) = temp_file_to_cleanup {
        if let Err(e) = std::fs::remove_file(&temp_path) {
            eprintln!("Warning: Failed to remove temporary decrypted file {}: {}", temp_path.display(), e);
        }
    }

    // 3. Construct and return the CollaboratorTomlData structure
    Ok(CollaboratorTomlData {
        user_name,
        user_salt_list,
        ipv4_addresses,
        ipv6_addresses,
        gpg_publickey_id,
        gpg_key_public,
        sync_interval,
        updated_at_timestamp,
    })
}

/// Extracts the `updated_at_timestamp` from TOML data.
///
/// This function takes a byte slice containing TOML data and attempts to extract
/// the `updated_at_timestamp` field as a `u64`.  It handles the cases where
/// the field is missing, has an invalid type, or is out of the valid `u64` range.
///
/// # Arguments
///
/// * `toml_data`: The TOML data as a byte slice.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`: The `updated_at_timestamp` on success, or a
///    `ThisProjectError` if an error occurs.
fn extract_updated_at_timestamp(file_content: &[u8]) -> Result<u64, ThisProjectError> {
    // 1. Convert to String (handle UTF-8 errors).
    let file_str = std::str::from_utf8(file_content).map_err(|_| {
        ThisProjectError::InvalidData("Invalid UTF-8 in file content".into())
    })?;

    // 2. Check for "updated_at_timestamp = " line (TOML-style).
    for line in file_str.lines() {
        if line.starts_with("updated_at_timestamp = ") {
            let value_str = line.trim_start_matches("updated_at_timestamp = ");
            let timestamp = value_str.parse().map_err(|e: ParseIntError| {
                ThisProjectError::InvalidData(format!("Invalid timestamp: {}", e))
            })?;
            return Ok(timestamp);
        }
    }

    // 3. (Optional) If not TOML, try other formats (e.g., JSON).  Add this as needed.
    // ... (Code to handle other formats, checking for similar timestamp fields) ...

    // 4. If no recognized timestamp format is found.
    Err(ThisProjectError::InvalidData("Timestamp field not found in any recognized format".into()))
}

/*
Seri_Deseri Deserialize From End
*/

/// get unix time
/// e.g. for use with updated_at_timestamp
fn get_current_unix_timestamp() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .expect("System time is before the Unix epoch!") // Handle errors appropriately
        .as_secs()
}



/*

This demo code is only making one set of unique port assignments, but it should be making a sets of port assignment for each collaborator x other collaborators

Here is a sample of what the code should produce (the demo code does not produce this):
```sample
teamchannel_collaborators_with_access = ["alice", "bob", "charlotte"]
# meeting rooms, collaborator_port_assignments
[abstract_collaborator_port_assignments.alice_bob]
collaborator_ports = [
{ user_name = "alice", ready_port = 50001, intray_port = 50002, gotit_port = 50003 },
{ user_name = "bob", ready_port = 50004, intray_port = 50005, gotit_port = 50006 },
]
[abstract_collaborator_port_assignments.alice_charlotte]
collaborator_ports = [
{ user_name = "alice", ready_port = 50007, intray_port = 50008, gotit_port = 50009 },
{ user_name = "charlotte", ready_port = 50010, intray_port = 50011, gotit_port = 50012 },
]
[abstract_collaborator_port_assignments.bob_charlotte]
collaborator_ports = [
{ user_name = "bob", ready_port = 50013, intray_port = 50014, gotit_port = 50015 },
{ user_name = "charlotte", ready_port = 50016, intray_port = 50017, gotit_port = 50018 },
]
```
demo code:
// Generate collaborator port assignments
let mut abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();
// Add owner to collaborators list
let mut collaborators = Vec::new();
collaborators.push(owner.clone());
debug_log!(
"create_new_team_channel(): owner '{}' added to collaborators",
owner
);
// Generate random ports for the owner
let mut rng = rand::rng();
let ready_port = rng.random_range(40000..60000) as u16;
let tray_port = rng.random_range(40000..60000) as u16;
let gotit_port = rng.random_range(40000..60000) as u16;
let abstract_ports_data = AbstractTeamchannelNodeTomlPortsData {
user_name: owner.clone(),
ready_port,
intray_port: tray_port,
gotit_port,
};
debug_log!(
"create_new_team_channel(): owner's ports assigned - ready:{}, intray:{}, gotit:{}",
ready_port, tray_port, gotit_port
);
// Store in the HashMap with "owner_owner" key
abstract_collaborator_port_assignments.insert(
format!("{}_{}", owner.clone(), owner),
vec![ReadTeamchannelCollaboratorPortsToml { collaborator_ports: vec![abstract_ports_data] }],
);
debug_log!("create_new_team_channel(): owner added to port assignments");
// Retrieve project area data
debug_log!("Retrieving project area data...");
```

the current code is incomplete, or misconfigured, not generating the collaboration pairs:
we need pairs of different collaborators:
"alice_bob" (Alice collaborating with Bob)
"alice_charlotte" (Alice collaborating with Charlotte)
"bob_charlotte" (Bob collaborating with Charlotte)

Design factors:
1. random not sequential ports may be better for security
2. there will be an exclude-list and a range for generating ports (see below)
3. There needs to be a user-interface first step step to add collaborators by string input, and checking that each collaborator is in address book (or sub-folder)
teamchannel_collaborators_with_access = list of collaborators with access (as the name says)
4. the owner needs to be added along with those that the owner invites. the own IS to be added, not optional.

examples steps:
1. "Enter the user-names of collaborators you wish to invite separated by commas"
> user (alice) enters: bob,charlotte,duncan
The program checks that each name exists only once, e.g. make an alphabetical set. (or set and then an alphabetical string array)
The owner is just like any other collaborator in terms of the ports, include the owner alphabetically.
if a string (or more than one) was not in the list, say which it was and ask the user to re-enter the list: "Enter the user-names of collaborators you wish to invite separated by commas"

Checking that users exist works like this (there are a few steps here):
1. there is an exe-parent/COLLABORATOR_ADDRESSBOOK_PATH_STR/
directory.
Code to get directory where addressbook files are:
```rust
let collaborator_files_address_book_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
COLLABORATOR_ADDRESSBOOK_PATH_STR
) {
Ok(directory_path) => {
println!("Team channels directory: {}", directory_path.display());
directory_path
}
Err(io_error) => {
let error_msg = format!(
"Failed to ensure team_channels_dir exists: {}",
io_error
);
eprintln!("ERROR: {}", error_msg);
return Err(ThisProjectError::from(error_msg));
}
};
```
skip sub directories for now:
code showing how to find addressbook files
```rust
// 1. Construct File Path
let relative_file_path = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
.join(format!("{}__collaborator.toml", collaborator_name));
// Get the executable-relative base directory path
let abs_file_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
relative_file_path
) {
Ok(path) => path,
Err(e) => {
debug_log!("ROCST: Failed to resolve collaborator directory path: {}", e);
return Err(ThisProjectError::IoError(e));
}
};
```

maybe using the function
make_input_path_name_abs_executabledirectoryrelative_nocheck()
and then check if that file exists
2. adds the current-owner-user to that list
3. makes version-1 port assignments
4. should check 'globally' for port collisions...
if a file cannot be validated, just print a notice (and debug-log a notice) and skip it, don't crash the program.

We will make a new function to create an exclusion list so no ports collide:
- no ports can collide locally-in-this-team, 100% required.
- ideally no ports should collide globally, should be feasible but is not required.

So a first dev-task may be to make the new version of check_all_ports_in_team_channels_clearsign_validated() maybe
make_exclusionlist_check_ports_in_team_channels_clearsign_validated()
using existing ports as an "exclusion list" when generating new ports, and then double checking to make sure no collisions with self or exclusion list.

the global exclusion list will be made of the ports lists from all team-channels.

The may be a wrapper function
global_ports_exclusion_list_generator()
that uses the 'local'/single exclusion list make to run on all team channels.

e.g.for every team-channel node.toml
get a list of the team_channel directories:
- team_channels
// Ensure the project graph data directory exists relative to the executable
let team_channels_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
"project_graph_data/team_channels"
) {
Ok(directory_path) => {
println!("Team channels directory: {}", directory_path.display());
directory_path
}
Err(io_error) => {
let error_msg = format!(
"Failed to ensure team_channels_dir exists: {}",
io_error
);
eprintln!("ERROR: {}", error_msg);
return Err(ThisProjectError::from(error_msg));
}
};
add .../node.toml to that to get the config files

..
to sum up
1. Collect collaborators interactively: Prompt user to enter comma-separated collaborator names
2. Validate collaborators: Check each collaborator exists in the address book/sub-folder
3. Include owner: Add the current owner to the collaborator list
4. Generate pairwise port assignments: Create port assignments for every collaborator pair (not just one global set)
5. Check global port collisions:
Create a new function return_checked_ports_in_team_channels_clearsign_validated() [based on existing check_all_ports_in_team_channels_clearsign_validated()]
Scan all existing team channel node.toml files for used ports
Ensure new port assignments don't collide with existing ones
ALL ports across ALL pairs must be globally unique across the entire system
Retry on collision: If port assignments collide, regenerate until they're unique
`abstract_collaborator_port_assignments` HashMap should have keys like "alice_bob", "alice_charlotte", "bob_charlotte" with each containing the port data for both collaborators in that pair.
Each pair of collaborators have unique ports for that pair.
there is no redundant bob_alice port set. the name order is always the same as the collaborator list.
Pair Naming Convention: Should the pair names always follow the order they appear in the collaborator list? (e.g., if list is [alice, bob, charlotte], then pairs are alice_bob, alice_charlotte, bob_charlotte)
Total Pairs: For N collaborators, we generate N*(N-1)/2 unique pairs
2 collaborators = 1 pair
3 collaborators = 3 pairs
4 collaborators = 6 pairs
etc.
Port Count: Each pair contains port assignments for both collaborators in that pair, so each pair will have 6 ports total (3 ports  2 collaborators)
...
Generate unique port assignments for every collaborator pair
Ensure ALL ports are globally unique across the entire system
Check against existing team channels to prevent any collisions
since you are using an exclusion-list there should not be a collision. if a collusion happens even though you have an exclusion list show the user a warning and ask if they want to use a list that is locally-in-that-team not-colliding but not-globally-unique (though that can't really happen unless the exclusion list is not functioning)
with 33k possible ports, a small agile team will be able to use locally in that team unique ports.
my understanding is that 49152-65535: IANA designated "Dynamic/Private" ports - safest choice, is a safe port range to use.
of that is full (unlikely) use 32768-65535: Traditional ephemeral range on many Unix systems
"skip subdirectories" ignore any subdirectories in the address book folder entirely (there are none yet, and maybe won't be any)
to recap:
## Scope Confirmation
### 1. Interactive Collaborator Collection
- Prompt user to enter comma-separated collaborator names
- Validate each name exists in `project_graph_data/collaborator_files_address_book/` as `{name}__collaborator.toml`
- Skip subdirectories entirely in address book folder
- If any names don't exist, show which ones and re-prompt for the entire list
- Create alphabetical set (no duplicates)
- Always include the owner in the final collaborator list
### 2. Pairwise Port Assignment Generation
- Generate unique pairs for N collaborators: N*(N-1)/2 pairs
- Pair naming: alphabetical order from collaborator list (e.g., "alice_bob", "alice_charlotte", "bob_charlotte")
- Each pair gets 6 unique ports total (3 ports  2 collaborators)
- Store in `abstract_collaborator_port_assignments` HashMap with pair names as keys
### 3. Global Port Collision Prevention
- Create new function `return_checked_ports_in_team_channels_clearsign_validated()`
- Scan all existing `project_graph_data/team_channels/
*
 /node.toml` files for used ports
- Build exclusion list of all currently used ports across entire system
- Generate new ports from safe range (49152-65535, fallback to 32768-65535)
- ALL ports across ALL pairs must be globally unique system-wide
- If collision occurs despite exclusion list, warn user and offer locally-unique option
### 4. Error Handling
- Gracefully handle missing/invalid collaborator files (log and skip, don't crash)
- Handle file system errors appropriately
- Provide clear user feedback for validation failures
### 5. Port Range Strategy
- Primary: 49152-65535 (IANA Dynamic/Private ports)
- Fallback: 32768-65535 (Traditional ephemeral range)
### 6. Data Structure
The `abstract_collaborator_port_assignments` HashMap structure should look like:
```
"alice_bob" -> Vec<ReadTeamchannelCollaboratorPortsToml> with alice and bob's port data
"alice_charlotte" -> Vec<ReadTeamchannelCollaboratorPortsToml> with alice and charlotte's port data
"bob_charlotte" -> Vec<ReadTeamchannelCollaboratorPortsToml> with bob and charlotte's port data
```
structure:
[abstract_collaborator_port_assignments.alice_bob]
collaborator_ports = [
  { user_name = "alice", ready_port = 50001, intray_port = 50002, gotit_port = 50003 },
  { user_name = "bob", ready_port = 50004, intray_port = 50005, gotit_port = 50006 },
]


If a single team channel's node.toml fails validation in the exclusion list generator, skip it and continue (adding a warning to logs)

Scope of Ports to Include:
The exclusion list includes all ports found (ready, intray, gotit)
the exclusion list only needs the port: if a port is in use, it does not matter who is using it for what, only that it is in use and therefore not available.


## Return Type
**use: `HashSet<u16>`**
- Since you only need port numbers (not types), a `HashSet<u16>` is ideal
- Provides O(1) lookup performance when checking if a port is already in use
- Automatically handles duplicates
- Perfect for an exclusion list use case
## Function Structure
two-function approach:
### 1. Single Team Channel Function
```rust
/// Extracts all ports from a single team channel's node.toml file
/// Returns a HashSet of all ports found (ready, intray, gotit for all collaborators)
pub fn make_exclusionlist_from_single_team_channel(
node_toml_path: &Path,
collaborator_files_dir_relative: &str,
) -> Result<HashSet<u16>, ThisProjectError>
```
### 2. Global Function (No Parameters)
```rust
/// Scans ALL team channels and returns a complete exclusion list of all ports in use
/// Similar to the original function - takes no parameters and scans everything
pub fn global_ports_exclusion_list_generator() -> Result<HashSet<u16>, ThisProjectError>
```
This matches the pattern of the original function:
- No parameters needed
- Automatically determines paths using `make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path()`
- Walks through ALL team channels in `project_graph_data/team_channels`
- Hardcodes the collaborator path as COLLABORATOR_ADDRESSBOOK_PATH_STR
The global function would internally call the single-channel function for each `node.toml` found, aggregating all ports into one master `HashSet<u16>`.
...

*/



/// Checks all ports across all team channels for collisions and usage conflicts.
///
/// # Purpose
/// This function performs a comprehensive audit of all network ports configured across
/// all team channels in the project. It ensures that:
/// 1. No two collaborators are assigned the same port (collision detection)
/// 2. Ports that are supposed to be in use are actually available on the system
/// 3. All team channel configurations are properly clearsigned and validated
///
/// # Process Flow
/// 1. **Directory Setup**: Ensures the team channels directory exists
/// 2. **Channel Discovery**: Walks through all subdirectories looking for `node.toml` files
/// 3. **Security Validation**: Each `node.toml` must be clearsigned and validated
/// 4. **Port Extraction**: Extracts all port assignments from validated files
/// 5. **Collision Detection**: Checks for duplicate port assignments across channels
/// 6. **System Availability**: Verifies if ports marked as "in use" are actually available
///
/// # Security Model
/// - Only processes clearsigned `node.toml` files
/// - Uses owner-based GPG key validation via the collaborator addressbook system
/// - Skips any files that fail signature validation
///
/// # Error Handling
/// The function provides detailed error information and interactive warnings:
/// - Port collisions trigger a warning with user confirmation to continue
/// - Invalid configurations are logged but don't stop the entire scan
/// - Returns a comprehensive error if critical issues are found
///
/// # Returns
/// * `Ok(())` - If all ports are properly configured without collisions
/// * `Err(ThisProjectError)` - If critical errors occur:
///   - Directory access issues
///   - Systematic port collision patterns
///   - Critical configuration errors
///
/// # Example Output
/// ```text
/// === Team Channel Port Audit ===
/// Checking all team channels in: /path/to/project_graph_data/team_channels
///
/// Processing channel: team_alpha
///    Validated signature for owner: alice
///   Found 3 collaborator pairs with 6 port assignments
///
/// Processing channel: team_beta
///    Validated signature for owner: bob
///   Found 2 collaborator pairs with 4 port assignments
///
///   PORT COLLISION DETECTED!
/// Port 50001 is assigned multiple times:
///   - team_alpha: alice (ready_port) in pair alice_bob
///   - team_beta: charlie (ready_port) in pair charlie_dave
///
/// Press Enter to continue scanning or Ctrl+C to abort...
///
/// === Summary ===
/// Total channels scanned: 2
/// Total port assignments: 10
/// Collisions found: 1
/// ```
pub fn check_all_ports_in_team_channels_clearsign_validated() -> Result<(), ThisProjectError> {
    println!("=== Team Channel Port Audit ===");

    // --- Stage 1: Directory Setup ---
    println!("Setting up team channels directory...");

    // Ensure the project graph data directory exists relative to the executable
    let team_channels_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        "project_graph_data/team_channels"
    ) {
        Ok(directory_path) => {
            println!("Team channels directory: {}", directory_path.display());
            directory_path
        }
        Err(io_error) => {
            let error_msg = format!(
                "Failed to ensure team_channels_dir exists: {}",
                io_error
            );
            eprintln!("ERROR: {}", error_msg);
            return Err(ThisProjectError::from(error_msg));
        }
    };

    // Get collaborator files directory for addressbook lookups
    let collaborator_files_dir_relative = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    /*
    Is this not updated for .gpgclearsign?
    */

    // --- Stage 2: Initialize Tracking Structures ---

    // Why is this making a new struct??
    // Track all port assignments with their context for detailed collision reporting
    #[derive(Debug, Clone)]
    struct PortAssignmentContext {
        channel_name: String,
        pair_name: String,
        user_name: String,
        port_type: String, // "ready", "intray", or "gotit"
    }

    let mut port_registry: HashMap<u16, Vec<PortAssignmentContext>> = HashMap::new();
    let mut channels_processed = 0;
    let mut total_port_assignments = 0;
    let mut validation_failures = 0;
    let mut collision_count = 0;

    println!("\nScanning for team channel configurations...\n");

    // --- Stage 3: Walk Through Team Channels ---
    for entry in WalkDir::new(&team_channels_dir)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| e.file_type().is_dir())
    {
        /*
        workflow:

        */

        let node_toml_path = entry.path().join("node.toml");

        // Skip directories without node.toml
        if !node_toml_path.exists() {
            continue;
        }

        // Extract channel name from directory path
        let channel_name = entry.path()
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("unknown")
            .to_string();

        // Skip the root directory itself
        if entry.path() == team_channels_dir {
            continue;
        }

        println!("Processing channel: {}", channel_name);
        channels_processed += 1;

        /*
        pub fn read_all_collaborator_port_assignments_clearsigntoml_optimized(
            path_to_clearsigned_toml: &Path,
            // addressbook_files_directory_relative: &str,  // pass in constant here
	       readcopy_path_to_addressbook_file: &Path,
        ) -> Result<HashMap<String, Vec<AbstractTeamchannelNodeTomlPortsData>>, GpgError> {

        */

        // --- Stage 4: Read and Validate Clearsigned Configuration ---
        match read_all_collaborator_port_assignments_clearsigntoml_optimized(
            &node_toml_path,
            collaborator_files_dir_relative,
        ) {
            Ok(port_assignments) => {
                println!("   Signature validated successfully");
                println!("  Found {} collaborator pairs", port_assignments.len());

                // --- Stage 5: Process Port Assignments ---
                for (pair_name, assignments) in port_assignments {
                    for assignment in assignments {
                        // Track each port with its context
                        let port_contexts = [
                            (assignment.ready_port, "ready"),
                            (assignment.intray_port, "intray"),
                            (assignment.gotit_port, "gotit"),
                        ];

                        for (port, port_type) in port_contexts {
                            total_port_assignments += 1;

                            let context = PortAssignmentContext {
                                channel_name: channel_name.clone(),
                                pair_name: pair_name.clone(),
                                user_name: assignment.user_name.clone(),
                                port_type: port_type.to_string(),
                            };

                            // Add to registry
                            port_registry
                                .entry(port)
                                .or_insert_with(Vec::new)
                                .push(context);
                        }
                    }
                }

                // Also check if authorized collaborators can be read (optional)
                match read_teamchannel_collaborators_with_access_from_clearsigntoml(
                    &node_toml_path,
                    collaborator_files_dir_relative,
                ) {
                    Ok(collaborators) => {
                        println!("  Authorized collaborators: {:?}", collaborators);
                    }
                    Err(e) => {
                        println!("    Could not read authorized collaborators: {}", e.to_string());
                    }
                }
            }
            Err(e) => {
                validation_failures += 1;
                eprintln!("   Validation FAILED: {}", e.to_string());
                eprintln!("  Skipping this channel due to security validation failure");
                continue;
            }
        }

        println!(); // Empty line between channels
    }

    // --- Stage 6: Analyze Port Collisions ---
    println!("=== Port Collision Analysis ===\n");

    let mut collision_found = false;

    for (port, contexts) in &port_registry {
        if contexts.len() > 1 {
            collision_found = true;
            collision_count += 1;

            // Print collision warning
            println!("  PORT COLLISION DETECTED!");
            println!("Port {} is assigned multiple times:", port);

            for context in contexts {
                println!(
                    "  - Channel '{}': {} ({}_port) in pair {}",
                    context.channel_name,
                    context.user_name,
                    context.port_type,
                    context.pair_name
                );
            }

            println!();

            // Check if the port is actually in use on the system
            if is_port_in_use(*port) {
                println!("   CRITICAL: Port {} is currently IN USE on the system!", port);
            } else {
                println!("   Port {} is not currently in use on the system", port);
            }

            // Interactive warning - ask user to continue
            println!("\nPress Enter to continue scanning or Ctrl+C to abort...");
            let mut input = String::new();
            match io::stdin().read_line(&mut input) {
                Ok(_) => {
                    println!("Continuing scan...\n");
                }
                Err(e) => {
                    return Err(ThisProjectError::from(format!(
                        "Failed to read user input: {}",
                        e
                    )));
                }
            }
        }
    }

    if !collision_found {
        println!(" No port collisions detected!");
    }

    // --- Stage 7: Summary Report ---
    println!("\n=== Summary ===");
    println!("Total channels scanned: {}", channels_processed);
    println!("Total port assignments: {}", total_port_assignments);
    println!("Unique ports used: {}", port_registry.len());
    println!("Validation failures: {}", validation_failures);
    println!("Port collisions found: {}", collision_count);

    // --- Stage 8: Final Status ---
    if collision_found {
        eprintln!("\n Port audit FAILED: {} collision(s) detected", collision_count);
        eprintln!("Please resolve port conflicts before proceeding.");

        // Create detailed error message
        let mut collision_details = String::from("Port collisions detected:\n");
        for (port, contexts) in &port_registry {
            if contexts.len() > 1 {
                collision_details.push_str(&format!("  Port {}: {} assignments\n", port, contexts.len()));
            }
        }

        Err(ThisProjectError::PortCollision(collision_details))
    } else if validation_failures > 0 {
        eprintln!("\n  Port audit completed with {} validation failures", validation_failures);
        eprintln!("Some channels could not be verified due to signature issues.");
        Ok(())
    } else {
        println!("\n Port audit PASSED: All ports properly configured!");
        debug_log("Done check_all_ports_in_team_channels_clearsign_validated()");
        Ok(())
    }
}

/*

*/


/// Extracts all ports from a single team channel's node.toml file.
///
/// # Purpose
/// This function reads a clearsigned `node.toml` file from a team channel and extracts
/// all configured network ports (ready, intray, and gotit ports) for all collaborator
/// pairs. The extracted ports are returned as a HashSet for efficient lookup when
/// checking for port collisions.
///
/// # Parameters
/// * `node_toml_path` - The absolute path to the node.toml file to process
/// * `collaborator_files_dir_relative` - The relative path to the collaborator files
///   directory (typically COLLABORATOR_ADDRESSBOOK_PATH_STR)
///
/// # Security
/// - Only processes clearsigned files that pass GPG validation
/// - Uses the collaborator addressbook system for owner verification
/// - Returns an empty set if validation fails (with appropriate logging)
///
/// # Returns
/// * `Ok(HashSet<u16>)` - A set of all ports found in the file
/// * `Err(ThisProjectError)` - If critical errors occur (not validation failures)
///
/// # Example
/// let ports = make_exclusionlist_from_single_team_channel(
///     Path::new("/path/to/team_channel/node.toml"),
///     COLLABORATOR_ADDRESSBOOK_PATH_STR
/// )?;
/// println!("Found {} unique ports in use", ports.len());
/// node_toml_path
pub fn make_exclusionlist_from_single_team_channel(
    addressbook_readcopy_path_string: &str,
    node_readcopy_path: &Path,  // node_readcopy_path
) -> Result<HashSet<u16>, ThisProjectError> {
    // Initialize the port set
    let mut port_set: HashSet<u16> = HashSet::new();

    // Check if the file exists
    if !node_readcopy_path.exists() {
        debug_log!(
            "make_exclusionlist_from_single_team_channel: File does not exist: {}",
            node_readcopy_path.display()
        );
        // Return empty set for non-existent files
        return Ok(port_set);
    }

    // Extract channel name for logging
    let channel_name = node_readcopy_path
        .parent()
        .and_then(|p| p.file_name())
        .and_then(|n| n.to_str())
        .unwrap_or("unknown");

    debug_log!(
        "make_exclusionlist_from_single_team_channel: Processing channel '{}'",
        channel_name
    );

    // TODO ? instead use read_teamchannel_collaborator_ports_clearsigntoml_without_keyid()

    /*
    addressbook_readcopy_path_string: &str,
    path_to_clearsigned_toml: &str,

    */
    // Read and validate the clearsigned configuration
    // match read_all_collaborator_port_assignments_clearsigntoml_optimized(
    match read_abstract_collaborator_portassignments_from_clearsigntoml_withoutkeyid(
        &addressbook_readcopy_path_string, // addressbook_readcopy_path_string
        &node_readcopy_path.display().to_string(), // path_to_clearsigned_toml
    ) {
        Ok(port_assignments) => {
            debug_log!(
                "make_exclusionlist_from_single_team_channel: Successfully validated channel '{}'",
                channel_name
            );

            // Extract all ports from all collaborator pairs
            for (pair_name, assignments) in port_assignments {
                debug_log!(
                    "make_exclusionlist_from_single_team_channel: Processing pair '{}'",
                    pair_name
                );

                // Process each collaborator in the pair
                for assignment in assignments {
                    // Add all three port types to the set
                    port_set.insert(assignment.ready_port);
                    port_set.insert(assignment.intray_port);
                    port_set.insert(assignment.gotit_port);

                    debug_log!(
                        "make_exclusionlist_from_single_team_channel: Added ports for user '{}': \
                         ready={}, intray={}, gotit={}",
                        assignment.user_name,
                        assignment.ready_port,
                        assignment.intray_port,
                        assignment.gotit_port
                    );
                }
            }

            debug_log!(
                "make_exclusionlist_from_single_team_channel: Channel '{}' total unique ports: {}",
                channel_name,
                port_set.len()
            );
        }
        Err(e) => {
            // Log the validation failure but don't propagate the error
            // Return empty set for files that fail validation
            eprintln!(
                "WARNING: Skipping channel '{}' due to validation failure: {}",
                channel_name,
                e.to_string()
            );
            debug_log!(
                "make_exclusionlist_from_single_team_channel: Validation failed for channel '{}': {}",
                channel_name,
                e.to_string()
            );
        }
    }

    Ok(port_set)
}

// alt
/// Searches for a node configuration file in the given directory.
///
/// This function looks for either `node.toml` or `node.gpgtoml` in the specified directory.
/// It checks for `node.toml` first, and if not found, checks for `node.gpgtoml`.
///
/// # Arguments
///
/// * `input_node_parent_path` - The directory path where to search for the node configuration files
///
/// # Returns
///
/// * `Some(PathBuf)` - The full path to the found configuration file (either node.toml or node.gpgtoml)
/// * `None` - Neither configuration file was found in the directory
///
/// # Example
///
/// ```
/// let parent_path = Path::new("/home/user/project");
/// if let Some(config_path) = find_node_toml_or_gpgtoml_file(parent_path) {
///     println!("Found configuration at: {:?}", config_path);
/// } else {
///     println!("No configuration file found");
/// }
/// ```
fn alt_find_node_toml_or_gpgtoml_file(input_node_parent_path: &Path) -> Option<PathBuf> {
    // First, try to find node.toml in the parent directory
    let node_toml = input_node_parent_path.join("node.toml");

    // Check if node.toml exists and is a regular file (not a directory)
    if node_toml.exists() && node_toml.is_file() {
        // Return the path to node.toml if found
        return Some(node_toml);
    }

    // If node.toml wasn't found, try to find node.gpgtoml
    let node_gpgtoml = input_node_parent_path.join("node.gpgtoml");

    // Check if node.gpgtoml exists and is a regular file (not a directory)
    if node_gpgtoml.exists() && node_gpgtoml.is_file() {
        // Return the path to node.gpgtoml if found
        return Some(node_gpgtoml);
    }

    // Neither file was found in the directory
    None
}
// // Usage example for your specific case:
// let current_full_file_path = PathBuf::from("/your/actual/path");

// // Call the function to find either node.toml or node.gpgtoml
// let node_toml_path = match find_node_toml_or_gpgtoml_file(&current_full_file_path) {
//     Some(path) => {
//         // Successfully found one of the configuration files
//         debug_log!(
//             "nav_graph_look_read_node_toml() node_toml_path -> {:?}",
//             path.clone()
//         );

//         // Add more detailed existence checking
//         debug_log!("Checking if path exists: {:?}", path.exists());
//         debug_log!("Checking if path is file: {:?}", path.is_file());

//         // Return the found path
//         path
//     },
//     None => {
//         // Neither node.toml nor node.gpgtoml was found
//         debug_log!(
//             "nav_graph_look_read_node_toml() no configuration file found in: {:?}",
//             current_full_file_path
//         );

//         // Handle the error case - you need to decide what to do here
//         // Option 1: Return an error from your function
//         return Err("No node configuration file found".to_string());

//         // Option 2: Use a default or panic (not recommended)
//         // panic!("No node configuration file found");
//     }
// };

// // At this point, node_toml_path contains the PathBuf to whichever file was found

/// Searches for a node configuration file in the given directory.
///
/// This function looks for either `node.toml` or `node.gpgtoml` in the specified directory.
/// It checks for `node.toml` first, and if not found, checks for `node.gpgtoml`.
///
/// # Arguments
///
/// * `input_node_parent_path` - The directory path where to search for the node configuration files
///
/// # Returns
///
/// * `Ok(Some(PathBuf))` - The full path to the found configuration file (either node.toml or node.gpgtoml)
/// * `Ok(None)` - Neither configuration file was found in the directory
/// * `Err(String)` - An error occurred while checking the files
///
/// # Example
///
/// ```
/// let parent_path = Path::new("/home/user/project");
/// match find_node_toml_or_gpgtoml_file(parent_path) {
///     Ok(Some(path)) => println!("Found configuration at: {:?}", path),
///     Ok(None) => println!("No configuration file found"),
///     Err(e) => eprintln!("Error: {}", e),
/// }
/// ```
fn find_node_toml_or_gpgtoml_file(input_node_parent_path: &Path) -> Result<Option<PathBuf>, String> {
    // Validate that the input path exists and is a directory
    if !input_node_parent_path.exists() {
        return Err(format!(
            "Parent directory does not exist: {:?}",
            input_node_parent_path
        ));
    }

    if !input_node_parent_path.is_dir() {
        return Err(format!(
            "Path is not a directory: {:?}",
            input_node_parent_path
        ));
    }

    // First check for node.toml
    let node_toml_path = input_node_parent_path.join("node.toml");

    debug_log!(
        "find_node_toml_or_gpgtoml_file() checking for node.toml at: {:?}",
        node_toml_path
    );

    // Check if node.toml exists and is a file
    if node_toml_path.exists() && node_toml_path.is_file() {
        debug_log!(
            "find_node_toml_or_gpgtoml_file() found node.toml at: {:?}",
            node_toml_path
        );
        return Ok(Some(node_toml_path));
    }

    // If node.toml not found, check for node.gpgtoml
    let node_gpgtoml_path = input_node_parent_path.join("node.gpgtoml");

    debug_log!(
        "find_node_toml_or_gpgtoml_file() checking for node.gpgtoml at: {:?}",
        node_gpgtoml_path
    );

    // Check if node.gpgtoml exists and is a file
    if node_gpgtoml_path.exists() && node_gpgtoml_path.is_file() {
        debug_log!(
            "find_node_toml_or_gpgtoml_file() found node.gpgtoml at: {:?}",
            node_gpgtoml_path
        );
        return Ok(Some(node_gpgtoml_path));
    }

    // Neither file was found
    debug_log!(
        "find_node_toml_or_gpgtoml_file() no configuration file found in: {:?}",
        input_node_parent_path
    );

    Ok(None)
}
// // use example
// let current_full_file_path = PathBuf::from("/home/user/project/nodes/example");

// // Find the configuration file (could be either node.toml OR node.gpgtoml)
// let node_toml_path = match find_node_toml_or_gpgtoml_file(&current_full_file_path) {
//     Ok(Some(path)) => {
//         // This is the path to whichever file was found (node.toml OR node.gpgtoml)
//         debug_log!("Found configuration file at: {:?}", path);
//         path  // <-- This could be either file!
//     },
//     Ok(None) => {
//         // No file found - handle the error properly
//         return Err("Neither node.toml nor node.gpgtoml found".to_string());
//     },
//     Err(error_message) => {
//         // Error occurred - handle it properly
//         return Err(error_message);
//     }
// };

// // node_toml_path now contains the path to whichever file was found

/// Scans ALL team channels and returns a complete exclusion list of all ports in use.
///
/// # Purpose
/// This function provides a comprehensive view of all network ports currently allocated
/// across all team channels in the project. It's designed to prevent port collisions
/// when creating new team channels or adding collaborators by maintaining a global
/// registry of used ports.
///
/// # Process
/// 1. Locates the team channels directory
/// 2. Walks through all subdirectories looking for `node.toml` files
/// 3. For each valid team channel found:
///    - Validates the clearsigned configuration
///    - Extracts all port assignments
///    - Adds them to the global exclusion set
/// 4. Returns the complete set of all ports in use
///
/// # Security
/// - Only includes ports from properly clearsigned and validated configurations
/// - Skips any channels that fail validation (logs warnings but continues)
/// - Uses the standard collaborator addressbook for verification
///
/// # Error Handling
/// - Directory access errors are propagated as critical failures
/// - Individual file validation failures are logged but don't stop the scan
/// - Returns partial results if some channels can't be processed
///
/// # Performance
/// - Uses HashSet for O(1) lookup performance
/// - Processes files sequentially to avoid resource contention
/// - Caches nothing - always provides current state
///
/// # Returns
/// * `Ok(HashSet<u16>)` - Set of all ports currently in use across all channels
/// * `Err(ThisProjectError)` - If unable to access the team channels directory
///
/// # Example
///
/// match global_ports_exclusion_list_generator() {
///     Ok(exclusion_list) => {
///         println!("Total ports in use globally: {}", exclusion_list.len());
///         // Check if a specific port is available
///         if !exclusion_list.contains(&50001) {
///             println!("Port 50001 is available");
///         }
///     }
///     Err(e) => eprintln!("Failed to generate exclusion list: {}", e),
/// }
///
pub fn global_ports_exclusion_list_generator() -> Result<HashSet<u16>, ThisProjectError> {
    println!("=== Generating Global Port Exclusion List ===");

    // Initialize the global port set
    let mut global_port_set: HashSet<u16> = HashSet::new();

    // Set up the team channels directory
    let team_channels_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        "project_graph_data/team_channels"
    ) {
        Ok(directory_path) => {
            debug_log!(
                "global_ports_exclusion_list_generator: Team channels directory: {}",
                directory_path.display()
            );
            directory_path
        }
        Err(io_error) => {
            let error_msg = format!(
                "Failed to access team_channels directory: {}",
                io_error
            );
            eprintln!("ERROR: {}", error_msg);
            return Err(ThisProjectError::from(error_msg));
        }
    };

    // Set the collaborator files directory path
    let collaborator_files_dir_relative = COLLABORATOR_ADDRESSBOOK_PATH_STR;

    // Statistics tracking
    let mut channels_processed = 0;
    let mut channels_skipped = 0;
    let mut total_ports_found = 0;

    debug_log!("global_ports_exclusion_list_generator: Starting directory walk...");



    // code from load_core_node...()
    debug_log!(
        "Starting: load_core_node_from_toml_file(), team_channels_dir -> {:?}",
        &team_channels_dir,
    );

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(format!(
                "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            ).into());
        }
    };


    // Walk through all team channel directories
    for entry in WalkDir::new(&team_channels_dir)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| e.file_type().is_dir())
    {
        // Skip the root directory itself
        if entry.path() == team_channels_dir {
            continue;
        }

        debug_log!("entry.path() {:?}", &entry.path().display());

        // Construct path to node.toml or node.gpgtoml
        // Find the configuration file (could be either node.toml OR node.gpgtoml)
        let node_toml_path = match find_node_toml_or_gpgtoml_file(&entry.path()) {
            Ok(Some(path)) => {
                // This is the path to whichever file was found (node.toml OR node.gpgtoml)
                debug_log!("Found configuration file at: {:?}", path);
                path  // <-- This could be either file!
            },
            Ok(None) => {
                // No file found - handle the error properly
                // return Err("Neither node.toml nor node.gpgtoml found".to_string());
                return Err(ThisProjectError::InvalidInput("Neither node.toml nor node.gpgtoml found".to_string()));
            },
            Err(error_message) => {
                // Error occurred - handle it properly
                // return Err(error_message);
                return Err(ThisProjectError::TomlVanillaDeserialStrError(error_message));
            }
        };

        // Add more detailed existence checking
        debug_log!("Checking if path exists: {:?}", node_toml_path.exists());
        debug_log!("Checking if path is file: {:?}", node_toml_path.is_file());

        // Skip directories without node.toml
        if !node_toml_path.exists() {
            continue;
        }

        //?
        // Extract channel name for logging
        let channel_name = entry.path()
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("unknown")
            .to_string();

        debug_log!(
            "global_ports_exclusion_list_generator: Processing channel '{}'",
            channel_name
        );




        // code from load_core_node...()
        // Get the UME temp directory path with proper GpgError conversion
        let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
            .map_err(|io_err| GpgError::ValidationError(
                format!("Failed to get UME temp directory path: {}", io_err)
            ))?;

        // Using Debug trait for more detailed error information
        let node_readcopy_path = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
            &node_toml_path,
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ).map_err(|e| format!("Failed to get temporary read copy of TOML file: {:?}", e))?;

        ////////////////////////////////
        // Extract Owner for Key Lookup
        ////////////////////////////////
        let owner_name_of_toml_field_key_to_read = "owner";
        debug_log!(
            "Reading file owner from field '{}' for security validation",
            owner_name_of_toml_field_key_to_read
        );

        let file_owner_username = match read_single_line_string_field_from_toml(
            &node_readcopy_path,  // TODO convert to string?
            owner_name_of_toml_field_key_to_read,
        ) {
            Ok(username) => {
                if username.is_empty() {
                    // Convert to String error instead of GpgError
                    return Err(format!(
                        "Field '{}' is empty in TOML file. File owner is required for security validation.",
                        owner_name_of_toml_field_key_to_read
                    ).into());
                }
                username
            }
            Err(e) => {
                // Convert to String error instead of GpgError
                return Err(format!(
                    "Failed to read file owner from field '{}': {}",
                    owner_name_of_toml_field_key_to_read, e
                // ));
                ).into());
            }
        };
        println!("File owner: '{}'", file_owner_username);

        // Get the UME temp directory path with proper GpgError conversion
        let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
            .map_err(|io_err| GpgError::ValidationError(
                format!("Failed to get UME temp directory path: {}", io_err)
            ))?;

        // Extract the addressbook path string with inline error conversion
        let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
            &file_owner_username,
            COLLABORATOR_ADDRESSBOOK_PATH_STR,
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ).map_err(|e| format!(
            "Failed to get addressbook path for user '{}': {:?}",
            file_owner_username,
            e
        ))?;

        // Define cleanup closure
        let cleanup_closure = || {
            let _ = cleanup_collaborator_temp_file(
                &node_readcopy_path,
                &base_uma_temp_directory_path,
                );
            let _ = cleanup_collaborator_temp_file(
                &addressbook_readcopy_path_string,
                &base_uma_temp_directory_path,
                );
        };

        let node_owners_public_gpg_key = read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml(
            &addressbook_readcopy_path_string,
        ).map_err(|e| format!(
            "Failed to get addressbook path for user '{}': {:?}",
            file_owner_username,
            e
        ))?;

        // 2. Paths & Reading-Copies Part 2: addressbook path and read-copy
        // Verify the addressbook file's clearsign signature
        let verify_addressbook_file_result = match verify_clearsign(
            &addressbook_readcopy_path_string,
            &node_owners_public_gpg_key,
        ) {
            Ok(is_valid) => is_valid,
            Err(e) => {
                // Clean up temporary files before returning error
                cleanup_closure();
                return Err(format!(
                    "Failed to verify addressbook clearsign signature for user '{}': {:?}",
                    file_owner_username,
                    e
                ).into());
            }
        };

        // 3. Validate Part 1: validate addressbook file and get node-owner's public gpg
        // (This section would go here if needed)

        // 4. Validation Part 2: validate Node (clearsign validation of .toml)
        // Verify the node file's clearsign signature
        let verify_node_file_result = match verify_clearsign(
            &node_readcopy_path,
            &node_owners_public_gpg_key,
        ) {
            Ok(is_valid) => is_valid,
            Err(e) => {
                // Clean up temporary files before returning error
                cleanup_closure();
                return Err(format!(
                    "Failed to verify node file clearsign signature for user '{}': {:?}",
                    file_owner_username,
                    e
                ).into());
            }
        };

        // Check if both verification results are valid
        // If either verification failed, clean up and return error
        if !verify_addressbook_file_result || !verify_node_file_result {

            debug_log("Whoops, something faileded...");

            // Clean up temporary files
            cleanup_closure();

            // Provide detailed error message about which verification failed
            let mut error_details = Vec::new();
            if !verify_addressbook_file_result {
                error_details.push("addressbook file signature verification failed");
            }
            if !verify_node_file_result {
                error_details.push("node file signature verification failed");
            }

            return Err(format!(
                "Clearsign validation failed for user '{}': {}",
                file_owner_username,
                error_details.join(" and ")
            ).into());
        }

		// make type path
        let node_readcopy_pathtype = Path::new(&node_readcopy_path);

        // Process this channel's ports
        match make_exclusionlist_from_single_team_channel(
            &addressbook_readcopy_path_string,
            &node_readcopy_pathtype,
        ) {
            Ok(channel_ports) => {
                let port_count = channel_ports.len();
                if port_count > 0 {
                    channels_processed += 1;
                    total_ports_found += port_count;

                    // Merge this channel's ports into the global set
                    global_port_set.extend(channel_ports);

                    debug_log!(
                        "global_ports_exclusion_list_generator: Channel '{}' contributed {} ports",
                        channel_name,
                        port_count
                    );
                } else {
                    channels_skipped += 1;
                    debug_log!(
                        "global_ports_exclusion_list_generator: Channel '{}' had no valid ports",
                        channel_name
                    );
                }
            }
            Err(e) => {
                // This shouldn't happen as make_exclusionlist_from_single_team_channel
                // handles errors gracefully, but log it just in case
                channels_skipped += 1;
                eprintln!(
                    "WARNING: Unexpected error processing channel '{}': {}",
                    channel_name,
                    e.to_string()
                );
                debug_log!(
                    "global_ports_exclusion_list_generator: Error processing channel '{}': {}",
                    channel_name,
                    e.to_string()
                );
            }
        }
    }

    // Print summary
    println!("\n=== Exclusion List Generation Summary ===");
    println!("Channels successfully processed: {}", channels_processed);
    println!("Channels skipped (validation failed or empty): {}", channels_skipped);
    println!("Total ports found: {}", total_ports_found);
    println!("Unique ports in exclusion list: {}", global_port_set.len());

    debug_log!(
        "global_ports_exclusion_list_generator: Complete. {} unique ports in exclusion list",
        global_port_set.len()
    );

    Ok(global_port_set)
}

/// WARNING: 'validation' needs to be defined TODO
/// Interactively collects and validates collaborator names from user input.
///
/// # Purpose
/// This function provides an interactive interface for users to specify which
/// collaborators should have access to a new team channel. It ensures all
/// specified collaborators exist in the address book before proceeding.
///
/// # Process
/// 1. Prompts user for comma-separated collaborator names
/// 2. Validates each name exists as a collaborator file
/// 3. Re-prompts if any names are invalid
/// 4. Returns a sorted, deduplicated list of valid collaborators
///
/// # Parameters
/// * `owner` - The owner's name to be included in the final list
///
/// # Returns
/// * `Ok(Vec<String>)` - Alphabetically sorted list of collaborators including owner
/// * `Err(ThisProjectError)` - If critical errors occur
///
/// # Example Interaction
///
/// Enter the user-names of collaborators you wish to invite separated by commas:
/// > bob, charlotte, alice, bob
///
///  Found collaborator: alice
///  Found collaborator: bob
///  Found collaborator: charlotte
///
/// Final collaborator list: ["alice", "bob", "charlotte", "owner"]
///
pub fn collect_and_validate_collaborators(
    owner: &str,
) -> Result<Vec<String>, ThisProjectError> {
    println!("\n=== Collaborator Setup ===");

    // Get the collaborator files directory
    let collaborator_files_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        COLLABORATOR_ADDRESSBOOK_PATH_STR
    ) {
        Ok(directory_path) => {
            debug_log!(
                "collect_and_validate_collaborators: Collaborator directory: {}",
                directory_path.display()
            );
            directory_path
        }
        Err(io_error) => {
            let error_msg = format!(
                "Failed to access collaborator files directory: {}",
                io_error
            );
            eprintln!("ERROR: {}", error_msg);
            return Err(ThisProjectError::from(error_msg));
        }
    };

    loop {
        // Prompt for input
        print!("Enter the user-names of collaborators you wish to invite separated by commas: ");
        io::stdout().flush().map_err(|e| {
            ThisProjectError::from(format!("Failed to flush stdout: {}", e))
        })?;

        // Read user input
        let mut input = String::new();
        io::stdin().read_line(&mut input).map_err(|e| {
            ThisProjectError::from(format!("Failed to read user input: {}", e))
        })?;

        // Parse input into individual names
        let mut collaborator_set: HashSet<String> = input
            .split(',')
            .map(|s| s.trim().to_lowercase())
            .filter(|s| !s.is_empty())
            .collect();

        // Always include the owner
        collaborator_set.insert(owner.to_lowercase());

        // Validate each collaborator
        let mut invalid_names = Vec::new();
        let mut valid_names = Vec::new();

        println!("\nValidating collaborators...");

        for name in &collaborator_set {
            // Skip checking the owner (we trust they exist)
            if name == owner {
                valid_names.push(name.clone());
                continue;
            }

            // // Construct the collaborator file path
            // let collaborator_file = format!("{}__collaborator.toml", name);
            // let file_path = collaborator_files_dir.join(&collaborator_file);

            // // Check if the file exists
            // if file_path.exists() {
            //     println!("   Found collaborator: {}", name);
            //     valid_names.push(name.clone());
            //     debug_log!(
            //         "collect_and_validate_collaborators: Validated collaborator '{}' at {}",
            //         name,
            //         file_path.display()
            //     );
            // } else {
            //     println!("   NOT FOUND: {}", name);
            //     invalid_names.push(name.clone());
            //     debug_log!(
            //         "collect_and_validate_collaborators: Collaborator '{}' not found at {}",
            //         name,
            //         file_path.display()
            //     );
            // }

            // Construct the collaborator file paths for both possible extensions
            let collaborator_gpgtoml = format!("{}__collaborator.gpgtoml", name);
            let collaborator_toml = format!("{}__collaborator.toml", name);

            let gpgtoml_path = collaborator_files_dir.join(&collaborator_gpgtoml);
            let toml_path = collaborator_files_dir.join(&collaborator_toml);

            // Check if either file exists (prefer .gpgtoml for security)
            let file_exists = if gpgtoml_path.exists() {
                debug_log!(
                    "collect_and_validate_collaborators: Found GPG encrypted collaborator file for '{}' at {}",
                    name,
                    gpgtoml_path.display()
                );
                true
            } else if toml_path.exists() {
                debug_log!(
                    "collect_and_validate_collaborators: Found clearsigned collaborator file for '{}' at {}",
                    name,
                    toml_path.display()
                );
                true
            } else {
                false
            };

            // Check if the file exists
            if file_exists {
                println!("   Found collaborator: {}", name);
                valid_names.push(name.clone());
            } else {
                println!("   NOT FOUND: {}", name);
                invalid_names.push(name.clone());
                debug_log!(
                    "collect_and_validate_collaborators: Collaborator '{}' not found (checked both .gpgtoml and .toml)",
                    name
                );
            }


        }

        // Check if all names are valid
        if invalid_names.is_empty() {
            // Sort alphabetically and return
            valid_names.sort();
            println!("\nFinal collaborator list: {:?}", valid_names);
            return Ok(valid_names);
        } else {
            // Show error and re-prompt
            eprintln!("\n The following collaborators were not found in the address book:");
            for name in &invalid_names {
                eprintln!("   - {}", name);
            }
            println!("\nPlease try again with valid collaborator names.\n");
        }
    }
}

/// Generates a unique port not in the exclusion list.
///
/// # Parameters
/// * `rng` - Random number generator
/// * `exclusion_list` - Set of ports already in use
/// * `local_used_ports` - Set of ports used locally in this generation session
/// * `primary_range` - Primary port range to try first (start, end)
/// * `fallback_range` - Fallback range if primary is exhausted (start, end)
///
/// # Returns
/// * `Ok(u16)` - A unique port number
/// * `Err(ThisProjectError)` - If no available ports found
fn generate_unique_port(
    rng: &mut impl Rng,
    exclusion_list: &HashSet<u16>,
    local_used_ports: &HashSet<u16>,
    primary_range: (u16, u16),
    fallback_range: (u16, u16),
) -> Result<u16, ThisProjectError> {
    // Try primary range first
    let mut attempts = 0;
    const MAX_ATTEMPTS: u32 = 1000;

    while attempts < MAX_ATTEMPTS {
        let port = rng.random_range(primary_range.0..=primary_range.1);
        if !exclusion_list.contains(&port) && !local_used_ports.contains(&port) {
            return Ok(port);
        }
        attempts += 1;
    }

    // Try fallback range
    attempts = 0;
    while attempts < MAX_ATTEMPTS {
        let port = rng.random_range(fallback_range.0..=fallback_range.1);
        if !exclusion_list.contains(&port) && !local_used_ports.contains(&port) {
            debug_log!(
                "generate_unique_port: Using fallback range for port {}",
                port
            );
            return Ok(port);
        }
        attempts += 1;
    }

    Err(ThisProjectError::from(
        "Unable to find available port after maximum attempts"
    ))
}

// /// Generates pairwise port assignments for all collaborators.
// ///
// /// # Purpose
// /// Creates unique port assignments for every pair of collaborators in a team channel.
// /// Each pair gets 6 unique ports (3 for each collaborator) that don't conflict with
// /// any existing ports in the system.
// ///
// /// # Parameters
// /// * `collaborators` - Sorted list of all collaborators (including owner)
// /// * `exclusion_list` - Set of all ports currently in use globally
// ///
// /// # Returns
// /// * `Ok(HashMap)` - Map of pair names to port assignments
// /// * `Err(ThisProjectError)` - If unable to generate unique ports
// ///
// /// # Port Ranges
// /// * Primary: 49152-65535 (IANA Dynamic/Private ports)
// /// * Fallback: 32768-65535 (Traditional ephemeral range)
// pub fn generate_pairwise_port_assignments(
//     collaborators: &[String],
//     exclusion_list: &HashSet<u16>,
// ) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, ThisProjectError> {
//     println!("\n=== Generating Pairwise Port Assignments ===");

//     let mut port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();
//     let mut local_used_ports: HashSet<u16> = HashSet::new();
//     let mut rng = rand::rng();

//     // Define port ranges
//     const PRIMARY_RANGE: (u16, u16) = (49152, 65535);
//     const FALLBACK_RANGE: (u16, u16) = (32768, 65535);

//     // Calculate total number of pairs
//     let n = collaborators.len();
//     let total_pairs = n * (n - 1) / 2;
//     println!("Generating {} collaboration pairs for {} collaborators", total_pairs, n);

//     // Generate pairs
//     for i in 0..n {
//         for j in (i + 1)..n {
//             let collaborator1 = &collaborators[i];
//             let collaborator2 = &collaborators[j];
//             let pair_name = format!("{}_{}", collaborator1, collaborator2);

//             println!("\nGenerating ports for pair: {}", pair_name);

//             // Generate ports for first collaborator
//             let ready_port1 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(ready_port1);

//             let intray_port1 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(intray_port1);

//             let gotit_port1 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(gotit_port1);

//             // Generate ports for second collaborator
//             let ready_port2 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(ready_port2);

//             let intray_port2 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(intray_port2);

//             let gotit_port2 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(gotit_port2);

//             // Create port assignment structures
//             let ports_data1 = AbstractTeamchannelNodeTomlPortsData {
//                 user_name: collaborator1.clone(),
//                 ready_port: ready_port1,
//                 intray_port: intray_port1,
//                 gotit_port: gotit_port1,
//             };

//             let ports_data2 = AbstractTeamchannelNodeTomlPortsData {
//                 user_name: collaborator2.clone(),
//                 ready_port: ready_port2,
//                 intray_port: intray_port2,
//                 gotit_port: gotit_port2,
//             };

//             // Store in the HashMap
//             port_assignments.insert(
//                 pair_name.clone(),
//                 vec![ReadTeamchannelCollaboratorPortsToml {
//                     collaborator_ports: vec![ports_data1, ports_data2],
//                 }],
//             );

//             println!("  {} ports: ready={}, intray={}, gotit={}",
//                 collaborator1, ready_port1, intray_port1, gotit_port1);
//             println!("  {} ports: ready={}, intray={}, gotit={}",
//                 collaborator2, ready_port2, intray_port2, gotit_port2);

//             debug_log!(
//                 "generate_pairwise_port_assignments: Pair '{}' assigned 6 ports",
//                 pair_name
//             );
//         }
//     }

//     // Final verification - ensure no local collisions
//     if local_used_ports.len() != (total_pairs * 6) as usize {
//         let error_msg = format!(
//             "CRITICAL: Local port collision detected! Expected {} unique ports but got {}",
//             total_pairs * 6,
//             local_used_ports.len()
//         );
//         eprintln!("{}", error_msg);
//         return Err(ThisProjectError::from(error_msg));
//     }

//     println!("\n Successfully generated {} unique ports across {} pairs",
//         local_used_ports.len(), total_pairs);

//     Ok(port_assignments)
// }

/// Generates pairwise port assignments for all collaborators.
///
/// # Purpose
/// Creates unique port assignments for every pair of collaborators in a team channel.
/// Each pair gets 6 unique ports (3 for each collaborator) that don't conflict with
/// any existing ports in the system.
///
/// # Parameters
/// * `collaborators` - Sorted list of all collaborators (including owner)
/// * `exclusion_list` - Set of all ports currently in use globally
///
/// # Returns
/// * `Ok(HashMap)` - Map of pair names to port assignments
/// * `Err(ThisProjectError)` - If unable to generate unique ports
///
/// # Port Ranges
/// * Primary: 49152-65535 (IANA Dynamic/Private ports)
/// * Fallback: 32768-65535 (Traditional ephemeral range)
pub fn generate_pairwise_port_assignments(
    collaborators: &[String],
    exclusion_list: &HashSet<u16>,
) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, ThisProjectError> {

    debug_log("GPPA Staring generate_pairwise_port_assignments");

    println!("\n=== Generating Pairwise Port Assignments ===");

    let mut port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();
    let mut local_used_ports: HashSet<u16> = HashSet::new();
    let mut rng = rand::rng();

    // Define port ranges
    const PRIMARY_RANGE: (u16, u16) = (49152, 65535);
    const FALLBACK_RANGE: (u16, u16) = (32768, 65535);

    // Calculate total number of pairs
    let n = collaborators.len();
    let total_pairs = n * (n - 1) / 2;
    println!("Generating {} collaboration pairs for {} collaborators", total_pairs, n);

    // Generate pairs
    for i in 0..n {
        for j in (i + 1)..n {
            let collaborator1 = &collaborators[i];
            let collaborator2 = &collaborators[j];
            let pair_name = format!("{}_{}", collaborator1, collaborator2);

            println!("\nGenerating ports for pair: {}", pair_name);

            // Generate ports for first collaborator
            let ready_port1 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(ready_port1);

            let intray_port1 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(intray_port1);

            let gotit_port1 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(gotit_port1);

            // Generate ports for second collaborator
            let ready_port2 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(ready_port2);

            let intray_port2 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(intray_port2);

            let gotit_port2 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(gotit_port2);

            // Create port assignment structures
            let ports_data1 = AbstractTeamchannelNodeTomlPortsData {
                user_name: collaborator1.clone(),
                ready_port: ready_port1,
                intray_port: intray_port1,
                gotit_port: gotit_port1,
            };

            let ports_data2 = AbstractTeamchannelNodeTomlPortsData {
                user_name: collaborator2.clone(),
                ready_port: ready_port2,
                intray_port: intray_port2,
                gotit_port: gotit_port2,
            };

            // Store in the HashMap with Vec wrapper (required by CoreNode)
            port_assignments.insert(
                pair_name.clone(),
                vec![ReadTeamchannelCollaboratorPortsToml {
                    collaborator_ports: vec![ports_data1, ports_data2],
                }],
            );

            println!("  {} ports: ready={}, intray={}, gotit={}",
                collaborator1, ready_port1, intray_port1, gotit_port1);
            println!("  {} ports: ready={}, intray={}, gotit={}",
                collaborator2, ready_port2, intray_port2, gotit_port2);

            debug_log!(
                "GPPA: Pair '{}' assigned 6 ports",
                pair_name
            );
        }
    }

    // Final verification - ensure no local collisions
    if local_used_ports.len() != (total_pairs * 6) as usize {
        let error_msg = format!(
            "GPPA error CRITICAL: Local port collision detected! Expected {} unique ports but got {}",
            total_pairs * 6,
            local_used_ports.len()
        );
        eprintln!("{}", error_msg);
        return Err(ThisProjectError::from(error_msg));
    }

    println!("\n Successfully generated {} unique ports across {} pairs",
        local_used_ports.len(), total_pairs);

    Ok(port_assignments)
}

/// Main function to create team channel port assignments with global collision prevention.
///
/// # Purpose
/// Orchestrates the complete process of creating port assignments for a new team channel:
/// 1. Generates global exclusion list
/// 2. Collects and validates collaborators
/// 3. Generates pairwise port assignments
/// 4. Handles collision scenarios
///
/// # Parameters
/// * `owner` - The owner creating the team channel
///
/// # Returns
/// * `Ok((collaborators, port_assignments))` - The validated collaborators and their port assignments
/// * `Err(ThisProjectError)` - If the process fails
pub fn create_teamchannel_port_assignments(
    owner: &str,
) -> Result<(Vec<String>, HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>), ThisProjectError> {
    println!("\n=== Creating Team Channel Port Assignments ===");
    println!("Owner: {}", owner);

    // Step 1: Generate global exclusion list
    println!("\nStep 1: Checking existing port assignments...");
    let exclusion_list = match global_ports_exclusion_list_generator() {
        Ok(ports) => {
            println!("Found {} ports already in use globally", ports.len());
            ports
        }
        Err(e) => {
            eprintln!("WARNING: Could not generate global exclusion list: {}", e);
            eprintln!("Proceeding with empty exclusion list (may cause collisions)");
            HashSet::new()
        }
    };

    // Step 2: Collect and validate collaborators
    println!("\nStep 2: Setting up collaborators...");
    let collaborators = collect_and_validate_collaborators(owner)?;

    // Step 3: Generate pairwise port assignments
    println!("\nStep 3: Generating port assignments...");
    let port_assignments = match generate_pairwise_port_assignments(&collaborators, &exclusion_list) {
        Ok(assignments) => assignments,
        Err(e) => {
            eprintln!("\n Failed to generate globally unique ports: {}", e);

            // Offer fallback option
            println!("\nWould you like to proceed with locally unique ports?");
            println!("(These may conflict with other team channels)");
            print!("Continue? [y/N]: ");
            io::stdout().flush().map_err(|e| {
                ThisProjectError::from(format!("Failed to flush stdout: {}", e))
            })?;

            let mut input = String::new();
            io::stdin().read_line(&mut input).map_err(|e| {
                ThisProjectError::from(format!("Failed to read user input: {}", e))
            })?;

            if input.trim().to_lowercase() == "y" {
                // Try again with empty exclusion list
                println!("\nGenerating locally unique ports...");
                generate_pairwise_port_assignments(&collaborators, &HashSet::new())?
            } else {
                return Err(ThisProjectError::from("Port assignment cancelled by user"));
            }
        }
    };

    println!("\n Team channel port assignments created successfully!");

    Ok((collaborators, port_assignments))
}


/// Checks if a specific port is currently in use on the system.
///
/// # Purpose
/// This function attempts to bind to a port to determine if it's already in use.
/// It's used during port collision detection to identify which conflicts are
/// most critical (ports already bound vs. just configuration conflicts).
///
/// # Arguments
/// * `port` - The port number to check
///
/// # Returns
/// * `true` - If the port is in use (binding fails)
/// * `false` - If the port is available (binding succeeds)
///
/// # Implementation Note
/// The function attempts to bind to both IPv4 and IPv6 addresses to ensure
/// comprehensive checking across different network configurations.
fn is_port_in_use(port: u16) -> bool {
    use std::net::{TcpListener, SocketAddr, IpAddr, Ipv4Addr, Ipv6Addr};

    // Check IPv4
    let ipv4_addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), port);
    let ipv4_in_use = TcpListener::bind(ipv4_addr).is_err();

    // Check IPv6
    let ipv6_addr = SocketAddr::new(IpAddr::V6(Ipv6Addr::LOCALHOST), port);
    let ipv6_in_use = TcpListener::bind(ipv6_addr).is_err();

    // Port is in use if either binding fails
    ipv4_in_use || ipv6_in_use
}

/// Checks if UMA should NOT perform a hard restart.
///
/// Check for a Restart
/// The logic here is easy to get backwards:
/// There are two flags that are checked
/// regarding shut-down.
/// There is the normal ~should_continue flag,
/// which is checked with a should_halt_uma checker.
/// To keep things symetric, there is a parallel
/// system for hard-reboot, working the same way
/// with one exception:
/// If you should restart this also re-reset the 'quit'
/// function (so you are not in an infinite loop of quit-restart).
/// if you check should_not_hard_restart() (this function)
/// and find that you should (quite) not-restart, it works the same way.
/// This function reads the hard restart flag file to determine if UMA should perform a hard restart.
/// The logic works as follows:
///
/// - If file contains "0": Return true (meaning: do NOT restart, normal shutdown)
/// - If file contains "1": Return false (meaning: yes DO restart)
/// - On file read errors: Return false (safer to restart than get stuck)
///
/// When a restart is indicated (function returns false), it also resets the
/// continue_uma flag to "1" to prevent an infinite loop of quit-restart.
///
/// # Returns
///
/// * `bool` - true if UMA should NOT restart (normal shutdown), false if it SHOULD restart
pub fn should_not_hard_restart() -> bool {
    // Get the absolute path to the hard restart flag file
    let file_path = match get_hard_restart_flag_path() {
        Ok(path) => path,
        Err(e) => {
            debug_log!("Error resolving path to hard restart flag: {}", e);
            return false; // Default to restarting if we can't resolve the path
        }
    };

    // Read the file content
    let file_content = match fs::read_to_string(&file_path) {
        Ok(content) => content.trim().to_string(),
        Err(e) => {
            debug_log!("Error reading hard restart flag file: {}", e);
            return false; // Default to restarting if we can't read the file
        }
    };

    // Process the flag value
    let should_not_restart = file_content == "0";

    if should_not_restart {
        debug_log!("Hard restart flag is '0': Normal shutdown (no restart)");
        return true; // Do NOT restart (normal shutdown)
    } else {
        debug_log!("Hard restart flag is '1': Will restart UMA");

        // Reset the continue_uma flag to avoid quit-restart loop
        match initialize_continue_uma_signal() {
            Ok(_) => debug_log!("Reset continue_uma flag to '1' for restart"),
            Err(e) => debug_log!("Warning: Failed to reset continue_uma flag: {}", e)
        }

        return false; // DO restart
    }
}

// TODO not used? use with dubug_assert flag?
/// Prints the status of all control flags for debugging purposes.
///
/// This function reads and displays the values and locations of all flag files
/// used by UMA. This can be helpful for troubleshooting boot and shutdown issues.
pub fn debug_print_flag_status() {
    debug_log!("===== UMA FLAG STATUS =====");

    // Check continue_uma flag
    match get_continue_uma_path() {
        Ok(path) => {
            debug_log!("Continue UMA flag path: {:?}", path);
            match fs::read_to_string(&path) {
                Ok(content) => debug_log!("Continue UMA flag value: '{}'", content.trim()),
                Err(e) => debug_log!("Error reading Continue UMA flag: {}", e)
            }
        },
        Err(e) => debug_log!("Error resolving Continue UMA flag path: {}", e)
    }

    // Check hard restart flag
    match get_hard_restart_flag_path() {
        Ok(path) => {
            debug_log!("Hard restart flag path: {:?}", path);
            match fs::read_to_string(&path) {
                Ok(content) => debug_log!("Hard restart flag value: '{}'", content.trim()),
                Err(e) => debug_log!("Error reading hard restart flag: {}", e)
            }
        },
        Err(e) => debug_log!("Error resolving hard restart flag path: {}", e)
    }

    // Check sync start OK flag
    match get_sync_start_ok_flag_path() {
        Ok(path) => {
            debug_log!("Sync start OK flag path: {:?}", path);
            match fs::read_to_string(&path) {
                Ok(content) => debug_log!("Sync start OK flag value: '{}'", content.trim()),
                Err(e) => debug_log!("Error reading sync start OK flag: {}", e)
            }
        },
        Err(e) => debug_log!("Error resolving sync start OK flag path: {}", e)
    }

    debug_log!("===== END FLAG STATUS =====");
}

// // old relative path version
// fn dir_at_path_is_empty_returns_false(path_to_dir: &Path) -> bool {

//     debug_log!("dir_at_path_is_empty_returns_false()-> Checking if directory is empty: {:?}", path_to_dir);
//     if let Ok(mut entries) = fs::read_dir(path_to_dir) {

//         entries.next().is_some() // Returns false if the directory is empty
//     } else {
//         true // Assume directory is NOT empty if an error occurs reading it
//     }
// }


// use std::fs;
// use std::path::Path;
// use crate::manage_absolute_executable_directory_relative_paths::make_input_path_name_abs_executabledirectoryrelative_nocheck;

/// Checks if a directory is empty and returns the appropriate boolean value.
///
/// This function attempts to check if the directory at the given path is empty.
/// It converts the provided path to an absolute path relative to the executable's
/// location before performing the check.
///
/// # Arguments
///
/// * `path_to_dir` - A reference to a Path that represents the directory to check.
///                   This can be either an absolute path or a path relative to the executable.
///
/// # Returns
///
/// * `bool` - Returns `false` if the directory exists and is empty.
///            Returns `true` if the directory is not empty OR if any error occurs
///            (e.g., the directory doesn't exist, permissions issues, etc.)
///
/// # Note
///
/// The function name indicates its inverse behavior: it returns `false` when
/// a directory is empty, and `true` otherwise. This pattern is maintained for
/// backward compatibility with existing code.
fn dir_at_path_is_empty_returns_false(path_to_dir: &Path) -> bool {
    debug_log!("dir_at_path_is_empty_returns_false()-> Checking if directory is empty: {:?}", path_to_dir);

    // Try to convert the path to an absolute path relative to the executable
    let abs_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(path_to_dir) {
        Ok(path) => path,
        Err(e) => {
            debug_log!("Error resolving absolute path: {}", e);
            return true; // Assume NOT empty (return true) if path conversion fails
        }
    };

    debug_log!("Checking absolute path: {:?}", abs_path);

    // Check if the path exists and is a directory
    if !abs_path.exists() {
        debug_log!("Path does not exist: {:?}", abs_path);
        return true; // Assume NOT empty (return true) if path doesn't exist
    }

    if !abs_path.is_dir() {
        debug_log!("Path exists but is not a directory: {:?}", abs_path);
        return true; // Assume NOT empty (return true) if path is not a directory
    }

    // Attempt to read the directory entries
    match fs::read_dir(&abs_path) {
        Ok(mut entries) => {
            // If there are any entries, the directory is not empty
            let has_entries = entries.next().is_some();

            if has_entries {
                debug_log!("Directory is NOT empty: {:?}", abs_path);
                true // Directory is NOT empty, return true
            } else {
                debug_log!("Directory is empty: {:?}", abs_path);
                false // Directory IS empty, return false
            }
        },
        Err(e) => {
            debug_log!("Error reading directory entries: {}", e);
            true // Assume NOT empty (return true) if an error occurs reading the directory
        }
    }
}

fn get_ipv4_addresses() -> Result<Option<Vec<Ipv4Addr>>, io::Error> {
    let mut addresses = Vec::new();
    loop {
        let mut input = String::new();
        io::stdin().read_line(&mut input)?;
        let input = input.trim();

        if input.to_lowercase() == "done" {
            break;
        } else if input.is_empty() {
            return Ok(None);
        }

        let addr: Ipv4Addr = input.parse()
                               .map_err(|_| io::Error::new(io::ErrorKind::InvalidInput, "Invalid IPv4 address"))?;
        addresses.push(addr);
    }
    Ok(Some(addresses))
}

fn get_ipv6_addresses() -> Result<Option<Vec<Ipv6Addr>>, io::Error> {
    let mut addresses = Vec::new();
    loop {
        let mut input = String::new();
        io::stdin().read_line(&mut input)?;
        let input = input.trim();

        if input.to_lowercase() == "done" {
            break;
        } else if input.is_empty() {
            return Ok(None);
        }

        let addr: Ipv6Addr = input.parse()
                               .map_err(|_| io::Error::new(io::ErrorKind::InvalidInput, "Invalid IPv6 address"))?;
        addresses.push(addr);
    }
    Ok(Some(addresses))
}

// pub fn sign_toml_file(file_path: &Path) -> Result<(), Error> {
//     let output = MainStdCommand::new("gpg")
//         .arg("--clearsign")
//         .arg(file_path)
//         .output()
//         .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to run GPG: {}", e)))?;

//     if output.status.success() {
//         fs::write(file_path, output.stdout)?; // Overwrite with the signed content
//         debug_log!("File {} successfully signed with GPG.", file_path.display());
//         Ok(())
//     } else {
//         debug_log!("GPG signing failed: {}", String::from_utf8_lossy(&output.stderr));
//         Err(Error::new(ErrorKind::Other, "GPG signing failed"))
//     }
// }

pub fn verify_toml_signature(file_path: &Path) -> Result<(), Error> {
    let output = StdCommand::new("gpg")
        .arg("--verify")
        .arg(file_path)
        .output()
        .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to run GPG: {}", e)))?;

    if output.status.success() {
        debug_log!("GPG signature of {} is valid.", file_path.display());
        Ok(())
    } else {
        debug_log!("GPG verification failed: {}", String::from_utf8_lossy(&output.stderr));
        Err(Error::new(ErrorKind::Other, "GPG signature invalid"))
    }
}

// //relative path version
// fn debug_log(message: &str) {
//     if DEBUG_FLAG {
//         let mut file = OpenOptions::new()
//             .append(true)
//             .create(true)
//             .open("uma.log")
//             .expect("Failed to open log file");

//         writeln!(file, "{}", message).expect("Failed to write to log file");
//     }
// }
/// Logs a debug message to a log file located relative to the executable directory.
///
/// This function only writes to the log file if the DEBUG_FLAG is set to true.
/// e.g. const DEBUG_FLAG: bool = true;
/// The log file (uma.log) will be created in the same directory as the executable
/// if it doesn't exist, or appended to if it already exists.
///
/// # Arguments
///
/// * `message` - The debug message to write to the log file
///
/// # Note
///
/// This function handles errors internally and does not propagate them
/// to the caller, to maintain backward compatibility with existing code.
fn debug_log(message: &str) {
    if DEBUG_FLAG {
        // Get the log file path relative to the executable
        let log_file_path_result = make_input_path_name_abs_executabledirectoryrelative_nocheck("uma.log");

        if let Err(path_error) = log_file_path_result {
            // Print error but don't panic
            eprintln!("Failed to determine log file path: {}", path_error);
            return;
        }

        let log_file_path = log_file_path_result.unwrap(); // Safe after check

        // Open the log file
        let file_result = std::fs::OpenOptions::new()
            .append(true)
            .create(true)
            .open(&log_file_path);

        if let Err(file_error) = file_result {
            eprintln!("Failed to open log file at {}: {}", log_file_path.display(), file_error);
            return;
        }

        let mut file = file_result.unwrap(); // Safe after check

        // Write to the log file
        if let Err(write_error) = writeln!(file, "{}", message) {
            eprintln!("Failed to write to log file: {}", write_error);
        }
    }
}

/* TODO
 * A. read-copy
 * B. clearsigned toml
 * C. gpg-option
 * ...is this for... nodes and adressbook or just messages? (maybe messages clerasigned too...)

this is for all files send-able...
maybe
1. check for clearsign
2. validate if clearsign
3. check for .gpgtoml
4. validate if .gpgtoml
5. extract time?
 */
/// TODO this must be replaced
/// read timestamps from .toml files, like you were born to do just that...on Mars!!
///
fn get_toml_file_updated_at_timestamp(file_path: &Path) -> Result<u64, ThisProjectError> {
    debug_log!(
        "Starting get_toml_file_updated_at_timestamp, file_path -> {:?}",
        file_path
    );

    let toml_string = std::fs::read_to_string(file_path)?;

    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = toml::from_str(&toml_string)?;

    let timestamp = toml_value
        .get("updated_at_timestamp") // Access the "updated_at_timestamp" field
        .and_then(Value::as_integer) // Try to convert to an integer
        .and_then(|ts| ts.try_into().ok()) // Try to convert to u64
        .ok_or_else(|| {
            ThisProjectError::InvalidData(format!(
                "Missing or invalid 'updated_at_timestamp' in TOML file: {}",
                file_path.display()
            ))
        })?;

    debug_log!(
        "[Done] get_toml_file_updated_at_timestamp, timestamp -> {:?}",
        timestamp
    );

    Ok(timestamp)
}

/// Macro for logging debug messages to a file located relative to the executable directory.
///
/// This macro formats the input like println! and only executes if DEBUG_FLAG is true.
/// The log file (uma.log) will be created in the same directory as the executable
/// if it doesn't exist, or appended to if it already exists.
///
/// # Examples
///
/// ```
/// debug_log!("Starting application");
/// debug_log!("Value: {}", some_variable);
/// ```
#[macro_export]
macro_rules! debug_log {
    ($($arg:tt)*) => {
        if DEBUG_FLAG {
            // Get the log file path relative to the executable
            let log_file_path_result = crate::manage_absolute_executable_directory_relative_paths::make_input_path_name_abs_executabledirectoryrelative_nocheck("uma.log");

            match log_file_path_result {
                Ok(log_file_path) => {
                    // Open the log file in append mode, creating it if it doesn't exist
                    match std::fs::OpenOptions::new()
                        .append(true)
                        .create(true)
                        .open(&log_file_path)
                    {
                        Ok(mut file) => {
                            // Write the formatted message to the file
                            if let Err(write_err) = writeln!(file, $($arg)*) {
                                eprintln!("Failed to write to log file: {}", write_err);
                            }
                        },
                        Err(open_err) => {
                            eprintln!("Failed to open log file at {}: {}",
                                log_file_path.display(), open_err);
                        }
                    }
                },
                Err(path_err) => {
                    eprintln!("Failed to determine log file path: {}", path_err);
                }
            }
        }
    };
}

// maybe deprecated
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct RemoteCollaboratorPortsData {
    remote_collaborator_name: String,
    remote_ipv6_address: Ipv6Addr,
    remote_collaborator_gpg_publickey_id: String,
    remote_public_gpg: String,
    remote_sync_interval: u64, // depricated? controlled by team-channel?
    remote_ready_port__their_desk_you_listen: u16, // locally: 'you' listen to their port on 'their' desk
    remote_intray_port__their_desk_you_send: u16, // locally: 'you' add files to their port on 'their' desk
    remote_gotit_port__their_desk_you_listen: u16, // locally: 'you' listen to their port on 'their' desk
}

/// struct for reading/extracting raw abstract port assignments
/// from the team_channels/NAME/node.toml
#[derive(Debug, Deserialize, Serialize, Clone, Hash, PartialEq, Eq)] // Add
struct AbstractTeamchannelNodeTomlPortsData {
    user_name: String,
    ready_port: u16,
    intray_port: u16,
    gotit_port: u16, // locally: 'you' listen to their port on 'their' desk
}

/// Represents port assignments for a collaborator in a `CoreNode`.
///
/// This struct holds six different ports used for communication and synchronization
/// between two collaborators.
/// Because Rust does not automatically deal with 'list of dicts' in python terms
/// this struct is a list (array) of 'dictionaries/hashmaps' which are a separate struct
/// so this list is a single list, that is a list of other structs that are dicts/hashmaps
#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct ReadTeamchannelCollaboratorPortsToml {
    /// The port used by the REMOTE collaborator to signal readiness to receive data.
    collaborator_ports: Vec<AbstractTeamchannelNodeTomlPortsData>,
}


/// Instance-Role-Specific Local-Meeting-Room-Struct
/// This is no longer for an abstract set of data
/// that can be used in different ways in different instances,
/// This is now one of those specific instances with local roles
/// and one local way of using those data.
/// The abstract port-assignements will be converted into a
/// disambiguated and clarified specific local instance roles
/// set of port assignments:
/// - local_user_role,
/// - remote_collaborator_role.
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct MeetingRoomSyncDataset {
    local_user_name: String,
    local_user_salt_list: Vec<u128>,
    local_user_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    local_user_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    local_user_gpg_publickey_id: String,
    local_user_public_gpg: String,
    local_user_sync_interval: u64,
    local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen for files sent by the other collaborator
    local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk

    remote_collaborator_name: String,
    remote_collaborator_salt_list: Vec<u128>,
    remote_collaborator_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    remote_collaborator_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    remote_collaborator_gpg_publickey_id: String,
    remote_collaborator_public_gpg: String,
    remote_collaborator_sync_interval: u64,
    remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
    remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' add files to their port on 'their' desk
    remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
}

/// ForLocalOwnerDeskThread data from MeetingRoomSyncDataset
/// Get Needed, When Needed
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct ForLocalOwnerDeskThread {
    local_user_name: String,
    remote_collaborator_name: String,
    local_user_salt_list: Vec<u128>,
    remote_collaborator_salt_list: Vec<u128>,
    local_user_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    local_user_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    remote_collaborator_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    remote_collaborator_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    local_user_gpg_publickey_id: String,
    local_user_public_gpg: String,
    local_user_sync_interval: u64,
    local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen for files sent by the other collaborator
    local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
}

/// ForRemoteCollaboratorDeskThread data from MeetingRoomSyncDataset
/// Get Needed, When Needed
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct ForRemoteCollaboratorDeskThread {
    remote_collaborator_name: String,
    local_user_name: String,
    remote_collaborator_salt_list: Vec<u128>,
    local_user_salt_list: Vec<u128>,
    remote_collaborator_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    remote_collaborator_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    local_user_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    local_user_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    remote_collaborator_gpg_publickey_id: String,
    remote_collaborator_public_gpg: String,
    remote_collaborator_sync_interval: u64,
    remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
    remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' add files to their port on 'their' desk
    remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
}

/// for translate_port_assignments() to export as
/// Get Needed, When Needed
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct RoleBasedLocalPortSet {
    local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen for files sent by the other collaborator
    local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
    remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' add files to their port on 'their' desk
    remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
}

fn translate_port_assignments(
    local_user_name: &str,
    remote_collaborator_name: &str,
    abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
) -> Result<RoleBasedLocalPortSet, MyCustomError> {
    debug_log!("tpa: Entering translate_port_assignments() function");

    // 1. Construct the key for the meeting room based on user names
    let meeting_room_key = get_meeting_room_lookup_fieldkey(local_user_name, remote_collaborator_name);
    debug_log!("tpa 1. Meeting room key: {}", meeting_room_key);

    // 2. Get the port assignment array for this meeting room
    let meeting_room_ports = abstract_collaborator_port_assignments
        .get(&meeting_room_key)
        .ok_or_else(|| MyCustomError::from(io::Error::new(
            io::ErrorKind::NotFound,
            format!("tpa 2. Port assignments not found for meeting room: {}", meeting_room_key),
        )))?;

    // 3. Extract local and remote ports from the vector
    let mut local_ports = None;
    let mut remote_ports = None;

    // Iterate through the ReadTeamchannelCollaboratorPortsToml structs
    for port_data in meeting_room_ports {
        // Iterate through the collaborator_ports vector within each struct
        for port_set in &port_data.collaborator_ports {
            if port_set.user_name == local_user_name {
                local_ports = Some(port_set.clone());
            } else if port_set.user_name == remote_collaborator_name {
                remote_ports = Some(port_set.clone());
            }
        }
    }

    // 4. Ensure both local and remote ports were found
    let local_ports = local_ports.ok_or_else(|| MyCustomError::from(io::Error::new(
        io::ErrorKind::NotFound,
        format!("tpa 4. Local port assignments not found for user: {}", local_user_name),
    )))?;
    let remote_ports = remote_ports.ok_or_else(|| MyCustomError::from(io::Error::new(
        io::ErrorKind::NotFound,
        format!("tpa 4. Remote port assignments not found for user: {}", remote_collaborator_name),
    )))?;

    // 5. Construct and return the RoleBasedLocalPortSet
    Ok(RoleBasedLocalPortSet {
        local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: local_ports.ready_port,
        localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: local_ports.intray_port,
        local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: local_ports.gotit_port,
        remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: remote_ports.ready_port,
        remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: remote_ports.intray_port,
        remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: remote_ports.gotit_port,
    })
}

/// Encrypts data using GPG with the specified recipient's public key.
///
/// This function uses the `gpg` command-line tool to encrypt the data. It assumes that `gpg`
/// is installed and accessible in the system's PATH.
///
/// # Arguments
///
/// * `data`: The data to encrypt as a byte slice.
/// * `recipient_public_key`: The recipient's public GPG key.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`:  A `Result` containing the encrypted data as a `Vec<u8>` on success,
///   or a `ThisProjectError` on failure.
fn encrypt_with_gpg(data: &[u8], recipient_public_key: &str) -> Result<Vec<u8>, ThisProjectError> {
    /*
    // // Example Use:

    // 5. Encrypt clearsigned data
    let encrypted_data = encrypt_with_gpg(&clearsigned_data, &public_key_string)?;

    // 6. Create export directory if it doesn't exist
    let export_dir = PathBuf::from("invites_updates/addressbook_invite/export");
    create_dir_all(&export_dir)?;

    // 7. Write encrypted data to file. Use a timestamp to avoid overwriting.
    let export_file_path = export_dir.join(format!(
        "{}_addressbook_{}.gpgtoml",
        local_owner_username,
        get_current_unix_timestamp() // Or use a UUID
    ));
    let mut file = File::create(&export_file_path)?;
    file.write_all(&encrypted_data)?;
    */

    let mut child = StdCommand::new("gpg")
        .arg("--encrypt")
        .arg("--recipient")
        .arg(recipient_public_key)
        .stdin(std::process::Stdio::piped())
        .stdout(std::process::Stdio::piped())
        .stderr(std::process::Stdio::piped())
        .spawn()?;

    // Write the data to encrypt to the GPG process's standard input
    {
        let stdin = child.stdin.as_mut().ok_or_else(|| ThisProjectError::NetworkError("Failed to open stdin for GPG process".to_string()))?;
        stdin.write_all(data)?;
    }

    let output = child.wait_with_output()?;

    if output.status.success() {
        Ok(output.stdout) // Return the encrypted data
    } else {
        // Log the GPG error
        let stderr = String::from_utf8_lossy(&output.stderr);
        debug_log!("GPG encryption error: {}", stderr);
        Err(ThisProjectError::NetworkError(format!("GPG encryption failed: {}", stderr)))
    }
}




// // Helper function for translate_port_assignments
// // to construct the meeting room key
// Helper function to construct the meeting room key
fn get_meeting_room_lookup_fieldkey(user1: &str, user2: &str) -> String {
    let mut names = vec![user1, user2];
    names.sort(); // Ensure consistent key regardless of user order
    format!("{}_{}", names[0], names[1])
}

// Helper function to extract ports from a TOML table
fn extract_ports_from_table(port_set: &toml::map::Map<String, Value>) -> Result<AbstractTeamchannelNodeTomlPortsData, MyCustomError> {
    Ok(AbstractTeamchannelNodeTomlPortsData {
        user_name: port_set
            .get("user_name")
            .ok_or_else(|| MyCustomError::from(io::Error::new(
                io::ErrorKind::InvalidData,
                "Missing 'user_name' in port set",
            )))?
            .as_str()
            .ok_or_else(|| MyCustomError::from(io::Error::new(
                io::ErrorKind::InvalidData,
                "'user_name' is not a string",
            )))?
            .to_string(),
        ready_port: port_set
            .get("ready_port")
            .ok_or_else(|| MyCustomError::from(io::Error::new(
                io::ErrorKind::InvalidData,
                "Missing 'ready_port' in port set",
            )))?
            .as_integer()
            .ok_or_else(|| MyCustomError::from(io::Error::new(
                io::ErrorKind::InvalidData,
                "'ready_port' is not an integer",
            )))? as u16,
        intray_port: port_set
            .get("intray_port")
            .ok_or_else(|| MyCustomError::from(io::Error::new(
                io::ErrorKind::InvalidData,
                "Missing 'intray_port' in port set",
            )))?
            .as_integer()
            .ok_or_else(|| MyCustomError::from(io::Error::new(
                io::ErrorKind::InvalidData,
                "'intray_port' is not an integer",
            )))? as u16,
        gotit_port: port_set
            .get("gotit_port")
            .ok_or_else(|| MyCustomError::from(io::Error::new(
                io::ErrorKind::InvalidData,
                "Missing 'gotit_port' in port set",
            )))?
            .as_integer()
            .ok_or_else(|| MyCustomError::from(io::Error::new(
                io::ErrorKind::InvalidData,
                "'gotit_port' is not an integer",
            )))? as u16,
    })
}

/// Extracts the list of collaborator names from a team channel's `node.toml` file.
///
/// This function reads the `node.toml` file at the specified path, parses the TOML data,
/// and extracts the collaborator names from the `abstract_collaborator_port_assignments` table.
///
/// # Arguments
///
/// * `node_toml_path` - The path to the team channel's `node.toml` file.
///
/// # Returns
///
/// * `Result<Vec<String>, String>` - A `Result` containing a vector of collaborator names
///   on success, or a `String` describing the error on failure.
fn get_collaborator_names_from_node_toml(node_toml_path: &Path) -> Result<Vec<String>, String> {
    debug_log!("GCNRNT 4. Entering get_collaborator_names_from_node_toml() with path: {:?}", node_toml_path);

    // // 1. Read the node.toml file
    // let toml_string = match std::fs::read_to_string(node_toml_path) {
    //     Ok(content) => {
    //         debug_log!("GCNRNT Successfully read node.toml file. Contents:\n{}", content);
    //         content
    //     },
    //     Err(e) => return Err(format!("GCNRNT Error reading node.toml file: {}", e)),
    // };

    // // 2. Parse the TOML data
    // // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    // let toml_value: Value = match toml::from_str(&toml_string) {
    //     Ok(value) => {
    //         debug_log!("GCNRNT Successfully parsed TOML data. Value: {:?}", value);
    //         value
    //     },
    //     Err(e) => return Err(format!("GCNRNT Error parsing node.toml data: {}", e)),
    // };


    let target_path_string = node_toml_path.to_string_lossy();


    ////////////////////////////////
    // Extract Owner for Key Lookup
    ////////////////////////////////
    let owner_name_of_toml_field_key_to_read = "owner";
    debug_log!(
        "LCNFTF: Reading file owner from field '{}' for security validation",
        owner_name_of_toml_field_key_to_read
    );

    // get node_owners_public_gpg_key

    let file_owner_username = match read_single_line_string_field_from_toml(
        &node_toml_path.to_string_lossy(),  // TODO convert to string?
        owner_name_of_toml_field_key_to_read,
    ) {
        Ok(username) => {
            if username.is_empty() {
                // Convert to String error instead of GpgError
                return Err(format!(
                    "LCNFTF: Field '{}' is empty in TOML file. File owner is required for security validation.",
                    owner_name_of_toml_field_key_to_read
                ));
            }
            username
        }
        Err(e) => {
            // Convert to String error instead of GpgError
            return Err(format!(
                "LCNFTF: Failed to read file owner from field '{}': {}",
                owner_name_of_toml_field_key_to_read, e
            ));
        }
    };
    println!("LCNFTF: File owner: '{}'", file_owner_username);
    debug_log!("LCNFTF: File owner: '{}'", file_owner_username);

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(format!(
                "LCNFTF: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            ));
        }
    };

    // Get the UME temp directory path with explicit String conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| {
            let gpg_error = GpgError::ValidationError(
                format!("LCNFTF: Failed to get UME temp directory path: {}", io_err)
            );
            // Convert GpgError to String for the function's return type
            format!("LCNFTF: {:?}", gpg_error)
        })?;

    // Extract the addressbook path string with inline error conversion
    let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_owner_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| format!(
        "LCNFTF: Failed to get addressbook path for user '{}': {:?}",
        file_owner_username,
        e
    ))?;

    // // Define cleanup closure
    // let cleanup_closure = || {
    //     let _ = cleanup_collaborator_temp_file(
    //         &node_toml_path,
    //         &base_uma_temp_directory_path,
    //         );
    //     let _ = cleanup_collaborator_temp_file(
    //         &addressbook_readcopy_path_string,
    //         &base_uma_temp_directory_path,
    //         );
    // };

    /*
    pub fn read_stringarray_from_clearsigntoml_without_publicgpgkey(
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
        name_of_toml_field_key_to_read: &str,
    ) -> Result<Vec<String>, String> {
    */

    // Example: Read _ from the clearsigned TOML file
    let collaborator_names_array = read_stringarray_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &target_path_string,           // Target clearsigned filepath string
        "teamchannel_collaborators_with_access"                // Field to read
    ).map_err(|e| {
        // cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: description_for_tui sFailed to read description_for_tui: {}", e)
    })?;


    // // 3. Extract collaborator names from abstract_collaborator_port_assignments
    // let mut collaborator_names = Vec::new();
    // debug_log!("GCNRNT Looking for table 'abstract_collaborator_port_assignments'");
    // if let Some(collaborator_assignments_table) = toml_value.get("abstract_collaborator_port_assignments").and_then(Value::as_table) {
    //     debug_log!("GCNRNT Found table 'abstract_collaborator_port_assignments'. Entries: {:?}", collaborator_assignments_table);
    //     for (pair_name, _) in collaborator_assignments_table {
    //         debug_log!("GCNRNT Processing pair: {}", pair_name);
    //         // Split the pair name (e.g., "alice_bob") into individual names
    //         let names: Vec<&str> = pair_name.split('_').collect();
    //         collaborator_names.extend(names.iter().map(|&s| s.to_string()));
    //     }
    // } else {
    //     debug_log!("GCNRNT Table 'abstract_collaborator_port_assignments' not found.");
    // }

    debug_log!("GCNRNT Exiting get_collaborator_names_from_node_toml() with names: {:?}", collaborator_names_array);
    // 4. Return the list of collaborator names
    Ok(collaborator_names_array)
}

/// Extracts the abstract port assignments from a team channel's `node.toml` file.
///
/// This function reads the `node.toml` file, parses the TOML data, and extracts the
/// `collaborator_port_assignments` table, returning it as a HashMap.
///
/// # Arguments
///
/// * `node_toml_path` - The path to the team channel's `node.toml` file.
///
/// # Returns
///
/// * `Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, String>` - A `Result` containing a HashMap of
///   collaborator pair names to their port assignments on success, or a `String` describing the error on failure.
fn get_abstract_port_assignments_from_node_toml(
    node_toml_path: &Path
) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, String> {
    debug_log!("GAPAFNT 5. starting get_abstract_port_assignments_from_node_toml(): 1. Entering function with path: {:?}", node_toml_path);

    // 1. Read the node.toml file
    let toml_string = match std::fs::read_to_string(node_toml_path) {
        Ok(content) => {
            debug_log!("GAPAFNT: 2. Successfully read node.toml file.");
            content
        },
        Err(e) => {
            let error_message = format!("GAPAFNT: Error reading node.toml file: {}", e);
            debug_log!("{}", error_message);
            return Err(error_message);
        }
    };

    // 2. Parse the TOML data
    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = match toml::from_str(&toml_string) {
        Ok(value) => {
            debug_log!("GAPAFNT: 3. Successfully parsed TOML data.");
            value
        },
        Err(e) => {
            let error_message = format!("GAPAFNT: Error parsing node.toml data: {}", e);
            debug_log!("{}", error_message);
            return Err(error_message);
        }
    };

    // 3. Extract the abstract_collaborator_port_assignments table
    let mut abstract_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();
    debug_log!("GAPAFNT: 4. Looking for 'abstract_collaborator_port_assignments' table.");
    if let Some(collaborator_assignments_table) = toml_value.get("abstract_collaborator_port_assignments").and_then(Value::as_table) {
        debug_log!("GAPAFNT: 5. Found 'abstract_collaborator_port_assignments' table.");
        for (pair_name, pair_data) in collaborator_assignments_table {
            debug_log!("GAPAFNT: 6. Processing pair: {}", pair_name);
            if let Some(ports_array) = pair_data.get("collaborator_ports").and_then(Value::as_array) {
                debug_log!("GAPAFNT: 7. Found 'collaborator_ports' array for pair: {}", pair_name);
                let mut ports_for_pair = Vec::new();
                for port_data in ports_array {
                    debug_log!("GAPAFNT: 8. Processing port data: {:?}", port_data);
                    let port_data_str = toml::to_string(&port_data).unwrap();

                    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    let collaborator_port: AbstractTeamchannelNodeTomlPortsData = toml::from_str(&port_data_str)
                        .map_err(|e| format!("GAPAFNT: Error deserializing collaborator port: {}", e))?;
                    debug_log!("GAPAFNT: 9. Deserialized port data: {:?}", collaborator_port);
                    ports_for_pair.push(ReadTeamchannelCollaboratorPortsToml {
                        collaborator_ports: vec![collaborator_port],
                    });
                }
                debug_log!("GAPAFNT: 10. Inserting ports for pair: {} into HashMap.", pair_name);
                abstract_port_assignments.insert(pair_name.to_string(), ports_for_pair);
            } else {
                debug_log!("GAPAFNT: 11. 'collaborator_ports' array not found for pair: {}", pair_name);
            }
        }
    } else {
        debug_log!("GAPAFNT: 12. 'abstract_collaborator_port_assignments' table not found.");
    }

    debug_log!("GAPAFNT: 13. Exiting function with port assignments: {:?}", abstract_port_assignments);
    // 4. Return the abstract_port_assignments HashMap
    Ok(abstract_port_assignments)
}

// ALPHA VERSION
// Function to read a simple string from a file
pub fn read_state_string(file_name: &str) -> Result<String, std::io::Error> {
    // TODO needs to be exe-relative etc...
    debug_log!("read_state_string (file_name)->{}", file_name);

    let file_path = get_sessionstateitems_path()?.join(file_name);

    debug_log!("read_state_string 1. Channel directory path (file_path)->{:?}", file_path);

    fs::read_to_string(file_path)
}

// ALPHA VERSION
// Function to validate a simple string
/*
Where: Add this to  state_utils.rs module or a similar location.

Purpose: You can define validation rules based on the specific session state item. For example, checking if a string is not empty, if a TOML file has the expected structure, or even performing GPG signature verification.
*/
pub fn validate_state_string(value: &str) -> bool {
    !value.is_empty()
}


// use std::sync::mpmc::Sender;
use std::sync::mpsc::{self, Sender, Receiver, TryRecvError};

/// Thread message types for browser inter-thread communication
///
/// These messages are passed between the input thread, watch thread,
/// and main thread to coordinate actions in the message browser.
enum BrowserThreadMessage {
    KeyInput(char),     // A character was typed
    Backspace,          // Backspace key pressed
    Enter,              // Enter key pressed
    DirectoryChanged,   // Directory contents changed (new messages)
    Exit,               // Request to exit browser
}

/// Modal message viewing states
///
/// Controls whether the browser updates with new messages
/// or prioritizes uninterrupted user input.
#[derive(PartialEq, Clone, Copy, Debug)]
enum MessageViewMode {
    Refresh, // Allow real-time updates, input may be interrupted
    Insert,  // No updates, focus on uninterrupted input
}

/// Input thread function for message browser
///
/// Continuously reads keyboard input and sends appropriate messages
/// to the main thread through the channel.
fn run_message_browser_input_thread(sender: Sender<BrowserThreadMessage>) {
    let mut stdin = io::stdin();
    let mut buffer = [0; 1];

    loop {
        if stdin.read_exact(&mut buffer).is_ok() {
            let message = match buffer[0] {
                b'\n' | b'\r' => BrowserThreadMessage::Enter,
                8 | 127 => BrowserThreadMessage::Backspace,
                b'q' => BrowserThreadMessage::Exit,
                c => BrowserThreadMessage::KeyInput(c as char),
            };

            // If send fails, the receiver has been dropped, so exit thread
            if sender.send(message).is_err() {
                break;
            }
        }

        thread::sleep(Duration::from_millis(10));
    }
}

/// Directory watch thread for message browser
///
/// Periodically checks for changes in the message directory
/// and notifies the main thread when changes are detected.
fn run_message_browser_watch_thread(sender: Sender<BrowserThreadMessage>, path: PathBuf) {
    let mut last_hash = 0;

    loop {
        thread::sleep(Duration::from_millis(2000));

        match calculate_message_directory_hash(&path) {
            Ok(current_hash) => {
                if current_hash != last_hash {
                    last_hash = current_hash;

                    // If send fails, the receiver has been dropped, so exit thread
                    if sender.send(BrowserThreadMessage::DirectoryChanged).is_err() {
                        break;
                    }
                }
            },
            Err(_) => {
                // Error calculating hash - directory might be inaccessible
                // Just continue and try again next cycle
            }
        }
    }
}

/// Calculate a hash of the message directory contents
///
/// Used to efficiently detect when directory contents have changed
/// without having to compare all files.
fn calculate_message_directory_hash(path: &Path) -> io::Result<u64> {
    let mut hasher = DefaultHasher::new();

    for entry in fs::read_dir(path)? {
        let entry = entry?;
        let metadata = entry.metadata()?;

        // Hash filename, size, and modification time
        entry.file_name().hash(&mut hasher);
        metadata.len().hash(&mut hasher);
        if let Ok(modified) = metadata.modified() {
            modified.hash(&mut hasher);
        }
    }

    Ok(hasher.finish())
}


// Compression Algorithm Enum
#[derive(Debug, Deserialize, Serialize, Clone, PartialEq)]
enum CompressionAlgorithm {
    Deflate,
    Brotli,
    Zstd,
    None,
}

/// Represents the different input modes of the UMA application's TUI.
///
/// The TUI can be in one of these modes at a time, determining how user input
/// is interpreted and handled.
#[derive(PartialEq, Clone, Debug)]
enum InputMode {
    /// MainCommand Mode:  The default mode. The user can type commands (e.g., "help", "quit", "m")
    /// to navigate the project graph or interact with UMA features.
    MainCommand,
    /// Insert Text Mode:  Used for entering text, such as instant messages. In this mode,
    /// user input is treated as text to be added to the current context.
    InsertText,
    TaskCommand,
}

struct App {
    tui_directory_list: Vec<String>, // For directories in the current path
    tui_file_list: Vec<String>,       // For files in the current path
    tui_focus: usize,                  // Index of the highlighted item in the TUI list
    tui_textmessage_list: Vec<String>, // Content of messages in the current IM conversation
    tui_width: usize,
    tui_height: usize,

    current_path: PathBuf,              // Current directory being used
    input_mode: InputMode,
    command_input_integer:  Option<usize>,
    current_command_input: Option<String>,
    current_text_input: Option<String>,
    graph_navigation_instance_state: GraphNavigationInstanceState,

    // For Task Display
    next_path_lookup_table: HashMap<usize, PathBuf>,
    ordered_task_column_list: Vec<String>,
    task_display_table: Vec<String>, // ?

}


impl App {
    /*


    */
    fn update_next_path_lookup_table(&mut self) {

        debug_log("Starting update_next_path_lookup_table ");

        // Clear previous entries.
        self.next_path_lookup_table.clear();

        match self.input_mode {
            InputMode::MainCommand => {
                for (i, item) in self.tui_directory_list.iter().enumerate() {
                    let next_path = self.current_path.join(item);
                    self.next_path_lookup_table.insert(i + 1, next_path);
                }
                }
            InputMode::TaskCommand => {
                if self.is_at_task_browser_root() { // COLUMN Navigation (if at root)
                    for (i, column) in self.tui_directory_list.iter().enumerate() {
                        let next_path = self.current_path.join(column);
                        self.next_path_lookup_table.insert(i + 1, next_path);
                    }
                } else { //TASK Navigation if within a column
                    for (i, item) in self.tui_file_list.iter().enumerate() {
                        if let Some(task_path) = self.get_full_task_path(i){
                        self.next_path_lookup_table.insert(i + 1, task_path);
                        }
                    }
                }
            }
            InputMode::InsertText => {
                // Do nothing, as no file-system based paths are used for inputting messages.
            }
            }
    }

    // fn new(graph_navigation_instance_state: GraphNavigationInstanceState) -> App {
    //     App {
    //         tui_focus: 0,
    //         current_path: PathBuf::from("project_graph_data/team_channels"),

    /// Creates a new App instance with state initialized from executable-relative paths
    ///
    /// # Arguments
    /// * `graph_navigation_instance_state` - Initial graph navigation state
    ///
    /// # Returns
    /// * `Result<App, io::Error>` - A new App instance or an error if paths cannot be resolved
    fn new(graph_navigation_instance_state: GraphNavigationInstanceState) -> Result<App, io::Error> {
        // Get executable-relative path for project data
        let executable_parent_directory = get_absolute_path_to_executable_parentdirectory()?;
        let target_path = executable_parent_directory.join("project_graph_data/team_channels");

        // Verify the path exists
        if !abs_executable_directory_relative_exists(&target_path)? {
            return Err(io::Error::new(
                io::ErrorKind::NotFound,
                format!("Required directory not found: {:?}", target_path)
            ));
        }

        // Canonicalize the path
        let current_exe_dir_relative_abs_path_canonicalized = target_path.canonicalize()?;

        // Create and return the App instance
        Ok(App {
            tui_focus: 0,
            current_path: current_exe_dir_relative_abs_path_canonicalized,
            input_mode: InputMode::MainCommand,
            tui_file_list: Vec::new(), // Initialize files
            tui_directory_list: Vec::new(), // Initialize files
            tui_textmessage_list: Vec::new(), // Initialize files
            tui_width: 80, // default posix terminal size
            tui_height: 42, // default posix terminal size
            command_input_integer: None,
            current_command_input: None,
            current_text_input: None,
            graph_navigation_instance_state, // Initialize the field

            next_path_lookup_table: HashMap::new(),
            ordered_task_column_list: Vec::new(),
            task_display_table: Vec::new(),
        })
    }
    /*

    ## Task Display

    struct GraphNavigationInstanceState {
        local_owner_user: String, // Store the local user data here
        // local_owner_hash_list: Vec<u8>,
        active_team_channel: String,
        default_im_messages_expiration_days: u64,
        default_task_nodes_expiration_days: u64,
        tui_height: u8,
        tui_width: u8,
        current_full_file_path: PathBuf,
        current_node_teamchannel_collaborators_with_access: Vec<String>,
        current_node_name: String,
        current_node_owner: String,
        current_node_description_for_tui: String,
        current_node_directory_path: PathBuf,
        current_node_unique_id: Vec<u8>,
        current_node_members: Vec<String>,
        home_square_one: bool,

        next_path_lookup_table: HashMap<usize, PathBuf>,
        ordered_task_column_list: Vec<String>, // not needed here?
        task_display_table: Vec<String>, // ?
        }

    impl GraphNavigationInstanceState {
        maybe populate the next_path_lookup_table and task_display_table
        using functions here
    }

    note: columns are (node) directories with a formatted directory name:
    int underscore string: sequence number left to right, underscore, and display name
    to be systematically processed.

    note: the TUI display table should have int space string for the columns and for the tasks

    ### Task Display Parts:
    1. a sequence counter (to mostly increment)
    2. an ordered list of column paths
    3. display table: maybe array of strings (for the TUI to show as a simple table)
    4. path lookup dictionary: a {int:path} path lookup dictionary (for the user-interface to select next path)

    ### Column-item Steps: columns are (node) directories
    1. Preset/Reset the Task Display Parts (see above)
    2. read the "#_str" column names, start the sequence counter after the highest
    3. add column names and numbers (from #_str") to the path lookup dict (these are the column headers)
    4. add column numbers and names to display table (maybe truncate list name depending on display size if name is too long)
    5. add column path to ordered column path list

    ### Task-item Steps: tasks are (node) directories
    1. tasks: iterate through the ordered column path list (in order), for each column:
    2. simple sort the tasks (directories) in the column (directory), alphanumeric
    3. use and increment sequence counter. use the current sequence int and when done increment
    4. add task names and numbers (from #_str") to the path lookup dict: add as rows in the current column
    5. add task number and name to path lookup dictionary


    // example
    let mut graph_state = GraphNavigationInstanceState { /* initialize fields */ };
    graph_state.update_task_display()?;
    graph_state.print_task_display(); // For debugging

    */

    // /// Updates the task display components based on the current directory
    // pub fn update_task_display(&mut self) -> std::io::Result<()> {
    //     // Reset display components
    //     self.next_path_lookup_table.clear();
    //     self.ordered_task_column_list.clear();
    //     self.task_display_table.clear();

    //     let mut sequence_counter: usize = 1;

    //     // Clone the PathBuf to avoid borrowing issues
    //     // Get absolute path from current directory
    //     let channel_dir_path = self.current_path.clone();
    //     debug_log!(
    //         "update_task_display, channel_dir_path -> {:?}",
    //         channel_dir_path
    //     );


    //     // // A. Print the absolute path of the channel directory
    //     // match channel_dir_path.canonicalize() {
    //     //     Ok(abs_path) => debug_log!("update_task_display. Absolute channel directory path: {:?}", abs_path),
    //     //     Err(e) => debug_log!("Error update_task_display. getting absolute path of channel directory: {}", e),
    //     // }

    //     // Process columns
    //     self.process_columns(&channel_dir_path, &mut sequence_counter)?;

    //     // Process tasks in each column
    //     self.process_tasks(&mut sequence_counter)?;

    //     Ok(())
    // }

    //     /// Process column directories and create headers
    //     fn process_columns(&mut self, channel_dir_path: &Path, sequence_counter: &mut usize) -> std::io::Result<()> {
    //         let mut columns: Vec<(usize, String, PathBuf)> = Vec::new();

    //         // Collect and parse column directories
    //         for entry in fs::read_dir(channel_dir_path)? {
    //             let entry = entry?;
    //             let path = entry.path();
    //             if path.is_dir() {
    //                 if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
    //                     if let Some((seq, display_name)) = parse_directory_name(name) {
    //                         columns.push((seq, display_name.to_string(), path));
    //                         *sequence_counter = (*sequence_counter).max(seq + 1);
    //                     }
    //                 }
    //             }
    //         }

    //         // Sort columns by sequence number
    //         columns.sort_by_key(|(seq, _, _)| *seq);

    //         // Create header row
    //         let mut header_row = String::new();
    //         for (seq, display_name, path) in &columns {
    //             // Add to path lookup
    //         self.next_path_lookup_table.insert(*seq, path.clone());


    //             // Add to ordered column list
    //             self.ordered_task_column_list.push(path.to_string_lossy().to_string());

    //             // Add to display table header
    //             let truncated_name = truncate_string(&display_name,
    //                 (self.tui_width as usize / columns.len()).saturating_sub(5));
    //             header_row.push_str(&format!("{:3} {:<20} ", seq, truncated_name));
    //         }

    //         self.task_display_table.push(header_row);
    //         Ok(())
    //     }

    //     /// Process tasks within each column
    //     fn process_tasks(&mut self, sequence_counter: &mut usize) -> std::io::Result<()> {
    //         let max_rows = self.get_max_tasks_count()?;
    //         let column_count = self.ordered_task_column_list.len();

    //         // Initialize rows
    //         for _ in 0..max_rows {
    //             let mut row = String::new();
    //             for _ in 0..column_count {
    //                 row.push_str(&" ".repeat(25)); // Adjust spacing based on your needs
    //             }
    //             self.task_display_table.push(row);
    //         }

    //         // Process each column
    //         for (col_idx, column_path_str) in self.ordered_task_column_list.iter().enumerate() {
    //             let column_path = Path::new(column_path_str);
    //             let mut tasks: Vec<(String, PathBuf)> = Vec::new();

    //             // Collect tasks in current column
    //             for entry in fs::read_dir(column_path)? {
    //                 let entry = entry?;
    //                 let path = entry.path();
    //                 if path.is_dir() {
    //                     if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
    //                         tasks.push((name.to_string(), path));
    //                     }
    //                 }
    //             }

    //             // Sort tasks
    //             tasks.sort_by(|(a, _), (b, _)| a.cmp(b));

    //             // Process each task
    //             for (row_idx, (task_name, task_path)) in tasks.iter().enumerate() {
    //                 if row_idx + 1 >= self.task_display_table.len() {
    //                     break;
    //                 }

    //                 // Add to path lookup
    //                 self.next_path_lookup_table.insert(*sequence_counter, task_path.clone());

    //                 // Update display table
    //                 let display_text = format!("{:3} {}", sequence_counter,
    //                     truncate_string(task_name, 20));

    //                 // Update the specific position in the row
    //                 let row = &mut self.task_display_table[row_idx + 1];
    //                 let start_pos = col_idx * 25;
    //                 let end_pos = start_pos + display_text.len().min(25);
    //                 if start_pos < row.len() {
    //                     let mut new_row = row[..start_pos].to_string();
    //                     new_row.push_str(&display_text);
    //                     new_row.push_str(&row[end_pos..]);
    //                     self.task_display_table[row_idx + 1] = new_row;
    //                 }

    //                 *sequence_counter += 1;
    //             }
    //         }

    //         Ok(())
    //     }

    /// Updates the task display components and returns formatted headers and data
    pub fn update_task_display(&mut self) -> std::io::Result<(Vec<String>, Vec<Vec<String>>)> {
        // Reset display components
        self.next_path_lookup_table.clear();
        self.ordered_task_column_list.clear();
        self.task_display_table.clear();

        let mut sequence_counter: usize = 1;
        // Clone the PathBuf to avoid borrowing issues
        // Get absolute path from current directory
        let channel_dir_path = self.current_path.clone();
        debug_log!(
            "update_task_display, channel_dir_path -> {:?}",
            channel_dir_path
        );

        // Initialize vectors for headers and data
        let mut headers: Vec<String> = Vec::new();
        let mut data: Vec<Vec<String>> = Vec::new();

        // Process columns and collect headers
        self.process_columns(&channel_dir_path, &mut sequence_counter, &mut headers)?;

        // Process tasks and collect data
        self.process_tasks(&mut sequence_counter, &headers, &mut data)?;

        Ok((headers, data))
    }

    fn process_columns(
        &mut self,
        current_dir: &Path,
        sequence_counter: &mut usize,
        headers: &mut Vec<String>
    ) -> std::io::Result<()> {
        let mut columns: Vec<(usize, String, PathBuf)> = Vec::new();

        // Collect and parse column directories
        for entry in fs::read_dir(current_dir)? {
            let entry = entry?;
            let path = entry.path();
            if path.is_dir() {
                if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
                    if let Some((seq, display_name)) = parse_directory_name(name) {
                        columns.push((seq, display_name.to_string(), path));
                        *sequence_counter = (*sequence_counter).max(seq + 1);
                    }
                }
            }
        }

        // Sort columns by sequence number
        columns.sort_by_key(|(seq, _, _)| *seq);

        // Process columns
        for (seq, display_name, path) in columns {
            // Add to path lookup
            self.next_path_lookup_table.insert(seq, path.clone());

            // Add to ordered column list
            self.ordered_task_column_list.push(path.to_string_lossy().to_string());

            // Add to headers
            let truncated_name = truncate_string(&display_name, 12);
            headers.push(format!("{:3} {}", seq, truncated_name));
        }

        Ok(())
    }

    fn process_tasks(
        &mut self,
        sequence_counter: &mut usize,
        headers: &[String],
        data: &mut Vec<Vec<String>>
    ) -> std::io::Result<()> {
        let max_rows = self.get_max_tasks_count()?;

        // Initialize data rows
        for _ in 0..max_rows {
            data.push(vec![String::new(); headers.len()]);
        }

        // Process each column
        for (col_idx, column_path_str) in self.ordered_task_column_list.iter().enumerate() {
            let column_path = Path::new(column_path_str);
            let mut tasks: Vec<(String, PathBuf)> = Vec::new();

            // Collect tasks in current column
            for entry in fs::read_dir(column_path)? {
                let entry = entry?;
                let path = entry.path();
                if path.is_dir() {
                    if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
                        tasks.push((name.to_string(), path));
                    }
                }
            }

            // Sort tasks
            tasks.sort_by(|(a, _), (b, _)| a.cmp(b));

            // Process each task
            for (row_idx, (task_name, task_path)) in tasks.iter().enumerate() {
                if row_idx >= data.len() {
                    break;
                }

                // Add to path lookup
                self.next_path_lookup_table.insert(*sequence_counter, task_path.clone());

                // Add to data matrix
                let display_text = format!("{:3} {}",
                    sequence_counter,
                    truncate_string(task_name, 12)
                );

                data[row_idx][col_idx] = display_text;

                *sequence_counter += 1;
            }
        }

        Ok(())
    }


    /// Gets the maximum number of tasks across all columns
    fn get_max_tasks_count(&self) -> std::io::Result<usize> {
        let mut max_count = 0;
        for column_path_str in &self.ordered_task_column_list {
            let count = fs::read_dir(column_path_str)?
                .filter_map(|entry| entry.ok())
                .filter(|entry| entry.path().is_dir())
                .count();
            max_count = max_count.max(count);
        }
        Ok(max_count)
    }

    /// Prints the current task display (for debugging)
    pub fn print_task_display(&self) {
        for row in &self.task_display_table {
            println!("{}", row);
        }
    }


    fn handle_tui_action(&mut self) -> Result<(), io::Error> { // Now returns Result
        debug_log("app fn handle_tui_action() started");

        // self.update_next_path_lookup_table();

        if self.is_in_team_channel_list() {
            debug_log("is_in_team_channel_list");
            debug_log(&format!("handle_tui_action() current_path: {:?}", self.current_path));

            let input = tiny_tui::get_input()?; // Get input here
            if let Ok(index) = input.parse::<usize>() {
                let item_index = index - 1; // Adjust for 0-based indexing
                if item_index < self.tui_directory_list.len() {
                    let selected_channel = &self.tui_directory_list[item_index];
                    debug_log(&format!("Selected channel: {}", selected_channel)); // Log the selected channel name

                    self.current_path = self.current_path.join(selected_channel);

                    debug_log(&format!("handle_tui_action() New current_path: {:?}", self.current_path)); // Log the updated current path

                    self.graph_navigation_instance_state.current_full_file_path = self.current_path.clone();
                    self.graph_navigation_instance_state.nav_graph_look_read_node_toml();

                    // Log the state after loading node.toml
                    debug_log(&format!("handle_tui_action() State after nav_graph_look_read_node_toml: {:?}", self.graph_navigation_instance_state));

                    // ... enter IM browser or other features ...
                } else {
                    debug_log("Invalid index.");
                }
            }
        } else if self.is_in_message_posts_browser_directory() {
            // ... handle other TUI actions ...
            debug_log("else if self.is_in_message_posts_browser_directory()");


        }
        debug_log("end app fn handle_tui_action()");
        Ok(()) // Return Ok if no errors
    }

    fn get_focused_channel_path(&self) -> Option<PathBuf> {
        let channel_name = self.tui_file_list.get(self.tui_focus)?;
        Some(self.current_path.join(channel_name))
    }

    // // TODO not being used
    // fn enter_message_posts_browser(&mut self, channel_path: PathBuf) {
    //     // Update the current path to the instant message browser directory within the selected channel
    //     self.current_path = channel_path.join("message_posts_browser");
    //     // Load the instant messages for this channel
    //     self.load_im_messages(); // No need to pass any arguments
    //     // Reset the TUI focus to the beginning of the message list
    //     self.tui_focus = 0;
    // }



    /// Modal Interactive Message Browser with Dual Refresh/Insert Modes
    ///
    /// # Purpose
    /// Provides a message viewing and composing interface that balances:
    /// - Real-time message updates (in Refresh mode)
    /// - Uninterrupted text input (in Insert mode)
    ///
    /// # Mode System
    /// The function implements a modal interface with two states:
    /// 1. REFRESH MODE: Terminal updates automatically when new messages arrive
    ///    - Pros: Always shows latest messages
    ///    - Cons: May interrupt typing
    ///
    /// 2. INSERT MODE: Terminal freezes updates to allow uninterrupted typing
    ///    - Pros: User can type without interruption
    ///    - Cons: May miss new messages until mode is toggled
    ///
    /// # User Experience
    /// - Toggle between modes: Press ENTER with empty input
    /// - Exit browser: Type 'q', 'quit', 'b', or 'back'
    /// - Send message: Type message and press ENTER in either mode
    ///
    /// # Implementation Details
    /// - Uses three concurrent threads:
    ///   1. Main thread: Manages state and rendering
    ///   2. Input thread: Captures user keystrokes
    ///   3. Watch thread: Monitors directory for changes
    ///
    /// # Parameters
    /// * `channel_path` - Path to the channel containing the message_posts_browser directory
    ///
    /// # Returns
    /// * `io::Result<()>` - Success or IO error
    ///
    /// # Thread Safety
    /// - Uses message passing (mpsc channels) between threads
    /// - No shared mutable state between threads
    /// - Safe shutdown of all threads on exit
    ///
    /// # State Management
    /// - Updates App.current_path to message directory
    /// - Sets App.input_mode appropriately
    /// - Loads messages via App.load_im_messages()
    /// - Restores previous path on exit
    pub fn enter_modal_message_posts_browser(&mut self, channel_path: PathBuf) -> io::Result<()> {
        debug_log("starting enter_modal_message_posts_browser()");

        // Store the original path for restoration on exit
        let original_path = self.current_path.clone();

        // Update the current path to the instant message browser directory
        self.current_path = channel_path.join("message_posts_browser");

        debug_log!(
            "enter_modal_message_posts_browser() app.current_path after joining 'message_posts_browser': {:?}",
            self.current_path
        );

        // Verify directory exists
        if !self.current_path.exists() {
            println!("enter_modal_message_posts_browser Message directory not found!");
            self.current_path = original_path; // Restore original path
            return Ok(());
        }

        // Load initial messages
        self.load_im_messages();

        // Initialize the modal message browser state
        let mut current_message_view_mode = MessageViewMode::Refresh;
        let mut user_input_buffer = String::new();
        let terminal_width = self.graph_navigation_instance_state.tui_width as u16;
        let terminal_height = self.graph_navigation_instance_state.tui_height as u16;

        // Set up channel for thread communication
        let (message_tx, message_rx): (Sender<BrowserThreadMessage>, Receiver<BrowserThreadMessage>) = mpsc::channel();

        // ----- SETUP INPUT THREAD -----
        let input_thread_sender = message_tx.clone();
        let input_thread = thread::spawn(move || {
            run_message_browser_input_thread(input_thread_sender);
        });

        // ----- SETUP DIRECTORY WATCH THREAD -----
        let watch_thread_sender = message_tx.clone();
        let watch_directory_path = self.current_path.clone();
        let watch_thread = thread::spawn(move || {
            run_message_browser_watch_thread(watch_thread_sender, watch_directory_path);
        });

        // ----- MAIN BROWSER LOOP -----
        let mut needs_display_refresh = true;

        // Initial render
        self.render_message_browser_screen(&current_message_view_mode, &user_input_buffer, terminal_width, terminal_height)?;

        // Process events until exit
        'browser_loop: loop {
            match message_rx.try_recv() {
                Ok(BrowserThreadMessage::KeyInput(c)) => {
                    if current_message_view_mode == MessageViewMode::Insert || !needs_display_refresh {
                        user_input_buffer.push(c);
                        needs_display_refresh = true;
                    }
                },
                Ok(BrowserThreadMessage::Backspace) => {
                    user_input_buffer.pop();
                    needs_display_refresh = true;
                },
                Ok(BrowserThreadMessage::Enter) => {
                    if user_input_buffer.is_empty() {
                        // Toggle between Refresh and Insert modes
                        let previous_mode = current_message_view_mode;
                        current_message_view_mode = match current_message_view_mode {
                            MessageViewMode::Refresh => MessageViewMode::Insert,
                            MessageViewMode::Insert => MessageViewMode::Refresh,
                        };

                        // If switching from Insert to Refresh, immediately refresh
                        if previous_mode == MessageViewMode::Insert && current_message_view_mode == MessageViewMode::Refresh {
                            self.load_im_messages();
                        }

                        needs_display_refresh = true;
                    } else {
                        // Process non-empty input (possibly a command or message)
                        // match user_input_buffer.as_str() {
                        //     "q" | "quit" | "b" | "back" => {
                        //         // Exit message browser
                        //         break 'browser_loop;
                        //     },
                        //     _ => {
                        //         // Send message
                        //         self.add_new_message_from_input(&user_input_buffer)?;
                        //         user_input_buffer.clear();
                        //         self.load_im_messages();
                        //         needs_display_refresh = true;
                        //     }
                        // }
                        match user_input_buffer.as_str() {
                            "q" | "quit" | "b" | "back" => {
                                break 'browser_loop;
                            },
                            "--custom" => {
                                // Launch custom message Q&A
                                user_input_buffer.clear();
                                self.create_custom_message_interactive()?;
                                self.load_im_messages();
                                needs_display_refresh = true;
                            },
                            _ => {
                                // Normal message send
                                self.add_new_message_from_input(&user_input_buffer)?;
                                user_input_buffer.clear();
                                self.load_im_messages();
                                needs_display_refresh = true;
                            }
                        }
                    }
                },
                Ok(BrowserThreadMessage::DirectoryChanged) => {
                    if current_message_view_mode == MessageViewMode::Refresh {
                        self.load_im_messages();
                        needs_display_refresh = true;
                    }
                },
                Ok(BrowserThreadMessage::Exit) => {
                    // Exit due to quit command
                    break 'browser_loop;
                },
                Err(TryRecvError::Empty) => {
                    // No messages, continue
                },
                Err(TryRecvError::Disconnected) => {
                    // Channel closed, exit
                    break 'browser_loop;
                }
            }

            // Refresh display if needed
            if needs_display_refresh {
                self.render_message_browser_screen(&current_message_view_mode, &user_input_buffer, terminal_width, terminal_height)?;
                needs_display_refresh = false;
            }

            // Small sleep to prevent tight loop
            thread::sleep(Duration::from_millis(10));
        }

        // Clean up and exit
        // No need to join threads as they'll be cleaned up when program exits

        // Restore original path and mode
        self.current_path = original_path;
        self.input_mode = InputMode::MainCommand;

        // Final update before returning to main app
        self.update_directory_list()?;

        // Clear screen for clean transition
        print!("\x1B[2J\x1B[1;1H");
        io::stdout().flush()?;

        debug_log("ending: ender_modal...");
        Ok(())
    }

    /// Create custom message with interactive Q&A prompts
    ///
    /// Prompts user for:
    /// - Recipients (from available collaborators)
    /// - Expiration time (in minutes)
    /// - Encryption setting (unless required by policy)
    /// - Message text
    ///
    /// # Returns
    ///
    /// * `Ok(())` - Message created successfully or user cancelled
    /// * `Err(io::Error)` - If message creation fails
    fn create_custom_message_interactive(&mut self) -> io::Result<()> {
        // Clear screen for clean Q&A interface
        print!("\x1B[2J\x1B[1;1H");
        io::stdout().flush()?;

        println!("=== Custom Message Creation ===\n");

        // 1. Get Recipients with retry loop
        let recipients = loop {
            println!("Available collaborators:");
            for (i, collab) in self.graph_navigation_instance_state
                .current_node_teamchannel_collaborators_with_access
                .iter()
                .enumerate()
            {
                println!("  {}. {}", i + 1, collab);
            }
            println!("\nRecipients (comma-separated names, or ENTER for all, or 'c' to cancel):");

            let mut input = String::new();
            io::stdin().read_line(&mut input)?;
            let input = input.trim();

            if input == "c" || input == "cancel" {
                println!("\n Message creation cancelled");
                println!("\nPress ENTER to continue...");
                let mut _dummy = String::new();
                io::stdin().read_line(&mut _dummy)?;
                return Ok(());
            }

            if input.is_empty() {
                // Empty = all recipients
                break Vec::new();
            }

            // Validate recipients
            let mut validated = Vec::new();
            let mut all_valid = true;

            for name in input.split(',') {
                let trimmed = name.trim();
                if self.graph_navigation_instance_state
                    .current_node_teamchannel_collaborators_with_access
                    .contains(&trimmed.to_string())
                {
                    validated.push(trimmed.to_string());
                } else {
                    println!(" Error: '{}' not in collaborator list", trimmed);
                    all_valid = false;
                }
            }

            if all_valid && !validated.is_empty() {
                break validated;
            }

            if !all_valid {
                println!("\nPlease try again with valid names.\n");
            }
        };

        // 2. Get Expiration (in minutes)
        let expires_minutes = loop {
            println!("\nExpiration time (in minutes from now, or ENTER for default 30 days):");

            let mut input = String::new();
            io::stdin().read_line(&mut input)?;
            let input = input.trim();

            if input.is_empty() {
                // Default: 30 days
                break 30 * 24 * 60;
            }

            match input.parse::<u64>() {
                Ok(minutes) if minutes > 0 => break minutes,
                _ => {
                    println!(" Invalid input. Please enter a positive number or press ENTER for default.");
                }
            }
        };

        // 3. Get Encryption Setting (with override check)
        let use_encryption = if self.graph_navigation_instance_state.message_post_gpgtoml_required == Some(true) {
            println!("\nEncryption: REQUIRED by channel policy (gpgtoml will be used)");
            true
        } else {
            loop {
                println!("\nUse encryption? (y/n, default: n):");

                let mut input = String::new();
                io::stdin().read_line(&mut input)?;

                match input.trim().to_lowercase().as_str() {
                    "y" | "yes" => break true,
                    "n" | "no" | "" => break false,
                    _ => {
                        println!(" Invalid input. Please enter 'y' or 'n'.");
                    }
                }
            }
        };

        // 4. Get Message Text (single line only)
        let text_message = loop {
            println!("\nMessage text:");

            let mut input = String::new();
            io::stdin().read_line(&mut input)?;
            let text = input.trim();

            if text.is_empty() {
                println!(" Message text cannot be empty.");
            } else {
                break text.to_string();
            }
        };

        // 5. Preview and Confirm
        println!("\n--- Message Preview ---");

        let recipients_display = if recipients.is_empty() {
            "All".to_string()
        } else {
            recipients.join(", ")
        };

        println!("To: {}", recipients_display);
        println!("Expires: {} minutes from now", expires_minutes);
        println!("Encrypted: {}", use_encryption);
        println!("Text: {}", text_message);

        loop {
            println!("\nSend this message? (y/n):");

            let mut input = String::new();
            io::stdin().read_line(&mut input)?;

            match input.trim().to_lowercase().as_str() {
                "y" | "yes" => {
                    // Create and send message
                    self.send_custom_message(
                        recipients,
                        expires_minutes,
                        use_encryption,
                        text_message,
                    )?;

                    println!("\n Message sent!");
                    break;
                }
                "n" | "no" => {
                    println!("\n Message cancelled");
                    break;
                }
                _ => {
                    println!(" Invalid input. Please enter 'y' or 'n'.");
                }
            }
        }

        // Pause before returning to browser
        println!("\nPress ENTER to continue...");
        let mut _dummy = String::new();
        io::stdin().read_line(&mut _dummy)?;

        Ok(())
    }

    /// Send custom message with specified settings
    ///
    /// Helper function that handles the actual message creation and saving.
    fn send_custom_message(
        &mut self,
        recipients: Vec<String>,
        expires_minutes: u64,
        use_encryption: bool,
        text_message: String,
    ) -> io::Result<()> {
        // Calculate expiration timestamp
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
            .as_secs();

        let expires_at = now + (expires_minutes * 60);

        // Read metadata to get node info
        let metadata_path = self.current_path.join("0.toml");
        let metadata_string = fs::read_to_string(&metadata_path)?;

        // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
        let metadata: NodeInstMsgBrowserMetadata = toml::from_str(&metadata_string)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("TOML error: {}", e)))?;

        // Get next sequential file path
        let file_path = get_next_message_file_path(
            &self.current_path,
            &self.graph_navigation_instance_state.local_owner_user
        );

        debug_log!("SCMSG: Creating message at: {:?}", file_path);

        /*
        impl MessagePostFile {
            fn new(
                graph_navigation_instance_state: &GraphNavigationInstanceState,
                owner: &str, // owner
                node_name: &str, // node_name
                filepath_in_node: &str, //filepath_in_node
                text_message: &str, // text_message
                recipients_list: Vec<String>, // teamchannel_collaborators_with_access
                messagepost_gpgtoml: bool,
                expires_at: Option<u64>,  // NEW: Custom expiration, or None for default
            ) -> MessagePostFile {
        */

        // Create message with custom settings
        let message = MessagePostFile::new(
            &self.graph_navigation_instance_state,
            &self.graph_navigation_instance_state.local_owner_user,
            &metadata.node_name,
            &metadata.path_in_node,
            &text_message,
            if recipients.is_empty() {
                self.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access.clone()
            } else {
                recipients.clone()
            },
            use_encryption,
            Some(expires_at),
        );

        // Serialize
        let toml_data = toml::to_string(&message)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Serialization error: {}", e)))?;

        // Save based on encryption setting
        if use_encryption {
            let base_path = file_path.with_extension("");
            save_message_as_gpgtoml(&base_path, &toml_data)?;
        } else {
            save_message_as_clearsigned_toml(&file_path, &toml_data)?;
        }

        // Write sync flags
        let final_recipients = if recipients.is_empty() {
            &self.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access
        } else {
            &recipients
        };

        let _ = write_newfile_sendq_flag(final_recipients, &file_path);

        debug_log!("SCMSG: Message created successfully");

        Ok(())
    }

    // fn create_custom_message_interactive(&mut self) -> io::Result<()> {
    //     // Clear screen for clean Q&A interface
    //     print!("\x1B[2J\x1B[1;1H");
    //     io::stdout().flush()?;

    //     println!("=== Custom Message Creation ===\n");

    //     // 1. Get Recipients
    //     println!("Available collaborators:");
    //     for (i, collab) in self.graph_navigation_instance_state
    //         .current_node_teamchannel_collaborators_with_access
    //         .iter()
    //         .enumerate()
    //     {
    //         println!("  {}. {}", i + 1, collab);
    //     }
    //     println!("\nRecipients (comma-separated names, or ENTER for all):");

    //     let recipients = read_and_validate_recipients(
    //         &self.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access
    //     )?;

    //     // 2. Get Expiration (in minutes)
    //     println!("\nExpiration time (in minutes from now, or ENTER for default 30 days):");
    //     let expires_minutes = read_expiration_minutes()?;

    //     // 3. Get Encryption Setting (with override check)
    //     let use_encryption = if self.graph_navigation_instance_state.message_post_gpgtoml_required == Some(true) {
    //         println!("\nEncryption: REQUIRED by channel policy (gpgtoml will be used)");
    //         true
    //     } else {
    //         println!("\nUse encryption? (y/n, default: n):");
    //         read_yes_no_choice()?
    //     };

    //     // 4. Get Message Text
    //     // 4. Get Message Text (SINGLE LINE)
    //     println!("\nMessage text:");
    //     let mut text_message = String::new();
    //     io::stdin().read_line(&mut text_message)?;
    //     let text_message = text_message.trim();

    //     if text_message.is_empty() {
    //         println!(" Message cannot be empty");
    //         println!("\nPress ENTER to continue...");
    //         let mut _dummy = String::new();
    //         io::stdin().read_line(&mut _dummy)?;
    //         return Ok(());
    //     }

    //     // 5. Confirm and create
    //     println!("\n--- Message Preview ---");

    //     let recipients_display = if recipients.is_empty() {
    //         "All".to_string()
    //     } else {
    //         recipients.join(", ")
    //     };

    //     println!("To: {}", recipients_display);
    //     println!("Expires: {} minutes from now", expires_minutes);
    //     println!("Encrypted: {}", use_encryption);
    //     println!("Text: {}", text_message);
    //     println!("\nSend this message? (y/n):");


    //     if read_yes_no_choice()? {
    //         // Calculate expiration timestamp
    //         let now = SystemTime::now()
    //             .duration_since(UNIX_EPOCH)
    //             .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
    //             .as_secs();

    //         let expires_at = now + (expires_minutes * 60);

    //         // Read metadata to get node info
    //         let metadata_path = self.current_path.join("0.toml");
    //         let metadata_string = fs::read_to_string(&metadata_path)?;
    //         let metadata: NodeInstMsgBrowserMetadata = toml::from_str(&metadata_string)
    //             .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("TOML error: {}", e)))?;

    //         /*
    //         fn new(
    //             graph_navigation_instance_state: &GraphNavigationInstanceState,

    //             owner: &str, // owner
    //             node_name: &str, // node_name
    //             filepath_in_node: &str, //filepath_in_node
    //             text_message: &str, // text_message
    //             recipients_list: Vec<String>, // teamchannel_collaborators_with_access
    //             messagepost_gpgtoml: bool,
    //             expires_at: Option<u64>,  // NEW: Custom expiration, or None for default
    //         ) -> MessagePostFile {
    //         */

    //         // Create message directly with custom settings
    //         let message = MessagePostFile::new(
    //             &self.graph_navigation_instance_state,
    //             &self.graph_navigation_instance_state.local_owner_user,
    //             &metadata.node_name,
    //             &metadata.path_in_node,
    //             &text_message,
    //             if recipients.is_empty() {
    //                 self.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access.clone()
    //             } else {
    //                 recipients.clone()
    //             },
    //             use_encryption,
    //             Some(expires_at),  // NEW: Custom expiration
    //         );

    //         // Generate filename and save
    //         let timestamp = now;
    //         let filename = format!("{}_{}.toml",
    //             timestamp,
    //             self.graph_navigation_instance_state.local_owner_user
    //         );
    //         let file_path = self.current_path.join(filename);

    //         // Serialize
    //         let toml_data = toml::to_string(&message)
    //             .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Serialization error: {}", e)))?;

    //         // Save based on encryption setting
    //         if use_encryption {
    //             let base_path = file_path.with_extension("");
    //             save_message_as_gpgtoml(&base_path, &toml_data)?;
    //         } else {
    //             save_message_as_clearsigned_toml(&file_path, &toml_data)?;
    //         }

    //         // Write sync flags
    //         let final_recipients = if recipients.is_empty() {
    //             &self.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access
    //         } else {
    //             &recipients
    //         };
    //         let _ = write_newfile_sendq_flag(final_recipients, &file_path);

    //         println!("\n Message sent!");
    //     } else {
    //         println!("\n Message cancelled");
    //     }

    //     // Pause before returning to browser
    //     println!("\nPress ENTER to continue...");
    //     let mut _dummy = String::new();
    //     io::stdin().read_line(&mut _dummy)?;

    //     Ok(())
    // }

    /// Helper function to render the message browser screen
    ///
    /// Displays:
    /// 1. Message list from tui_textmessage_list
    /// 2. Mode indicator (Refresh/Insert)
    /// 3. Input prompt with current buffer
    fn render_message_browser_screen(
        &self,
        message_view_mode: &MessageViewMode,
        input_buffer: &str,
        terminal_width: u16,
        terminal_height: u16
    ) -> io::Result<()> {
        // Clear screen
        print!("\x1B[2J\x1B[1;1H");

        // 1. Display messages using existing function
        tiny_tui::simple_render_list(&self.tui_textmessage_list, &self.current_path);

        // 2. Fill remaining space to position info bar correctly
        let path_lines = 1; // Header line showing path
        let message_count = self.tui_textmessage_list.len();
        let info_bar_position = (terminal_height - 2) as usize;

        for _ in 0..info_bar_position.saturating_sub(path_lines + message_count) {
            println!();
        }

        // 3. Display mode info bar with clear instructions
        match message_view_mode {
            MessageViewMode::Refresh => println!("\\|/  Refresh Mode - - empty 'enter' to  insert mode"),
            MessageViewMode::Insert => println!(">_  Insert Mode - empty 'enter' to toggle refresh-mode"),
        }

        // 4. Display input prompt with current buffer
        print!("> {}", input_buffer);
        io::stdout().flush()
    }

    /// Add a new message from user input
    ///
    /// Creates a new message file with the user's input as content
    fn add_new_message_from_input(&mut self, input: &str) -> io::Result<()> {
        let local_owner_user = &self.graph_navigation_instance_state.local_owner_user;

        // Generate the next available message filename
        let message_path = get_next_message_file_path(&self.current_path, local_owner_user);

        // Add the message using existing function
        add_im_message(
            &message_path,
            local_owner_user,
            input.trim(),
            &self.graph_navigation_instance_state,
        ).map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Failed to add message: {}", e)))
    }

    /// Load instant messages from current directory
    ///
    /// # Purpose
    ///
    /// Loads all instant message files from the current directory, handling both
    /// clearsigned (.toml) and encrypted (.gpgtoml) formats. Displays messages
    /// in the TUI message list.
    ///
    /// # Process Flow
    ///
    /// 1. Clear existing message list
    /// 2. Check if directory contains messages (excluding 0.toml metadata)
    /// 3. If empty, prompt user to create first message
    /// 4. For each message file:
    ///    - Get readable temp copy (decrypt if .gpgtoml, verify if clearsigned)
    ///    - Read owner and text fields
    ///    - Add to display list
    ///    - Clean up temp copy
    ///
    /// # Message File Formats
    ///
    /// - `.toml` files: Clearsigned TOML (authenticated but readable)
    /// - `.gpgtoml` files: Encrypted TOML (requires decryption)
    /// - `0.toml`: Metadata file (excluded from message list)
    ///
    /// # Error Handling
    ///
    /// Errors are logged but don't halt loading - allows partial message display
    /// if some files fail to load. First message creation errors are fatal.
    ///
    /// # Side Effects
    ///
    /// - Clears `self.tui_textmessage_list`
    /// - Populates `self.tui_textmessage_list` with loaded messages
    /// - May prompt user for input if channel is empty
    /// - Creates temp files for reading (cleaned up after use)
    fn load_im_messages(&mut self) {
        debug_log!("LIM: Starting load_im_messages");
        debug_log!("LIM: Current path: {:?}", self.current_path);

        self.tui_textmessage_list.clear();

        // Verify current path is a directory
        if !self.current_path.is_dir() {
            debug_log!("LIM: Current path is not a directory");
            return;
        }

        debug_log!("LIM: Scanning directory for message files");

        // // Collect all entries in directory (max depth 1)
        // let entries: Vec<_> = WalkDir::new(&self.current_path)
        //     .max_depth(1)
        //     .into_iter()
        //     .filter_map(|entry| entry.ok())
        //     .filter(|entry| entry.path().is_file())
        //     .collect();

        // Collect all entries in directory (max depth 1)
        let mut entries: Vec<_> = WalkDir::new(&self.current_path)
            .max_depth(1)
            .into_iter()
            .filter_map(|entry| entry.ok())
            .filter(|entry| entry.path().is_file())
            .collect();

        // Sort entries by numeric prefix in filename (1__, 2__, 3__, etc.)
        entries.sort_by_key(|entry| {
            entry.path()
                .file_name()
                .and_then(|n| n.to_str())
                .and_then(|s| s.split("__").next())  // Get part before "__"
                .and_then(|num_str| num_str.parse::<u64>().ok())  // Parse as number
                .unwrap_or(u64::MAX)  // Put unparseable names at end
        });

        debug_log!("LIM: Entries sorted by filename prefix");

        // Debug: Log all found files
        debug_log!("LIM: === Files found in directory ===");
        for entry in &entries {
            debug_log!("LIM:   {:?}", entry.path());
        }
        debug_log!("LIM: === End of file list ===");

        // Check if directory is empty or only contains 0.toml
        let has_messages = entries.iter().any(|entry| {
            if let Some(file_name) = entry.path().file_name() {
                file_name != OsStr::new("0.toml")
            } else {
                false
            }
        });

        if !has_messages {
            // Channel is empty - prompt for first message
            debug_log!("LIM: Channel is empty, prompting for first message");
            println!("This channel is empty. Write a welcoming message:");

            let mut first_message = String::new();
            if let Err(e) = io::stdin().read_line(&mut first_message) {
                debug_log!("LIM: Failed to read user input: {}", e);
                return;
            }

            let local_owner_user = self.graph_navigation_instance_state.local_owner_user.clone();
            let this_file_name = format!("1__{}.toml", local_owner_user);

            debug_log!("LIM: Creating first message file: {}", this_file_name);

            /*
            fn add_im_message(
                incoming_file_path: &Path,
                owner: &str,
                text: &str,
                signature: Option<String>,
                graph_navigation_instance_state: &GraphNavigationInstanceState,
            ) -> Result<(), io::Error> {
            */

            // Add the first message
            match add_im_message(
                &self.current_path.join(this_file_name),
                &local_owner_user,
                first_message.trim(),
                &self.graph_navigation_instance_state,
            ) {
                Ok(()) => {
                    debug_log!("LIM: First message created successfully");
                    // Recursively reload messages
                    self.load_im_messages();
                    return;
                }
                Err(e) => {
                    debug_log!("LIM: Failed to add first message: {}", e);
                    println!("Error creating first message: {}", e);
                    return;
                }
            }
        }

        // Get GPG fingerprint for decryption/verification
        debug_log!("LIM: Getting GPG fingerprint from uma.toml");
        let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => {
                debug_log!("LIM: GPG fingerprint retrieved: {}", fingerprint);
                fingerprint
            }
            Err(e) => {
                debug_log!("LIM: Failed to read GPG fingerprint from uma.toml: {}", e);
                println!("Error: Cannot load messages without GPG fingerprint");
                return;
            }
        };

        // Get temp directory for read copies
        let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
            Ok(path) => path,
            Err(e) => {
                debug_log!("LIM: Failed to get temp directory path: {}", e);
                println!("Error: Cannot create temp directory for message reading");
                return;
            }
        };

        // Load messages (excluding 0.toml)
        debug_log!("LIM: Loading message files");
        let mut loaded_count = 0;
        let mut error_count = 0;

        for entry in entries {
            if !entry.path().is_file() {
                continue;
            }

            // Get filename
            let file_name = match entry.path().file_name() {
                Some(name) => name.to_string_lossy().to_string(),
                None => {
                    debug_log!("LIM: Entry has no filename: {:?}", entry.path());
                    continue;
                }
            };

            // Skip metadata file
            if file_name == "0.toml" {
                debug_log!("LIM: Skipping metadata file: {}", file_name);
                continue;
            }

            debug_log!("LIM: Processing message file: {}", file_name);

            // Get readable temp copy (handles both .toml and .gpgtoml)
            let message_readcopy_path = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
                entry.path(),
                &gpg_full_fingerprint_key_id_string,
                &base_uma_temp_directory_path,
            ) {
                Ok(path) => {
                    debug_log!("LIM: Got temp read copy at: {}", path);
                    path
                }
                Err(e) => {
                    debug_log!("LIM: Failed to get readable copy of {}: {:?}", file_name, e);
                    error_count += 1;
                    continue;
                }
            };

            // Read owner field
            let owner = match read_single_line_string_field_from_toml(
                &message_readcopy_path,
                "owner",
            ) {
                Ok(owner_value) => {
                    if owner_value.is_empty() {
                        debug_log!("LIM: Owner field is empty in {}", file_name);
                        error_count += 1;
                        continue;
                    }
                    owner_value
                }
                Err(e) => {
                    debug_log!("LIM: Failed to read owner from {}: {}", file_name, e);
                    error_count += 1;
                    continue;
                }
            };

            // Read text_message field
            let text_message = match read_single_line_string_field_from_toml(
                &message_readcopy_path,
                "text_message",
            ) {
                Ok(text) => {
                    if text.is_empty() {
                        debug_log!("LIM: text_message field is empty in {}", file_name);
                        error_count += 1;
                        continue;
                    }
                    text
                }
                Err(e) => {
                    debug_log!("LIM: Failed to read text_message from {}: {}", file_name, e);
                    error_count += 1;
                    continue;
                }
            };

            debug_log!("LIM: Successfully loaded message from {}: {} chars", owner, text_message.len());

            // Add to display list
            self.tui_textmessage_list.push(format!("{}: {}", owner, text_message));
            loaded_count += 1;

            // Note: temp file cleanup is handled by the OS or explicit cleanup
            // depending on how get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml works
        }

        debug_log!("LIM: Finished loading messages: {} messages loaded, {} problems", loaded_count, error_count);

        if loaded_count == 0 && error_count > 0 {
            println!("Warning: Failed to load any messages from this channel");
        }
    }

    // fn load_im_messages(&mut self) {
    //     debug_log("starting: load_im_messages called");
    //     debug_log(&format!("self.current_path  {:?}", self.current_path));
    //     self.tui_textmessage_list.clear();

    //     if self.current_path.is_dir() {
    //         debug_log(&format!("self.current_path  {:?}", self.current_path));
    //         let entries: Vec<_> = WalkDir::new(&self.current_path)
    //             .max_depth(1) // Add this line to limit depth
    //             .into_iter()
    //             .filter_map(|entry| entry.ok())
    //             .filter(|entry| entry.path().is_file())
    //             .collect();

    //         // Inspection block (print file paths)
    //         debug_log("=== Files in entries ===");
    //         for entry in &entries {
    //             debug_log(&format!("  {:?}", entry.path()));
    //         }
    //         debug_log("=== End of entries ===");

    //         // Check if only 0.toml exists (or if the directory is empty)
    //         if entries.is_empty() ||
    //         (entries.len() == 1 && entries[0].path().file_name().unwrap() == OsStr::new("0.toml")) {
    //             // Only 0.toml exists (or no files exist), prompt for the first message
    //             println!("This channel is empty. Write a welcoming message:");
    //             let mut first_message = String::new();
    //             io::stdin().read_line(&mut first_message).unwrap();

    //             // Assuming 'local_owner_user' is already loaded in your main function
    //             let local_owner_user = self.graph_navigation_instance_state.local_owner_user.clone(); // Access from graph_navigation_instance_state

    //             let this_file_name = format!("1__{}.toml", local_owner_user);
    //             let last_section = extract_last_path_section(&self.current_path);

    //             // Add the first message (assuming the current user is the owner)
    //             /*
    //             TODO Top priority area:

    //             maybe used GraphNavigationInstanceState node data to fill in these values

    //             fn add_im_message(
    //                 path: &Path,
    //                 owner: &str,
    //                 text: &str,
    //                 signature: Option<String>,
    //                 graph_navigation_instance_state: &GraphNavigationInstanceState, // Pass local_user_metadata here
    //             ) -> Result<(), io::Error> {
    //             */


    //             debug_log(&format!("this_file_name {:?}", this_file_name));
    //             // debug_log(&format!("self.current_path.join(this_file_name)  {:?}", self.current_path.join(this_file_name)));

    //             add_im_message(
    //                 &self.current_path.join(this_file_name), // path
    //                 &local_owner_user, // owner
    //                 first_message.trim(), // text
    //                 None, // signature
    //                 &self.graph_navigation_instance_state, // use GraphNavigationInstanceState
    //             ).expect("Failed to add first message");


    //             // Reload entries after adding the first message
    //             self.load_im_messages(); // No arguments needed
    //             return;
    //         }

    //         // Load messages (excluding 0.toml)
    //         for entry in entries {
    //             if entry.path().is_file() {
    //                 let file_name = entry.path().file_name().unwrap().to_string_lossy().to_string();
    //                 if file_name != "0.toml" {
    //                     // Read the file contents
    //                     let file_contents = fs::read_to_string(entry.path()).expect("Failed to read message file");

    //                     // Assuming you're parsing the TOML into a MessagePostFile struct called 'message'
    //                     let message: MessagePostFile = toml::from_str(&file_contents).unwrap();

    //                     debug_log(&format!("file_name from {}", file_name));
    //                     debug_log(&format!("Added message from {}", message.owner));

    //                     // Add the message to the list for display
    //                     self.tui_textmessage_list.push(format!("{}: {}", message.owner, message.text_message));
    //                 }
    //             }
    //         }
    //     }

    //     // // Render the message list
    //     // tiny_tui::render_list(
    //     //     &self.tui_textmessage_list,
    //     //     &self.current_path,
    //     //     &self.graph_navigation_instance_state.agenda_process,
    //     //     &self.graph_navigation_instance_state.goals_features_subfeatures_tools_targets,
    //     //     &self.graph_navigation_instance_state.scope,
    //     //     &self.graph_navigation_instance_state.pa2_schedule,
    //     // );
    // }

    fn enter_task_browser(&mut self) {
        debug_log!("task-mode: starting: enter_task_browser");
        if self.current_path.exists() {
            self.load_tasks();
            self.input_mode = InputMode::TaskCommand;
        } else {
            debug_log!("'task_browser' directory not found in current node.");

        }
    }


    fn is_at_task_browser_root(&self) -> bool {
        self.current_path.ends_with("task_browser") && self.tui_file_list.is_empty()
    }

    fn get_current_column_name(&self) -> Option<String> {
        let last_section = extract_last_path_section(&self.current_path);
        if let Some(name) = last_section {
            if name.starts_with('#') {
                Some(name)
            } else { None }
        } else { None }
    }

    fn get_full_task_path(&self, task_index: usize) -> Option<PathBuf> {
        debug_log("starting get_full_task_path()");
        // Extract data to form a path:
        if let Some(task_entry) = self.tui_file_list.get(task_index) {
            let parts: Vec<&str> = task_entry.split('.').collect(); // Corrected split and collect
            let task_name = parts.last().unwrap_or(&"").trim(); // Ensure this handles empty/invalid input
            let column_index_parts: Vec<&str> = parts[0].split(' ').collect();
            if column_index_parts.len() >= 1 {
                let column_name = column_index_parts[0]; // Ensure this handles empty/invalid input

                let task_path = self.current_path.join(column_name).join(task_name); // Ensure this handles potential path errors
                Some(task_path)
            } else { None }

        } else { None }

    }

    // What? selection? ...????
    fn handle_task_action(&mut self, input: &str) -> bool { // Return true to exit task mode
        // TODO handle 'b' back

        if input == "q" || input == "quit" || input == "b" || input == "back" {
            self.input_mode = InputMode::MainCommand; //Switch back to MainCommand mode
            self.current_path.pop(); // Go back to parent directory ("task_browser")
            self.load_tasks();        //Refresh task view at the previous parent level.
            return false;             // Stay in the main loop (don't exit Uma)

        } else if let Ok(selection) = input.parse::<usize>() {
            // ... (Logic for task number handling - See detailed code below)
        } else {
            debug_log!("Invalid task command.");
            // (Optional) Display error message in TUI
        }
        false // Don't exit task mode by default for other commands
    }

    /// headers/columns = directories with names starting with int and underscore such as 1_plan 2_started 3_done
    /// the number and underscore should be removed
    /// the number should be used as the header/column number
    /// for MVP each directory-name in side each column-directory becomes a row-item in that column
    /// e.g. if 1_plan contains a directory called "report" then given report a sequential number
    /// and list it under the header "plan"
    /// results sent to display_table() as function or as method
    fn load_tasks(&mut self) {
        debug_log!("task-mode: starting: tasks app: load_tasks");
        self.tui_directory_list.clear(); // Clear directories
        self.tui_file_list.clear();  // Clear files

        let task_browser_dir = &self.current_path;

        if self.is_at_task_browser_root() {

            // Version 2: More detailed error handling
            match self.update_task_display() {
                Ok((headers, data)) => {
                    if headers.is_empty() {
                        debug_log("Warning: No headers found in task display");
                        tiny_tui::render_tasks_table(
                            &["No Tasks".to_string()],
                            &Vec::new(),
                            &self.current_path,
                        );
                    } else {
                        // pub fn render_tasks_table(headers: &[String], data: &[Vec<String>], current_path: &Path) {
                        tiny_tui::render_tasks_table(
                            &headers,
                            &data,
                            &self.current_path,
                        );


                    }
                },
                Err(e) => {
                    debug_log(&format!("Error updating task display: {}", e));
                    // Show error message in table format
                    tiny_tui::render_tasks_table(
                        &["Error".to_string()],
                        &vec![vec![format!("Failed to load tasks: {}", e)]],
                        &self.current_path
                    );
                }
            }

        } else { // Inside a column
             // ... (task display within a column remains the same)
            let mut file_list = Vec::new();

            //Iterate through tasks and add to file_list (no column header)
            if let Ok(entries) = read_dir(task_browser_dir) {
                for (i, entry) in entries.flatten().enumerate() {
                    if entry.file_type().unwrap().is_dir() {  // Check for directories
                        file_list.push(format!("{}. {}", i + 1, entry.file_name().to_string_lossy().to_string())); //Corrected type here
                    }
                }
            } else {
                // ... handle errors
            }

            // Render the list using the correct parameters:
            tiny_tui::render_list(
                &file_list,      // Pass the file list
                &self.current_path, //Pass the current path
                &self.graph_navigation_instance_state.pa1_process,
                &self.graph_navigation_instance_state.pa2_schedule,
                &self.graph_navigation_instance_state.pa3_users,
                &self.graph_navigation_instance_state.pa4_features,
                &self.graph_navigation_instance_state.pa5_mvp,
                &self.graph_navigation_instance_state.pa6_feedback,
            );
        }
    }

    fn next(&mut self) {
        if self.tui_focus < self.tui_file_list.len() - 1 {
            self.tui_focus += 1;
        }
    }

    fn previous(&mut self) {
        if self.tui_focus > 0 {
            self.tui_focus -= 1;
        }
    }

    // What is wrong with the brain of the person who invented this function?
    fn is_in_team_channel_list(&self) -> bool {
        self.current_path == PathBuf::from("project_graph_data/team_channels")
    }

    fn is_in_message_posts_browser_directory(&self) -> bool {
        self.current_path.ends_with("message_posts_browser")
    }

    fn get_tui_focus_node_path(&self) -> Option<PathBuf> {
        if let Some(tui_focus_file) = self.tui_file_list.get(self.tui_focus) {
            Some(PathBuf::from(tui_focus_file))
        } else {
            None
        }
    }

    fn display_error(&mut self, message: &str) {
        // Implement logic to display the error message in the input box or status bar
        // ... (e.g., update a field in App that's displayed in the UI)
        println!("Error: {}", message); // Example: Print the error to the console for now
    }

    fn get_current_list(&self) -> &Vec<String> {
        match self.tui_focus {
            0 => &self.tui_directory_list,
            1 => &self.tui_file_list,
            2 => &self.tui_textmessage_list,
            _ => panic!("Invalid tui_focus value"),
        }
    }

    fn update_directory_list(&mut self) -> io::Result<()> {
        self.tui_directory_list.clear();

        for entry in fs::read_dir(&self.current_path)? {
            let entry = entry?;
            let path = entry.path();
            if path.is_dir() { // Only add directories to the list
                let file_name = path.file_name().unwrap().to_string_lossy().to_string();
                self.tui_directory_list.push(file_name);
            }
        }

        Ok(())
    }

}
// end impl App {

/// Represents local user configuration for Uma collaboration tools.
/// This struct holds all user-specific settings including identity,
/// GPG key information, and UI preferences.
#[derive(Debug, Clone)]
struct LocalUserUma {
    /// The username/nickname for this Uma instance owner
    uma_local_owner_user: String,
    /// Full GPG key fingerprint for encryption/signing
    gpg_full_fingerprint_key_id_string: String,
    /// Number of days before IM messages expire (default: 28)
    uma_default_im_messages_expiration_days: u64,
    /// Number of days before task nodes expire (default: 90)
    uma_default_task_nodes_expiration_days: u64,
    /// Terminal UI height in rows (default: 24)
    tui_height: u8,
    /// Terminal UI width in columns (default: 80)
    tui_width: u8,
    /// Refresh rate in seconds for log mode display (default: 1.5)
    log_mode_refresh: f32,
}
/*
Sample:

// Get armored public key, using key-id (full fingerprint in)
let full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
    Ok(fingerprint) => fingerprint,
    Err(e) => {
        eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
        return Err(ThisProjectError::from(format!(
            "Failed to read GPG fingerprint from uma.toml: {}", e
        )));
    }
};

// Read individual fields when you don't need the whole struct
let uma_local_owner_user = match LocalUserUma::read_owner_from_file(&uma_toml_path) {
    Ok(owner) => owner,
    Err(e) => {
        eprintln!("Failed to read owner from uma.toml: {}", e);
        return Ok(false);
    }
};

let gpg_fingerprint = match LocalUserUma::read_gpg_fingerprint_from_file(&uma_toml_path) {
    Ok(fingerprint) => fingerprint,
    Err(e) => {
        eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
        return Ok(false);
    }
};

debug_log!("Loaded user: {} with GPG key: {}", uma_local_owner_user, gpg_fingerprint);
*/

impl LocalUserUma {

    /// Creates a new LocalUserUma instance with the specified owner and GPG fingerprint.
    /// Other fields are initialized with sensible defaults.
    ///
    /// # Arguments
    /// * `uma_local_owner_user` - The username for this Uma instance
    /// * `gpg_full_fingerprint_key_id_string` - The full GPG key fingerprint
    ///
    /// # Returns
    /// A new LocalUserUma instance with default values for non-specified fields
    fn new(
        uma_local_owner_user: String,
        gpg_full_fingerprint_key_id_string: String,
    ) -> LocalUserUma {
        LocalUserUma {
            uma_local_owner_user,
            gpg_full_fingerprint_key_id_string,
            uma_default_im_messages_expiration_days: 28,  // Default to 28 days
            uma_default_task_nodes_expiration_days: 90,  // Default to 90 days
            tui_height: 24,
            tui_width: 80,
            log_mode_refresh: 1.5,  // Refresh every 1.5 seconds
        }
    }

    /// Saves the entire LocalUserUma configuration to a file in plain text format.
    /// Each field is written as a key-value pair on its own line.
    ///
    /// # Arguments
    /// * `path` - The absolute path where the configuration file should be written
    ///
    /// # Returns
    /// * `Ok(())` if the file was written successfully
    /// * `Err(io::Error)` if there was an I/O error
    fn save_to_uma_toml_file(&self, path: &Path) -> Result<(), io::Error> {
        // Build the configuration string with all fields
        let config_content = format!(
            r#"uma_local_owner_user = "{}"
gpg_full_fingerprint_key_id_string = "{}"
uma_default_im_messages_expiration_days = {}
uma_default_task_nodes_expiration_days = {}
tui_height = {}
tui_width = {}
log_mode_refresh = {}"#,
            self.uma_local_owner_user,
            self.gpg_full_fingerprint_key_id_string,
            self.uma_default_im_messages_expiration_days,
            self.uma_default_task_nodes_expiration_days,
            self.tui_height,
            self.tui_width,
            self.log_mode_refresh
        );

        // Write the content to the file
        fs::write(path, config_content)?;
        Ok(())
    }

    /// Reads only the uma_local_owner_user field from a configuration file.
    ///
    /// # Arguments
    /// * `path` - The absolute path to the configuration file
    ///
    /// # Returns
    /// * `Ok(String)` containing the owner username if found
    /// * `Err(io::Error)` if the file couldn't be read or the field wasn't found
    fn read_owner_from_file() -> Result<String, io::Error> {
        // Get the absolute path to the flag file relative to the executable
        let uma_toml_path_exerel_abs = make_input_path_name_abs_executabledirectoryrelative_nocheck(
            "uma.toml"
        )?;

        let file = fs::File::open(uma_toml_path_exerel_abs)?;
        let reader = BufReader::new(file);

        for line in reader.lines() {
            let line = line?;
            let trimmed = line.trim();

            if trimmed.starts_with("uma_local_owner_user") {
                if let Some(equals_pos) = trimmed.find('=') {
                    let value = trimmed[equals_pos + 1..].trim();
                    return Self::parse_string_value(value);
                }
            }
        }

        Err(io::Error::new(
            io::ErrorKind::InvalidData,
            "uma_local_owner_user not found in configuration file",
        ))
    }

    // TODO: this should use clearsign verification
    /// Reads only the gpg_full_fingerprint_key_id_string field from a configuration file.
    ///
    /// # Arguments
    /// * `path` - The absolute path to the configuration file
    ///
    /// # Returns
    /// * `Ok(String)` containing the GPG fingerprint if found
    /// * `Err(io::Error)` if the file couldn't be read or the field wasn't found
    ///
    /// sample
    ///     // Get armored public key, using key-id (full fingerprint in)
    /// let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
    ///     Ok(fingerprint) => fingerprint,
    ///     Err(e) => {
    ///         return Err(io::Error::new(
    ///             io::ErrorKind::Other,
    ///             format!("implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}", e)
    ///         ));
    ///     }
    /// };
    ///
    fn read_gpg_fingerprint_from_file() -> Result<String, io::Error> {

        // Get the absolute path to the flag file relative to the executable
        let uma_toml_path_exerel_abs = make_input_path_name_abs_executabledirectoryrelative_nocheck(
            "uma.toml"
        )?;

        let file = fs::File::open(uma_toml_path_exerel_abs)?;
        let reader = BufReader::new(file);

        for line in reader.lines() {
            let line = line?;
            let trimmed = line.trim();

            if trimmed.starts_with("gpg_full_fingerprint_key_id_string") {
                if let Some(equals_pos) = trimmed.find('=') {
                    let value = trimmed[equals_pos + 1..].trim();
                    return Self::parse_string_value(value);
                }
            }
        }

        Err(io::Error::new(
            io::ErrorKind::InvalidData,
            "gpg_full_fingerprint_key_id_string not found in configuration file",
        ))
    }

    /// Helper function to parse a string value from the configuration format.
    /// Handles quoted strings and removes the quotes.
    ///
    /// # Arguments
    /// * `value` - The raw value string from the configuration file
    ///
    /// # Returns
    /// * `Ok(String)` with quotes removed if present
    /// * `Err(io::Error)` if the value format is invalid
    fn parse_string_value(value: &str) -> Result<String, io::Error> {
        let trimmed = value.trim();

        // Remove quotes if present
        if trimmed.starts_with('"') && trimmed.ends_with('"') && trimmed.len() >= 2 {
            Ok(trimmed[1..trimmed.len() - 1].to_string())
        } else {
            // Accept unquoted strings as well
            Ok(trimmed.to_string())
        }
    }

}

/// for an intermediate step in converting data types
#[derive(Debug, Deserialize, serde::Serialize, Clone)]
struct RawProtoDataToml {
    user_name: String,
    user_salt_list: Vec<String>,
    ipv4_addresses: Option<Vec<Ipv4Addr>>,
    ipv6_addresses: Option<Vec<Ipv6Addr>>,
    gpg_publickey_id: String,
    gpg_key_public: String,
    sync_interval: u64,
    updated_at_timestamp: u64,
}

#[derive(Debug, Deserialize, serde::Serialize, Clone)]
struct CollaboratorTomlData {
    user_name: String,
    user_salt_list: Vec<u128>,
    ipv4_addresses: Option<Vec<Ipv4Addr>>,
    ipv6_addresses: Option<Vec<Ipv6Addr>>,
    gpg_publickey_id: String,
    gpg_key_public: String,
    sync_interval: u64,
    updated_at_timestamp: u64,
}

impl CollaboratorTomlData {
    fn new(
        user_name: String,
        user_salt_list: Vec<u128>, // Take ownership of user_salt_list
        ipv4_addresses: Option<Vec<Ipv4Addr>>,
        ipv6_addresses: Option<Vec<Ipv6Addr>>,
        gpg_publickey_id: String,
        gpg_key_public: String,
        sync_interval: u64,
        updated_at_timestamp: u64,
    ) -> CollaboratorTomlData {
        debug_log!("CollaboratorTomlData.new: user_salt_list {:?}", user_salt_list);
        CollaboratorTomlData {
            user_name,
            user_salt_list,
            ipv4_addresses,
            ipv6_addresses,
            gpg_publickey_id,
            gpg_key_public,
            sync_interval,
            updated_at_timestamp,
        }
    }
}


/*
addressbook creation with gpg encryption
*/

/// Prompts the user to choose between clearsigned TOML or GPG encrypted clearsigned TOML format.
///
/// This function presents a choice to the user for how to save the collaborator configuration:
/// - Clearsigned TOML (.toml) - Type "yes" (case-insensitive)
/// - GPG encrypted clearsigned TOML (.gpgtoml) - Any other input (default)
///
/// The function validates user input and returns their choice.
///
/// # Returns
/// * `true` - User chose clearsigned TOML only
/// * `false` - User chose GPG encrypted clearsigned TOML (default)
fn prompt_user_for_collaborator_file_format() -> bool {
    use std::io::{self, Write};

    println!("\n=== Collaborator File Format Selection ===");
    println!("Do you want to save this as a read-able clearsigned .toml, not encrypted .gpgtoml (also clearsigned)?");
    println!("The default (recommended) is GPG protected (.gpgtoml).");
    println!("Type 'clearsign' to choose clearsign only, anything else (or empty enter) for default (recommended) GPG encrypted.");
    print!("\nEnter your choice: ");

    // Ensure the prompt is displayed immediately
    let _ = io::stdout().flush();

    // Read user input
    let mut input = String::new();
    match io::stdin().read_line(&mut input) {
        Ok(_) => {
            // Trim whitespace and convert to lowercase for case-insensitive comparison
            let cleaned_input = input.trim().to_lowercase();
            // Return true only if user explicitly typed "yes"
            cleaned_input == "clearsign"
        }
        Err(e) => {
            eprintln!("Error reading input: {}. Defaulting to GPG encrypted format.", e);
            false // Default to encrypted on error
        }
    }
}

/// Encrypts a clearsigned TOML file using a provided GPG public key.
///
/// This function takes a clearsigned TOML file and encrypts it using the provided
/// public key content directly, without any keyring operations. The encrypted
/// content is saved to a new file with the .gpgtoml extension.
///
/// # Security
/// - Uses the public key content directly without keyring operations
/// - Creates temporary files with restricted permissions
/// - Ensures cleanup of all temporary files
/// - Does not modify or access the GPG keyring
///
/// # Arguments
/// * `clearsigned_toml_path` - Path to the clearsigned TOML file to encrypt
/// * `gpg_key_public` - The GPG public key content to use for encryption
/// * `output_gpgtoml_path` - Path where the encrypted file should be saved
///
/// # Returns
/// * `Result<(), std::io::Error>` - Ok(()) on success, or an error
fn encrypt_clearsigned_toml_with_public_key_content(
    clearsigned_toml_path: &Path,
    gpg_key_public: &str,
    output_gpgtoml_path: &Path,
) -> Result<(), std::io::Error> {
    use std::fs;
    use std::process::Command;

    debug_log!("Starting GPG encryption of clearsigned TOML");
    debug_log!("Input file: {}", clearsigned_toml_path.display());
    debug_log!("Output file: {}", output_gpgtoml_path.display());

    // Create a temporary file for the public key
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map_err(|e| std::io::Error::new(
            std::io::ErrorKind::Other,
            format!("Time error: {}", e)
        ))?
        .as_nanos();

    let temp_pubkey_filename = format!("temp_pubkey_{}.asc", timestamp);
    let temp_dir = std::env::temp_dir();
    let temp_pubkey_path = temp_dir.join(&temp_pubkey_filename);

    // Write the public key to temporary file
    debug_log!("Writing public key to temporary file: {}", temp_pubkey_path.display());
    fs::write(&temp_pubkey_path, gpg_key_public)?;

    // Ensure cleanup happens regardless of success or failure
    let cleanup_result = (|| -> Result<(), std::io::Error> {
        // Read the clearsigned content
        let clearsigned_content = fs::read_to_string(clearsigned_toml_path)?;

        // Use GPG to encrypt with the public key directly (no keyring operations)
        let output = Command::new("gpg")
            .arg("--batch")
            .arg("--yes")
            .arg("--trust-model")
            .arg("always") // Trust the key without keyring
            .arg("--armor")
            .arg("--encrypt")
            .arg("--recipient-file")
            .arg(&temp_pubkey_path) // Use the public key file directly
            .arg("--output")
            .arg(output_gpgtoml_path)
            .arg(clearsigned_toml_path)
            .output()?;

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("GPG encryption failed: {}", stderr)
            ));
        }

        debug_log!("Successfully encrypted file to: {}", output_gpgtoml_path.display());
        Ok(())
    })();

    // Always clean up the temporary public key file
    if let Err(e) = fs::remove_file(&temp_pubkey_path) {
        eprintln!("Warning: Failed to remove temporary public key file {}: {}",
                  temp_pubkey_path.display(), e);
    }

    cleanup_result
}

/// Adds a new collaborator by creating a TOML configuration file in the executable-relative
/// collaborator directory.
///
/// This function creates a `CollaboratorTomlData` instance from the provided parameters,
/// serializes it to TOML format, and saves it to a file in the collaborator directory.
/// The file path is determined relative to the executable location rather than the current
/// working directory to ensure consistent path resolution regardless of where the program
/// is executed from.
///
/// The user is prompted to choose between:
/// - Clearsigned TOML file (.toml) - for compatibility
/// - GPG encrypted clearsigned TOML file (.gpgtoml) - for enhanced security (default)
///
/// # Security
/// - Files are always clearsigned for integrity verification
/// - Optional GPG encryption provides confidentiality
/// - The collaborator's public key is used for encryption
/// - No keyring operations are performed
///
/// # Arguments
///
/// * `user_name` - The collaborator's username
/// * `user_salt_list` - List of salt values used for this collaborator
/// * `ipv4_addresses` - Optional list of IPv4 addresses associated with the collaborator
/// * `ipv6_addresses` - Optional list of IPv6 addresses associated with the collaborator
/// * `gpg_publickey_id` - The GPG public key ID for the collaborator
/// * `gpg_key_public` - The GPG public key content for the collaborator
/// * `sync_interval` - The synchronization interval in seconds
/// * `updated_at_timestamp` - Unix timestamp of when this collaborator data was last updated
///
/// # Returns
///
/// * `Result<(), std::io::Error>` - Ok(()) if the operation succeeded, or an error if any step failed
///
/// # Errors
///
/// This function can return errors in the following cases:
/// * If creating the collaborator directory fails
/// * If serializing the collaborator data to TOML fails
/// * If creating or writing to the file fails
/// * If GPG operations fail (clearsigning or encryption)
pub fn make_new_collaborator_addressbook_toml_file(
    user_name: String,
    user_salt_list: Vec<u128>,
    ipv4_addresses: Option<Vec<Ipv4Addr>>,
    ipv6_addresses: Option<Vec<Ipv6Addr>>,
    gpg_publickey_id: String,
    gpg_key_public: String,
    sync_interval: u64,
    updated_at_timestamp: u64,
) -> Result<(), std::io::Error> {
    /*
    use std::fs::File;
    use std::io::Write;
    use std::net::{Ipv4Addr, Ipv6Addr};
    use std::path::Path;

    // Import the path management module
    use crate::manage_absolute_executable_directory_relative_paths::make_input_path_name_abs_executabledirectoryrelative_nocheck;
    use crate::manage_absolute_executable_directory_relative_paths::prepare_file_parent_directories_abs_executabledirectoryrelative;
    */
    debug_log("Starting: fn make_new_collaborator_addressbook_toml_file");

    // Log function parameters for debugging
    debug_log!("user_name {:?}", user_name);
    debug_log!("user_salt_list {:?}", &user_salt_list);
    debug_log!("ipv4_addresses {:?}", ipv4_addresses);
    debug_log!("ipv6_addresses {:?}", ipv6_addresses);
    debug_log!("gpg_publickey_id {:?}", &gpg_publickey_id);
    debug_log!("gpg_key_public {:?}", &gpg_key_public);
    debug_log!("sync_interval {:?}", sync_interval);
    debug_log!("updated_at_timestamp {:?}", updated_at_timestamp);

    // Create the CollaboratorTomlData instance
    let collaborator = CollaboratorTomlData::new(
        user_name,
        user_salt_list,
        ipv4_addresses,
        ipv6_addresses,
        gpg_publickey_id,
        gpg_key_public,
        sync_interval,
        updated_at_timestamp,
    );

    debug_log!("collaborator {:?}", collaborator);

    // Serialize the collaborator to TOML format
    // TODO this may need to be done inhouse
    let toml_string = match serialize_collaborator_to_toml(&collaborator) {
        Ok(content) => {
            debug_log!("Successfully serialized collaborator to TOML");
            content
        },
        Err(e) => {
            debug_log!("Error serializing to TOML: {}", e);
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("TOML serialization error: {}", e),
            ));
        }
    };

    // Loop until we successfully create a collaborator file
    // This ensures the system can proceed, as it cannot function without this file
    loop {
        // Prompt user for file format choice
        let use_clearsign_only = prompt_user_for_collaborator_file_format();

        // Determine the file extension based on user choice
        let file_extension = if use_clearsign_only {
            "toml"
        } else {
            "gpgtoml"
        };

        debug_log!("User selected file format: .{}", file_extension);

        // Construct the relative path to the collaborator file
        // For .gpgtoml, we'll create a temporary .toml first
        let relative_path = format!(
            "{}/{}__collaborator.{}",
            COLLABORATOR_ADDRESSBOOK_PATH_STR,
            collaborator.user_name,
            if use_clearsign_only { "toml" } else { "toml" } // Always start with .toml
        );

        // TODO is it correct that this is not used??
        // Convert the relative path to an absolute path based on the executable's directory
        let file_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
            &relative_path
        ) {
            Ok(path) => path,
            Err(e) => {
                eprintln!("Error creating absolute path: {}. Trying again...", e);
                continue; // Try again
            }
        };

        // Ensure parent directories exist
        let prepared_path = match prepare_file_parent_directories_abs_executabledirectoryrelative(
            &relative_path
        ) {
            Ok(path) => path,
            Err(e) => {
                eprintln!("Error preparing parent directories: {}. Trying again...", e);
                continue; // Try again
            }
        };

        // Log the constructed file path
        debug_log!("Attempting to write collaborator file to: {:?}", prepared_path.display());

        // --- Block for file writing ---
        // This ensures `file` is dropped and the file is closed before the GPG operation.
        {
            let mut file = match File::create(&prepared_path) {
                Ok(f) => f,
                Err(e) => {
                    // Corrected debug_log! usage:
                    eprintln!("Error creating file '{}': {}. Trying again...", prepared_path.display(), e);
                    continue; // Try again
                }
            };

            // Write the serialized TOML to the file
            match file.write_all(toml_string.as_bytes()) {
                Ok(_) => {
                    // Corrected debug_log! usage:
                    debug_log!("Successfully wrote initial TOML data to collaborator file: {}", prepared_path.display());
                    // Do NOT return Ok(()) here yet. Proceed to the next step.
                },
                Err(e) => {
                    // Corrected debug_log! usage:
                    eprintln!("Error writing TOML data to file '{}': {}. Trying again...", prepared_path.display(), e);
                    continue; // Try again
                }
            }
        } // `file` is dropped here, so it's closed.

        // Now that the TOML file is written and closed, proceed to clearsign it in-place.
        // Corrected debug_log! usage:
        debug_log!("Attempting to clearsign the TOML file '{}' in-place.", prepared_path.display());

        // Call the in-place clearsigning function.
        // Note: `prepared_path` is a `PathBuf`. `&prepared_path` correctly provides a `&Path`.
        match convert_toml_filewithkeyid_into_clearsigntoml_inplace(&prepared_path) {
            Ok(()) => {
                // Clearsigning was successful.
                // Corrected debug_log! usage:
                debug_log!("Successfully converted '{}' to clearsigned TOML in-place.", prepared_path.display());

                // Now decide whether to encrypt or leave as clearsigned
                if use_clearsign_only {
                    // User chose clearsigned only, we're done
                    return Ok(());
                } else {
                    // User chose GPG encrypted, proceed with encryption
                    let gpgtoml_relative_path = format!(
                        "{}/{}__collaborator.gpgtoml",
                        COLLABORATOR_ADDRESSBOOK_PATH_STR,
                        collaborator.user_name,
                    );

                    let gpgtoml_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(&gpgtoml_relative_path) {
                        Ok(path) => path,
                        Err(e) => {
                            eprintln!("Error creating GPG output path: {}. Trying again...", e);
                            // Clean up the temporary .toml file
                            let _ = std::fs::remove_file(&prepared_path);
                            continue; // Try again
                        }
                    };

                    // Encrypt the clearsigned TOML file
                    match encrypt_clearsigned_toml_with_public_key_content(
                        &prepared_path,
                        &collaborator.gpg_key_public,
                        &gpgtoml_path
                    ) {
                        Ok(()) => {
                            // Encryption successful, remove the temporary .toml file
                            debug_log!("Successfully created encrypted file: {}", gpgtoml_path.display());

                            // Delete the temporary clearsigned .toml file
                            if let Err(e) = std::fs::remove_file(&prepared_path) {
                                eprintln!("Warning: Failed to remove temporary file {}: {}",
                                          prepared_path.display(), e);
                            }

                            return Ok(());
                        }
                        Err(e) => {
                            eprintln!("GPG encryption failed: {}. Please choose again.", e);
                            // Clean up the temporary .toml file
                            let _ = std::fs::remove_file(&prepared_path);
                            continue; // Try again with new user choice
                        }
                    }
                }
            }
            Err(gpg_error) => {
                // Clearsigning failed.
                eprintln!("Failed to clearsign file: {}. Trying again...", gpg_error);
                // Clean up the failed file
                let _ = std::fs::remove_file(&prepared_path);
                continue; // Try again
            }
        }
    } // End of retry loop
}


//     // Log the constructed file path
//     debug_log!("Attempting to write collaborator file to: {:?}", prepared_path);

//     // Create the file and write the TOML data
//     let mut file = match File::create(&prepared_path) {
//         Ok(f) => f,
//         Err(e) => {
//             debug_log!("Error creating file: {}", e);
//             return Err(e);
//         }
//     };

//     // Write the serialized TOML to the file
//     match file.write_all(toml_string.as_bytes()) {
//         Ok(_) => {
//             debug_log!("Successfully wrote collaborator file");
//             Ok(())
//         },
//         Err(e) => {
//             debug_log!("Error writing to file: {}", e);
//             Err(e)
//         }
//     }

//     // TODO function must be modified to allow ending after this
//     // logging success or failure would be wise.
//     // make clearsign-toml file remove old file...overwrite...
//     // let clearsigntoml_result =
//     convert_toml_filewithkeyid_into_clearsigntoml_inplace(
//     prepared_path
//     );

// }

/// old relative path vesion
// fn make_new_collaborator_addressbook_toml_file(
//     user_name: String,
//     user_salt_list: Vec<u128>,
//     ipv4_addresses: Option<Vec<Ipv4Addr>>,
//     ipv6_addresses: Option<Vec<Ipv6Addr>>,
//     gpg_publickey_id: String,
//     gpg_key_public: String,
//     sync_interval: u64,
//     updated_at_timestamp: u64,
// ) -> Result<(), std::io::Error> {
//     debug_log("Starting: fn make_new_collaborator_addressbook_toml_file( ...cupa tea?");

//     debug_log!("user_name {:?}", user_name);
//     debug_log!("user_salt_list {:?}", &user_salt_list);
//     debug_log!("ipv4_addresses {:?}", ipv4_addresses);
//     debug_log!("ipv6_addresses {:?}", ipv6_addresses);
//     debug_log!("gpg_publickey_id {:?}", &gpg_publickey_id);
//     debug_log!("gpg_key_public {:?}", &gpg_key_public);
//     debug_log!("sync_interval {:?}", sync_interval);
//     debug_log!("updated_at_timestamp {:?}", updated_at_timestamp);

//     // print-log stops here.
//     // so maybe let collaborator = CollaboratorTomlData::new( is failing

//     // likely failing
//     // Create the CollaboratorTomlData instance using the existing new() method:

//     // let collaborator = CollaboratorTomlData::new(
//     //     user_name,
//     //     user_salt_list,          // Empty vector for user_salt_list
//     //     ipv4_addresses,                // None for ipv4_addresses
//     //     None,                // None for ipv6_addresses
//     //     "".to_string(),      // Empty string for gpg_publickey_id
//     //     "".to_string(),      // Empty String for gpg_key_public
//     //     sync_interval,                   // 0 for sync_interval
//     //     updated_at_timestamp,                   // 0 for updated_at_timestamp
//     // );
//     // debug_log!("printing collaborator: {:?}", collaborator);

//     let collaborator = CollaboratorTomlData::new(
//         user_name,
//         user_salt_list,
//         ipv4_addresses,
//         ipv6_addresses,
//         gpg_publickey_id,
//         gpg_key_public,
//         sync_interval,
//         updated_at_timestamp,
//     );

//     debug_log!("collaborator {:?}", collaborator);

//     // Serialize the data:
//     // let toml_string = toml::to_string(&collaborator).map_err(|e| {
//     //     std::io::Error::new(
//     //         std::io::ErrorKind::Other,
//     //         format!("TOML serialization error: {}", e),
//     //     )
//     // })?;



//     match serialize_collaborator_to_toml(&collaborator) {
//         Ok(toml_string) => {
//             println!("Serialized TOML:\n{}", toml_string);

//             // Write the TOML string to a file (example file path)
//             // match write_toml_to_file("collaborator_data.toml", &toml_string) {
//             //     Ok(_) => println!("TOML data written to file successfully."),
//             //     Err(e) => println!("Error writing to file: {}", e),
//             // }
//             debug_log!("toml_string {:?}", toml_string);

//             // Construct the file path:
//             let file_path = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
//                 .join(format!("{}__collaborator.toml", collaborator.user_name));

//             // Log the constructed file path:
//             debug_log!("Attempting to write collaborator file to: {:?}", file_path);

//             // Create the file and write the data:
//             let mut file = File::create(file_path.clone())?;
//             file.write_all(toml_string.as_bytes())?;

//         }
//         Err(e) => println!("Error serializing to TOML: {}", e),
//     }

//      // // Check for potential errors during file creation:
//      // match File::create(&file_path) {
//      //     Ok(mut file) => {
//      //         debug_log!("File creation succeeded.");

//      //         // Check for errors while writing to the file:
//      //         match file.write_all(toml_string.as_bytes()) {
//      //             Ok(_) => {
//      //                 debug_log!("Collaborator file written successfully.");
//      //             },
//      //             Err(err) => {
//      //                 debug_log!("Error writing data to collaborator file: {:?}", err);
//      //                 // Consider returning the error here for more explicit error handling
//      //                 // return Err(err);
//      //             }
//      //         }
//      //     },
//      //     Err(err) => {
//      //         debug_log!("Error creating collaborator file: {:?}", err);
//      //         // Return the error here to propagate it
//      //         return Err(err);
//      //     }
//      // }

//     Ok(())
// }

fn check_collaborator_collisions(
    new_collaborator: &CollaboratorTomlData,
    existing_collaborators: &Vec<CollaboratorTomlData>
 ) -> Option<String> {
    for existing in existing_collaborators {
        if existing.user_name == new_collaborator.user_name {
            return Some("Error: A collaborator with that username already exists!".to_string());
        }
        // Add checks for IP and port conflicts
    }
    None // No collisions
}

fn add_collaborator_qa(
    // graph_navigation_instance_state: &GraphNavigationInstanceState
) -> Result<(), io::Error> {

    println!("Name: Enter collaborator user name:");
    let mut new_username = String::new();
    io::stdin().read_line(&mut new_username)?;
    let new_username = new_username.trim().to_string();

    // Salt List!
    println!("Salt List: Press Enter for random, or type 'manual' for manual input");
    let mut new_usersalt_list_input = String::new();
    io::stdin().read_line(&mut new_usersalt_list_input)?;
    let new_usersalt_list_input = new_usersalt_list_input.trim().to_string();

    let new_usersalt_list: Vec<u128> = if new_usersalt_list_input == "manual" {
        let mut salts = Vec::new();
        for i in 1..=4 {
            println!("Enter salt {} (u128):", i);
            let mut salt_input = String::new();
            io::stdin().read_line(&mut salt_input)?;
            let salt: u128 = salt_input.trim().parse().expect("Invalid input, so using u128 input for salt");
            salts.push(salt);
        }
        salts
    } else {
        // Generate 4 random u128 salts
        (0..4)
            .map(|_| rand::rng().random())
            .collect()
    };

    println!("Using salts: {:?}", new_usersalt_list);


    // choice...
    // Get IP address input method
    // TODO for auto-detect don't use local-only ports... duh!!
    println!("Do you want to auto-detect IPv6 and IPv4? ('yes' or 'no' for manual input)");
    let mut pick_ip_find_method = String::new();
    io::stdin().read_line(&mut pick_ip_find_method)?;
    let pick_ip_find_method = pick_ip_find_method.trim().to_string();

    let (ipv4_addresses, ipv6_addresses) = if pick_ip_find_method == "yes" {
        // Auto-detect IP addresses
        let detected_addresses = get_local_ip_addresses()?;
        let mut ipv4_addresses: Option<Vec<Ipv4Addr>> = None;
        let mut ipv6_addresses: Option<Vec<Ipv6Addr>> = None;

        for addr in detected_addresses {
            match addr {
                IpAddr::V4(v4) => {
                    if ipv4_addresses.is_none() {
                        ipv4_addresses = Some(Vec::new());
                    }
                    ipv4_addresses.as_mut().unwrap().push(v4);
                }
                IpAddr::V6(v6) => {
                    if ipv6_addresses.is_none() {
                        ipv6_addresses = Some(Vec::new());
                    }
                    ipv6_addresses.as_mut().unwrap().push(v6);
                }
            }
        }
        (ipv4_addresses, ipv6_addresses) // Return the detected addresses
    } else {
        // Manual IP address input
        println!("Enter IPv4 address (or 'done' if finished, leave blank to skip):");
        let ipv4_addresses = get_ipv4_addresses()?;

        println!("Enter IPv6 address (or 'done' if finished, leave blank to skip):");
        let ipv6_addresses = get_ipv6_addresses()?;
        (ipv4_addresses, ipv6_addresses) // Return the manually entered addresses
    };

    println!("Enter the collaborator's public GPG key ID (public, NOT PRIVATE!!):");
    let mut gpg_publickey_id = String::new();
    io::stdin().read_line(&mut gpg_publickey_id)?;
    let gpg_publickey_id = gpg_publickey_id.trim().to_string();

    println!("Enter the collaborator's public GPG key is ascii armored lines (public, NOT PRIVATE!!):");
    let mut gpg_key_public = String::new();
    io::stdin().read_line(&mut gpg_key_public)?;
    let gpg_key_public = gpg_key_public.trim().to_string();

    println!("Enter the collaborator's sync interval in seconds (default: 60):");
    let mut sync_interval_input = String::new();
    io::stdin().read_line(&mut sync_interval_input)?;
    let sync_interval: u64 = sync_interval_input.trim().parse().unwrap_or(60);

    // Error Handling (You'll want to add more robust error handling here)
    if new_username.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "Username cannot be empty",
        ));
    }

    // Create the CollaboratorTomlData struct
    let new_collaborator = CollaboratorTomlData::new(
        new_username, // for: user_name
        new_usersalt_list, // for: user_salt
        ipv4_addresses,
        ipv6_addresses,
        gpg_publickey_id,
        gpg_key_public,
        sync_interval,
        get_current_unix_timestamp(), // for: updated_at_timestamp
    );

    // Load existing collaborators from files
    // let existing_collaborators = read_a_collaborator_setup_toml().unwrap_or_default();
    // let (existing_collaborators, errors) = read_one_collaborator_addressbook_toml().unwrap_or_default();

    // Persist the new collaborator
    make_new_collaborator_addressbook_toml_file(
        new_collaborator.user_name.clone(),
        new_collaborator.user_salt_list.clone(),
        new_collaborator.ipv4_addresses,
        new_collaborator.ipv6_addresses,
        new_collaborator.gpg_publickey_id,
        new_collaborator.gpg_key_public,
        new_collaborator.sync_interval,
        new_collaborator.updated_at_timestamp,
    )?;

    println!("CollaboratorTomlData '{}' added!", new_collaborator.user_name);
    Ok(())
}

fn check_team_channel_collision(channel_name: &str) -> bool {
     let team_channels_dir = Path::new("project_graph_data/team_channels");
     let channel_path = team_channels_dir.join(channel_name);
     channel_path.exists()
}


fn read_and_validate_recipients(allowed: &[String]) -> io::Result<Vec<String>> {
    let mut input = String::new();
    io::stdin().read_line(&mut input)?;

    if input.trim().is_empty() {
        return Ok(Vec::new()); // Empty = all recipients
    }

    let mut validated = Vec::new();
    for name in input.trim().split(',') {
        let trimmed = name.trim();
        if allowed.contains(&trimmed.to_string()) {
            validated.push(trimmed.to_string());
        } else {
            println!("Warning: '{}' not in collaborator list, skipping", trimmed);
        }
    }

    if validated.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "No valid recipients specified"
        ));
    }

    Ok(validated)
}

fn read_expiration_minutes() -> io::Result<u64> {
    let mut input = String::new();
    io::stdin().read_line(&mut input)?;

    if input.trim().is_empty() {
        // Default: 30 days
        return Ok(30 * 24 * 60);
    }

    match input.trim().parse::<u64>() {
        Ok(minutes) if minutes > 0 => Ok(minutes),
        _ => {
            println!("Invalid input, using default (30 days)");
            Ok(30 * 24 * 60)
        }
    }
}

fn read_yes_no_choice() -> io::Result<bool> {
    let mut input = String::new();
    io::stdin().read_line(&mut input)?;

    match input.trim().to_lowercase().as_str() {
        "y" | "yes" => Ok(true),
        "n" | "no" | "" => Ok(false),
        _ => {
            println!("Invalid input, treating as 'no'");
            Ok(false)
        }
    }
}

fn read_multiline_text() -> io::Result<String> {
    let mut lines = Vec::new();
    loop {
        let mut line = String::new();
        io::stdin().read_line(&mut line)?;

        if line.trim().is_empty() {
            break;
        }
        lines.push(line.trim_end().to_string());
    }

    if lines.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "Message text cannot be empty"
        ));
    }

    Ok(lines.join("\n"))
}

/// Represents the current state of a user's navigation within the UMA project graph.
///
/// This struct holds information about the currently active team channel, the current node,
/// and other session-related data. It is used to manage user navigation and track the context
/// of user interactions.
///
/// In UMA, the file path of the `node.toml` file within the `project_graph_data/team_channels`
/// directory uniquely identifies a team channel. This method reads data from the `node.toml`
/// file at the current path to determine the active team channel and load relevant information.
#[derive(Debug, Deserialize, Serialize, Clone)]
struct GraphNavigationInstanceState {
    local_owner_user: String, // Store the local user data here
    // local_owner_hash_list: Vec<u8>,
    active_team_channel: String,
    default_im_messages_expiration_days: u64,
    default_task_nodes_expiration_days: u64,
    tui_height: u8,
    tui_width: u8,
    current_full_file_path: PathBuf,
    current_node_teamchannel_collaborators_with_access: Vec<String>,
    current_node_name: String,
    current_node_owner: String,
    current_node_description_for_tui: String,
    current_node_directory_path: PathBuf,
    current_node_unique_id: Vec<u8>,
    current_node_members: Vec<String>,
    home_square_one: bool,
    // from task fields:
    // project module items as task-ish thing
    pa1_process: String,
    pa2_schedule: Vec<u64>, // Vec<u64>,?
    pa3_users: String,
    // goals_features_subfeatures_tools_targets: String,
    pa4_features: String,
    pa5_mvp: String,
    pa6_feedback: String,
    /*
    pa1_process
    pa2_schedule
    pa3_users
    pa4_features
    pa5_mvp
    pa6_feedback

    The project areas
        pa1_process - Process: Values, Agenda, Methods, Coordinated Decisions (Data/System)Ecology: Collapse & Productivity
        pa2_schedule - Schedule: (?; whole; this iteration)
        pa3_users - Users: Stakeholders & Needs & Goals Evaluation (of users)
        pa4_features - Features: User-Features & Subfeatures (or hidden features)
        pa5_mvp - MVP: 'MVP's (Minimum Viable Products); Tools & 'Tool Stack / Tech Stack'
        pa6_feedback - Feedback: Tests, Ecological Effects, Communication, Documentation & Iteration (~agile)
    */

    /// message_post_gpgtoml_required
    message_post_gpgtoml_required:  Option<bool>,

    /// Integer validation ranges as tuples (min, max) - inclusive bounds
    message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Integer-string validation ranges as tuples (min, max) for the integer part
    message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Maximum string length
    message_post_max_string_length_int: Option<usize>,

    /// Whether posts are public or private
    message_post_is_public_bool: Option<bool>,

    /// Whether user confirmation is required before posting
    message_post_user_confirms_bool: Option<bool>,

    /// Start time for accepting posts (UTC POSIX timestamp)
    message_post_start_date_utc_posix: Option<i64>,

    /// End time for accepting posts (UTC POSIX timestamp)
    message_post_end_date_utc_posix: Option<i64>,

	// // limit of how many posts (or per time duration)
 //    max_posts: Option<i64>,
 //    duration_for_maxposts: MaxPostsDurationUnitsEnum, // hours, days, weeks
 //    n_durations_for_maxposts: Option<i64>,
}

impl GraphNavigationInstanceState {

    /// To read a node toml: See if you want to use load_core_node_from_toml_file() instead.
    ///
    /// This is the routine check to see, as you navigate around
    /// if you are not entering a new node (do nothing becuase
    /// there is no node.toml), if you are entering a new normal node,
    /// or if you are entering the special-case of a team-channel node.
    ///
    /// Loads and updates the `GraphNavigationInstanceState` based on the `current_full_file_path`.
    ///
    /// This method is called whenever the user navigates to a new directory within the
    /// UMA project graph. It determines the type of node (team-channel, project,
    ///  messages, tasks, etc., etc.)
    /// based on the `current_full_file_path` and loads relevant information from the
    /// `node.toml` file, updating the internal state accordingly.
    ///
    /// ## Team Channel Nodes
    ///
    /// If the `current_full_file_path` indicates a team-channel node (a directory within
    /// `project_graph_data/team_channels`), this method performs the following:
    ///
    /// 1. Sets the `active_team_channel` to the name of the team-channel.
    /// 2. Loads collaborator port assignments from the `node.toml` file.
    /// 3. Populates the `collaborator_ports` field with a `HashMap` mapping collaborator
    ///    usernames to their respective `CollaboratorPorts` struct.
    ///
    /// ## Other Node Types
    ///
    /// For project nodes and task nodes, this method will load relevant data from
    /// the `node.toml` file but will NOT load active_team_channel, as this is
    ///  only relevant at the team-channel level.
    ///
    /// ## Error Handling
    ///
    /// If the `node.toml` file is not found or cannot be parsed, the method logs an error
    /// message and returns without updating the state.
    ///
    /// This function specifically loads Port assignments if the `current_full_file_path`
    /// corresponds to a team-channel node, as indicated by the path being within the
    /// `project_graph_data/team_channels` directory.
    ///
    /// Not all information has the same owner-author and privacy requirements and so cannot be obtained from any mythical singularity. Port-assignments are made by the owner of the team-channel so as to be guaranteed not to collide and adding a new user/collaborator will not disrupt existing processes/collaborators/users/workers/participants/network-connections.
    /// A user's ip addresses and gpg keys and screen-name can only come from, and be owned by, that user/collaborator.
    ///
    /// Likewise, the list of possible collaborators is set by the team-channel-owner. But whether another collaborator has actually shared their private connection data with you is and must be 100% their choice done by them and owned by them GPG signed by them and GPG encrypted for only 'you' (the current user) to use.
    ///
    /// The 'collaborators' for your session are then an intersection between these two categories of sources of truth: the collaborators who have connected with you (their choice, their owned documents), and the collaborators invited to the team-channel by the team-channel-owner (their choice, their owned document).
    /// Note: Your no-context set of all-collaborators is everyone in every channel, a general no-context address-book.
    /// By analogy: Tom is organizing a flower show and says Alice Bob and you are invited, and he asks you to call them.
    /// Bob is the one who chooses who to invite.
    /// You have an address book that includes Alice and Bob and everyone else in your address book.
    ///
    /// To make these call-connections you need to find the intersection between these two sets:
    /// 1. Who did the team-owner (Tom) invite to the flower show?
    /// 2. Who is in your address book?
    ///
    /// You cannot call everyone in your address book, because Tom didn't invite everyone in your address book.
    /// And Tom can't tell you Bob's phone number and call availability information, because only Bob can tell you his own private information.
    ///
    /// This means there are at least two sources or two different categories of truths that must be used when loading "state" for a session in a team-channel in Uma.
    ///
    /// Note: it is crutial that he source of truth for whether a node is a team-channel node be the file-structure itself
    /// and that code to extract team-channel connection data (such as port-assignments) is never attempted used in other
    /// nodes such as non-team-channel nodes within that team-channel (nearly ~everything is a node, only a few are team-channels)
    fn nav_graph_look_read_node_toml(&mut self) {
        debug_log!(
            "starting nav_graph_look_read_node_toml() self.current_full_file_path -> {:?}, self.active_team_channel.clone() -> {:?}",

            self.current_full_file_path.clone(),
            self.active_team_channel.clone(),
        );

        // TODO check for node.toml or .gpgtoml

        // Construct path to node.toml or node.gpgtoml
        // Find the configuration file (could be either node.toml OR node.gpgtoml)
        let node_toml_path = match find_node_toml_or_gpgtoml_file(
            &self.current_full_file_path,
            ) {
            Ok(Some(path)) => {
                // This is the path to whichever file was found (node.toml OR node.gpgtoml)
                debug_log!("Found configuration file at: {:?}", path);
                path  // <-- This could be either file!
            },
            Ok(None) => {
                // No file found - handle the error properly
                debug_log("Neither node.toml nor node.gpgtoml found");
                return;
            },
            Err(e) => {
                // Error occurred - handle it properly
                debug_log!("Neither node.toml nor node.gpgtoml found >> {}", e);
                return;
            }
        };

        // Now you have node_toml_path available for use
        debug_log!(
            "nav_graph_look_read_node_toml() node_toml_path -> {:?}",
            node_toml_path.clone()
        );

        // Add more detailed existence checking
        debug_log!("Checking if path exists: {:?}", node_toml_path.exists());
        debug_log!("Checking if path is file: {:?}", node_toml_path.is_file());

        debug_log!(
            "nav_graph_look_read_node_toml() node_toml_path -> {:?}",
            node_toml_path.clone()
        );

        debug_log!(
            "nav_graph_look_read_node_toml() node_toml_path -> {:?}",
            node_toml_path.clone()
        );

        // Add more detailed existence checking
        debug_log!("Checking if path exists: {:?}", node_toml_path.exists());
        debug_log!("Checking if path is file: {:?}", node_toml_path.is_file());

        // if no file exists, return immediately!
        if !node_toml_path.exists() {
            debug_log!("No node.toml at {:?} - this directory is not a node", node_toml_path);
            return;
        }

        // Try to read the file metadata
        match fs::metadata(&node_toml_path) {
            Ok(metadata) => {
                debug_log!("File metadata found: is_file={}, size={}", metadata.is_file(), metadata.len());
            },
            Err(e) => {
                debug_log!("\n\n nav_graph_look_read_node_toml() Error reading file metadata: {}", e);
            }
        }

        debug_log("In nav_graph_look_read_node_toml(), next calling: load_core_node_from_toml_file(file_path: &Path) -> Result<CoreNode");
        // Try to open and read the file
        match fs::read_to_string(&node_toml_path) {
            Ok(contents) => {
                debug_log!("Successfully read file, content length: {}", contents.len());


                // Load and parse the node.toml file
                let this_node = match load_core_node_from_toml_file(&node_toml_path) {
                    Ok(node) => node,
                    Err(e) => {
                        debug_log!("ERROR: nav_graph_look_read_node_toml(), load_core_node_from_toml_file(), Failed to load node.toml: {}", e);
                        return;
                    }
                };

                debug_log!("nav_graph_look_read_node_toml(), this_node -> {:?}", this_node);

                // Check if this is a Team Channel Node using path components
                let is_team_channel = self.current_full_file_path
                    .components()
                    .any(|component| component.as_os_str() == "team_channels");

                if is_team_channel {
                    // Update state for team channel node
                    self.active_team_channel = this_node.node_name.clone();
                    self.current_node_teamchannel_collaborators_with_access = this_node.teamchannel_collaborators_with_access.clone();
                    self.current_node_name = this_node.node_name.clone();
                    self.current_node_owner = this_node.owner.clone();
                    self.current_node_description_for_tui = this_node.description_for_tui.clone();
                    self.current_node_directory_path = this_node.directory_path.clone();
                    self.current_node_unique_id = this_node.node_unique_id;
                    self.home_square_one = false;

                    // Project Areas
                    self.pa1_process = this_node.pa1_process;
                    self.pa2_schedule = this_node.pa2_schedule;
                    self.pa3_users = this_node.pa3_users;
                    self.pa4_features = this_node.pa4_features;
                    self.pa5_mvp = this_node.pa5_mvp;
                    self.pa6_feedback = this_node.pa6_feedback;
                } else {
                    debug_log!("nav_graph_look_read_node_toml(), not a team channel node");
                    /*
                    this should be loading... node items...
                    */

                    // Update state for non-team-channel nodes
                    // These fields should be updated for ANY node type
                    self.current_node_teamchannel_collaborators_with_access = this_node.teamchannel_collaborators_with_access.clone();
                    self.current_node_name = this_node.node_name.clone();
                    self.current_node_owner = this_node.owner.clone();
                    self.current_node_description_for_tui = this_node.description_for_tui.clone();
                    self.current_node_directory_path = this_node.directory_path.clone();
                    self.current_node_unique_id = this_node.node_unique_id;
                    // self.current_node_members = this_node.members.clone();
                    self.home_square_one = false;

                    // Project Areas - these should be available for any node
                    self.pa1_process = this_node.pa1_process;
                    self.pa2_schedule = this_node.pa2_schedule;
                    self.pa3_users = this_node.pa3_users;
                    self.pa4_features = this_node.pa4_features;
                    self.pa5_mvp = this_node.pa5_mvp;
                    self.pa6_feedback = this_node.pa6_feedback;

                    // Message posting configuration fields (if present in CoreNode)
                    self.message_post_gpgtoml_required = this_node.message_post_gpgtoml_required;
                    self.message_post_data_format_specs_integer_ranges_from_to_tuple_array = this_node.message_post_data_format_specs_integer_ranges_from_to_tuple_array;
                    self.message_post_data_format_specs_int_string_ranges_from_to_tuple_array = this_node.message_post_data_format_specs_int_string_ranges_from_to_tuple_array;
                    self.message_post_max_string_length_int = this_node.message_post_max_string_length_int;
                    self.message_post_is_public_bool = this_node.message_post_is_public_bool;
                    self.message_post_user_confirms_bool = this_node.message_post_user_confirms_bool;
                    self.message_post_start_date_utc_posix = this_node.message_post_start_date_utc_posix;
                    self.message_post_end_date_utc_posix = this_node.message_post_end_date_utc_posix;

                    // Note: We do NOT update active_team_channel
                    // because these are only relevant for team-channel nodes


                }
            },
            Err(e) => {
                // the error would be an error in reading node.toml
                // it is not an error to not need to try to read
                // a file that is not there.
                debug_log!("NGLRNT Error reading file: {}", e);
                debug_log!("NGLRNTThis directory is not a node. nav_graph_look_read_node_toml() node.toml not found at {:?}. ", node_toml_path);
                return;
            }
        }

        // // create team channel...path state
        // // set file-state team-channel's current_node_directory_path
        // let file_path = get_sessionstateitems_path()?.join("current_node_directory_path.txt");
        // if let Some(path_str) = self.current_node_directory_path.to_str() {
        //     fs::write(file_path, path_str)?;
        // }

        // create team channel...path state
        // set file-state team-channel's current_node_directory_path
        if let Ok(session_path) = get_sessionstateitems_path() {
            let file_path = session_path.join("current_node_directory_path.txt");
            if let Some(path_str) = self.current_node_directory_path.to_str() {
                if let Err(e) = fs::write(file_path, path_str) {
                    debug_log!("NGLRNT Failed to write file: {}", e);
                    // Optionally log the error or handle it in another way
                }
            }
        } else {
            debug_log!("NGLRNT Failed to get session state items path");
            // Optionally log the error or handle it in another way
        }

        debug_log!("NGLRNT Done: ending: nav_graph_look_read_node_toml()");
    }
}  // end of impl GraphNav...

/// Helper function to parse directory name in format "number_name"
fn parse_directory_name(name: &str) -> Option<(usize, &str)> {
    let parts: Vec<&str> = name.splitn(2, '_').collect();
    if parts.len() == 2 {
        if let Ok(num) = parts[0].parse::<usize>() {
            return Some((num, parts[1]));
        }
    }
    None
}

/// Helper function to truncate string to specified length
fn truncate_string(s: &str, max_len: usize) -> String {
    if s.len() <= max_len {
        s.to_string()
    } else {
        format!("{}...", &s[..max_len.saturating_sub(3)])
    }
}

//e.g.
// // Load active_team_channel:
// self.active_team_channel = fs::read_to_string(session_items_path.join("active_team_channel.txt"))?;

#[derive(Debug, Deserialize, Serialize, Clone)]
enum NodePriority {
    High,
    Medium,
    Low,
}

/*
the .toml files and the overall Uma~browser must be able to know their location in the overall project_graph_data/file-system

1. command 'make node' needs to be filled in to make a node in the 'current'
graph-dungeon location.
2. produce a .toml file in the node when node is made
3. load from the .toml file node is navigated into
4. node_name needs to be integrated, and accessed when the node is navigated into
*/

/// Represents a core node in the UMA project graph.
///
/// This struct holds information about a node, including its name, description, collaborators,
/// port assignments for collaborators, and other metadata. It is used to save and load node
/// data to and from `node.toml` files.
///
/// # Collaborator Ports
///
/// Collaborator port assignments are stored in the `abstract_collaborator_port_assignments` field, which is a
/// `HashMap`. The keys of the `HashMap` are the usernames of the collaborators (strings),
/// and the values are instances of the `CollaboratorPorts` struct.
///
/// The `CollaboratorPorts` struct contains six `u16` fields representing the different ports
/// assigned to each collaborator for synchronization purposes:
///  - `ready_port`: The port used by a collaborator to signal they are ready to receive data.
///  - `tray_port`: The port used to send files to a collaborator (their "in-tray").
///  - `gotit_port`: The port used by a collaborator to confirm receipt of a file.
///  - `self_ready_port`: The port this node listens on for ready signals from the collaborator.
///  - `self_tray_port`: The port this node listens on for incoming files from the collaborator.
///  - `self_gotit_port`: The port this node uses to confirm file receipt to the collaborator.
///
/// ## Serialization and Deserialization
///
/// When saving a `CoreNode` to a `node.toml` file (using the `save_node_to_clearsigned_file` function),
/// the `abstract_collaborator_port_assignments` field is serialized as a TOML table where the keys are the
/// collaborator usernames and the values are tables containing the six port assignments.
///
/// When loading a `CoreNode` from a `node.toml` file (using the `load_node_from_file` function),
/// the TOML table representing collaborator ports is deserialized into the
/// `abstract_collaborator_port_assignments` field.
///
/// ## Example `node.toml` Section
///
/// ```toml
/// [abstract_collaborator_port_assignments]
/// alice = { ready_port = 50001, tray_port = 50002, gotit_port = 50003, self_ready_port = 50004, self_tray_port = 50005, self_gotit_port = 50006 }
/// bob = { ready_port = 50011, tray_port = 50012, gotit_port = 50013, self_ready_port = 50014, self_tray_port = 50015, self_gotit_port = 50016 }
/// ```
///
/// there is a design and security debate over how to define a team-channel node
/// I think it is safer to define it as a physical directory basal location, in the team_channels direcorry
/// rather than give it ia declarative-definiiton where anyone could invent or uninvent a team-channel
/// and all the port use that goes along with that
#[derive(Debug, Deserialize, Serialize, Clone)]
struct CoreNode {
    /// The name of the node. This is used for display and identification.
    node_name: String,

    // /// Is node.toml file gpg encrypted
    corenode_gpgtoml: bool,

    /// A description of the node, intended for display in the TUI.
    description_for_tui: String,
    /// A unique identifier for the node, generated using pearson hashes of the other fields
    node_unique_id: Vec<u8>,
    /// The path to the directory on the file system where the node's data is stored.
    directory_path: PathBuf,
    /// An order number used to define the node's position within a list or hierarchy.
    // order_number: u32,
    /// The priority of the node, which can be High, Medium, or Low.
    // priority: NodePriority,
    /// The username of the owner of the node.
    owner: String,
    /// The Unix timestamp representing when the node was last updated.
    updated_at_timestamp: u64,
    /// The Unix timestamp representing when the node will expire.
    expires_at: u64,
    /// A vector of `CoreNode` structs representing the child nodes of this node.
    // children: Vec<CoreNode>,
    /// An ordered vector of collaborator usernames associated with this node.
    teamchannel_collaborators_with_access: Vec<String>,
    /// A map containing port assignments for each collaborator associated with the node.
    abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,

    // project areas: project module items as task-ish thing
    pa1_process: String,
    pa2_schedule: Vec<u64>,
    pa3_users: String,
    pa4_features: String,
    pa5_mvp: String,
    pa6_feedback: String,

    /////////////////
    // message_posts
    /////////////////

    // /// maybe: gpg encrypted messages? (new clearsign standard?)
    pub message_post_gpgtoml_required: Option<bool>,

    /// Integer validation ranges as tuples (min, max) - inclusive bounds
    pub message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Integer-string validation ranges as tuples (min, max) for the integer part
    pub message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Maximum string length
    pub message_post_max_string_length_int: Option<usize>,

    /// Whether posts are public or private
    pub message_post_is_public_bool: Option<bool>,

    /// Whether user confirmation is required before posting
    pub message_post_user_confirms_bool: Option<bool>,

    /// Start time for accepting posts (UTC POSIX timestamp)
    pub message_post_start_date_utc_posix: Option<i64>,

    /// End time for accepting posts (UTC POSIX timestamp)
    pub message_post_end_date_utc_posix: Option<i64>,

	// limit of how many posts (or per time duration)
    // pub max_posts: Option<i64>,
    // pub duration_for_maxposts: MaxPostsDurationUnitsEnum, // hours, days, weeks
    // pub n_durations_for_maxposts: Option<i64>,
}

/// Creates a new `CoreNode` instance.
///
/// # Arguments
///
/// * `node_name` - The name of the node.
/// * `description_for_tui` - A description for display in the TUI.
/// * `directory_path` - The path to the node's directory.
/// * `order_number` - The order number for the node.
/// * `priority` - The priority of the node.
/// * `owner` - The username of the node's owner.
/// * `collaborators` - An ordered vector of collaborator usernames.
/// * `abstract_collaborator_port_assignments` - A map of collaborator port assignments.
///
/// # Returns
///
/// * A new `CoreNode` instance with the given attributes.
///
/// The name of the node. This is used for display and identification.
/// node_name: String,
/// A description of the node, intended for display in the TUI.
/// description_for_tui: String,
/// A unique identifier for the node, generated using a timestamp at node creation.
/// node_unique_id: u64,
/// The path to the directory on the file system where the node's data is stored.
/// directory_path: PathBuf,
/// An order number used to define the node's position within a list or hierarchy.
/// order_number: u32,
/// The priority of the node, which can be High, Medium, or Low.
/// priority: NodePriority,
/// The username of the owner of the node.
/// owner: String,
/// The Unix timestamp representing when the node was last updated.
/// updated_at_timestamp: u64,
/// The Unix timestamp representing when the node will expire.
/// expires_at: u64,
/// A vector of `CoreNode` structs representing the child nodes of this node.
/// children: Vec<CoreNode>,
/// An ordered vector of collaborator usernames associated with this node.
/// teamchannel_collaborators_with_access: Vec<String>,
/// A map containing port assignments for each collaborator associated with the node.
/// abstract_collaborator_port_assignments: HashMap<String, CollaboratorPorts>,
///
/// # Arguments
///
/// * `node_name` - The name of the node
/// * `description_for_tui` - Description to display in the TUI
/// * `directory_path` - Absolute path to the node's directory
/// * `owner` - Username of the node owner
/// * `teamchannel_collaborators_with_access` - List of collaborators with access
/// * `abstract_collaborator_port_assignments` - Port assignments for collaborators
/// * `pa1_process` - Project area 1: process description
/// * `pa2_schedule` - Project area 2: schedule timestamps
/// * `pa3_users` - Project area 3: users description
/// * `pa4_features` - Project area 4: features description
/// * `pa5_mvp` - Project area 5: MVP description
/// * `pa6_feedback` - Project area 6: feedback description
/// message_post_gpgtoml_required
/// * `message_post_data_format_specs_integer_ranges_from_to_tuple_array` - Integer validation ranges
/// * `message_post_data_format_specs_int_string_ranges_from_to_tuple_array` - Integer-string validation ranges
/// * `message_post_max_string_length_int` - Max string length for int-string pairs
/// * `message_post_is_public_bool` - Whether posts are public
/// * `message_post_user_confirms_bool` - Whether user confirmation is required
/// * `message_post_start_date_utc_posix` - Start date for accepting posts
/// * `message_post_end_date_utc_posix` - End date for accepting posts
impl CoreNode {
    fn new(
        node_name: String,
        corenode_gpgtoml: bool,
        description_for_tui: String,
        directory_path: PathBuf,
        owner: String,
        teamchannel_collaborators_with_access: Vec<String>,
        abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
        // Project Areas
        pa1_process: String,
        pa2_schedule: Vec<u64>, // Vec<u64>
        pa3_users: String,
        pa4_features: String,
        pa5_mvp: String,
        pa6_feedback: String,
        // Message Post Configuration
        message_post_gpgtoml_required: Option<bool>,
        message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,
        message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,
        message_post_max_string_length_int: Option<usize>,
        message_post_is_public_bool: Option<bool>,
        message_post_user_confirms_bool: Option<bool>,
        message_post_start_date_utc_posix: Option<i64>,
        message_post_end_date_utc_posix: Option<i64>,
    ) -> Result<CoreNode, ThisProjectError> {

        debug_log!("Starting CoreNode::new");
        debug_log!("implCoreNode-new: Directory path received: {:?}", directory_path);
        debug_log!("implCoreNode-new: Checking if directory exists: {}", directory_path.exists());
        debug_log!("implCoreNode-new: Absolute path: {:?}", directory_path.canonicalize().unwrap_or(directory_path.clone()));

        debug_log!("implCoreNode-new: About to get current timestamp");
        let expires_at = get_current_unix_timestamp() + 11111111111;
        let updated_at_timestamp = get_current_unix_timestamp();
        debug_log!("implCoreNode-new: Got timestamps");

        // Get armored public key, using key-id (full fingerprint in)
        let full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => fingerprint,
            Err(e) => {
                eprintln!("implCoreNode-new: Failed to read GPG fingerprint from uma.toml: {}", e);
                return Err(ThisProjectError::from(format!(
                    "implCoreNode-new: Failed to read GPG fingerprint from uma.toml: {}", e
                )));
            }
        };

        // 1. Get the salt list using the correct function
        debug_log!("implCoreNode-new: About to get address book data for owner: {}", owner);
        let owner_data = match get_addressbook_file_by_username(
            &owner,
            &full_fingerprint_key_id_string,
            ) {
            Ok(data) => {
                debug_log!("implCoreNode-new: Successfully got address book data");
                data
            },
            Err(e) => {
                debug_log!("implCoreNode-new: impl corenode new() Error getting address book data: {:?}", e);
                return Err(e);
            }
        };
        let salt_list = owner_data.user_salt_list;

        debug_log!("implCoreNode-new: About to calculate node_unique_id");
        // 2. Calculate the hash
        // TODO add new fields to hash
        let node_unique_id = match calculate_corenode_hashes(
            &node_name,
            &description_for_tui,
            updated_at_timestamp,
            &salt_list,
        ) {
            Ok(id) => {
                debug_log!("implCoreNode-new: Successfully calculated node_unique_id");
                id
            },
            Err(e) => {
                debug_log!("implCoreNode-new: Error calculating node_unique_id: {:?}", e);
                return Err(e);
            }
        };

        debug_log!("implCoreNode-new: About to create CoreNode instance");
        // 3. Create the CoreNode instance
        let node = CoreNode {
            node_name,
            corenode_gpgtoml,
            description_for_tui,
            node_unique_id,
            directory_path,
            owner,
            updated_at_timestamp,
            expires_at,
            teamchannel_collaborators_with_access,
            abstract_collaborator_port_assignments,
            // Project Areas
            pa1_process,
            pa2_schedule, // Vec<u64>
            pa3_users,
            pa4_features,
            pa5_mvp,
            pa6_feedback,
            // Message Post Configuration
            message_post_gpgtoml_required,
            message_post_data_format_specs_integer_ranges_from_to_tuple_array,
            message_post_data_format_specs_int_string_ranges_from_to_tuple_array,
            message_post_max_string_length_int,
            message_post_is_public_bool,
            message_post_user_confirms_bool,
            message_post_start_date_utc_posix,
            message_post_end_date_utc_posix,
        };
        debug_log!("Successfully created CoreNode instance");

        Ok(node)
    }

    /// Saves the `CoreNode` data to a `node.toml` file.
    ///
    /// This function serializes the `CoreNode` struct into TOML format and writes
    /// it to a file at the path specified by the `directory_path` field, creating
    /// the directory if it doesn't exist.
    ///
    /// # Error Handling
    ///
    /// Returns a `Result<(), io::Error>` to handle potential errors during:
    ///  - TOML serialization
    ///  - Directory creation
    ///  - File writing
    fn save_node_to_clearsigned_file(&self) -> Result<(), io::Error> {
        // Debug logging for initial state
        debug_log!("in imple CoreNode: SNCTF -> Starting save_node_to_clearsigned_file!");
        debug_log!("SNCTF: Current working directory: {:?}", std::env::current_dir()?);
        debug_log!("SNCTF: Target directory path: {:?}", self.directory_path);

        // 1. Verify and create directory structure
        if !self.directory_path.exists() {
            debug_log!("SNCTF: Directory doesn't exist, creating it");
            fs::create_dir_all(&self.directory_path)?;
        }
        debug_log!("SNCTF: Directory now exists: {}", self.directory_path.exists());

        // 2. Verify directory is actually a directory
        if !self.directory_path.is_dir() {
            debug_log!("SNCTF: Path exists but is not a directory!");
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNCTF: Path exists but is not a directory"
            ));
        }

        // 3. Serialize the CoreNode struct to a TOML string
        let toml_string = toml::to_string(&self).map_err(|e| {
            debug_log!("SNCTF: TOML serialization error: {}", e);
            io::Error::new(
                io::ErrorKind::Other,
                format!("SNCTF: TOML serialization error: {}", e),
            )
        })?;
        debug_log!("SNCTF: Successfully serialized CoreNode to TOML");

        // 4. Construct and verify the file path
        let file_path = self.directory_path.join("node.toml");
        debug_log!("SNCTF: Full file path for node.toml: {:?}", file_path);

        // 5. Verify parent directory one more time
        if let Some(parent) = file_path.parent() {
            if !parent.exists() {
                debug_log!("SNCTF: Parent directory missing, creating: {:?}", parent);
                fs::create_dir_all(parent)?;
            }
        }

        // 6. Write the TOML data to the file
        debug_log!("SNCTF: Writing TOML data to file...");
        fs::write(&file_path, &toml_string)?;

        // 7. Verify the file was created
        if file_path.exists() {
            debug_log!("SNCTF: Successfully created node.toml at: {:?}", file_path);
        } else {
            debug_log!("SNCTF: Warning: File write succeeded but file doesn't exist!");
        }

        /*

        this will include an extra lookup step:
                1. get file_owner name from the clearsign-toml file
                2. look up user addressbook file by user-name
                3. get key-id from file-owner's addressbook file
                4. clearsign with key-id so that reader can varify clearsign with public-key
                from addressbook file.
                convert_toml_filewithkeyid_into_clearsigntoml_inplace?
                maybe new function with extra lookup step...

        the new function will be:
        fn convert_tomlfile_without_keyid_into_clearsigntoml_inplace(
            path_to_toml_file: &Path,
        ) -> Result<(), GpgError> {

        these may be the needed steps:

            // Read username from the configuration file, mapping any reading errors to our error type
            let file_owner_username = read_single_line_string_field_from_toml(config_path_str, "owner")
                .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
                    format!("Failed to read file_owner_username from config: {}", error_message)
                ))?;

            debug_log!("file_owner_username {}", file_owner_username);

            // Convert the collaborator files directory to an absolute path based on the executable's location
            // AND verify that the directory exists (returns error if not found or not a directory)
            let addressbook_files_directory_relative = COLLABORATOR_ADDRESSBOOK_PATH_STR;
            let addressbook_files_directory_absolute = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(
                addressbook_files_directory_relative
            ).map_err(|io_error| ThisProjectError::IoError(io_error))?;

            // Construct the path to the user's collaborator file, which contains their GPG key ID
            let collaborator_filename = format!("{}__collaborator.toml", file_owner_username);
            let user_config_path = addressbook_files_directory_absolute.join(collaborator_filename);

            debug_log!("user_config_path {}", user_config_path.display());

            // Convert the collaborator file path to string for TOML reading
            let user_config_path_str = user_config_path.to_str()
                .ok_or_else(|| ThisProjectError::InvalidInput("Cannot convert collaborator file path to string".to_string()))?;

            debug_log!("user_config_path {}", user_config_path.display());
            println!("user_config_path {}", user_config_path.display());

            // Extract the GPG key ID from the collaborator file
            let gpg_key_id = read_singleline_string_from_clearsigntoml(user_config_path_str, "gpg_publickey_id")
                .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
                    format!("export_public_gpg_key_converts_to_abs_path() Failed read_singleline_string_from_clearsigntoml() to read GPG key ID from clearsigntoml collaborator file: {}", error_message)
                ))?;


                notes:
                File Types Being Handled:

        The Target TOML File (the one we want to clearsign):

        Initially: Plain TOML file (NOT clearsigned)
        Contains: An owner field with the username
        Read with: read_single_line_string_field_from_toml()
        End state: Will become clearsigned after our function runs


        The Collaborator Addressbook File ({username}__collaborator.toml):

        Already clearsigned TOML
        Contains: The gpg_publickey_id field
        Read with: read_singleline_string_from_clearsigntoml()
        Remains unchanged by our function

        scope summary:
                Scope Confirmation
        Purpose
        Create a function that clearsigns a plain TOML file in-place, but unlike the existing function, this one does not expect the gpg_publickey_id to be present in the target TOML file. Instead, it performs a multi-step lookup process to determine which GPG key to use for signing.
        Key Differences from Existing Function

        Target TOML file: Does NOT contain gpg_publickey_id field
        Target TOML file: MUST contain an owner field with the file owner's username
        Additional lookup: Uses the owner's username to find their collaborator addressbook file
        GPG key source: Extracts the gpg_publickey_id from the owner's addressbook file (not from the target file)

        Process Flow

        Read owner username from the target TOML file (plain TOML)

        Field name: "owner"
        Use: read_single_line_string_field_from_toml()


        Construct addressbook file path

        Base directory: COLLABORATOR_ADDRESSBOOK_PATH_STR (relative to executable)
        Convert to absolute path using: make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error()
        Filename pattern: {owner_username}__collaborator.toml


        Read GPG key ID from the addressbook file

        The addressbook file is already clearsigned
        Field name: "gpg_publickey_id"
        Use: read_singleline_string_from_clearsigntoml()


        Clearsign the target file

        Use the extracted GPG key ID to sign the original target TOML file
        Replace the original file in-place with its clearsigned version



        File States

        Target TOML file: Starts as plain TOML  Ends as clearsigned TOML
        Addressbook file: Already clearsigned  Remains unchanged (read-only operation)

        */
        debug_log!("SNCTF: Starting convert_tomlfile_without_keyid_into_clearsigntoml_inplace()");

        // Get armored public key, using key-id (full fingerprint in)
        let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => fingerprint,
            Err(e) => {
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}", e)
                ));
            }
        };

        convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
            &file_path,
            COLLABORATOR_ADDRESSBOOK_PATH_STR,
            &gpg_full_fingerprint_key_id_string,
        )
        .map_err(|gpg_err| {
            // Convert GpgError to std::io::Error
            std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("SNCTF: GPG into_clearsign operation failed: {:?}", gpg_err),
            )
        })?;

        Ok(())
    }

    // fn update_updated_at_timestamp(&mut self) {
    //     self.updated_at_timestamp = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
    // }

    /// Saves the `CoreNode` data to a `node.gpgtoml` file.
    ///
    /// This function serializes the `CoreNode` struct into TOML format,
    /// clearsigns it with the local user's GPG key, then encrypts it
    /// with their public key, and writes it as a GPG encrypted clearsigned file
    /// at the path specified by the `directory_path` field, creating
    /// the directory if it doesn't exist.
    ///
    /// # Process Flow
    ///
    /// 1. Serialize CoreNode to TOML
    /// 2. Write to temporary file in project temp directory
    /// 3. Clearsign the temp file in-place using user's secret key
    /// 4. Extract user's public key from GPG keyring
    /// 5. Encrypt the clearsigned file with public key
    /// 6. Save as node.gpgtoml in target directory
    /// 7. Clean up all temporary files
    ///
    /// # Error Handling
    ///
    /// Returns a `Result<(), io::Error>` to handle potential errors during:
    ///  - TOML serialization
    ///  - Directory creation
    ///  - File writing
    ///  - GPG operations (clearsigning and encryption)
    ///  - Temp file cleanup (ensures no files left in production)
    fn save_node_as_gpgtoml(&self) -> Result<(), io::Error> {
        // Debug logging for initial state
        debug_log!("in impl CoreNode: SNAGTF -> Starting save_node_as_gpgtoml!");
        debug_log!("SNAGTF: Current working directory: {:?}", std::env::current_dir()?);
        debug_log!("SNAGTF: Target directory path: {:?}", self.directory_path);

        // 1. Verify and create target directory structure
        if !self.directory_path.exists() {
            debug_log!("SNAGTF: Directory doesn't exist, creating it");
            fs::create_dir_all(&self.directory_path)?;
        }
        debug_log!("SNAGTF: Directory now exists: {}", self.directory_path.exists());

        // 2. Verify directory is actually a directory
        if !self.directory_path.is_dir() {
            debug_log!("SNAGTF: Path exists but is not a directory!");
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNAGTF: Path exists but is not a directory"
            ));
        }

        // 3. Serialize the CoreNode struct to a TOML string
        let toml_string = toml::to_string(&self).map_err(|e| {
            debug_log!("SNAGTF: TOML serialization error: {}", e);
            io::Error::new(
                io::ErrorKind::Other,
                format!("SNAGTF: TOML serialization error: {}", e),
            )
        })?;
        debug_log!("SNAGTF: Successfully serialized CoreNode to TOML");

        // 4. Get temp directory and create unique temp file path
        let temp_dir = get_base_uma_temp_directory_path()?;
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
            .as_secs();
        let temp_file_name = format!("node_{}.toml", timestamp);
        let temp_file_path = temp_dir.join(temp_file_name);
        debug_log!("SNAGTF: Temp file path: {:?}", temp_file_path);

        // 5. Write TOML data to temp file
        debug_log!("SNAGTF: Writing TOML data to temp file...");
        fs::write(&temp_file_path, &toml_string)?;

        // Verify temp file was created
        if !temp_file_path.exists() {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNAGTF: Failed to create temp file"
            ));
        }
        debug_log!("SNAGTF: Successfully created temp file at: {:?}", temp_file_path);

        // 6. Get GPG fingerprint for the local user
        let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => {
                debug_log!("SNAGTF: Retrieved GPG fingerprint: {}", fingerprint);
                fingerprint
            },
            Err(e) => {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("impl CoreNode save_node_as_gpgtoml: Failed to read GPG fingerprint from uma.toml: {}", e)
                ));
            }
        };

        // 7. Clearsign the temp file in-place
        debug_log!("SNAGTF: Starting clearsign operation on temp file");
        match convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
            &temp_file_path,
            COLLABORATOR_ADDRESSBOOK_PATH_STR,
            &gpg_full_fingerprint_key_id_string,
        ) {
            Ok(()) => {
                debug_log!("SNAGTF: Successfully clearsigned temp file");
            },
            Err(gpg_err) => {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("SNAGTF: GPG clearsign operation failed: {:?}", gpg_err),
                ));
            }
        }

        // 8. Extract public key from GPG keyring using fingerprint
        debug_log!("SNAGTF: Extracting public key from GPG for fingerprint: {}", gpg_full_fingerprint_key_id_string);
        let public_key_output = std::process::Command::new("gpg")
            .arg("--armor")
            .arg("--export")
            .arg(&gpg_full_fingerprint_key_id_string)
            .output()
            .map_err(|e| {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("SNAGTF: Failed to execute GPG export command: {}", e)
                )
            })?;

        // Check if GPG command succeeded
        if !public_key_output.status.success() {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            let stderr = String::from_utf8_lossy(&public_key_output.stderr);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SNAGTF: GPG export failed: {}", stderr)
            ));
        }

        // Convert public key bytes to string
        let public_key_string = String::from_utf8(public_key_output.stdout)
            .map_err(|e| {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("SNAGTF: Failed to convert public key to UTF-8: {}", e)
                )
            })?;

        // Verify we got a valid public key
        if public_key_string.trim().is_empty() {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNAGTF: GPG export returned empty public key"
            ));
        }
        debug_log!("SNAGTF: Successfully extracted public key from GPG");

        // 9. Construct final output path for encrypted file
        let final_file_path = self.directory_path.join("node.gpgtoml");
        debug_log!("SNAGTF: Final encrypted file path: {:?}", final_file_path);

        // 10. Encrypt the clearsigned temp file with the public key
        debug_log!("SNAGTF: Starting encryption of clearsigned file");
        match encrypt_clearsigned_toml_with_public_key_content(
            &temp_file_path,
            &public_key_string,
            &final_file_path
        ) {
            Ok(()) => {
                debug_log!("SNAGTF: Successfully created encrypted file at: {:?}", final_file_path);
            },
            Err(e) => {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("SNAGTF: Encryption failed: {:?}", e)
                ));
            }
        }

        // 11. Clean up temp file (critical for production)
        debug_log!("SNAGTF: Cleaning up temp file");
        if let Err(e) = fs::remove_file(&temp_file_path) {
            // Log warning but don't fail the operation since the main task succeeded
            debug_log!("SNAGTF: Warning: Failed to remove temp file: {}", e);
        }

        // 12. Verify final file exists
        if final_file_path.exists() {
            debug_log!("SNAGTF: Success! node.gpgtoml created at: {:?}", final_file_path);
        } else {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNAGTF: Final file creation appeared successful but file doesn't exist"
            ));
        }

        debug_log!("SNAGTF: save_node_as_gpgtoml completed successfully");
        Ok(())
    }

}

/// Calculates Pearson hashes for the provided CoreNode fields and salts.
/// This function is now external to CoreNode, taking individual fields as arguments.
///
/// Args:
///     node_name: The node's name.
///     description: The node's description.
///     timestamp: The node's timestamp.
///     salt_list: The list of salts for hashing.
///
/// Returns:
///     Result<Vec<u8>, ThisProjectError>: A vector of calculated hashes, or an error.
fn calculate_corenode_hashes(
    node_name: &str,
    description: &str,
    updated_at_timestamp: u64,
    salt_list: &[u128],
) -> Result<Vec<u8>, ThisProjectError> {
    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(node_name.as_bytes());
    data_to_hash.extend_from_slice(description.as_bytes());
    data_to_hash.extend_from_slice(&updated_at_timestamp.to_be_bytes());

    let mut hash_list = Vec::new();
    for salt in salt_list {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());
        match pearson_hash_base(&salted_data) {
            Ok(hash) => hash_list.push(hash),
            Err(e) => return Err(e.into()),  // Return the error.
        }
    }
    Ok(hash_list)
}

/*
let node_unique_id_str_result = extract_string_from_toml_bytes(received_file_bytes, "node_unique_id");

// Then handle the result...
match node_unique_id_str_result {
    Ok(node_unique_id_str) => {
        // Use the node_unique_id_str
    }
    Err(e) => {
        // Handle error
    }
}
*/
/// Extracts a string value associated with a given key from a TOML-formatted byte slice.
///
/// This function manually parses the byte slice, looking for a line that matches the
/// format `key = "value"`.  It handles cases where the key is not found or the value is
/// not enclosed in double quotes. It does NOT handle TOML arrays or tables.
/// It does NOT depend on the serde or toml crate.
///
/// # Arguments
///
/// * `toml_bytes`: The TOML data as a byte slice.
/// * `key`: The key to search for.
///
/// # Returns
///
/// * `Result<String, ThisProjectError>`: The extracted value or an error.
fn extract_string_from_toml_bytes(toml_bytes: &[u8], key: &str) -> Result<String, ThisProjectError> {
    let toml_str = std::str::from_utf8(toml_bytes).map_err(|_| ThisProjectError::InvalidData("Invalid UTF-8".into()))?;

    for line in toml_str.lines() {
        let line = line.trim();
        if line.starts_with(key) && line.contains('=') {
            let parts: Vec<&str> = line.split('=').map(|s| s.trim()).collect();
            if parts.len() == 2 {
                let value = parts[1];
                if value.starts_with('"') && value.ends_with('"') {
                    return Ok(value[1..value.len() - 1].to_string());
                } else {
                    return Err(ThisProjectError::InvalidData("Value not in quotes".into()));
                }
            }
        }
    }
    Err(ThisProjectError::InvalidData(format!("Key '{}' not found", key).into()))
}

/// update_collaborator_sendqueue_timestamp_log
/// ### making a new timestamp (maybe good to do each session)
/// 1. pick a target collaborator
/// 2. make sure path exists:
/// ```path
/// sync_data/team_channel/collaborator_name/
/// ```
/// 2. make a mut u64 variable called back_of_queue_timestamp = 0
/// 3. crawl through the files and subdirectories (recursively) in the teamchannel (only the team_channel directory tree, not all of uma) looking at files:
/// 4. if a .toml file,
/// 5. if owner=target_collaborator,
/// 6. if updated_at_timestamp exists
/// 7. write/rewrite a stub-file of that timestamp to:
/// ```path
/// sync_data/team_channel/collaborator_name/372385339229
/// ```
/// 8. if timestamp is higher than back_of_queue_timestamp, then
/// back_of_queue_timestamp = new value
/// 9. write/rewrite:
/// ```path
/// sync_data/team_channel/collaborator_name/back_of_queue_timestamp
/// ```
/// - Note: the paper trail of timestamps allows backtracking easily for error correction. quick sort to e.g. go-back-five
fn update_collaborator_sendqueue_timestamp_log(
    team_channel_name: &str,
    collaborator_name: &str,
) -> Result<u64, ThisProjectError> {
    let sync_data_dir = PathBuf::from("sync_data")
        .join(team_channel_name)
        .join(collaborator_name);
    fs::create_dir_all(&sync_data_dir)?;

    let mut back_of_queue_timestamp = 0;
    let team_channel_path = PathBuf::from("project_graph_data").join(team_channel_name);  // Use the read name

    // 3. Crawl through the team channel directory tree
    for entry in WalkDir::new(team_channel_path) {
        let entry = entry?;
        if entry.file_type().is_file() && entry.path().extension() == Some(OsStr::new("toml")) {
            // 4. If a .toml file
            let toml_string = fs::read_to_string(entry.path())?;

            // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
            let toml_value: Value = toml::from_str(&toml_string)?;

            // 5. If owner = target collaborator
            if toml_value.get("owner").and_then(Value::as_str) == Some(collaborator_name) {
                // 6. If updated_at_timestamp exists
                if let Some(timestamp) = toml_value.get("updated_at_timestamp").and_then(Value::as_integer) {
                    let timestamp = timestamp as u64;

                    // // 7. Write stub file
                    // let stub_file_path = sync_data_dir.join(timestamp.to_string());
                    // fs::File::create(stub_file_path)?;

                    // 8. Update back_of_queue_timestamp
                    if timestamp > back_of_queue_timestamp {
                        back_of_queue_timestamp = timestamp;
                    }
                }
            }
        }
    }

    // 9. Write back_of_queue_timestamp
    let timestamp_file_path = sync_data_dir.join("back_of_queue_timestamp");
    fs::write(timestamp_file_path, back_of_queue_timestamp.to_string())?;

    debug_log!(
        "End of update_collaborator_sendqueue_timestamp_log, back_of_queue_timestamp -> {:?}",
        back_of_queue_timestamp
    );

    Ok(back_of_queue_timestamp)
}

fn display_simple_tui_table(headers: &[&str], data: &[Vec<&str>]) {
    // Print headers
    for header in headers {
        print!("{:<15} ", header); // Left-align with padding
    }
    println!();

    // Print separator
    println!("{}", "-".repeat(headers.len() * 15));

    // Print data rows
    for row in data {
        for item in row {
            print!("{:<15} ", item);
        }
        println!();
    }
}

// fn main() {
//     let headers = vec!["Column 1", "Column 2", "Column 3"];
//     let data = vec![
//         vec!["Data A", "Data B", "Data C"],
//         vec!["Data D", "Data E", "Data F"],
//     ];
//     display_table(&headers, &data);
// }


/*
Under Construction!
should not use any 3rd party crates
- pending:
-- clearsign validate: new functions in clearsign module
-- add new fields for message-post

- only extract values from validated files
AGAIN: ONLY EXTRACT VALUES FROM VALIDATED FILES!
AGAIN: ONLY EXTRACT VALUES FROM VALIDATED FILES!!
NO BACK DOORS
AGAIN: ONLY EXTRACT VALUES FROM VALIDATED FILES!!!
NO VALIDATION = NO EXTRACTED VALUE
NO BACK DOORS!!!!!!!
NO EXCEPTIONS

use functions from clearsign module

    Get the current-local-user's gpg in this function with something like this:
            // Get GPG key fingerprint
            let full_fingerprint_key_id_string = match q_and_a_user_selects_gpg_key_full_fingerprint() {
                Ok(fingerprint) => {
                    println!("Selected key id (full fingerprint): {}", fingerprint);
                    fingerprint
                }
                Err(e) => {
                    eprintln!("Error selecting GPG key fingerprint: {}", e);
                    return Ok(false);
                }
            };

# Workflow for reading Nodes (CoreNodes) including team-channels

load_core_node_from_toml_file(
        path,
    )

get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_path,
        &gpg_full_fingerprint_key_id_string,
    )


The top level summary is more simplified than the actual steps which are more intertwined. Overall the workflow is: get path -> validate/verify file -> extract field. But you cannot validate/verify the node.toml file until you have both validated and extracted data from the addressbook file.

1. Paths & Reading-Copies Part 1: node.toml path and read-copy
2. Paths & Reading-Copies Part 2: addressbook path and read-copy
3. Verification/Validation Part 1: validate/verify addressbook file and get node-owner's public gpg
4. Extraction Part 1: Addressbook field extraction.
5. Verification/Validation Part 2: validate/verify Node (clearsign validation of .toml)
6. Extraction Part 2: Node.toml Field Extraction
7. Cleanup
8. Return Node Struct (CoreNode)


Step 1: Paths & Reading-Copies Part 1: node.toml path and read-copy
There are several reasons for separate paths and reading-copies.
While it is somewhat an undesirable swiss-army-knife: a file-to-be-read may be .toml or a .gpgtoml. A simple clearsign-toml is simpler than a .gpgtoml, but the workflow for a .gpgtoml introduces at least two useful robustness steps.

Reading from a reading-copy rather than from an original file: While collisions are likely to be rare, it is probably a good standard best practice (in general, not without exceptions) for Uma to do all file-reading from reading-copies of files. This should be better in a distributed-graph-database of files where any file owner can move or update a file at any time. Also, the modus-operandi of Uma is that individual files are always small modules, with any larger structure being made of small modular parts, so there should be no issues of copying a large file when there are no large files.

Another benefit of .gpgtoml files is the implicit 'login/signin' step that prevents any hardware-operator (physical or remote) who does not control the local-owner-user's gpg keys from using Uma ('Anti Evil-Maid').

That said, there is a balance between .gpgtoml advantages and the original Aim of Uma being "These are files and folders on your computer." Uma is a narrowly purpose-specific file(system)-sharing system (a distributed graph-database), not a file-hiding system. The whole point of Uma is using and sharing files so that you and chosen collaborators can look at the files you create. The main outlier may be the addressbook files which, while not containing any secrets, are not 'useful project files' and it does add to security-hardening (and 'login') to .gpg encrypt those. Team-channel files are likely an ongoing grey area: some people may prefer to .gpg encrypt these too, but in many cases being able to read and modify these files as files is likely useful. A compromise may be having a minimal team-channel file that is .gpg encrypted and using other nodes for more details.
It likely makes sense to leave this up to the team, and to "Nudge" (see book title and association with Kahneman/Tversky) people towards default-more-security that they can opt out of: so addressbook files are definitely .gpgtoml by default, and team-channel files...probably .gpgtoml by default.

Nodes (node.toml files) like addressbook files can be either clearsign-toml .toml files or gpg encrypted .gpgtoml encrypted clearsigned .toml files
(encryption is done with the local owner's public key (so the local owner decrypts with their private key using that key's key-id), clearsigning is with the file-owner's private key: so the clearsign is validated/verified using the file-owner's shared public gpg-key (which is in their addressbook file, looked up by the user's name (or 'handle')))

If failing to make a read copy, e.g. due to file collisions with that file being updated or moved at the exact time of read-copy, the procedure should be to wait and try again twice before considering this to be an error/failure. Collisions in uses of files are expected to be rare but are expected.

Every error-section of the function after this point must delete the read-copies as a first step of the error handling process.


Step 2. Paths & Reading-Copies Part 2: addressbook path and read-copy
The owner of the addressbook file cannot be found until the node.toml file is readable and read.

- use node.toml owner name
- get Addressbook directory path simplified
- get real path to read-copy with:
pub fn get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
    collaborator_name: &str,
    addressbook_files_directory_relative: &str,
    gpg_full_fingerprint_key_id_string: &str,
) -> Result<(PathBuf, PathBuf), GpgError>


Step 3. Verification/Validation Part 1: validate addressbook file and get node-owner's public gpg key

node_owners_public_gpg_key = read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml()


Step 4. Extraction Part 1: Addressbook field extraction.

In order to validate/verify the node.toml files we need to
get the file-owner's public-gpg-key from file-owner's addressbook:
read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml()


Step 5. Verification/Validation Part 2: validate Node file (clearsign validation of .toml)
- validate and proceed or delete read-copies and return-error

While some would probably argue for punting on (skipping) gpg-clearsign-validation of the node.toml file on the grounds that later other functions to load data from the unverified file probably include some kind of implicit validation steps, that procrastination/excuse is not good-process and invites potential risks. First see if the file can be clearsign-validated. If the file cannot be clearsign-validated, do not attempt to load any data from a known to be bad and possibly tampered-with file.

The terminology or semantics might be confusing but the workflow should be clear.
There is no path to export an extracted field value bypassing the validated-extraction process. We have to 'read' the name of the file owner from the file, but that is not stored in a variable capable of returning that as an extracted-output.

The return-extracted-verified/validated-value process must be used for all 'extracted-to-output' fields. On the one hand this is redundantly reading the field a second time, on the other hand it is applying a uniform process and not skimping on due diligence for the sake of creating a liability and irregular workflows.

    // // 5. Validation Part 2: validate Node (clearsign validation of .toml)
    let verify_node_file_result = verify_clearsign(
    	&node_readcopy_path,
    	&node_owners_public_gpg_key,
    );


Step 6. Extraction Part 2: Node.toml Field Extraction
Fields should be individually extracted using a standardized individual validation/verification process.

There need to be individual functions for reading clearsign_toml fields,
from clearsing-toml files that do not contain the public gpg-key, based on:
A. the datatype of the 'value' (as in key (field name) and value (data), as in key
B. if the struct field is 'option' (possibly None)

likely the input parameters will be the same for all such functions:
(
    pathstr_to_config_file_that_contains_gpg_key: &str,
    pathstr_to_target_clearsigned_file: &str,
    name_of_toml_field_key_to_read: &str,
)

Nodes and 'Get-Needed-When-Need' (Get something that is needed when it is needed; not get everything when you do not need it.):
By default Uma operates on a "Get (what is) needed when (it is) needed." basis, but in this case you actually do need to load all node fields when entering that node.
However, the reading of each field is not exempt: reading every struct item from a toml file does NOT mean greedily, lazily, slopily, and dangerously, pulling the entire file into memory. Uma operates by strictly dealing only with specific approved structs and enum structures, period. People will try to put malicious executable code into a 'file to share,' but Uma does not deal with random files or random data: Rust structs within Rust enums are shared with Uma, externatized in the form of (clearsigned and gpg encrypted) .toml files, with strict size and other parameters. Uma is not a random filesharing system.

This will probably evolve over time but to date the datatypes needed are:

Data Types (including 'Option'):
    string
    vec<u8>
    PathBuf
    u64
    vec<String>
    HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
    Option<Vec<(i32, i32)>>,
    Option<usize>,
    Option<bool>,
    Option<i64>,

Functions:
    string -> read_singleline_string_from_clearsigntoml_without_publicgpgkey()
    vec<u8> -> read_u8_array_from_clearsigntoml_without_publicgpgkey()
    PathBuf -> read_pathbuf_from_clearsigntoml_without_publicgpgkey()
    u64 -> read_u64_from_clearsigntoml_without_publicgpgkey()
    vec<String> -> read_stringarray_from_clearsigntoml_without_publicgpgkey()

   HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
-> read_hashmap_corenode_ports_from_clearsigntoml_without_publicgpgkey()

Option<Vec<(i32, i32)>> -> read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey()
    Option<usize> -> read_option_usize_from_clearsigntoml_without_publicgpgkey()
    Option<bool> -> read_option_bool_from_clearsigntoml_without_publicgpgkey()
    Option<i64> -> read_option_i64_from_clearsigntoml_without_publicgpgkey()


For reference, this is the CoreNode struct showing the struct fields that have said datatypes:
struct CoreNode {
    /// The name of the node. This is used for display and identification.
    node_name: String,

    /// A description of the node, intended for display in the TUI.
    description_for_tui: String,

    /// A unique identifier for the node, generated using pearson hashes of the other fields
    node_unique_id: Vec<u8>,

    /// The path to the directory on the file system where the node's data is stored.
    directory_path: PathBuf,

    /// An order number used to define the node's position within a list or hierarchy.
    // order_number: u32,
    /// The priority of the node, which can be High, Medium, or Low.
    // priority: NodePriority,
    /// The username of the owner of the node.
    owner: String,

    /// The Unix timestamp representing when the node was last updated.
    updated_at_timestamp: u64,

    /// The Unix timestamp representing when the node will expire.
    expires_at: u64,

    /// A vector of `CoreNode` structs representing the child nodes of this node.
    // children: Vec<CoreNode>,
    /// An ordered vector of collaborator usernames associated with this node.
    teamchannel_collaborators_with_access: Vec<String>,

    /// A map containing port assignments for each collaborator associated with the node.
    abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,

    // project areas: project module items as task-ish thing
    pa1_process: String,
    pa2_schedule: Vec<u64>,
    pa3_users: String,
    pa4_features: String,
    pa5_mvp: String,
    pa6_feedback: String,


    /////////////////
    // message_posts
    /////////////////

    /// Integer validation ranges as tuples (min, max) - inclusive bounds
    pub message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Integer-string validation ranges as tuples (min, max) for the integer part
    pub message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Maximum string length
    pub message_post_max_string_length_int: Option<usize>,

    /// Whether posts are public or private
    pub message_post_is_public_bool: Option<bool>,

    /// Whether user confirmation is required before posting
    pub message_post_user_confirms_bool: Option<bool>,

    /// Start time for accepting posts (UTC POSIX timestamp)
    pub message_post_start_date_utc_posix: Option<i64>,

    /// End time for accepting posts (UTC POSIX timestamp)
    pub message_post_end_date_utc_posix: Option<i64>,

	// limit of how many posts (or per time duration)
    // pub max_posts: Option<i64>,
    // pub duration_for_maxposts: MaxPostsDurationUnitsEnum, // hours, days, weeks
    // pub n_durations_for_maxposts: Option<i64>,
}


Step 7. Cleanup
If the process gets this far, hopefully it usually does, the temporary read-files are deleted.
```
   fn cleanup_collaborator_temp_file(temp_file_path: &Path) -> Result<(), GpgError> {
```

Step 8. Return Node Struct (struct CoreNode)
return the struct (after deleting the read-files), or an error (after deleting the read-files).

*/
/// Loads a `CoreNode` from a TOML file, handling potential errors.
///
/// # Arguments
///
/// * `file_path` - The path to the TOML file containing the node data.
///
/// # Returns
///
/// * `Result<CoreNode, String>` - `Ok(CoreNode)` if the node is successfully loaded,
///    `Err(String)` containing an error message if an error occurs.
///
///
fn load_core_node_from_toml_file(
    file_path: &Path,
) -> Result<CoreNode, String> {

    /*
    1. Paths & Reading-Copies Part 1: node.toml path and read-copy
    2. Paths & Reading-Copies Part 2: addressbook path and read-copy
    3. Validate Part 1: validate addressbook file and get node-owner's public gpg
    4. Validation Part 2: validate Node (clearsign validation of .toml)
    5. Field Extraction
    6. Cleanup
    7. Return Node Struct (CoreNode)



    1. updating Nodes: Plan A
    -> fn load_core_node_from_toml_file

    - add feature to look first for and optionally read .gpgtoml for addressbook files
    - add identification of local owner user addressbook file
    - select key for self-decrypt for local owner user .gpgtoml
    - maybe need to add that to app/navigation state?
    - feature to enable headless OS enter passphrase for local owner user .gpgtoml
    - add feature to save .gpgtoml format of addressbook file (e.g. in invite/update)

    - functions to read each field of clearsigned node
    - adding new 'modular message-post' fields to navigation state

    workflow, steps:
    validation: clearsign validation of the node.toml file,
       which is a file without the gpg-public-key to validate,
       so use the owner field to get the owners public gpg key
       from their addressbook file (which will also need to be
           clearsign validated...after it is .gpg decrypted,
           using the current-user's gpg-key-id from
           the uma.toml config file)

    1.1 get path to addressbook file
    get_path_to_temp_copy_of_addressbook_toml_or_decrypted_gpgtoml(
    collaborator_name: &str,
    addressbook_files_directory_relative: &str,
    gpg_full_fingerprint_key_id_string: &str,

    2 validate and get public gpg key from file...
    clearsign multiilne string?

    3. extract data from node.toml fields

    4. remove temp file

    5. return struct

    note: once decrypted temp file is made, any error should delete that file

    last (and with any error) remove temp file:
    fn cleanup_collaborator_temp_file(temp_file_path: &Path) -> Result<(), GpgError> {
    */


    debug_log!(
        "LCNFTF: Starting: load_core_node_from_toml_file(), file_path -> {:?}",
        file_path,
    );

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(format!(
                "LCNFTF: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            ));
        }
    };

    // // 1. Paths & Reading-Copies Part 1: node.toml path and read-copy

    // Get the UME temp directory path with explicit String conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| {
            let gpg_error = GpgError::ValidationError(
                format!("LCNFTF: Failed to get UME temp directory path: {}", io_err)
            );
            // Convert GpgError to String for the function's return type
            format!("LCNFTF: {:?}", gpg_error)
        })?;

    // Using Debug trait for more detailed error information
    let node_readcopy_path = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_path,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| format!("LCNFTF: Failed to get temporary read copy of TOML file: {:?}", e))?;

    // //    // simple read string to get owner name
    // //    // not for extraction and return, just part of validation


    ////////////////////////////////
    // Extract Owner for Key Lookup
    ////////////////////////////////
    let owner_name_of_toml_field_key_to_read = "owner";
    debug_log!(
        "LCNFTF: Reading file owner from field '{}' for security validation",
        owner_name_of_toml_field_key_to_read
    );

    // get node_owners_public_gpg_key

    let file_owner_username = match read_single_line_string_field_from_toml(
        &node_readcopy_path,  // TODO convert to string?
        owner_name_of_toml_field_key_to_read,
    ) {
        Ok(username) => {
            if username.is_empty() {
                // Convert to String error instead of GpgError
                return Err(format!(
                    "LCNFTF: Field '{}' is empty in TOML file. File owner is required for security validation.",
                    owner_name_of_toml_field_key_to_read
                ));
            }
            username
        }
        Err(e) => {
            // Convert to String error instead of GpgError
            return Err(format!(
                "LCNFTF: Failed to read file owner from field '{}': {}",
                owner_name_of_toml_field_key_to_read, e
            ));
        }
    };
    println!("LCNFTF: File owner: '{}'", file_owner_username);
    debug_log!("LCNFTF: File owner: '{}'", file_owner_username);

    // TODO returns full response not just string
    // because the filepath needs to be constructed
    // this is a separate function
	// let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
    //        &file_owner_username,
    //        COLLABORATOR_ADDRESSBOOK_PATH_STR,
    //        &gpg_full_fingerprint_key_id_string,
    //    );

    // Get the UME temp directory path with error handling
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| format!(
            "LCNFTF: Failed to get UME temp directory path: {:?}",
            io_err
        ))?;

    // Extract the addressbook path string with inline error conversion
    let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_owner_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| format!(
        "LCNFTF: Failed to get addressbook path for user '{}': {:?}",
        file_owner_username,
        e
    ))?;

    // Define cleanup closure
    let cleanup_closure = || {
        let _ = cleanup_collaborator_temp_file(
            &node_readcopy_path,
            &base_uma_temp_directory_path,
            );
        let _ = cleanup_collaborator_temp_file(
            &addressbook_readcopy_path_string,
            &base_uma_temp_directory_path,
            );
    };

    // use function for general .toml or .gpgtoml readcopy
    // let node_owners_public_gpg_key = read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml(
    //     &addressbook_readcopy_path_string,
    // );

    let node_owners_public_gpg_key = read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml(
        &addressbook_readcopy_path_string,
    ).map_err(|e| format!(
        "LCNFTF: Failed to get addressbook path for user '{}': {:?}",
        file_owner_username,
        e
    ))?;

    // 2. Paths & Reading-Copies Part 2: addressbook path and read-copy
    // Verify the addressbook file's clearsign signature
    let verify_addressbook_file_result = match verify_clearsign(
        &addressbook_readcopy_path_string,
        &node_owners_public_gpg_key,
    ) {
        Ok(is_valid) => is_valid,
        Err(e) => {
            // Clean up temporary files before returning error
            cleanup_closure();
            return Err(format!(
                "LCNFTF: Failed to verify addressbook clearsign signature for user '{}': {:?}",
                file_owner_username,
                e
            ));
        }
    };

    // 3. Validate Part 1: validate addressbook file and get node-owner's public gpg
    // (This section would go here if needed)

    // 4. Validation Part 2: validate Node (clearsign validation of .toml)
    // Verify the node file's clearsign signature
    let verify_node_file_result = match verify_clearsign(
        &node_readcopy_path,
        &node_owners_public_gpg_key,
    ) {
        Ok(is_valid) => is_valid,
        Err(e) => {
            // Clean up temporary files before returning error
            cleanup_closure();
            return Err(format!(
                "Failed to verify node file clearsign signature for user '{}': {:?}",
                file_owner_username,
                e
            ));
        }
    };

    // Check if both verification results are valid
    // If either verification failed, clean up and return error
    if !verify_addressbook_file_result || !verify_node_file_result {

        debug_log("LCNFTF: Whoops, something faileded...");

        // Clean up temporary files
        cleanup_closure();

        // Provide detailed error message about which verification failed
        let mut error_details = Vec::new();
        if !verify_addressbook_file_result {
            error_details.push("LCNFTF: addressbook file signature verification failed");
        }
        if !verify_node_file_result {
            error_details.push("LCNFTF: node file signature verification failed");
        }

        return Err(format!(
            "LCNFTF: Clearsign validation failed for user '{}': {}",
            file_owner_username,
            error_details.join(" and ")
        ));
    }


    // // 5. Field Extraction

    /*
    This will probably evolve over time but to date the datatypes needed are:
    string
    vec<u8>
    PathBuf
    u64
    vec<String>

   	HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,

    Option<Vec<(i32, i32)>>,
    Option<usize>,
    Option<bool>,
    Option<i64>,

Functions:

all use these parameters:
    pathstr_to_config_file_that_contains_gpg_key: &str,
    pathstr_to_target_clearsigned_file: &str,
    name_of_toml_field_key_to_read: &str,


    string -> read_singleline_string_from_clearsigntoml_without_publicgpgkey()
    vec<u8> -> read_u8_array_from_clearsigntoml_without_publicgpgkey()
    PathBuf -> read_pathbuf_from_clearsigntoml_without_publicgpgkey()
    u64 -> read_u64_from_clearsigntoml_without_publicgpgkey()
    vec<String> -> read_stringarray_from_clearsigntoml_without_publicgpgkey()

   HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
-> read_hashmap_corenode_ports_from_clearsigntoml_without_publicgpgkey()

Option<Vec<(i32, i32)>> -> read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey()
    Option<usize> -> read_option_usize_from_clearsigntoml_without_publicgpgkey()
    Option<bool> -> read_option_bool_from_clearsigntoml_without_publicgpgkey()
    Option<i64> -> read_option_i64_from_clearsigntoml_without_publicgpgkey()

struct CoreNode {
    /// The name of the node. This is used for display and identification.
    node_name: String,
    /// A description of the node, intended for display in the TUI.
    description_for_tui: String,
    /// A unique identifier for the node, generated using pearson hashes of the other fields
    node_unique_id: Vec<u8>,
    /// The path to the directory on the file system where the node's data is stored.
    directory_path: PathBuf,
    /// An order number used to define the node's position within a list or hierarchy.
    // order_number: u32,
    /// The priority of the node, which can be High, Medium, or Low.
    // priority: NodePriority,
    /// The username of the owner of the node.
    owner: String,
    /// The Unix timestamp representing when the node was last updated.
    updated_at_timestamp: u64,
    /// The Unix timestamp representing when the node will expire.
    expires_at: u64,
    /// A vector of `CoreNode` structs representing the child nodes of this node.
    // children: Vec<CoreNode>,
    /// An ordered vector of collaborator usernames associated with this node.
    teamchannel_collaborators_with_access: Vec<String>,
    /// A map containing port assignments for each collaborator associated with the node.
    abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,

    // project areas: project module items as task-ish thing
    pa1_process: String,
    pa2_schedule: Vec<u64>,
    pa3_users: String,
    pa4_features: String,
    pa5_mvp: String,
    pa6_feedback: String,

    /////////////////
    // message_posts
    /////////////////

    /// Integer validation ranges as tuples (min, max) - inclusive bounds
    pub message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Integer-string validation ranges as tuples (min, max) for the integer part
    pub message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Maximum string length
    pub message_post_max_string_length_int: Option<usize>,

    /// Whether posts are public or private
    pub message_post_is_public_bool: Option<bool>,

    /// Whether user confirmation is required before posting
    pub message_post_user_confirms_bool: Option<bool>,

    /// Start time for accepting posts (UTC POSIX timestamp)
    pub message_post_start_date_utc_posix: Option<i64>,

    /// End time for accepting posts (UTC POSIX timestamp)
    pub message_post_end_date_utc_posix: Option<i64>,

	// limit of how many posts (or per time duration)
    // pub max_posts: Option<i64>,
    // pub duration_for_maxposts: MaxPostsDurationUnitsEnum, // hours, days, weeks
    // pub n_durations_for_maxposts: Option<i64>,
    }
    */


    // 1. Read File Contents
    /*
    /// match read_singleline_string_from_clearsigntoml_without_publicgpgkey(
    ///     config_path,
    ///     target_path,
    ///     "api_endpoint"
    /// ) {
    ///     Ok(value) => println!("API Endpoint: {}", value),
    ///     Err(e) => eprintln!("Error: {}", e)
    /// }
    /// ```
    ///
    pub fn read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
        name_of_toml_field_key_to_read: &str,
    ) -> Result<String, String> {

    */

    /*
    // Define cleanup closure
    let cleanup = || {
        cleanup_collaborator_temp_file(node_readcopy_path);
        cleanup_collaborator_temp_file(addressbook_readcopy_path_string);
    };

    // Use the function to read a value - convert Path to &str
    let file_path_str = file_path.to_str()
        .ok_or_else(|| {
            cleanup_closure();
            "Invalid file path encoding".to_string()
        })?;

    // Example: Read node_id from the clearsigned TOML file
    let node_id = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        "config/security.toml",  // Config file containing GPG key
        file_path_str,           // Target clearsigned file
        "node_id"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("Failed to read node_id: {}", e)
    })?;
    */

    // Example: Read _ from the clearsigned TOML file
    let node_name = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "node_name"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: node_name Failed to read node_name: {}", e)
    })?;

    // TODO...should be bool not option bool
    // Example: Read _ from the clearsigned TOML file
    let corenode_gpgtoml = read_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,                // Target clearsigned file
        "corenode_gpgtoml"                  // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: node_name Failed to read corenode_gpgtoml: {}", e)
    })?;

    // Example: Read _ from the clearsigned TOML file
    let description_for_tui = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "description_for_tui"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: description_for_tui sFailed to read description_for_tui: {}", e)
    })?;

    // Example: Read _ from the clearsigned TOML file
    let node_unique_id = read_u8_array_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "node_unique_id"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: node_unique_id Failed to read node_unique_id: {}", e)
    })?;

    // Example: Read _ from the clearsigned TOML file
    let directory_path = read_pathbuf_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "directory_path"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: directory_path Failed to read directory_pathe_id: {}", e)
    })?;



    // Example: Read _ from the clearsigned TOML file
    let owner = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "owner"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: owner Failed to read owner: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let updated_at_timestamp = read_u64_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "updated_at_timestamp"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: updated_at_timestamp Failed to read updated_at_timestamp: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let expires_at = read_u64_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "expires_at"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: expires_at Failed to read expires_at: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let teamchannel_collaborators_with_access = read_stringarray_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "teamchannel_collaborators_with_access"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: teamchannel_collaborators_with_access Failed to read teamchannel_collaborators_with_access: {}", e)
    })?;


    debug_log("LCNFTF: starting read_teamchannel_collaborator_ports_clearsigntoml_without_keyid...");

    /*
    pub fn read_hashmap_corenode_ports_from_clearsigntoml_without_publicgpgkey(
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
    ) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, String> {
    */

    // Example: Read _ from the clearsigned TOML file
    let abstract_collaborator_port_assignments = read_teamchannel_collaborator_ports_clearsigntoml_without_keyid(
        &addressbook_readcopy_path_string,     // Config file containing GPG key
        &node_readcopy_path,                   // Target clearsigned file
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: read_abstract_collaborator_port_assignments Failed to read abstract_collaborator_port_assignments: {}", e)
    })?;



	////?////////////
	// Project Areas
	/////////////////

    // Example: Read _ from the clearsigned TOML file
    let pa1_process = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa1_process"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: pa1_process Failed to read pa1_process: {}", e)
    })?;



    // Example: Read _ from the clearsigned TOML file
    let pa2_schedule = read_u64_array_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa2_schedule"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: pa2_schedule Failed to read pa2_schedule: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let pa3_users = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa3_users"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error:  pa3_users Failed to read pa3_users: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let pa4_features = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa4_features"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: pa4_features Failed to read pa4_features: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let pa5_mvp = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa5_mvp"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: pa5_mvp Failed to read pa5_mvp: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let pa6_feedback = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa6_feedback"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: pa6_feedback Failed to read pa6_feedback: {}", e)
    })?;

	////////////////
	// Message-Post
	////////////////

	// Example: Read _ from the clearsigned TOML file
    let message_post_gpgtoml_required = read_option_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_gpgtoml_required"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_gpgtoml_required Failed to read message_post_gpgtoml_required: {}", e)
    })?;

    // Example: Read _ from the clearsigned TOML file
    let message_post_data_format_specs_integer_ranges_from_to_tuple_array = read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_data_format_specs_integer_ranges_from_to_tuple_array"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_data_format_specs_integer_ranges_from_to_tuple_array Failed to read message_post_data_format_specs_integer_ranges_from_to_tuple_array: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_data_format_specs_int_string_ranges_from_to_tuple_array = read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_data_format_specs_int_string_ranges_from_to_tuple_array"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_data_format_specs_int_string_ranges_from_to_tuple_array Failed to read message_post_data_format_specs_int_string_ranges_from_to_tuple_array: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_max_string_length_int = read_option_usize_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_max_string_length_int"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_max_string_length_int Failed to read message_post_max_string_length_int: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_is_public_bool = read_option_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_is_public_bool"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_is_public_bool Failed to read node_imessage_post_is_public_boold: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_user_confirms_bool = read_option_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_user_confirms_bool"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_user_confirms_bool Failed to read message_post_user_confirms_bool: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_start_date_utc_posix = read_option_i64_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_start_date_utc_posix"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_start_date_utc_posix Failed to read message_post_start_date_utc_posix: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_end_date_utc_posix = read_option_i64_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_end_date_utc_posix"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_end_date_utc_posix Failed to read message_post_end_date_utc_posix: {}", e)
    })?;

    /*
    TODO
    error[E0425]: cannot find value `message_post_max_string_length_int` in this scope
        --> src/main.rs:11420:9
        |
    11420 |         message_post_max_string_length_int,
        |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not found in this scope

    */

    // 6. Deserialize into CoreNode Struct (Manually)
    let core_node = CoreNode {
        // node_name: toml_value.get("node_name").and_then(Value::as_str).unwrap_or("").to_string(),
        // description_for_tui: toml_value.get("description_for_tui").and_then(Value::as_str).unwrap_or("").to_string(),
        // node_unique_id: node_unique_id,
        // directory_path: PathBuf::from(toml_value.get("directory_path").and_then(Value::as_str).unwrap_or("")),
        // owner: toml_value.get("owner").and_then(Value::as_str).unwrap_or("").to_string(),
        // updated_at_timestamp: toml_value.get("updated_at_timestamp").and_then(Value::as_integer).unwrap_or(0) as u64,
        // expires_at: toml_value.get("expires_at").and_then(Value::as_integer).unwrap_or(0) as u64,
        // teamchannel_collaborators_with_access: toml_value.get("teamchannel_collaborators_with_access").and_then(Value::as_array).map(|arr| arr.iter().filter_map(Value::as_str).map(String::from).collect()).unwrap_or_default(),

        node_name: node_name,
        corenode_gpgtoml: corenode_gpgtoml,
        description_for_tui: description_for_tui,
        node_unique_id: node_unique_id,
        directory_path: directory_path,
        owner: owner,
        updated_at_timestamp: updated_at_timestamp,
        expires_at: expires_at,
        teamchannel_collaborators_with_access: teamchannel_collaborators_with_access,

        abstract_collaborator_port_assignments: abstract_collaborator_port_assignments,

        // Project Areas
        pa1_process: pa1_process,
        pa2_schedule: pa2_schedule,
        pa3_users: pa3_users,
        pa4_features: pa4_features,
        pa5_mvp: pa5_mvp,
        pa6_feedback: pa6_feedback,

        // Message Post Configuration
        message_post_gpgtoml_required,
        message_post_data_format_specs_integer_ranges_from_to_tuple_array,
        message_post_data_format_specs_int_string_ranges_from_to_tuple_array,
        message_post_max_string_length_int,
        message_post_is_public_bool,
        message_post_user_confirms_bool,
        message_post_start_date_utc_posix,
        message_post_end_date_utc_posix,
    };

    // TODO
    // // 7. Handle collaborator port assignments
    // if let Some(collaborator_assignments_table) = toml_value.get("collaborator_port_assignments").and_then(Value::as_table) {
    //     for (pair_name, pair_data) in collaborator_assignments_table {
    //         debug_log("Looking for 'collaborator_ports' load_core...");
    //         if let Some(ports_list) = pair_data.get("collaborator_ports").and_then(Value::as_array) {
    //             // Create a vector to hold ReadTeamchannelCollaboratorPortsToml instances for this pair
    //             let mut ports_for_pair = Vec::new();

    //             for port_data in ports_list {
    //                 // Deserialize each AbstractTeamchannelNodeTomlPortsData from the array
    //                 let port_data_str = toml::to_string(&port_data).unwrap(); // Convert Value to String
    //                 let collaborator_port: AbstractTeamchannelNodeTomlPortsData = toml::from_str(&port_data_str).map_err(|e| format!("Error deserializing collaborator port: {}", e))?;

    //                 // Create ReadTeamchannelCollaboratorPortsToml and add it to the vector
    //                 let read_teamchannel_collaborator_ports_toml = ReadTeamchannelCollaboratorPortsToml {
    //                     collaborator_ports: vec![collaborator_port], // Wrap in a vector
    //                 };
    //                 ports_for_pair.push(read_teamchannel_collaborator_ports_toml);
    //             }

    //             // Insert the vector of ReadTeamchannelCollaboratorPortsToml into the HashMap
    //             core_node.abstract_collaborator_port_assignments.insert(pair_name.clone(), ports_for_pair);
    //         }
    //     }
    // }


    // // 6. Cleanup
    //
    debug_log("Proper cleansup");
    let _ = cleanup_collaborator_temp_file(
        &node_readcopy_path,
        &base_uma_temp_directory_path,
        );
    let _ = cleanup_collaborator_temp_file(
        &addressbook_readcopy_path_string,
        &base_uma_temp_directory_path,
        );

    // // 7. Return Node Struct (CoreNode)
    debug_log("LCNFTF DONE: Ending load_core_node_from_toml_file");
    Ok(core_node)
}



// Generic function to save any serializable data to a TOML file
pub fn save_toml_to_file<T: Serialize>(data: &T, file_path: &Path) -> Result<(), Error> {
    let toml_string = toml::to_string(data).map_err(|e| {
        Error::new(
            std::io::ErrorKind::Other,
            format!("TOML serialization error: {}", e),
        )
    })?;
    fs::write(file_path, toml_string)?;
    Ok(())
}

// ====================
// Message Post Section
// ====================

/// Creates a tuple of (directory_path, final_filename) for message post files.
///
/// # Purpose
///
/// This function handles the path and filename logic for instant message files,
/// determining the correct file extension based on encryption settings:
/// - `.toml` for clearsigned TOML files (unencrypted but signed)
/// - `.gpgtoml` for GPG encrypted TOML files
///
/// # Project Context
///
/// Instant messages in the system can be stored in two formats:
/// 1. Clearsigned TOML: Human-readable, cryptographically signed
/// 2. GPG Encrypted TOML: Encrypted + signed, only readable by key holder
///
/// The choice affects both file extension and subsequent processing pipeline.
/// This function ensures consistent naming across the message storage system.
///
/// # Arguments
///
/// * `incoming_path` - The full path including base filename (may include .toml extension)
/// * `use_encryption` - If `true`, use `.gpgtoml` extension; if `false`, use `.toml`
///
/// # Returns
///
/// * `Ok((directory, filename))` - Tuple of parent directory and final filename with correct extension
/// * `Err(io::Error)` - If path validation fails or path has no parent directory
///
/// # Error Cases
///
/// - Path has no filename component
/// - Path has no parent directory (e.g., root path or relative path with no parent)
/// - Path contains invalid UTF-8 (though this is handled gracefully)
///
/// # Examples
///
/// ```rust
/// use std::path::Path;
///
/// // Clearsigned format (unencrypted)
/// let input = Path::new("sync_data/team/messages/1234567890.toml");
/// let (dir, file) = create_messagepost_file_namepath_extension_tuple(input, false)?;
/// // dir: "sync_data/team/messages"
/// // file: "1234567890.toml"
///
/// // GPG encrypted format
/// let input = Path::new("sync_data/team/messages/1234567890.toml");
/// let (dir, file) = create_messagepost_file_namepath_extension_tuple(input, true)?;
/// // dir: "sync_data/team/messages"
/// // file: "1234567890.gpgtoml"
///
/// // Also works without extension in input
/// let input = Path::new("sync_data/team/messages/1234567890");
/// let (dir, file) = create_messagepost_file_namepath_extension_tuple(input, false)?;
/// // dir: "sync_data/team/messages"
/// // file: "1234567890.toml"
/// ```
fn create_messagepost_file_namepath_extension_tuple(
    incoming_path: &Path,
    use_encryption: bool,
) -> Result<(PathBuf, PathBuf), io::Error> {

    // Debug logging for inputs
    debug_log!("CMFNPET: Starting create_messagepost_file_namepath_extension_tuple");
    debug_log!("CMFNPET: incoming_path: {:?}", incoming_path);
    debug_log!("CMFNPET: use_encryption: {}", use_encryption);

    // Debug-Assert: Path must have a filename component
    // ONLY runs in debug builds, NOT in tests or release
    // #[cfg(not(test))]
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        incoming_path.file_name().is_some(),
        "CMFNPET: Path must contain a filename component"
    );

    // Production-Catch: Handle missing filename
    // This ALWAYS runs and returns Err instead of panicking
    let filename_os = incoming_path.file_name()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "CMFNPET: Path must contain a filename component"
        ))?;

    debug_log!("CMFNPET: Original filename: {:?}", filename_os);

    // Extract parent directory
    // Debug-Assert: Path must have a parent directory
    // ONLY runs in debug builds, NOT in tests or release
    // #[cfg(not(test))]
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        incoming_path.parent().is_some(),
        "CMFNPET: Path must have a parent directory"
    );

    // Production-Catch: Handle missing parent directory
    // This ALWAYS runs and returns Err instead of panicking
    let directory_path = incoming_path.parent()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "CMFNPET: Path must have a parent directory"
        ))?
        .to_path_buf();

    debug_log!("CMFNPET: Parent directory: {:?}", directory_path);

    // Strip any existing extension to get base filename
    // Use file_stem() to get filename without extension
    let base_filename = incoming_path.file_stem()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "CMFNPET: Cannot extract base filename"
        ))?;

    debug_log!("CMFNPET: Base filename (no extension): {:?}", base_filename);

    // Construct final filename with appropriate extension
    let final_filename = if use_encryption {
        // GPG encrypted format: use .gpgtoml extension
        let mut filename = base_filename.to_os_string();
        filename.push(".gpgtoml");
        PathBuf::from(filename)
    } else {
        // Clearsigned format: use .toml extension
        let mut filename = base_filename.to_os_string();
        filename.push(".toml");
        PathBuf::from(filename)
    };

    debug_log!("CMFNPET: Final filename with extension: {:?}", final_filename);

    // Debug-Assert: Final filename must have an extension
    // ONLY runs in debug builds, NOT in tests or release
    debug_assert!(
        final_filename.extension().is_some(),
        "CMFNPET: Final filename must have an extension"
    );

    // Production-Catch: Verify extension exists
    // This ALWAYS runs and returns Err instead of panicking
    if final_filename.extension().is_none() {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "CMFNPET: Failed to create filename with extension"
        ));
    }

    // Verify correct extension was applied
    let expected_extension = if use_encryption { "gpgtoml" } else { "toml" };

    // Debug-Assert: Extension must match encryption setting
    // ONLY runs in debug builds, NOT in tests or release
    debug_assert!(
        final_filename.extension()
            .and_then(|ext| ext.to_str())
            .map(|ext| ext == expected_extension)
            .unwrap_or(false),
        "CMFNPET: Extension must match encryption setting"
    );

    // Production-Catch: Verify correct extension
    // This ALWAYS runs and returns Err instead of panicking
    let actual_extension = final_filename.extension()
        .and_then(|ext| ext.to_str())
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::Other,
            "CMFNPET: Cannot read final extension"
        ))?;

    if actual_extension != expected_extension {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            format!(
                "CMFNPET: Extension mismatch: expected '{}', got '{}'",
                expected_extension,
                actual_extension
            )
        ));
    }

    debug_log!("CMFNPET: Successfully created tuple");
    debug_log!("CMFNPET: Directory: {:?}", directory_path);
    debug_log!("CMFNPET: Filename: {:?}", final_filename);

    Ok((directory_path, final_filename))
}

#[cfg(test)]
mod message_post_names_tests {
    use super::*;
    use std::path::Path;

    /// Test: Basic clearsigned TOML path handling with .toml input
    ///
    /// Verifies that when given a path with .toml extension and encryption disabled,
    /// the function correctly extracts directory and preserves .toml extension.
    #[test]
    fn test_clearsigned_with_toml_extension() {
        let input = Path::new("sync_data/team/messages/1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must succeed with valid path
        assert!(result.is_ok(), "Function should succeed with valid path");

        let (dir, file) = result.unwrap();

        // Test-Assert: Directory path must match expected
        assert_eq!(
            dir,
            PathBuf::from("sync_data/team/messages"),
            "Directory path should be extracted correctly"
        );

        // Test-Assert: Filename must match expected
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Filename should have .toml extension"
        );

        // Test-Assert: Extension must be 'toml'
        assert_eq!(
            file.extension().and_then(|e| e.to_str()),
            Some("toml"),
            "Extension should be 'toml'"
        );
    }

    /// Test: GPG encrypted path handling with .toml input
    ///
    /// Verifies that when given a path with .toml extension and encryption enabled,
    /// the function replaces the extension with .gpgtoml.
    #[test]
    fn test_encrypted_replaces_toml_extension() {
        let input = Path::new("sync_data/team/messages/1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, true);

        // Test-Assert: Function must succeed with valid path
        assert!(result.is_ok(), "Function should succeed with valid path");

        let (dir, file) = result.unwrap();

        // Test-Assert: Directory path must match expected
        assert_eq!(
            dir,
            PathBuf::from("sync_data/team/messages"),
            "Directory path should be extracted correctly"
        );

        // Test-Assert: Filename must have .gpgtoml extension
        assert_eq!(
            file,
            PathBuf::from("1234567890.gpgtoml"),
            "Filename should have .gpgtoml extension"
        );

        // Test-Assert: Extension must be 'gpgtoml'
        assert_eq!(
            file.extension().and_then(|e| e.to_str()),
            Some("gpgtoml"),
            "Extension should be 'gpgtoml'"
        );
    }

    /// Test: Path without extension, clearsigned format
    ///
    /// Verifies that the function adds .toml extension when input has no extension.
    #[test]
    fn test_no_extension_clearsigned() {
        let input = Path::new("sync_data/team/messages/1234567890");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must succeed with extensionless path
        assert!(result.is_ok(), "Function should succeed with extensionless path");

        let (dir, file) = result.unwrap();

        // Test-Assert: Directory must match expected
        assert_eq!(
            dir,
            PathBuf::from("sync_data/team/messages"),
            "Directory path should be extracted correctly"
        );

        // Test-Assert: Extension must be added
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should add .toml extension"
        );
    }

    /// Test: Path without extension, encrypted format
    ///
    /// Verifies that the function adds .gpgtoml extension when input has no extension.
    #[test]
    fn test_no_extension_encrypted() {
        let input = Path::new("sync_data/team/messages/1234567890");
        let result = create_messagepost_file_namepath_extension_tuple(input, true);

        // Test-Assert: Function must succeed with extensionless path
        assert!(result.is_ok(), "Function should succeed with extensionless path");

        let (dir, file) = result.unwrap();

        // Test-Assert: Directory must match expected
        assert_eq!(
            dir,
            PathBuf::from("sync_data/team/messages"),
            "Directory path should be extracted correctly"
        );

        // Test-Assert: Extension must be added
        assert_eq!(
            file,
            PathBuf::from("1234567890.gpgtoml"),
            "Should add .gpgtoml extension"
        );
    }

    /// Test: Different extension gets replaced (clearsigned)
    ///
    /// Verifies that non-.toml extensions are replaced with .toml for clearsigned.
    #[test]
    fn test_different_extension_replaced_clearsigned() {
        let input = Path::new("sync_data/team/messages/1234567890.txt");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must succeed
        assert!(result.is_ok(), "Function should succeed");

        let (_, file) = result.unwrap();

        // Test-Assert: Extension must be replaced
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should replace .txt with .toml"
        );
    }

    /// Test: Different extension gets replaced (encrypted)
    ///
    /// Verifies that non-.gpgtoml extensions are replaced with .gpgtoml for encrypted.
    #[test]
    fn test_different_extension_replaced_encrypted() {
        let input = Path::new("sync_data/team/messages/1234567890.txt");
        let result = create_messagepost_file_namepath_extension_tuple(input, true);

        // Test-Assert: Function must succeed
        assert!(result.is_ok(), "Function should succeed");

        let (_, file) = result.unwrap();

        // Test-Assert: Extension must be replaced
        assert_eq!(
            file,
            PathBuf::from("1234567890.gpgtoml"),
            "Should replace .txt with .gpgtoml"
        );
    }

    /// Test: Nested directory structure
    ///
    /// Verifies function works with deeply nested paths.
    #[test]
    fn test_nested_directory_structure() {
        let input = Path::new("a/b/c/d/e/message.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle nested paths
        assert!(result.is_ok(), "Function should handle nested paths");

        let (dir, file) = result.unwrap();

        // Test-Assert: Full nested path must be extracted
        assert_eq!(
            dir,
            PathBuf::from("a/b/c/d/e"),
            "Should extract full nested directory path"
        );

        // Test-Assert: Filename must be correct
        assert_eq!(
            file,
            PathBuf::from("message.toml"),
            "Should extract filename correctly"
        );
    }

    /// Test: Single directory level
    ///
    /// Verifies function works with minimal directory depth.
    #[test]
    fn test_single_directory_level() {
        let input = Path::new("messages/1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle single directory level
        assert!(result.is_ok(), "Function should handle single directory level");

        let (dir, file) = result.unwrap();

        // Test-Assert: Single directory must be extracted
        assert_eq!(
            dir,
            PathBuf::from("messages"),
            "Should extract single directory correctly"
        );

        // Test-Assert: Filename must be correct
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should extract filename correctly"
        );
    }
    /// Test: Error case - no filename
        ///
        /// Verifies function returns error when path has no filename component.
        #[test]
        fn test_error_no_filename() {
            // Use root path which has no filename
            let input = Path::new("/");
            let result = create_messagepost_file_namepath_extension_tuple(input, false);

            assert!(
                result.is_err(),
                "Function should return error for path without filename"
            );

            if let Err(e) = result {
                let error_msg = format!("{}", e);
                assert!(
                    error_msg.contains("filename component"),
                    "Error message should mention missing filename component, got: {}",
                    error_msg
                );
            }
        }

        /// Test: Error case - no parent directory
        ///
        /// Verifies function returns error when path has no parent.
        #[test]
        fn test_error_no_parent() {
            // Use root path which has no parent
            let input = Path::new("/");
            let result = create_messagepost_file_namepath_extension_tuple(input, false);

            assert!(
                result.is_err(),
                "Function should return error for path without parent directory"
            );

            if let Err(e) = result {
                let error_msg = format!("{}", e);
                assert!(
                    error_msg.contains("parent directory") || error_msg.contains("filename component"),
                    "Error message should mention missing parent directory, got: {}",
                    error_msg
                );
            }
        }

    /// Test: Complex filename with multiple dots
    ///
    /// Verifies that only the final extension is replaced, not intermediate dots.
    #[test]
    fn test_filename_with_multiple_dots() {
        let input = Path::new("messages/my.message.file.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, true);

        // Test-Assert: Function must handle multiple dots
        assert!(result.is_ok(), "Function should handle multiple dots");

        let (_, file) = result.unwrap();

        // Test-Assert: Dots in stem must be preserved
        assert_eq!(
            file,
            PathBuf::from("my.message.file.gpgtoml"),
            "Should preserve dots in filename stem and replace extension"
        );
    }

    /// Test: Filename with spaces
    ///
    /// Verifies function handles filenames containing spaces correctly.
    #[test]
    fn test_filename_with_spaces() {
        let input = Path::new("messages/my message file.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle spaces in filename
        assert!(result.is_ok(), "Function should handle spaces in filename");

        let (_, file) = result.unwrap();

        // Test-Assert: Spaces must be preserved
        assert_eq!(
            file,
            PathBuf::from("my message file.toml"),
            "Should preserve spaces in filename"
        );
    }

    /// Test: Absolute path (Unix-style)
    ///
    /// Verifies function works with absolute paths.
    #[test]
    #[cfg(unix)]
    fn test_absolute_path_unix() {
        let input = Path::new("/home/user/sync_data/messages/1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle absolute paths
        assert!(result.is_ok(), "Function should handle absolute paths");

        let (dir, file) = result.unwrap();

        // Test-Assert: Absolute directory path must be correct
        assert_eq!(
            dir,
            PathBuf::from("/home/user/sync_data/messages"),
            "Should extract absolute directory path correctly"
        );

        // Test-Assert: Filename must be correct
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should extract filename correctly from absolute path"
        );
    }

    /// Test: Absolute path (Windows-style)
    ///
    /// Verifies function works with Windows absolute paths.
    #[test]
    #[cfg(windows)]
    fn test_absolute_path_windows() {
        let input = Path::new("C:\\Users\\user\\sync_data\\messages\\1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle Windows absolute paths
        assert!(result.is_ok(), "Function should handle Windows absolute paths");

        let (dir, file) = result.unwrap();

        // Test-Assert: Windows absolute directory path must be correct
        assert_eq!(
            dir,
            PathBuf::from("C:\\Users\\user\\sync_data\\messages"),
            "Should extract Windows absolute directory path correctly"
        );

        // Test-Assert: Filename must be correct
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should extract filename correctly from Windows path"
        );
    }

    /// Test: Extension consistency - clearsigned always gives .toml
    ///
    /// Verifies that use_encryption=false always results in .toml extension.
    #[test]
    fn test_extension_consistency_clearsigned() {
        let test_cases = vec![
            "dir/file.toml",
            "dir/file.gpgtoml",
            "dir/file.txt",
            "dir/file.md",
            "dir/file",
        ];

        for input_str in test_cases {
            let input = Path::new(input_str);
            let result = create_messagepost_file_namepath_extension_tuple(input, false);

            // Test-Assert: Function must succeed for all test cases
            assert!(
                result.is_ok(),
                "Should succeed for input: {}",
                input_str
            );

            let (_, file) = result.unwrap();

            // Test-Assert: Extension must always be 'toml' for clearsigned
            assert_eq!(
                file.extension().and_then(|e| e.to_str()),
                Some("toml"),
                "Extension should always be 'toml' for clearsigned, input was: {}",
                input_str
            );
        }
    }

    /// Test: Extension consistency - encrypted always gives .gpgtoml
    ///
    /// Verifies that use_encryption=true always results in .gpgtoml extension.
    #[test]
    fn test_extension_consistency_encrypted() {
        let test_cases = vec![
            "dir/file.toml",
            "dir/file.gpgtoml",
            "dir/file.txt",
            "dir/file.md",
            "dir/file",
        ];

        for input_str in test_cases {
            let input = Path::new(input_str);
            let result = create_messagepost_file_namepath_extension_tuple(input, true);

            // Test-Assert: Function must succeed for all test cases
            assert!(
                result.is_ok(),
                "Should succeed for input: {}",
                input_str
            );

            let (_, file) = result.unwrap();

            // Test-Assert: Extension must always be 'gpgtoml' for encrypted
            assert_eq!(
                file.extension().and_then(|e| e.to_str()),
                Some("gpgtoml"),
                "Extension should always be 'gpgtoml' for encrypted, input was: {}",
                input_str
            );
        }
    }
}

/// Saves message content as a clearsigned TOML file.
///
/// # Purpose
///
/// Creates a cryptographically signed TOML file for instant messages
/// by writing the TOML content and then clearsigning it in-place.
///
/// # Process Flow (Mirrors save_node_to_clearsigned_file)
///
/// 1. Validate target directory and create if needed
/// 2. Write plain TOML content to target file
/// 3. Get local user's GPG fingerprint from uma.toml
/// 4. Clearsign the file in-place
///
/// # Arguments
///
/// * `target_file_path` - Full path where clearsigned file should be saved
/// * `toml_content` - Pre-serialized TOML string to be clearsigned
///
/// # Returns
///
/// * `Ok(())` - File successfully created and clearsigned
/// * `Err(io::Error)` - If any step fails
fn save_message_as_clearsigned_toml(
    target_file_path: &Path,
    toml_content: &str,
) -> Result<(), io::Error> {

    debug_log!("SMACT: Starting save_message_as_clearsigned_toml");
    debug_log!("SMACT: target_file_path: {:?}", target_file_path);
    debug_log!("SMACT: toml_content length: {} bytes", toml_content.len());

    // Debug-Assert: TOML content must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !toml_content.is_empty(),
        "SMACT: TOML content must not be empty"
    );

    // Production-Catch: Handle empty TOML content
    if toml_content.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "SMACT: TOML content must not be empty"
        ));
    }

    // 1. Get target directory and verify/create it
    let target_dir = target_file_path.parent()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "SMACT: Target path must have a parent directory"
        ))?;

    if !target_dir.exists() {
        debug_log!("SMACT: Target directory doesn't exist, creating it");
        fs::create_dir_all(target_dir)?;
    }
    debug_log!("SMACT: Directory now exists: {}", target_dir.exists());

    // 2. Verify directory is actually a directory
    if !target_dir.is_dir() {
        debug_log!("SMACT: Path exists but is not a directory!");
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMACT: Target parent path exists but is not a directory"
        ));
    }

    // 3. Write the TOML data to the file
    debug_log!("SMACT: Writing TOML data to file...");
    fs::write(target_file_path, toml_content)?;

    // 4. Verify the file was created
    if target_file_path.exists() {
        debug_log!("SMACT: Successfully created file at: {:?}", target_file_path);
    } else {
        debug_log!("SMACT: Warning: File write succeeded but file doesn't exist!");
    }

    // 5. Get local user's GPG fingerprint from uma.toml
    debug_log!("SMACT: Getting GPG fingerprint from uma.toml");
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => {
            debug_log!("SMACT: Retrieved GPG fingerprint: {}", fingerprint);
            fingerprint
        },
        Err(e) => {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMACT: Failed to read GPG fingerprint from uma.toml: {}", e)
            ));
        }
    };

    // 6. Clearsign the file in-place
    debug_log!("SMACT: Starting clearsign operation");
    convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
        target_file_path,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
    )
    .map_err(|gpg_err| {
        std::io::Error::new(
            std::io::ErrorKind::Other,
            format!("SMACT: GPG clearsign operation failed: {:?}", gpg_err),
        )
    })?;

    debug_log!("SMACT: Successfully created clearsigned message file at: {:?}", target_file_path);
    debug_log!("SMACT: save_message_as_clearsigned_toml completed successfully");

    Ok(())
}

#[cfg(test)]
mod tests_clearsigned_v2 {
    use super::*;
    use std::path::{Path, PathBuf};
    use std::fs;

    /// Helper function to create test temp directory
    fn create_test_temp_dir() -> Result<PathBuf, io::Error> {
        let temp_base = std::env::temp_dir();
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
            .as_secs();
        let test_dir = temp_base.join(format!("test_clearsign_v2_{}", timestamp));
        fs::create_dir_all(&test_dir)?;
        Ok(test_dir)
    }

    /// Helper function to cleanup test directory
    fn cleanup_test_dir(dir: &Path) {
        let _ = fs::remove_dir_all(dir);
    }

    /// Test: Error case - empty TOML content
    ///
    /// Verifies that the function returns an error when given empty TOML content.
    #[test]
    fn test_error_empty_toml_content() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let target_file = test_dir.join("test_message.toml");

        let result = save_message_as_clearsigned_toml(
            &target_file,
            "", // Empty content
        );

        assert!(result.is_err(), "Function should return error for empty TOML content");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("TOML content must not be empty"),
                "Error message should mention empty TOML content, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }

    // For save_message_as_clearsigned_toml test:
    #[test]
    fn test_error_no_parent_directory() {
        let result = save_message_as_clearsigned_toml(
            Path::new("message.toml"),
            "owner = \"test\"\ntext = \"message\"",
        );

        assert!(result.is_err(), "Function should return error for path without proper parent");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("parent directory") ||
                error_msg.contains("empty path") ||
                error_msg.contains("not a directory"),  // ADD THIS
                "Error message should mention parent directory issue, got: {}",
                error_msg
            );
        }
    }

    /// Test: Directory creation when target directory doesn't exist
    ///
    /// Verifies that the function creates necessary directories.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_creates_target_directory() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let nested_dir = test_dir.join("level1/level2/level3");
        let target_file = nested_dir.join("test_message.toml");

        // Directory shouldn't exist yet
        assert!(!nested_dir.exists(), "Nested directory should not exist yet");

        let _result = save_message_as_clearsigned_toml(
            &target_file,
            "owner = \"test\"\ntext = \"message\"",
        );

        // Would verify directory was created if GPG setup available

        cleanup_test_dir(&test_dir);
    }

    /// Test: TOML content with special characters
    ///
    /// Verifies that the function handles TOML with quotes, newlines, etc.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_toml_with_special_characters() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let target_file = test_dir.join("test_message.toml");

        let toml_content = r#"owner = "testuser"
text = "Message with \"quotes\" and\nnewlines"
timestamp = 1234567890"#;

        let result = save_message_as_clearsigned_toml(
            &target_file,
            toml_content,
        );

        // With GPG setup, this should succeed
        // Without GPG, validates that content validation passes
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("TOML content must not be empty"),
                "Should not fail on content validation with valid special chars"
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Large TOML content
    ///
    /// Verifies that the function can handle large message content.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_large_toml_content() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let target_file = test_dir.join("test_message.toml");

        // Create large content (10KB)
        let large_text = "x".repeat(10000);
        let toml_content = format!("owner = \"testuser\"\ntext = \"{}\"", large_text);

        let result = save_message_as_clearsigned_toml(
            &target_file,
            &toml_content,
        );

        // With GPG setup, should handle large content
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("TOML content must not be empty"),
                "Should not fail on content validation with large content"
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Basic functionality with valid inputs
    ///
    /// This test requires GPG setup to run fully.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_basic_clearsign_success() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");

        let target_file = test_dir.join("test_message.toml");
        let toml_content = "owner = \"testuser\"\ntext = \"Test message\"";

        let result = save_message_as_clearsigned_toml(
            &target_file,
            toml_content,
        );

        // With proper GPG setup, this should succeed
        // assert!(result.is_ok(), "Function should succeed with valid inputs");
        // assert!(target_file.exists(), "Target file should exist");

        cleanup_test_dir(&test_dir);
    }
}

// /// Saves message content as a GPG encrypted TOML file.
// ///
// /// # Purpose
// ///
// /// This function creates a cryptographically signed AND encrypted TOML file
// /// for instant messages. The encryption process:
// /// 1. Signs the content (clearsign) for authenticity verification
// /// 2. Encrypts the signed content for confidentiality
// /// 3. Results in a file readable only by the key holder
// ///
// /// # Project Context
// ///
// /// Instant messages in the system can be stored in two formats. This function
// /// handles the encrypted format which provides:
// /// - Cryptographic verification of message author (via signature)
// /// - Confidentiality through encryption (only key holder can read)
// /// - Protection against tampering
// /// - Maximum security for sensitive communications
// ///
// /// The encrypted format (.gpgtoml) is used when both authentication and
// /// privacy are required, as opposed to the clearsigned format which only
// /// provides authentication.
// ///
// /// # Process Flow
// ///
// /// 1. Validate inputs and construct target file path with .gpgtoml extension
// /// 2. Verify target directory exists or create it
// /// 3. Create temporary file in project temp directory
// /// 4. Write plain TOML content to temp file
// /// 5. Look up owner's GPG key ID from their collaborator addressbook
// /// 6. Clearsign temp file in-place using owner's GPG key
// /// 7. Extract owner's public key from GPG keyring
// /// 8. Encrypt clearsigned temp file with public key
// /// 9. Save encrypted content to final .gpgtoml file
// /// 10. Clean up all temporary files (even on errors)
// ///
// /// # Arguments
// ///
// /// * `base_file_path` - Path WITHOUT extension (function adds .gpgtoml)
// /// * `toml_content` - Pre-serialized TOML string to be encrypted
// /// * `owner_username` - Username of message owner (for GPG key lookup)
// /// * `addressbook_path` - Path to collaborator addressbook directory
// ///
// /// # Returns
// ///
// /// * `Ok(())` - File successfully created, clearsigned, and encrypted
// /// * `Err(io::Error)` - If any step fails (directory creation, file I/O, GPG operations)
// ///
// /// # Error Handling
// ///
// /// Errors can occur during:
// /// - Input validation
// /// - Target directory validation or creation
// /// - Temp file creation or writing
// /// - GPG key lookup in addressbook
// /// - Clearsigning operation
// /// - Public key extraction from GPG keyring
// /// - Encryption operation
// /// - Saving encrypted content to target
// /// - Temp file cleanup (logged but not fatal)
// ///
// /// All errors ensure temp file cleanup before returning.
// ///
// /// # Security Notes
// ///
// /// - Uses owner's GPG private key for signing (requires key access)
// /// - Uses owner's GPG public key for encryption
// /// - Signature can be verified after decryption using owner's public key
// /// - Content is BOTH signed AND encrypted (sign-then-encrypt pattern)
// /// - Temp files are created with restrictive permissions (system default)
// /// - Temp files are always cleaned up to prevent information leakage
// /// - Only the key holder can decrypt and read the content
// ///
// /// # File Extension
// ///
// /// The function automatically appends `.gpgtoml` extension to the base path.
// /// Example: `base_path = "messages/1234567890"`  creates `messages/1234567890.gpgtoml`
// ///
// /// # Examples
// ///
// /// ```rust
// /// use std::path::Path;
// ///
// /// let base_path = Path::new("sync_data/team/messages/1234567890");
// /// let toml = "owner = \"alice\"\ntext = \"Secret message\"";
// /// let result = save_message_as_gpgtoml(
// ///     base_path,
// ///     toml,
// ///     "alice",
// ///     "sync_data/addressbook"
// /// )?;
// /// // Creates: 1234567890.gpgtoml with encrypted content
// /// ```
// fn save_message_as_gpgtoml(
//     base_file_path: &Path,
//     toml_content: &str,
//     owner_username: &str,
//     addressbook_path: &str,
// ) -> Result<(), io::Error> {

//     // Debug logging for inputs
//     debug_log!("SMAGF: Starting save_message_as_gpgtoml");
//     debug_log!("SMAGF: base_file_path: {:?}", base_file_path);
//     debug_log!("SMAGF: owner_username: {}", owner_username);
//     debug_log!("SMAGF: addressbook_path: {}", addressbook_path);
//     debug_log!("SMAGF: toml_content length: {} bytes", toml_content.len());

//     // =================================================
//     // Debug-Assert (debug builds only), Production-Catch-Handle (always)
//     // =================================================

//     // Debug-Assert: TOML content must not be empty (debug builds only, NOT tests)
//     #[cfg(all(debug_assertions, not(test)))]
//     debug_assert!(
//         !toml_content.is_empty(),
//         "SMAGF: TOML content must not be empty"
//     );

//     // Production-Catch: Handle empty TOML content (always active)
//     if toml_content.is_empty() {
//         return Err(io::Error::new(
//             io::ErrorKind::InvalidInput,
//             "SMAGF: TOML content must not be empty"
//         ));
//     }

//     // Debug-Assert: Owner username must not be empty (debug builds only, NOT tests)
//     #[cfg(all(debug_assertions, not(test)))]
//     debug_assert!(
//         !owner_username.is_empty(),
//         "SMAGF: Owner username must not be empty"
//     );

//     // Production-Catch: Handle empty owner username (always active)
//     if owner_username.is_empty() {
//         return Err(io::Error::new(
//             io::ErrorKind::InvalidInput,
//             "SMAGF: Owner username must not be empty"
//         ));
//     }

//     // Debug-Assert: Addressbook path must not be empty (debug builds only, NOT tests)
//     #[cfg(all(debug_assertions, not(test)))]
//     debug_assert!(
//         !addressbook_path.is_empty(),
//         "SMAGF: Addressbook path must not be empty"
//     );

//     // Production-Catch: Handle empty addressbook path (always active)
//     if addressbook_path.is_empty() {
//         return Err(io::Error::new(
//             io::ErrorKind::InvalidInput,
//             "SMAGF: Addressbook path must not be empty"
//         ));
//     }

//     // 1. Construct final file path with .gpgtoml extension
//     debug_log!("SMAGF: Constructing final file path with .gpgtoml extension");

//     let final_file_path = base_file_path.with_extension("gpgtoml");

//     debug_log!("SMAGF: Final file path: {:?}", final_file_path);

//     // Debug-Assert: Final path must have gpgtoml extension (debug builds only, NOT tests)
//     #[cfg(all(debug_assertions, not(test)))]
//     debug_assert!(
//         final_file_path.extension().and_then(|e| e.to_str()) == Some("gpgtoml"),
//         "SMAGF: Final path must have gpgtoml extension"
//     );

//     // Production-Catch: Verify gpgtoml extension
//     if final_file_path.extension().and_then(|e| e.to_str()) != Some("gpgtoml") {
//         return Err(io::Error::new(
//             io::ErrorKind::Other,
//             "SMAGF: Failed to create path with gpgtoml extension"
//         ));
//     }

//     // 2. Verify and create target directory structure if needed
//     debug_log!("SMAGF: Verifying target directory");

//     let target_dir = final_file_path.parent()
//         .ok_or_else(|| io::Error::new(
//             io::ErrorKind::InvalidInput,
//             "SMAGF: Target path must have a parent directory"
//         ))?;

//     // Debug-Assert: Parent directory path must not be empty (debug builds only, NOT tests)
//     #[cfg(all(debug_assertions, not(test)))]
//     debug_assert!(
//         target_dir != Path::new(""),
//         "SMAGF: Parent directory must not be empty path"
//     );

//     // Production-Catch: Handle empty parent directory path
//     if target_dir == Path::new("") {
//         return Err(io::Error::new(
//             io::ErrorKind::InvalidInput,
//             "SMAGF: Parent directory is empty path"
//         ));
//     }

//     if !target_dir.exists() {
//         debug_log!("SMAGF: Target directory doesn't exist, creating it");
//         fs::create_dir_all(target_dir)?;
//     }

//     // Verify directory is actually a directory
//     if !target_dir.is_dir() {
//         return Err(io::Error::new(
//             io::ErrorKind::Other,
//             "SMAGF: Target parent path exists but is not a directory"
//         ));
//     }

//     debug_log!("SMAGF: Target directory verified: {:?}", target_dir);

//     // 3. Get temp directory and create unique temp file path
//     debug_log!("SMAGF: Creating temp file for encryption");

//     let temp_dir = get_base_uma_temp_directory_path()?;

//     let timestamp = std::time::SystemTime::now()
//         .duration_since(std::time::UNIX_EPOCH)
//         .map_err(|e| io::Error::new(
//             io::ErrorKind::Other,
//             format!("SMAGF: Time error: {}", e)
//         ))?
//         .as_secs();

//     let temp_file_name = format!("message_gpgtoml_{}_{}.toml", owner_username, timestamp);
//     let temp_file_path = temp_dir.join(temp_file_name);

//     debug_log!("SMAGF: Temp file path: {:?}", temp_file_path);

//     // 4. Write plain TOML content to temp file
//     debug_log!("SMAGF: Writing TOML content to temp file");

//     if let Err(e) = fs::write(&temp_file_path, toml_content) {
//         debug_log!("SMAGF: Failed to write temp file: {}", e);
//         return Err(e);
//     }

//     // Verify temp file was created
//     if !temp_file_path.exists() {
//         return Err(io::Error::new(
//             io::ErrorKind::Other,
//             "SMAGF: Failed to create temp file"
//         ));
//     }

//     debug_log!("SMAGF: Successfully wrote temp file");

//     // 5. Look up owner's GPG key ID from addressbook
//     debug_log!("SMAGF: Looking up GPG key ID for owner: {}", owner_username);

//     // Convert addressbook path to absolute path
//     let addressbook_dir = match make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(
//         addressbook_path
//     ) {
//         Ok(dir) => dir,
//         Err(e) => {
//             // Clean up temp file before returning error
//             let _ = fs::remove_file(&temp_file_path);
//             return Err(e);
//         }
//     };

//     debug_log!("SMAGF: Addressbook directory: {:?}", addressbook_dir);

//     // Construct path to owner's collaborator file
//     let collaborator_filename = format!("{}__collaborator.toml", owner_username);
//     let collaborator_file_path = addressbook_dir.join(collaborator_filename);

//     debug_log!("SMAGF: Collaborator file path: {:?}", collaborator_file_path);

//     // Verify collaborator file exists
//     if !collaborator_file_path.exists() {
//         // Clean up temp file before returning error
//         let _ = fs::remove_file(&temp_file_path);
//         return Err(io::Error::new(
//             io::ErrorKind::NotFound,
//             format!("SMAGF: Collaborator file not found for user: {}", owner_username)
//         ));
//     }

//     // Convert to string for TOML reading function
//     let collaborator_file_str = collaborator_file_path.to_str()
//         .ok_or_else(|| {
//             // Clean up temp file before returning error
//             let _ = fs::remove_file(&temp_file_path);
//             io::Error::new(
//                 io::ErrorKind::InvalidInput,
//                 "SMAGF: Cannot convert collaborator file path to string"
//             )
//         })?;

//     // Read GPG key ID from clearsigned collaborator file
//     let gpg_key_id = match read_singleline_string_from_clearsigntoml(
//         collaborator_file_str,
//         "gpg_publickey_id"
//     ) {
//         Ok(key_id) => {
//             debug_log!("SMAGF: Retrieved GPG key ID: {}", key_id);
//             key_id
//         },
//         Err(e) => {
//             // Clean up temp file before returning error
//             let _ = fs::remove_file(&temp_file_path);
//             return Err(io::Error::new(
//                 io::ErrorKind::Other,
//                 format!("SMAGF: Failed to read GPG key ID from collaborator file: {}", e)
//             ));
//         }
//     };

//     // Debug-Assert: GPG key ID must not be empty (debug builds only, NOT tests)
//     #[cfg(all(debug_assertions, not(test)))]
//     debug_assert!(
//         !gpg_key_id.is_empty(),
//         "SMAGF: GPG key ID must not be empty"
//     );

//     // Production-Catch: Handle empty GPG key ID (always active)
//     if gpg_key_id.is_empty() {
//         // Clean up temp file before returning error
//         let _ = fs::remove_file(&temp_file_path);
//         return Err(io::Error::new(
//             io::ErrorKind::InvalidData,
//             "SMAGF: GPG key ID from addressbook is empty"
//         ));
//     }

//     // 6. Clearsign the temp file in-place
//     debug_log!("SMAGF: Starting clearsign operation on temp file");

//     match convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
//         &temp_file_path,
//         addressbook_path,
//         &gpg_key_id,
//     ) {
//         Ok(()) => {
//             debug_log!("SMAGF: Successfully clearsigned temp file");
//         },
//         Err(gpg_err) => {
//             // Clean up temp file before returning error
//             let _ = fs::remove_file(&temp_file_path);
//             return Err(io::Error::new(
//                 io::ErrorKind::Other,
//                 format!("SMAGF: GPG clearsign operation failed: {:?}", gpg_err),
//             ));
//         }
//     }

//     // 7. Extract public key from GPG keyring using fingerprint
//     debug_log!("SMAGF: Extracting public key from GPG for fingerprint: {}", gpg_key_id);

//     let public_key_output = match std::process::Command::new("gpg")
//         .arg("--armor")
//         .arg("--export")
//         .arg(&gpg_key_id)
//         .output()
//     {
//         Ok(output) => output,
//         Err(e) => {
//             // Clean up temp file before returning error
//             let _ = fs::remove_file(&temp_file_path);
//             return Err(io::Error::new(
//                 io::ErrorKind::Other,
//                 format!("SMAGF: Failed to execute GPG export command: {}", e)
//             ));
//         }
//     };

//     // Check if GPG command succeeded
//     if !public_key_output.status.success() {
//         // Clean up temp file before returning error
//         let _ = fs::remove_file(&temp_file_path);
//         let stderr = String::from_utf8_lossy(&public_key_output.stderr);
//         return Err(io::Error::new(
//             io::ErrorKind::Other,
//             format!("SMAGF: GPG export failed: {}", stderr)
//         ));
//     }

//     // Convert public key bytes to string
//     let public_key_string = match String::from_utf8(public_key_output.stdout) {
//         Ok(key_str) => key_str,
//         Err(e) => {
//             // Clean up temp file before returning error
//             let _ = fs::remove_file(&temp_file_path);
//             return Err(io::Error::new(
//                 io::ErrorKind::Other,
//                 format!("SMAGF: Failed to convert public key to UTF-8: {}", e)
//             ));
//         }
//     };

//     // Verify we got a valid public key
//     if public_key_string.trim().is_empty() {
//         // Clean up temp file before returning error
//         let _ = fs::remove_file(&temp_file_path);
//         return Err(io::Error::new(
//             io::ErrorKind::Other,
//             "SMAGF: GPG export returned empty public key"
//         ));
//     }

//     debug_log!("SMAGF: Successfully extracted public key from GPG");

//     // 8. Encrypt the clearsigned temp file with the public key
//     debug_log!("SMAGF: Starting encryption of clearsigned file");

//     match encrypt_clearsigned_toml_with_public_key_content(
//         &temp_file_path,
//         &public_key_string,
//         &final_file_path
//     ) {
//         Ok(()) => {
//             debug_log!("SMAGF: Successfully created encrypted file at: {:?}", final_file_path);
//         },
//         Err(e) => {
//             // Clean up temp file before returning error
//             let _ = fs::remove_file(&temp_file_path);
//             return Err(io::Error::new(
//                 io::ErrorKind::Other,
//                 format!("SMAGF: Encryption failed: {:?}", e)
//             ));
//         }
//     }

//     // 9. Clean up temp file (critical for production)
//     debug_log!("SMAGF: Cleaning up temp file");

//     if let Err(e) = fs::remove_file(&temp_file_path) {
//         // Log warning but don't fail the operation since main task succeeded
//         debug_log!("SMAGF: Warning: Failed to remove temp file: {}", e);
//     }

//     // 10. Verify final file exists and is non-empty
//     if !final_file_path.exists() {
//         return Err(io::Error::new(
//             io::ErrorKind::Other,
//             "SMAGF: Final file creation appeared successful but file doesn't exist"
//         ));
//     }

//     // Check file size
//     match fs::metadata(&final_file_path) {
//         Ok(metadata) => {
//             let file_size = metadata.len();
//             debug_log!("SMAGF: Final file size: {} bytes", file_size);

//             if file_size == 0 {
//                 return Err(io::Error::new(
//                     io::ErrorKind::Other,
//                     "SMAGF: Final file was created but is empty"
//                 ));
//             }
//         },
//         Err(e) => {
//             return Err(io::Error::new(
//                 io::ErrorKind::Other,
//                 format!("SMAGF: Cannot read final file metadata: {}", e)
//             ));
//         }
//     }

//     debug_log!("SMAGF: Successfully created encrypted message file at: {:?}", final_file_path);
//     debug_log!("SMAGF: save_message_as_gpgtoml completed successfully");

//     Ok(())
// }

/// Saves message content as a GPG encrypted TOML file.
///
/// # Purpose
///
/// Creates a cryptographically signed AND encrypted TOML file.
///
/// # Process Flow (Mirrors save_node_as_gpgtoml)
///
/// 1. Verify target directory and create if needed
/// 2. Create temp file in project temp directory
/// 3. Write plain TOML to temp file
/// 4. Get local user's GPG fingerprint from uma.toml
/// 5. Clearsign temp file in-place
/// 6. Extract public key from GPG keyring
/// 7. Encrypt clearsigned file with public key
/// 8. Save to final .gpgtoml file
/// 9. Clean up temp file
///
/// # Arguments
///
/// * `base_file_path` - Path WITHOUT extension (function adds .gpgtoml)
/// * `toml_content` - Pre-serialized TOML string to be encrypted
///
/// # Returns
///
/// * `Ok(())` - File successfully created, clearsigned, and encrypted
/// * `Err(io::Error)` - If any step fails
fn save_message_as_gpgtoml(
    base_file_path: &Path,
    toml_content: &str,
) -> Result<(), io::Error> {

    debug_log!("SMAGF: Starting save_message_as_gpgtoml");
    debug_log!("SMAGF: base_file_path: {:?}", base_file_path);
    debug_log!("SMAGF: toml_content length: {} bytes", toml_content.len());

    // Debug-Assert: TOML content must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !toml_content.is_empty(),
        "SMAGF: TOML content must not be empty"
    );

    // Production-Catch: Handle empty TOML content
    if toml_content.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "SMAGF: TOML content must not be empty"
        ));
    }

    // 1. Construct final file path with .gpgtoml extension
    let final_file_path = base_file_path.with_extension("gpgtoml");
    debug_log!("SMAGF: Final file path: {:?}", final_file_path);

    // 2. Verify and create target directory structure if needed
    let target_dir = final_file_path.parent()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "SMAGF: Target path must have a parent directory"
        ))?;

    if !target_dir.exists() {
        debug_log!("SMAGF: Target directory doesn't exist, creating it");
        fs::create_dir_all(target_dir)?;
    }
    debug_log!("SMAGF: Directory now exists: {}", target_dir.exists());

    // Verify directory is actually a directory
    if !target_dir.is_dir() {
        debug_log!("SMAGF: Path exists but is not a directory!");
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMAGF: Target parent path exists but is not a directory"
        ));
    }

    // 3. Get temp directory and create unique temp file path
    let temp_dir = get_base_uma_temp_directory_path()?;

    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map_err(|e| io::Error::new(
            io::ErrorKind::Other,
            format!("SMAGF: Time error: {}", e)
        ))?
        .as_secs();

    let temp_file_name = format!("message_gpgtoml_{}.toml", timestamp);
    let temp_file_path = temp_dir.join(temp_file_name);

    debug_log!("SMAGF: Temp file path: {:?}", temp_file_path);

    // 4. Write plain TOML content to temp file
    debug_log!("SMAGF: Writing TOML content to temp file");

    if let Err(e) = fs::write(&temp_file_path, toml_content) {
        debug_log!("SMAGF: Failed to write temp file: {}", e);
        return Err(e);
    }

    // Verify temp file was created
    if !temp_file_path.exists() {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMAGF: Failed to create temp file"
        ));
    }

    debug_log!("SMAGF: Successfully wrote temp file");

    // 5. Get local user's GPG fingerprint from uma.toml
    debug_log!("SMAGF: Getting GPG fingerprint from uma.toml");

    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => {
            debug_log!("SMAGF: Retrieved GPG fingerprint: {}", fingerprint);
            fingerprint
        },
        Err(e) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Failed to read GPG fingerprint from uma.toml: {}", e)
            ));
        }
    };

    // 6. Clearsign the temp file in-place
    debug_log!("SMAGF: Starting clearsign operation on temp file");

    match convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
        &temp_file_path,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
    ) {
        Ok(()) => {
            debug_log!("SMAGF: Successfully clearsigned temp file");
        },
        Err(gpg_err) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: GPG clearsign operation failed: {:?}", gpg_err),
            ));
        }
    }

    // 7. Extract public key from GPG keyring using fingerprint
    debug_log!("SMAGF: Extracting public key from GPG for fingerprint: {}", gpg_full_fingerprint_key_id_string);

    let public_key_output = match std::process::Command::new("gpg")
        .arg("--armor")
        .arg("--export")
        .arg(&gpg_full_fingerprint_key_id_string)
        .output()
    {
        Ok(output) => output,
        Err(e) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Failed to execute GPG export command: {}", e)
            ));
        }
    };

    // Check if GPG command succeeded
    if !public_key_output.status.success() {
        // Clean up temp file before returning error
        let _ = fs::remove_file(&temp_file_path);
        let stderr = String::from_utf8_lossy(&public_key_output.stderr);
        return Err(io::Error::new(
            io::ErrorKind::Other,
            format!("SMAGF: GPG export failed: {}", stderr)
        ));
    }

    // Convert public key bytes to string
    let public_key_string = match String::from_utf8(public_key_output.stdout) {
        Ok(key_str) => key_str,
        Err(e) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Failed to convert public key to UTF-8: {}", e)
            ));
        }
    };

    // Verify we got a valid public key
    if public_key_string.trim().is_empty() {
        // Clean up temp file before returning error
        let _ = fs::remove_file(&temp_file_path);
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMAGF: GPG export returned empty public key"
        ));
    }

    debug_log!("SMAGF: Successfully extracted public key from GPG");

    // 8. Encrypt the clearsigned temp file with the public key
    debug_log!("SMAGF: Starting encryption of clearsigned file");

    match encrypt_clearsigned_toml_with_public_key_content(
        &temp_file_path,
        &public_key_string,
        &final_file_path
    ) {
        Ok(()) => {
            debug_log!("SMAGF: Successfully created encrypted file at: {:?}", final_file_path);
        },
        Err(e) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Encryption failed: {:?}", e)
            ));
        }
    }

    // 9. Clean up temp file (critical for production)
    debug_log!("SMAGF: Cleaning up temp file");

    if let Err(e) = fs::remove_file(&temp_file_path) {
        // Log warning but don't fail the operation since main task succeeded
        debug_log!("SMAGF: Warning: Failed to remove temp file: {}", e);
    }

    // 10. Verify final file exists and is non-empty
    if !final_file_path.exists() {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMAGF: Final file creation appeared successful but file doesn't exist"
        ));
    }

    // Check file size
    match fs::metadata(&final_file_path) {
        Ok(metadata) => {
            let file_size = metadata.len();
            debug_log!("SMAGF: Final file size: {} bytes", file_size);

            if file_size == 0 {
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    "SMAGF: Final file was created but is empty"
                ));
            }
        },
        Err(e) => {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Cannot read final file metadata: {}", e)
            ));
        }
    }

    debug_log!("SMAGF: Successfully created encrypted message file at: {:?}", final_file_path);
    debug_log!("SMAGF: save_message_as_gpgtoml completed successfully");

    Ok(())
}

#[cfg(test)]
mod tests_gpgtoml_v2 {
    use super::*;
    use std::path::{Path, PathBuf};
    use std::fs;

    /// Helper function to create test temp directory
    fn create_test_temp_dir() -> Result<PathBuf, io::Error> {
        let temp_base = std::env::temp_dir();
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
            .as_secs();
        let test_dir = temp_base.join(format!("test_gpgtoml_v2_{}", timestamp));
        fs::create_dir_all(&test_dir)?;
        Ok(test_dir)
    }

    /// Helper function to cleanup test directory
    fn cleanup_test_dir(dir: &Path) {
        let _ = fs::remove_dir_all(dir);
    }

    /// Test: Error case - empty TOML content
    ///
    /// Verifies that the function returns an error when given empty TOML content.
    #[test]
    fn test_error_empty_toml_content() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message");

        let result = save_message_as_gpgtoml(
            &base_file,
            "", // Empty content
        );

        assert!(result.is_err(), "Function should return error for empty TOML content");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("TOML content must not be empty"),
                "Error message should mention empty TOML content, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Error case - base path with no parent directory
    ///
    /// Verifies that the function returns an error when base path has no parent.
    #[test]
    fn test_error_no_parent_directory() {
        let result = save_message_as_gpgtoml(
            Path::new("message"), // Path with empty parent ("")
            "owner = \"test\"\ntext = \"message\"",
        );

        assert!(result.is_err(), "Function should return error for path without proper parent");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            // The error could be about parent directory or that empty path is not a directory
            assert!(
                error_msg.contains("parent directory") ||
                error_msg.contains("empty path") ||
                error_msg.contains("not a directory"),
                "Error message should mention parent directory issue, got: {}",
                error_msg
            );
        }
    }

    /// Test: Extension handling - gpgtoml extension is added
    ///
    /// Verifies that .gpgtoml extension is correctly added to base path.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_extension_added_correctly() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message");

        let result = save_message_as_gpgtoml(
            &base_file,
            "owner = \"test\"\ntext = \"message\"",
        );

        // With GPG setup, should create file with .gpgtoml extension
        // Without GPG, validates that path construction doesn't fail

        cleanup_test_dir(&test_dir);
    }

    /// Test: Extension handling - existing extension is replaced
    ///
    /// Verifies that if base path has an extension, it's replaced with .gpgtoml.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_existing_extension_replaced() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message.toml");

        let result = save_message_as_gpgtoml(
            &base_file,
            "owner = \"test\"\ntext = \"message\"",
        );

        // Should create .gpgtoml file, replacing .toml extension

        cleanup_test_dir(&test_dir);
    }

    /// Test: TOML content with special characters
    ///
    /// Verifies that the function handles TOML with quotes, newlines, etc.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_toml_with_special_characters() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message");

        let toml_content = r#"owner = "testuser"
text = "Message with \"quotes\" and\nnewlines"
timestamp = 1234567890"#;

        let result = save_message_as_gpgtoml(
            &base_file,
            toml_content,
        );

        // With GPG setup, should handle special characters
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("TOML content must not be empty"),
                "Should not fail on content validation with valid special chars"
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Large TOML content
    ///
    /// Verifies that the function can handle large message content.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_large_toml_content() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message");

        // Create large content (10KB)
        let large_text = "x".repeat(10000);
        let toml_content = format!("owner = \"testuser\"\ntext = \"{}\"", large_text);

        let result = save_message_as_gpgtoml(
            &base_file,
            &toml_content,
        );

        // With GPG setup, should handle large content
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("TOML content must not be empty"),
                "Should not fail on content validation with large content"
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Basic functionality with valid inputs
    ///
    /// This test requires GPG setup to run fully.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_basic_gpgtoml_success() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");

        let base_file = test_dir.join("test_message");
        let toml_content = "owner = \"testuser\"\ntext = \"Test message\"";

        let result = save_message_as_gpgtoml(
            &base_file,
            toml_content,
        );

        // With proper GPG setup, should create .gpgtoml file
        // assert!(result.is_ok(), "Function should succeed with valid inputs");
        // let expected_file = test_dir.join("test_message.gpgtoml");
        // assert!(expected_file.exists(), "Target file should exist with .gpgtoml extension");

        cleanup_test_dir(&test_dir);
    }
}

/// Add New Message File
///
/// # Purpose
///
/// Creates and saves an instant message file in either clearsigned TOML or
/// GPG encrypted TOML format, depending on the message settings.
///
/// # Project Context
///
/// This function is the main entry point for creating instant messages in the
/// team collaboration system. It:
/// - Parses recipient information from message text
/// - Validates recipients against team channel access list
/// - Creates appropriately formatted message file (clearsigned or encrypted)
/// - Sets up sync flags for message distribution to recipients
///
/// Messages can be in two formats:
/// 1. Clearsigned TOML (.toml): Signed but readable, for general team communication
/// 2. GPG Encrypted TOML (.gpgtoml): Signed and encrypted, for sensitive communication
///
/// # Process Flow
///
/// 1. Parse optional `{to:username}` syntax to restrict recipients
/// 2. Validate recipients are in team channel collaborator list
/// 3. Read message browser metadata from `0.toml`
/// 4. Create MessagePostFile struct with all message data
/// 5. Serialize message to TOML format
/// 6. Save as clearsigned or encrypted file based on settings
/// 7. Write sync flags for each recipient to trigger distribution
///
/// # Arguments
///
/// * `incoming_file_path` - Full path where message file should be saved (with extension)
/// * `owner` - Username of message author/sender
/// * `text` - Message text content (may include `{to:username}` for direct messages)
/// * `signature` - Optional cryptographic signature for message
/// * `graph_navigation_instance_state` - Current navigation state with collaborator info
///
/// # Returns
///
/// * `Ok(())` - Message file successfully created and sync flags written
/// * `Err(io::Error)` - If any step fails (file I/O, serialization, GPG operations)
///
/// # Recipient Syntax
///
/// Messages can include `{to:username}` to send to a specific recipient:
/// - `{to:alice}` - Send only to alice
/// - If recipient not in channel or is sender, falls back to default channel list
/// - Without `{to:}` syntax, sends to all channel collaborators
///
/// # Error Handling
///
/// Errors can occur during:
/// - Metadata file reading (0.toml)
/// - TOML serialization
/// - File saving (clearsign or encrypt operations)
/// - Sync flag writing
///
/// # Security Notes
///
/// - Clearsigned messages are authenticated but readable by anyone with file access
/// - Encrypted messages require recipient's GPG key to decrypt
/// - Message format determined by MessagePostFile.messagepost_gpgtoml flag
/// - All messages include sender authentication via GPG signature
///
/// # Examples
///
/// ```rust
/// // Send message to all channel collaborators (clearsigned)
/// add_im_message(
///     Path::new("sync_data/team/channel/messages/123.toml"),
///     "alice",
///     "Hello team!",
///     None,
///     &state
/// )?;
///
/// // Send direct message to bob (format depends on MessagePostFile settings)
/// add_im_message(
///     Path::new("sync_data/team/channel/messages/124.toml"),
///     "alice",
///     "{to:bob} Private message",
///     None,
///     &state
/// )?;
/// ```
fn add_im_message(
    incoming_file_path: &Path,
    owner: &str,
    text: &str,
    graph_navigation_instance_state: &GraphNavigationInstanceState,
) -> Result<(), io::Error> {

    debug_log!("AIM: Starting add_im_message");
    debug_log!("AIM: incoming_file_path: {:?}", incoming_file_path);
    debug_log!("AIM: owner: {}", owner);
    debug_log!("AIM: text length: {} bytes", text.len());

    // =================================================
    // Debug-Assert (debug builds only), Production-Catch-Handle (always)
    // =================================================

    // Debug-Assert: Owner must not be empty (debug builds only, NOT tests)
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !owner.is_empty(),
        "AIM: Owner must not be empty"
    );

    // Production-Catch: Handle empty owner
    if owner.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "AIM: Owner must not be empty"
        ));
    }

    // Debug-Assert: Text must not be empty (debug builds only, NOT tests)
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !text.is_empty(),
        "AIM: Message text must not be empty"
    );

    // Production-Catch: Handle empty text
    if text.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "AIM: Message text must not be empty"
        ));
    }

    // Debug-Assert: File path must have a filename (debug builds only, NOT tests)
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        incoming_file_path.file_name().is_some(),
        "AIM: File path must have a filename"
    );

    // Production-Catch: Handle missing filename
    if incoming_file_path.file_name().is_none() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "AIM: File path must have a filename"
        ));
    }

    // 1. Parse for {to:user} syntax to determine recipients
    debug_log!("AIM: Parsing recipient list");

    let mut recipients_list = graph_navigation_instance_state
        .current_node_teamchannel_collaborators_with_access
        .clone();

    if let Some(to_clause) = text.find("{to:") {
        if let Some(end_brace) = text[to_clause..].find('}') {
            let recipient_name = text[to_clause + 4..to_clause + end_brace].trim();

            debug_log!("AIM: Found clause for recipient: {}", recipient_name);

            recipients_list.clear(); // Clear default list: restrict to listed recipient only

            // 2. Check if recipient in team channel list and is not sender
            if graph_navigation_instance_state
                .current_node_teamchannel_collaborators_with_access
                .contains(&recipient_name.to_string())
                && recipient_name != owner
            {
                recipients_list.push(recipient_name.to_string()); // Add only the specified recipient
                debug_log!("AIM: Recipient validated and added: {}", recipient_name);
            } else {
                // Log if user not found
                debug_log!(
                    "AIM: 'to:' clause but recipient '{}' not found in channel or is sender.",
                    recipient_name
                );
            }
        }
    }

    debug_log!("AIM: Final recipients list: {:?}", recipients_list);

    // 3. Separate name and path - get parent directory
    debug_log!("AIM: Extracting parent directory");

    let parent_dir = incoming_file_path.parent()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "AIM: File path must have a parent directory"
        ))?;

    // Debug-Assert: Parent directory must not be empty path (debug builds only, NOT tests)
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        parent_dir != Path::new(""),
        "AIM: Parent directory must not be empty path"
    );

    // Production-Catch: Handle empty parent directory
    if parent_dir == Path::new("") {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "AIM: Parent directory is empty path"
        ));
    }

    debug_log!("AIM: Parent directory: {:?}", parent_dir);

    // 4. Read 0.toml to get this instant messenger browser room's settings
    debug_log!("AIM: Reading metadata from 0.toml");

    let metadata_path = parent_dir.join("0.toml");

    let metadata_string = fs::read_to_string(&metadata_path)
        .map_err(|e| io::Error::new(
            io::ErrorKind::Other,
            format!("AIM: Failed to read metadata file: {}", e)
        ))?;

    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let metadata: NodeInstMsgBrowserMetadata = toml::from_str(&metadata_string)
        .map_err(|e| io::Error::new(
            io::ErrorKind::Other,
            format!("AIM: TOML deserialization error: {}", e)
        ))?;

    debug_log!("AIM: Metadata loaded - node: {}, path: {}",
        metadata.node_name,
        metadata.path_in_node
    );

    // Extract node name and file path
    let node_name = metadata.node_name;
    let filepath_in_node = metadata.path_in_node;

    // 5. Create MessagePostFile struct
    debug_log!("AIM: Creating MessagePostFile");

    let message = MessagePostFile::new(
        graph_navigation_instance_state,
        owner,
        &node_name,
        &filepath_in_node,
        text,
        recipients_list.clone(),
        false, // messagepost_gpgtoml - default to clearsigned format
        None,  // NEW: None = use default expiration
    );

    debug_log!("AIM: MessagePostFile created, gpgtoml: {}", message.messagepost_gpgtoml);

    // 6. Serialize message to TOML
    debug_log!("AIM: Serializing message to TOML");

    let toml_data = toml::to_string(&message)
        .map_err(|e| io::Error::new(
            io::ErrorKind::Other,
            format!("AIM: TOML serialization error: {}", e)
        ))?;

    debug_log!("AIM: TOML serialization successful, {} bytes", toml_data.len());

    // 7. Save message file based on format setting
    debug_log!("AIM: Saving message file");

    if message.messagepost_gpgtoml {
        // GPG encrypted format - use base path without extension
        debug_log!("AIM: Using GPG encrypted format (.gpgtoml)");

        let base_path = incoming_file_path.with_extension("");

        save_message_as_gpgtoml(
            &base_path,
            &toml_data,
            // owner,
            // COLLABORATOR_ADDRESSBOOK_PATH_STR,
        )?;

        debug_log!("AIM: GPG encrypted message saved successfully");
    } else {
        // Clearsigned format - use full path
        debug_log!("AIM: Using clearsigned format (.toml)");

        /*
        fn save_message_as_clearsigned_toml(
            target_file_path: &Path,
            toml_content: &str,
        ) -> Result<(), io::Error> {
        */

        save_message_as_clearsigned_toml(
            incoming_file_path,
            &toml_data,
            // owner,
            // COLLABORATOR_ADDRESSBOOK_PATH_STR,
        )?;

        debug_log!("AIM: Clearsigned message saved successfully");
    }

    // 8. Write update flag for each possible remote collaborator
    // sync_data/teamtest/new_file_path_flags/bob
    // sync_data/teamtest/new_file_path_flags/charlotte
    // etc.
    debug_log!("AIM: Writing sync flags for recipients");

    let sync_result = write_newfile_sendq_flag(
        &recipients_list,
        incoming_file_path,
    );

    // Log but don't fail if sync flags fail (message is already saved)
    if let Err(e) = sync_result {
        debug_log!("AIM: Warning: Failed to write sync flags: {}", e);
    } else {
        debug_log!("AIM: Sync flags written successfully");
    }

    debug_log!("AIM: add_im_message completed successfully");

    Ok(())
}

#[cfg(test)]
mod tests_add_im_message {
    use super::*;
    use std::path::{Path, PathBuf};
    use std::fs;

    /// Helper to create minimal test state for testing
    ///
    /// Creates a GraphNavigationInstanceState with reasonable defaults
    /// for testing purposes. This avoids duplicating state initialization
    /// across multiple tests.
    fn create_minimal_test_state() -> GraphNavigationInstanceState {
        GraphNavigationInstanceState {
            local_owner_user: "testuser".to_string(),
            active_team_channel: String::new(),
            default_im_messages_expiration_days: 30,
            default_task_nodes_expiration_days: 90,
            tui_height: 24,
            tui_width: 80,
            current_full_file_path: PathBuf::from("/tmp/test"),
            current_node_teamchannel_collaborators_with_access: vec![],
            current_node_name: String::new(),
            current_node_owner: String::new(),
            current_node_description_for_tui: String::new(),
            current_node_directory_path: PathBuf::new(),
            current_node_unique_id: Vec::new(),
            current_node_members: Vec::new(),
            home_square_one: false,
            pa1_process: String::new(),
            pa2_schedule: Vec::new(),
            pa3_users: String::new(),
            pa4_features: String::new(),
            pa5_mvp: String::new(),
            pa6_feedback: String::new(),
            message_post_gpgtoml_required: None,
            message_post_data_format_specs_integer_ranges_from_to_tuple_array: None,
            message_post_data_format_specs_int_string_ranges_from_to_tuple_array: None,
            message_post_max_string_length_int: None,
            message_post_is_public_bool: None,
            message_post_user_confirms_bool: None,
            message_post_start_date_utc_posix: None,
            message_post_end_date_utc_posix: None,
        }
    }

    /// Helper function to create test temp directory
    fn create_test_temp_dir() -> Result<PathBuf, io::Error> {
        let temp_base = std::env::temp_dir();
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
            .as_secs();
        let test_dir = temp_base.join(format!("test_add_im_{}", timestamp));
        fs::create_dir_all(&test_dir)?;
        Ok(test_dir)
    }

    /// Helper function to cleanup test directory
    fn cleanup_test_dir(dir: &Path) {
        let _ = fs::remove_dir_all(dir);
    }

    /// Test: Error case - empty owner
    ///
    /// Verifies that the function returns an error when owner is empty.
    #[test]
    fn test_error_empty_owner() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let message_file = test_dir.join("test_message.toml");

        let state = create_minimal_test_state();

        let result = add_im_message(
            &message_file,
            "", // Empty owner
            "Test message",
            &state,
        );

        assert!(result.is_err(), "Function should return error for empty owner");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("Owner must not be empty"),
                "Error message should mention empty owner, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Error case - empty message text
    ///
    /// Verifies that the function returns an error when text is empty.
    #[test]
    fn test_error_empty_text() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let message_file = test_dir.join("test_message.toml");

        let state = create_minimal_test_state();

        let result = add_im_message(
            &message_file,
            "testuser",
            "", // Empty text
            &state,
        );

        assert!(result.is_err(), "Function should return error for empty text");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("Message text must not be empty"),
                "Error message should mention empty text, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }

    // /// Test: Error case - path with no filename
    // ///
    // /// Verifies that the function returns an error when path has no filename.
    // #[test]
    // fn test_error_no_filename() {
    //     let test_dir = create_test_temp_dir().expect("Failed to create test directory");
    //     let message_path = test_dir.join("messages/");

    //     let state = create_minimal_test_state();

    //     let result = add_im_message(
    //         &message_path,
    //         "testuser",
    //         "Test message",
    //         None,
    //         &state,
    //     );

    //     assert!(result.is_err(), "Function should return error for path without filename");

    //     if let Err(e) = result {
    //         let error_msg = format!("{}", e);
    //         assert!(
    //             error_msg.contains("must have a filename"),
    //             "Error message should mention missing filename, got: {}",
    //             error_msg
    //         );
    //     }

    //     cleanup_test_dir(&test_dir);
    // }

    /// Test: Error case - path with no filename / directory path
    ///
    /// Verifies that directory-like paths fail appropriately.
    /// Note: Path validation for file vs directory happens when reading metadata.
    #[test]
    fn test_error_directory_like_path() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let message_path = test_dir.join("messages/");

        let state = create_minimal_test_state();

        let result = add_im_message(
            &message_path,
            "testuser",
            "Test message",
            &state,
        );

        assert!(result.is_err(), "Function should return error for directory-like path");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            // Will fail at metadata reading stage since path isn't a proper file path
            assert!(
                error_msg.contains("Failed to read metadata file") ||
                error_msg.contains("must have a filename"),
                "Error should mention metadata or filename issue, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Error case - path with no parent directory
    ///
    /// Verifies that the function returns an error when path has no parent.
    #[test]
    fn test_error_no_parent_directory() {
        let state = create_minimal_test_state();

        let result = add_im_message(
            Path::new("message.toml"), // No parent directory
            "testuser",
            "Test message",
            &state,
        );

        assert!(result.is_err(), "Function should return error for path without parent");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("parent directory") || error_msg.contains("empty path"),
                "Error message should mention parent directory issue, got: {}",
                error_msg
            );
        }
    }

    /// Test: Message text with special characters
    ///
    /// Verifies that message text with quotes, newlines, etc. is handled.
    #[test]
    fn test_message_text_special_characters() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let message_file = test_dir.join("test_message.toml");

        let state = create_minimal_test_state();

        let text_with_specials = "Message with \"quotes\" and\nnewlines\nand\ttabs";

        /*
        fn add_im_message(
            incoming_file_path: &Path,
            owner: &str,
            text: &str,
            signature: Option<String>,
            graph_navigation_instance_state: &GraphNavigationInstanceState,
        ) -> Result<(), io::Error> {
        */

        let result = add_im_message(
            &message_file,
            "testuser",
            text_with_specials,
            &state,
        );

        // Will fail without 0.toml metadata file, but validates text handling
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("Message text must not be empty"),
                "Should not fail on text validation with special chars, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Owner with special characters
    ///
    /// Verifies that usernames with dots, dashes, underscores work.
    #[test]
    fn test_owner_special_characters() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let message_file = test_dir.join("test_message.toml");

        let state = create_minimal_test_state();

        let usernames = vec![
            "user.name",
            "user-name",
            "user_name",
            "user123",
        ];

        for username in usernames {
            let result = add_im_message(
                &message_file,
                username,
                "Test message",
                &state,
            );

            // Should not fail on username validation
            if let Err(e) = result {
                let error_msg = format!("{}", e);
                assert!(
                    !error_msg.contains("Owner must not be empty"),
                    "Should accept username '{}', got error: {}",
                    username,
                    error_msg
                );
            }
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Long message text
    ///
    /// Verifies that long messages are handled correctly.
    #[test]
    fn test_long_message_text() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let message_file = test_dir.join("test_message.toml");

        let state = create_minimal_test_state();

        // Create 5KB message
        let long_text = "x".repeat(5000);

        let result = add_im_message(
            &message_file,
            "testuser",
            &long_text,
            &state,
        );

        // Will fail without full setup, but validates large text handling
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("Message text must not be empty"),
                "Should not fail on text validation with large text, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }
}

// #[cfg(test)]
// mod tests_add_im_message {
//     use super::*;

//     // Helper to create minimal test state
//     fn create_minimal_test_state() -> GraphNavigationInstanceState {
//         GraphNavigationInstanceState {
//             local_owner_user: "testuser".to_string(),
//             active_team_channel: String::new(),
//             default_im_messages_expiration_days: 30,
//             default_task_nodes_expiration_days: 90,
//             tui_height: 24,
//             tui_width: 80,
//             current_full_file_path: PathBuf::from("/tmp/test"),
//             current_node_teamchannel_collaborators_with_access: vec![],
//             current_node_name: String::new(),
//             current_node_owner: String::new(),
//             current_node_description_for_tui: String::new(),
//             current_node_directory_path: PathBuf::new(),
//             current_node_unique_id: Vec::new(),
//             current_node_members: Vec::new(),
//             home_square_one: false,
//             pa1_process: String::new(),
//             pa2_schedule: Vec::new(),
//             pa3_users: String::new(),
//             pa4_features: String::new(),
//             pa5_mvp: String::new(),
//             pa6_feedback: String::new(),
//             message_post_gpgtoml_required: None,
//             message_post_data_format_specs_integer_ranges_from_to_tuple_array: None,
//             message_post_data_format_specs_int_string_ranges_from_to_tuple_array: None,
//             message_post_max_string_length_int: None,
//             message_post_is_public_bool: None,
//             message_post_user_confirms_bool: None,
//             message_post_start_date_utc_posix: None,
//             message_post_end_date_utc_posix: None,
//         }
//     }

//     #[test]
//     fn test_error_empty_owner() {
//         let state = create_minimal_test_state();
//         let result = add_im_message(
//             Path::new("dummy/message.toml"),
//             "",
//             "Test",
//             None,
//             &state,
//         );
//         assert!(result.is_err());
//     }
// }

#[derive(Debug, Deserialize, Serialize)]
struct NodeInstMsgBrowserMetadata {
    // every .toml has these four
    owner: String, // owner of this item
    teamchannel_collaborators_with_access: Vec<String>,
    updated_at_timestamp: u64, // utc posix timestamp
    expires_at: u64, // utc posix timestamp

    node_name: String,
    path_in_node: String,
    expiration_period_days: u64,
    max_message_size_char: u64,
    total_max_size_mb: u64,
}

impl NodeInstMsgBrowserMetadata {
    fn new(
        node_name: &str,
        owner: String
    ) -> NodeInstMsgBrowserMetadata {
        NodeInstMsgBrowserMetadata {
            node_name: node_name.to_string(),
            path_in_node: "/message_posts_browser".to_string(), // TODO
            expiration_period_days: 30, // Default: 7 days
            max_message_size_char: 4096, // Default: 4096 characters
            total_max_size_mb: 512, // Default: 1024 MB
            updated_at_timestamp: get_current_unix_timestamp(),
            expires_at: get_current_unix_timestamp(),  // TODO update this with real something
            teamchannel_collaborators_with_access: Vec::new(), // by default use state-struct node members
            owner: owner,
        }
    }
}



/*
Note: this might get generalized to fit in with vote an other files
but only if that is best
unless there is a clear reason to included created_at, it should not be included
nothing should be included with empirical data in support
*/
#[derive(Debug, Deserialize, Serialize)]
struct MessagePostFile {
    // every .toml has these four
    owner: String, // owner of this item
    node_name: String, // Name of the node this message belongs to
    filepath_in_node: String, // Relative path within the node's directory
    text_message: String, // content-body

    teamchannel_collaborators_with_access: Vec<String>,
    updated_at_timestamp: u64, // utc posix timestamp
    messagepost_gpgtoml: bool, // Is MessagePostFile file gpg encrypted
    expires_at: u64, // utc posix timestamp

    // links: Vec<String>,  // reference to node etc.
    // signature: Option<String>, // ???
}

impl MessagePostFile {
    fn new(
        graph_navigation_instance_state: &GraphNavigationInstanceState,
        owner: &str, // owner
        node_name: &str, // node_name
        filepath_in_node: &str, //filepath_in_node
        text_message: &str, // text_message
        recipients_list: Vec<String>, // teamchannel_collaborators_with_access
        messagepost_gpgtoml: bool,
        expires_at: Option<u64>,  // NEW: Custom expiration, or None for default
    ) -> MessagePostFile {
        let timestamp = get_current_unix_timestamp();

        // Use custom expiration if provided, otherwise calculate default
        let expires_at_timestamp = expires_at.unwrap_or_else(|| {
            timestamp + (graph_navigation_instance_state.default_im_messages_expiration_days * 24 * 60 * 60)
        });

        MessagePostFile {
            owner: owner.to_string(),
            teamchannel_collaborators_with_access: recipients_list,
            node_name: node_name.to_string(),
            filepath_in_node: filepath_in_node.to_string(),
            text_message: text_message.to_string(),
            updated_at_timestamp: timestamp,
            expires_at: expires_at_timestamp,  // Use calculated or custom value
            messagepost_gpgtoml: messagepost_gpgtoml,
        }
    }
    // fn new(
    //     owner: &str,
    //     node_name: &str, // Add node name as a parameter
    //     filepath_in_node: &str, // Add filepath_in_node as a parameter
    //     text_message: &str,
    //     signature: Option<String>,
    //     graph_navigation_instance_state: &GraphNavigationInstanceState,  // gets uma.toml data
    //     recipients_list: Vec<String>,
    //     messagepost_gpgtoml: bool,
    // ) -> MessagePostFile {
    //     let timestamp = get_current_unix_timestamp();
    //     // Calculate expiration date using the value from local_user_metadata
    //     let expires_at = timestamp +
    //         (graph_navigation_instance_state.default_im_messages_expiration_days * 24 * 60 * 60);
    //     // let teamchannel_collaborators_with_access = graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access.clone();

    //     MessagePostFile {
    //         owner: owner.to_string(),
    //         teamchannel_collaborators_with_access: recipients_list,
    //         node_name: node_name.to_string(), // Store the node name
    //         filepath_in_node: filepath_in_node.to_string(), // Store the filepath
    //         text_message: text_message.to_string(),
    //         updated_at_timestamp: timestamp, // utc posix timestamp
    //         expires_at: expires_at, // utc posix timestamp // TODO!! update this
    //         links: Vec::new(),
    //         signature: signature,
    //         messagepost_gpgtoml: messagepost_gpgtoml,
    //     }
    // }
}

// /// Broken
// /// Creates a new team-channel directory and its associated metadata.
// ///
// /// This function sets up the basic directory structure and files for a new team channel
// /// within the UMA project graph. It creates the necessary subdirectories and initializes
// /// the `node.toml` file with default values.
// ///
// /// # Arguments
// ///
// /// * `team_channel_name` - The name of the team channel to be created. This name will be used
// ///   for the directory name and in the `node.toml` metadata.
// /// * `owner` - The username of the owner of the team channel.
// ///
// /// TODO: where is the port node system setup here?
// fn create_new_team_channel(team_channel_name: String, owner: String) {
//     let team_channels_dir = Path::new("project_graph_data/team_channels");
//     let new_channel_path = team_channels_dir.join(&team_channel_name);

//     // 1. Create the team channel directory and subdirectories
//     if !new_channel_path.exists() {
//         fs::create_dir_all(new_channel_path.join("message_posts_browser"))
//             .expect("Failed to create team channel and subdirectories");

//         // 2. Create 0.toml for message_posts_browser with default metadata
//         let metadata_path = new_channel_path.join("message_posts_browser").join("0.toml");
//         let metadata = NodeInstMsgBrowserMetadata::new(&team_channel_name, owner.clone());
//         save_toml_to_file(&metadata, &metadata_path).expect("Failed to create 0.toml");
//     }
//     //     /*
//     //     fn new(
//     // TODO update this
//     //     ) -> Node {
//     //     */


//     // thread 'main' panicked at src/main.rs:4341:14:
//     // REASON: IoError(Os { code: 2, kind: NotFound, message: "No such file or directory" })
//     //
//     // 3. Create node.toml with initial data for the team channel
//     let new_node = CoreNode::new(
//         team_channel_name.clone(),
//         team_channel_name.clone(),
//         new_channel_path.clone(),
//         // 5,  // depricated
//         // NodePriority::Medium,  // depricated
//         owner,
//         Vec::new(), // Empty collaborators list for a new channel
//         HashMap::new(), // Empty collaborator ports map for a new channel
//     );

//     // new_node.save_node_to_clearsigned_file().expect("Failed to save initial node data");
//     new_node.expect("REASON").save_node_to_clearsigned_file().expect("Failed to save initial node data");

// }


/// Creates a new team-channel directory, subdirectories, and metadata files.
///
/// This function establishes the directory structure and configuration files needed for a new team
/// channel. It creates all necessary directories, assigns ports to the owner, and initializes
/// the channel with default settings. All paths are resolved relative to the executable location
/// rather than the current working directory, ensuring consistent behavior regardless of where
/// the program is executed from.
///
/// # Directory Structure Created
///
/// ```
/// project_graph_data/team_channels/[team_channel_name]/
///  message_posts_browser/
///     0.toml (metadata file)
///  task_browser/
///      1_planning/
///      2_started/
///      3_done/
/// ```
///
/// # Arguments
///
/// * `team_channel_name` - The name of the new team channel.
/// * `owner` - The username of the channel owner.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>` - `Ok(())` on success, or a `ThisProjectError`
///   describing the error.
///
/// # Errors
///
/// This function can fail with a `ThisProjectError` in the following cases:
/// * If creating any directory fails
/// * If saving TOML files fails
/// * If retrieving project area data fails
/// * If creating or saving the CoreNode fails
fn create_new_team_channel(team_channel_name: String, owner: String) -> Result<(), ThisProjectError> {
    /*
    // uses
    use std::collections::HashMap;
    use std::fs;
    use std::path::{Path, PathBuf};
    use rand::Rng;

    // Import the path management module
    use crate::manage_absolute_executable_directory_relative_paths::make_input_path_name_abs_executabledirectoryrelative_nocheck;
    use crate::manage_absolute_executable_directory_relative_paths::prepare_file_parent_directories_abs_executabledirectoryrelative;

    */
    debug_log("Starting CTC create_new_team_channel()");


    let corenode_gpgtoml = match q_and_a_get_corenode_gpgtoml() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA1 Process: {}", e);
            return Err(e);
        }
    };

    // Get the base directory path relative to executable location
    let team_channels_dir_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "project_graph_data/team_channels"
    ) {
        Ok(path) => path,
        Err(e) => {
            debug_log!("CTC: Error creating team_channels_dir path: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    };

    let new_channel_path = team_channels_dir_path.join(&team_channel_name);
    debug_log!("CTC: New channel path: {:?}", new_channel_path);

    // 1. Create Directory Structure (with error handling)
    // Create message_posts_browser directory
    let instant_msg_path = new_channel_path.join("message_posts_browser");
    match fs::create_dir_all(&instant_msg_path) {
        Ok(_) => debug_log!("CTC: Created message_posts_browser directory"),
        Err(e) => {
            debug_log!("CTC: Error creating message_posts_browser directory: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    }

    // Create task_browser directory
    let task_browser_path = new_channel_path.join("task_browser");
    match fs::create_dir_all(&task_browser_path) {
        Ok(_) => debug_log!("CTC: Created task_browser directory"),
        Err(e) => {
            debug_log!("CTC: Error creating task_browser directory: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    }

    // Create task browser columns
    let column_names = ["1_planning", "2_started", "3_done"];
    for col_name in column_names.iter() {
        let col_path = task_browser_path.join(col_name);
        match fs::create_dir_all(&col_path) {
            Ok(_) => debug_log!("CTC: Created task column directory: {}", col_name),
            Err(e) => {
                debug_log!("CTC: Error creating task column directory {}: {}", col_name, e);
                return Err(ThisProjectError::IoError(e));
            }
        }
    }

    // 2. Create and Save 0.toml Metadata (with error handling)
    let metadata_path = instant_msg_path.join("0.toml");
    let metadata = NodeInstMsgBrowserMetadata::new(&team_channel_name, owner.clone());

    match save_toml_to_file(&metadata, &metadata_path) {
        Ok(_) => debug_log!("CTC: Saved metadata to 0.toml"),
        Err(e) => {
            debug_log!("CTC: Error saving metadata: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    }

    // Generate collaborator port assignments

    /*
    full system v1
    */
    debug_log!("CTC: create_new_team_channel(): Starting port assignment generation for owner '{}'", owner);
    debug_log!("CTC: Retrieving project area data...");

    // Generate collaborator port assignments with global collision prevention
    debug_log!("CTC: create_new_team_channel(): Starting port assignment generation for owner '{}'", owner);

    let (collaborators, abstract_collaborator_port_assignments) = match create_teamchannel_port_assignments(&owner) {
        Ok((collab_list, port_assigns)) => {
            debug_log!(
                "CTC: create_new_team_channel(): Successfully generated port assignments for {} collaborators with {} pairs",
                collab_list.len(),
                port_assigns.len()
            );

            // Log details about each pair
            for (pair_name, assignments) in &port_assigns {
                debug_log!("CTC: create_new_team_channel(): Pair '{}':", pair_name);
                for assignment in &assignments[0].collaborator_ports {
                    debug_log!(
                        "  - {}: ready={}, intray={}, gotit={}",
                        assignment.user_name,
                        assignment.ready_port,
                        assignment.intray_port,
                        assignment.gotit_port
                    );
                }
            }

            (collab_list, port_assigns)
        }
        Err(e) => {
            let error_msg = format!(
                "CTC: Failed to create port assignments for team channel: {}",
                e.to_string()
            );
            eprintln!("ERROR: {}", error_msg);
            return Err(ThisProjectError::from(error_msg));
        }
    };

    debug_log!("CTC: create_new_team_channel(): Port assignments complete. Collaborators: {:?}", collaborators);

    // Log the results
    debug_log!("CTC: create_new_team_channel(): Collaborators with access: {:?}", collaborators);
    for (pair_name, assignments) in &abstract_collaborator_port_assignments {
        debug_log!("CTC: create_new_team_channel(): Pair '{}' has {} port assignments",
            pair_name,
            assignments.len()
        );
    }

    // Retrieve project area data
    debug_log!("CTC: Retrieving project area data...");

    let pa1_process = match q_and_a_get_pa1_process() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA1 Process: {}", e);
            return Err(e);
        }
    };

    let pa2_schedule = match q_and_a_get_pa2_schedule() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA2 Schedule: {}", e);
            return Err(e);
        }
    };

    let pa3_users = match q_and_a_get_pa3_users() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA3 Users: {}", e);
            return Err(e);
        }
    };

    let pa4_features = match q_and_a_get_pa4_features() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA4 Features: {}", e);
            return Err(e);
        }
    };

    let pa5_mvp = match q_and_a_get_pa5_mvp() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA5 MVP: {}", e);
            return Err(e);
        }
    };

    let pa6_feedback = match q_and_a_get_pa6_feedback() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA6 Feedback: {}", e);
            return Err(e);
        }
    };

    debug_log!("CTC: All project area data retrieved successfully");

    // 3. Create and Save CoreNode
    debug_log!("CTC: Creating CoreNode...");

    // option to save as .gpgtoml
    let new_node_result = CoreNode::new(
        team_channel_name.clone(),
        corenode_gpgtoml,
        team_channel_name,
        new_channel_path,
        owner,
        collaborators,
        abstract_collaborator_port_assignments,
        // Project Areas
        pa1_process,
        pa2_schedule,
        pa3_users,
        pa4_features,
        pa5_mvp,
        pa6_feedback,
        // Message Post Configuration - all None when no values
        None,  // message_post_gpgtoml_required
        None,  // message_post_data_format_specs_integer_ranges_from_to_tuple_array
        None,  // message_post_data_format_specs_int_string_ranges_from_to_tuple_array
        None,  // message_post_max_string_length_int
        None,  // message_post_is_public_bool
        None,  // message_post_user_confirms_bool
        None,  // message_post_start_date_utc_posix
        None,  // message_post_end_date_utc_posix
    );

    debug_log!("CTC: CoreNode creation complete, saving...");

    // User Q&A: Ask user to choose file format for node
    println!("\n=== Node File Format Selection ===");
    println!("Choose the format for saving the node file:");
    println!();
    println!("1. 'gpgtoml' - GPG encrypted clearsigned file (node.gpgtoml) [DEFAULT - RECOMMENDED]");
    println!("   - Maximum security: encrypted AND signed");
    println!("   - Only you can decrypt with your private key");
    println!("   - Integrity verified through clearsigning");
    println!();
    println!("2. 'clearsign' - Clearsigned only file (node.toml)");
    println!("   - Signed for integrity verification");
    println!("   - Contents readable by anyone");
    println!("   - Suitable for public/shared nodes");
    println!();
    print!("Enter your choice [gpgtoml/clearsign] (press Enter for default 'gpgtoml'): ");

    // Flush stdout to ensure the prompt appears
    std::io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    // Read user input
    let mut user_input = String::new();
    std::io::stdin().read_line(&mut user_input)
        .map_err(|e| {
            debug_log!("Error reading user input: {}", e);
            ThisProjectError::IoError(e)
        })?;

    // Trim and convert to lowercase for case-insensitive comparison
    let choice = user_input.trim().to_lowercase();

    // Determine which save method to use based on user input
    let use_encrypted = match choice.as_str() {
        "" => {
            // Empty input = use default (encrypted)
            println!("Using default: GPG encrypted clearsigned format (node.gpgtoml)");
            true
        },
        "gpgtoml" | "gpg" | "encrypted" | "secure" => {
            println!("Selected: GPG encrypted clearsigned format (node.gpgtoml)");
            true
        },
        "clearsign" | "clear" | "signed" | "toml" => {
            println!("Selected: Clearsigned only format (node.toml)");
            false
        },
        _ => {
            // Invalid input = use default with warning
            println!("Invalid input '{}'. Using default: GPG encrypted clearsigned format (node.gpgtoml)", choice);
            true
        }
    };

    // Handle the CoreNode creation result with chosen save method
    match new_node_result {
        Ok(new_node) => {
            if use_encrypted {
                // Save as GPG encrypted clearsigned file (node.gpgtoml)
                debug_log!("CoreNode created successfully, saving as encrypted file... -> new_node.save_node_as_gpgtoml()");
                match new_node.save_node_as_gpgtoml() {
                    Ok(_) => {
                        debug_log!("save_node_as_gpgtoml: CoreNode saved successfully as node.gpgtoml");
                        println!("\n Node successfully saved as encrypted file: {}/node.gpgtoml",
                                new_node.directory_path.display());
                        Ok(())
                    },
                    Err(e) => {
                        debug_log!("save_node_as_gpgtoml: Error saving CoreNode: {}", e);
                        eprintln!("\n Error saving node as encrypted file: {}", e);
                        Err(ThisProjectError::IoError(e))
                    }
                }
            } else {
                // Save as clearsigned only file (node.toml)
                debug_log!("CoreNode created successfully, saving as clearsigned file... -> new_node.save_node_to_clearsigned_file()");
                match new_node.save_node_to_clearsigned_file() {
                    Ok(_) => {
                        debug_log!("save_node_to_clearsigned_file: CoreNode saved successfully as node.toml");
                        println!("\n Node successfully saved as clearsigned file: {}/node.toml",
                                new_node.directory_path.display());
                        Ok(())
                    },
                    Err(e) => {
                        debug_log!("save_node_to_clearsigned_file: Error saving CoreNode: {}", e);
                        eprintln!("\n Error saving node as clearsigned file: {}", e);
                        Err(ThisProjectError::IoError(e))
                    }
                }
            }
        },
        Err(e) => {
            debug_log!("Error creating CoreNode: {}", e);
            eprintln!("\n Error creating CoreNode: {}", e);
            Err(e)
        }
    }
}

/// Updates an existing CoreNode by walking the user through optional field updates.
///
/// This function loads an existing CoreNode from disk, presents the current values of
/// updatable fields to the user, and allows them to optionally update each field through
/// a Q&A process. The user can choose to keep existing values (default) or enter new ones.
/// After all updates are collected, the modified node is saved back to disk.
///
/// # Updatable Fields
///
/// The following fields can be updated:
/// - **Team channel collaborators list** (primary update field)
/// - **Port assignments** (regenerated if collaborators change)
/// - **Project Areas**: pa1_process, pa2_schedule, pa3_users, pa4_features, pa5_mvp, pa6_feedback
/// - **Message Post Configuration**: All Option fields for message post settings
///
/// # Preserved Fields
///
/// The following fields are NOT modified:
/// - Core identity fields (owner, node_name, node_unique_id, directory_path)
/// - Directory structure (no filesystem changes except the node TOML file)
///
/// # Arguments
///
/// * `node_path` - The absolute path to the CoreNode TOML file to update
///
/// # Returns
///
/// * `Result<(), ThisProjectError>` - `Ok(())` on successful update and save,
///   or a `ThisProjectError` describing what went wrong
///
/// # Errors
///
/// This function can fail with a `ThisProjectError` in the following cases:
/// * If the node file cannot be loaded from the specified path
/// * If the node file cannot be parsed as a valid CoreNode
/// * If saving the updated node back to disk fails
/// * If user input cannot be read during Q&A
/// * If port assignment generation fails when collaborators are updated
///
/// # Example
///
/// ```
/// let node_path = PathBuf::from("/absolute/path/to/node.toml");
/// match update_core_node(node_path) {
///     Ok(()) => println!("Node updated successfully"),
///     Err(e) => eprintln!("Failed to update node: {}", e),
/// }
/// ```
fn update_core_node(
    node_path: PathBuf,
) -> Result<(), ThisProjectError> {
    // Log function entry
    debug_log!("UCN: Starting update_core_node for path: {:?}", node_path);

    // Step 1: Load the existing CoreNode from disk
    // Uses load_core_node_from_toml_file to read and parse the node.toml file
    let mut existing_node = match load_core_node_from_toml_file(&node_path) {
        Ok(node) => {
            debug_log!("UCN: Successfully loaded CoreNode from {:?}", node_path);
            node
        }
        Err(e) => {
            debug_log!("UCN: Failed to load CoreNode from {:?}: {}", node_path, e);
            // Map the error to ThisProjectError::InvalidData as per the error handling pattern
            return Err(ThisProjectError::InvalidData(e));
        }
    };

    println!("\n=== CoreNode Update Wizard ===");
    println!("Node: {}", existing_node.node_name);
    println!("Description: {}", existing_node.description_for_tui);
    println!("Owner: {}", existing_node.owner);
    println!("\nYou will be prompted to update various fields.");
    println!("Press Enter to keep existing values, or type new values when prompted.\n");

    // Step 2: Update Team Channel Collaborators (main field)
    println!("\n--- TEAM CHANNEL COLLABORATORS UPDATE ---");
    println!("Current collaborators with access: {:?}", existing_node.teamchannel_collaborators_with_access);
    print!("Do you want to update the collaborators list? [y/N]: ");

    // Flush stdout to ensure prompt appears
    use std::io::{self, Write};
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut input = String::new();
    io::stdin().read_line(&mut input).map_err(|e| ThisProjectError::IoError(e))?;

    let update_collaborators = input.trim().to_lowercase() == "y";
    let mut collaborators_changed = false;

    if update_collaborators {
        // Get new collaborators list
        println!("Enter new collaborators (comma-separated usernames):");
        println!("Note: The owner '{}' will be automatically included.", existing_node.owner);
        print!("> ");
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut collab_input = String::new();
        io::stdin().read_line(&mut collab_input).map_err(|e| ThisProjectError::IoError(e))?;

        // Parse collaborators, ensuring owner is included
        let mut new_collaborators: Vec<String> = collab_input
            .trim()
            .split(',')
            .map(|s| s.trim().to_string())
            .filter(|s| !s.is_empty())
            .collect();

        // Ensure owner is in the list
        if !new_collaborators.contains(&existing_node.owner) {
            new_collaborators.insert(0, existing_node.owner.clone());
        }

        // Check if collaborators actually changed
        collaborators_changed = new_collaborators != existing_node.teamchannel_collaborators_with_access;

        if collaborators_changed {
            existing_node.teamchannel_collaborators_with_access = new_collaborators;
            debug_log!("UCN: Team channel collaborators updated to: {:?}", existing_node.teamchannel_collaborators_with_access);

            // Step 3: Regenerate port assignments if collaborators changed
            println!("\nRegenerating port assignments for updated collaborators...");

            let (updated_collaborators, new_port_assignments) =
                match create_teamchannel_port_assignments(&existing_node.owner) {
                    Ok((collab_list, port_assigns)) => {
                        debug_log!(
                            "UCN: Successfully regenerated port assignments for {} collaborators",
                            collab_list.len()
                        );
                        (collab_list, port_assigns)
                    }
                    Err(e) => {
                        let error_msg = format!(
                            "UCN: Failed to regenerate port assignments: {}",
                            e.to_string()
                        );
                        eprintln!("ERROR: {}", error_msg);
                        return Err(ThisProjectError::from(error_msg));
                    }
                };

            // Update the node with new port assignments
            existing_node.teamchannel_collaborators_with_access = updated_collaborators;
            existing_node.abstract_collaborator_port_assignments = new_port_assignments;
            println!("Port assignments regenerated successfully.");
        } else {
            println!("Collaborators unchanged.");
        }
    }

    // Step 4: Optionally update port assignments (if collaborators didn't change)
    if !collaborators_changed {
        println!("\n--- PORT ASSIGNMENTS UPDATE ---");
        print!("Do you want to regenerate port assignments? [y/N]: ");
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut port_input = String::new();
        io::stdin().read_line(&mut port_input).map_err(|e| ThisProjectError::IoError(e))?;

        if port_input.trim().to_lowercase() == "y" {
            println!("Regenerating port assignments...");

            let (_, new_port_assignments) =
                match create_teamchannel_port_assignments(&existing_node.owner) {
                    Ok((collab_list, port_assigns)) => {
                        debug_log!("UCN: Port assignments regenerated");
                        (collab_list, port_assigns)
                    }
                    Err(e) => {
                        let error_msg = format!(
                            "UCN: Failed to regenerate port assignments: {}",
                            e.to_string()
                        );
                        eprintln!("ERROR: {}", error_msg);
                        return Err(ThisProjectError::from(error_msg));
                    }
                };

            existing_node.abstract_collaborator_port_assignments = new_port_assignments;
            println!("Port assignments regenerated successfully.");
        }
    }

    // Step 5: Update Project Areas
    println!("\n--- PROJECT AREAS UPDATE ---");

    // PA1 Process
    println!("\nPA1 Process (current value: {})", existing_node.pa1_process);
    print!("Update PA1 Process? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa1_input = String::new();
    io::stdin().read_line(&mut pa1_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa1_input.trim().to_lowercase() == "y" {
        existing_node.pa1_process = match q_and_a_get_pa1_process() {
            Ok(data) => {
                debug_log!("UCN: PA1 Process updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA1 Process: {}", e);
                return Err(e);
            }
        };
    }

    // PA2 Schedule (Vec<u64> - needs Debug formatting)
    println!("\nPA2 Schedule (current value: {:?})", existing_node.pa2_schedule);
    print!("Update PA2 Schedule? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa2_input = String::new();
    io::stdin().read_line(&mut pa2_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa2_input.trim().to_lowercase() == "y" {
        existing_node.pa2_schedule = match q_and_a_get_pa2_schedule() {
            Ok(data) => {
                debug_log!("UCN: PA2 Schedule updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA2 Schedule: {}", e);
                return Err(e);
            }
        };
    }

    // PA3 Users
    println!("\nPA3 Users (current value: {})", existing_node.pa3_users);
    print!("Update PA3 Users? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa3_input = String::new();
    io::stdin().read_line(&mut pa3_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa3_input.trim().to_lowercase() == "y" {
        existing_node.pa3_users = match q_and_a_get_pa3_users() {
            Ok(data) => {
                debug_log!("UCN: PA3 Users updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA3 Users: {}", e);
                return Err(e);
            }
        };
    }

    // PA4 Features
    println!("\nPA4 Features (current value: {})", existing_node.pa4_features);
    print!("Update PA4 Features? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa4_input = String::new();
    io::stdin().read_line(&mut pa4_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa4_input.trim().to_lowercase() == "y" {
        existing_node.pa4_features = match q_and_a_get_pa4_features() {
            Ok(data) => {
                debug_log!("UCN: PA4 Features updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA4 Features: {}", e);
                return Err(e);
            }
        };
    }

    // PA5 MVP
    println!("\nPA5 MVP (current value: {})", existing_node.pa5_mvp);
    print!("Update PA5 MVP? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa5_input = String::new();
    io::stdin().read_line(&mut pa5_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa5_input.trim().to_lowercase() == "y" {
        existing_node.pa5_mvp = match q_and_a_get_pa5_mvp() {
            Ok(data) => {
                debug_log!("UCN: PA5 MVP updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA5 MVP: {}", e);
                return Err(e);
            }
        };
    }

    // PA6 Feedback
    println!("\nPA6 Feedback (current value: {})", existing_node.pa6_feedback);
    print!("Update PA6 Feedback? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa6_input = String::new();
    io::stdin().read_line(&mut pa6_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa6_input.trim().to_lowercase() == "y" {
        existing_node.pa6_feedback = match q_and_a_get_pa6_feedback() {
            Ok(data) => {
                debug_log!("UCN: PA6 Feedback updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA6 Feedback: {}", e);
                return Err(e);
            }
        };
    }

    // Step 6: Update Message Post Configuration (Optional fields)
    println!("\n--- MESSAGE POST CONFIGURATION UPDATE ---");
    print!("Update message post configuration fields? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut msg_config_input = String::new();
    io::stdin().read_line(&mut msg_config_input).map_err(|e| ThisProjectError::IoError(e))?;

    if msg_config_input.trim().to_lowercase() == "y" {
        // Helper function to update optional fields
        // For now, we'll provide simple text input for these fields
        // In a real implementation, you might want more sophisticated Q&A functions

        println!("\nNote: Press Enter to keep existing value, or enter new value.");

        // Max string length
        print!("Max string length (current: {:?}): ", existing_node.message_post_max_string_length_int);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut max_len_input = String::new();
        io::stdin().read_line(&mut max_len_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !max_len_input.trim().is_empty() {
            match max_len_input.trim().parse::<usize>() {
                Ok(val) => {
                    existing_node.message_post_max_string_length_int = Some(val);
                    debug_log!("UCN: Max string length updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid number, keeping existing value.");
                }
            }
        }

        // Is public boolean
        print!("Is public? (true/false, current: {:?}): ", existing_node.message_post_is_public_bool);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut is_public_input = String::new();
        io::stdin().read_line(&mut is_public_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !is_public_input.trim().is_empty() {
            match is_public_input.trim().parse::<bool>() {
                Ok(val) => {
                    existing_node.message_post_is_public_bool = Some(val);
                    debug_log!("UCN: Is public updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid boolean, keeping existing value.");
                }
            }
        }

        // User confirms boolean
        print!("User confirms? (true/false, current: {:?}): ", existing_node.message_post_user_confirms_bool);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut user_confirms_input = String::new();
        io::stdin().read_line(&mut user_confirms_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !user_confirms_input.trim().is_empty() {
            match user_confirms_input.trim().parse::<bool>() {
                Ok(val) => {
                    existing_node.message_post_user_confirms_bool = Some(val);
                    debug_log!("UCN: User confirms updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid boolean, keeping existing value.");
                }
            }
        }

        // Start date (POSIX timestamp)
        print!("Start date (POSIX timestamp, current: {:?}): ", existing_node.message_post_start_date_utc_posix);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut start_date_input = String::new();
        io::stdin().read_line(&mut start_date_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !start_date_input.trim().is_empty() {
            match start_date_input.trim().parse::<i64>() {
                Ok(val) => {
                    existing_node.message_post_start_date_utc_posix = Some(val);
                    debug_log!("UCN: Start date updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid timestamp, keeping existing value.");
                }
            }
        }

        // End date (POSIX timestamp)
        print!("End date (POSIX timestamp, current: {:?}): ", existing_node.message_post_end_date_utc_posix);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut end_date_input = String::new();
        io::stdin().read_line(&mut end_date_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !end_date_input.trim().is_empty() {
            match end_date_input.trim().parse::<i64>() {
                Ok(val) => {
                    existing_node.message_post_end_date_utc_posix = Some(val);
                    debug_log!("UCN: End date updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid timestamp, keeping existing value.");
                }
            }
        }

        // Note: The integer ranges and string ranges fields would need more complex parsing
        // For now, leaving them as-is unless you have specific Q&A functions for them
        println!("\nNote: Integer ranges and string ranges configuration not updated in this version.");
    }

    // Update the timestamp to reflect the modification
    use std::time::{SystemTime, UNIX_EPOCH};
    existing_node.updated_at_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| ThisProjectError::from(format!("System time error: {}", e)))?
        .as_secs();

    // Step 7: Save the updated node back to disk
    println!("\n--- SAVING UPDATES ---");
    println!("Saving updated CoreNode to {:?}...", node_path);

    match existing_node.save_node_to_clearsigned_file() {
        Ok(_) => {
            debug_log!("UCN: CoreNode successfully saved to {:?}", node_path);
            println!("CoreNode updated and saved successfully!");
            Ok(())
        }
        Err(e) => {
            debug_log!("UCN: Failed to save CoreNode: {}", e);
            eprintln!("ERROR: Failed to save updated node: {}", e);
            Err(ThisProjectError::IoError(e))
        }
    }
}

/// Creates a new (core)Node directory, subdirectories, and metadata files.
/// Handles errors and returns a Result to indicate success or failure.
///
/// # Arguments
///
/// * `path_to_node` - Base path where the node will be created
/// * `teamchannel_collaborators_with_access` - List of collaborators
/// * `team_channel_name` - Name of the team channel
///
/// # Returns
///
/// * `Result<(), ThisProjectError>` - `Ok(())` on success, or a `ThisProjectError`
fn create_core_node(
    node_path: PathBuf,
    teamchannel_collaborators_with_access: Vec<String>,
) -> Result<(), ThisProjectError> {
    debug_log!("start create_core_node(), node_path -> {:?}", node_path);

    // Get user input for node name
    println!("Enter node name:");
    let mut node_name = String::new();
    io::stdin().read_line(&mut node_name)?;
    let node_name = node_name.trim().to_string();

    let corenode_gpgtoml = match q_and_a_get_corenode_gpgtoml() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA1 Process: {}", e);
            return Err(e);
        }
    };

    // Get user input for description
    println!("Enter project description:");
    let mut description = String::new();
    io::stdin().read_line(&mut description)?;
    let description = description.trim().to_string();

    // Create the specific node directory path
    let node_specific_path = node_path.join(&node_name);
    debug_log!("Creating node at specific path: {:?}", node_specific_path);

    // Create the main node directory
    fs::create_dir_all(&node_specific_path)?;

    // local owner user name
    let owner = get_local_owner_username();

    // Get user input for planning fields
    // Project Areas
    let pa1_process = q_and_a_get_pa1_process()?;
    let pa2_schedule = q_and_a_get_pa2_schedule()?;
    let pa3_users = q_and_a_get_pa3_users()?;
    let pa4_features = q_and_a_get_pa4_features()?;
    let pa5_mvp = q_and_a_get_pa5_mvp()?;
    let pa6_feedback = q_and_a_get_pa6_feedback()?;

    // Get user input for message post configuration fields

    let message_post_gpgtoml_required = q_and_a_get_message_post_gpgtoml_required()?;
    print!("\n");
    let message_post_integer_ranges = q_and_a_get_message_post_integer_ranges()?;
    print!("\n");
    let message_post_int_string_ranges = q_and_a_get_message_post_int_string_ranges()?;
    print!("\n");
    let message_post_max_string_length = q_and_a_get_message_post_max_string_length()?;
    print!("\n");
    let message_post_is_public = q_and_a_get_message_post_is_public()?;
    print!("\n");
    let message_post_user_confirms = q_and_a_get_message_post_user_confirms()?;
    print!("\n");
    let message_post_start_date = q_and_a_get_message_post_start_date()?;
    print!("\n");
    let message_post_end_date = q_and_a_get_message_post_end_date(message_post_start_date)?;

    // Create subdirectories within the node directory
    let message_dir = node_specific_path.join("message_posts_browser");
    let task_browser_dir = node_specific_path.join("task_browser");

    fs::create_dir_all(&message_dir)?;
    fs::create_dir_all(&task_browser_dir)?;

    // Create task browser columns
    for col_name in ["1_planning", "2_started", "3_done"].iter() {
        let col_path = task_browser_dir.join(col_name);
        fs::create_dir_all(&col_path)?;
        // TODO: Create column nodes (recursive call for later)
        // create_core_node(col_path, teamchannel_collaborators_with_access.clone(), format!("{}_{}", node_name, col_name))?;
        // TODO maybe custom shallow node with no tasks option needed...
    }

    // Create and Save metadata
    let metadata_path = message_dir.join("0.toml");
    let metadata = NodeInstMsgBrowserMetadata::new(&node_name, owner.clone());
    save_toml_to_file(&metadata, &metadata_path)?;

    // Create CoreNode instance
    let new_node_result = CoreNode::new(
        node_name.clone(),                 // node_name
        corenode_gpgtoml,
        description,                       // description_for_tui
        node_specific_path.clone(),        // directory_path
        owner,                             // owner
        teamchannel_collaborators_with_access,
        HashMap::new(),                    // for ports

        // Project Areas TODO TODO
        pa1_process,
        pa2_schedule,
        pa3_users,
        pa4_features,
        pa5_mvp,
        pa6_feedback,

        // Message Post Configuration
        message_post_gpgtoml_required,
        message_post_integer_ranges,
        message_post_int_string_ranges,
        message_post_max_string_length,
        message_post_is_public,
        message_post_user_confirms,
        message_post_start_date,
        message_post_end_date,
    );

    match new_node_result {
        Ok(new_node) => {
            // Save node.toml in the specific node directory
            new_node.save_node_to_clearsigned_file()?;
            debug_log!("Successfully created node: {:?}", node_specific_path);
            Ok(())
        }
        Err(e) => {
            debug_log!("Error creating CoreNode: {}", e);
            Err(e)
        }
    }
}

/// for passive view mode
fn run_passive_task_mode(path: &Path) -> io::Result<()> {
    debug_log("Starting passive task mode...");

    // 1. Read refresh rate from uma.toml (similar to log mode)
    // let refresh_rate = get_refresh_rate()?;
    let refresh_rate: f32 = 10.0;

    // 2. Initialize last known state
    let mut last_directory_state = get_directory_hash(path)?;

    // 3. Initial display
    tiny_tui::passive_display_tasks(path)?;

    // 4. Enter refresh loop
    loop {
        let current_directory_state = get_directory_hash(path)?;

        if current_directory_state != last_directory_state {
            print!("\x1B[2J\x1B[1;1H"); // Clear screen
            tiny_tui::passive_display_tasks(path)?;
            last_directory_state = current_directory_state;
        }

        thread::sleep(Duration::from_secs_f32(refresh_rate));
    }
}


/// for passive view mode
/// Passive Message View Mode Implementation
///
/// This function implements the core loop for the passive message viewer terminal,
/// which runs as a separate process from the main Uma application.
///
/// # System Architecture:
/// 1. Main Uma Application:
///    - User enters "m" command
///    - Launches new terminal with --passive_message_mode flag
///    - Continues with normal operation
///
/// 2. Passive View Process (this function):
///    - Runs in separate terminal
///    - Monitors message directory
///    - Updates display when changes detected
///
/// # Command Line Launch:
/// Launched via: uma --passive_message_mode [path_to_message_dir]
/// Example: uma --passive_message_mode /home/user/team1/channel1/message_posts_browser
///
/// # Operational Flow:
/// 1. Directory Monitoring:
///    - Calculates hash of directory state
///    - Detects changes by comparing hashes
///    - Refresh rate set by uma.toml (default: 5.0 seconds)
///
/// 2. Display Updates:
///    - Clears screen when changes detected
///    - Reads all message files
///    - Formats and displays messages
///    - Maintains chronological order
///
/// # Directory Structure Expected:
/// ```text
/// message_posts_browser/
///  0.toml (metadata)
///  1__user1.toml (message)
///  2__user2.toml (message)
///  3__user1.toml (message)
/// ```
///
/// # Message File Format:
/// TOML files containing:
/// - owner: String (username)
/// - text_message: String (content)
/// - timestamp: Optional<DateTime>
///
/// # Error Handling:
/// - Returns io::Error for file system issues
/// - Continues running on non-fatal errors
/// - Logs errors for debugging
///
/// # Display Format:
/// ```text
/// Channel: team1/channel1
///
/// 1. user1: message content
/// 2. user2: another message
/// 3. user1: third message
/// ```
///
/// # Important Notes:
/// - View-only mode (no message creation/editing)
/// - Independent process (no connection to main Uma)
/// - Must be manually closed (Ctrl+C)
/// - Does not maintain state between refreshes
/// - All data read fresh from files each update
///
/// # Related Components:
/// - get_directory_hash(): Generates state hash
/// - passive_display_messages(): Renders message list
/// - Main Uma's message mode launcher
/// - Message file TOML structure
///
/// # Configuration:
/// - Refresh rate from uma.toml
/// - Default refresh: 5.0 seconds
/// - Directory path from command line
///
/// # Dependencies:
/// - std::path for path handling
/// - std::fs for file operations
/// - std::thread for sleep
/// - std::io for error handling
/// - toml for message file parsing
///
/// This implementation prioritizes:
/// - Reliability over performance
/// - Simple direct file reading over caching
/// - Clear display over complex features
/// - Independence from main Uma process
fn run_passive_message_mode(path: &Path) -> io::Result<()> {
    debug_log("Starting passive message mode...");

    // 1. Read refresh rate from uma.toml (similar to log mode)
    // let refresh_rate = get_refresh_rate()?;
    let refresh_rate: f32 = 5.0;

    // 2. Initialize last known state
    let mut last_directory_state = get_directory_hash(path)?;

    // 3. Initial display
    tiny_tui::passive_display_messages(path)?;

    // 4. Enter refresh loop
    loop {
        let current_directory_state = get_directory_hash(path)?;

        if current_directory_state != last_directory_state {
            print!("\x1B[2J\x1B[1;1H"); // Clear screen
            tiny_tui::passive_display_messages(path)?;
            last_directory_state = current_directory_state;
        }

        thread::sleep(Duration::from_secs_f32(refresh_rate));
    }
}





/// for passive view mode
fn get_directory_hash(path: &Path) -> io::Result<u64> {
    let mut hasher = DefaultHasher::new();

    for entry in WalkDir::new(path).max_depth(1) {
        let entry = entry?;
        if entry.path().is_file() {
            let metadata = entry.metadata()?;
            metadata.modified()?.hash(&mut hasher);
            metadata.len().hash(&mut hasher);
        }
    }

    Ok(hasher.finish())
}

/*
Q&A Functions for 6pa, 6 Project Areas
*/

/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa1_process() -> Result<String, ThisProjectError> {
    println!("Enter Process statement: Project Process: Workflow Type, STEM Integration, Values, Agenda, Methods, Coordinated Decisions, (Data/System)Ecology: Collapse & Productivity (default option: Agile, Kahneman-Tversky, Definition-Studies)
:");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Agile, Kahneman-Tversky, Definition-Studies".to_string();
    }


    Ok(input.to_string())
}

/// Gets schedule information and converts to required format for create_core_node()
///
/// This function provides two options for setting the project start time:
/// - Use current UTC time ("now")
/// - Enter a custom date
///
/// After determining the start time, it prompts for project duration and calculates
/// the end timestamp.
///
/// The function will re-prompt for any invalid inputs rather than failing immediately,
/// providing a better user experience.
///
/// # Returns
/// * `Ok(Vec<u64>)` - Vector containing [start_timestamp, end_timestamp, duration_seconds]
/// * `Err(ThisProjectError)` - If input/output operations fail
///
/// # Example Flow
/// ```text
/// Would you like to use current UTC time as your project's start time? (y/n): y
/// Current UTC time selected: 2024-01-15 14:30:45
///
/// Project Schedule: Enter project duration in days: 14
///
/// Project Schedule Summary:
///   Start: 2024-01-15 14:30:45 UTC
///   End: 2024-01-29 14:30:45 UTC
///   Duration: 14 days (1209600 seconds)
/// ```
fn q_and_a_get_pa2_schedule() -> Result<Vec<u64>, ThisProjectError> {
    debug_log("starting q_and_a_get_pa2_schedule()");

    // Get current year for validation once at the start
    let current_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| {
            ThisProjectError::InvalidData(format!("System time error: {}", e))
        })?
        .as_secs() as i64;
    let (current_year, _, _, _, _, _) = timestamp_to_utc_components(current_timestamp);

    // Ask if user wants to use current time as start with retry loop
    let use_now = loop {
        println!("\n'Now'? -> Use current UTC time as project's start time? (y)es / (n)o");
        print!("> ");

        // Ensure prompt is displayed before reading input
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut use_now_input = String::new();
        io::stdin().read_line(&mut use_now_input).map_err(|e| ThisProjectError::IoError(e))?;

        match use_now_input.trim().to_lowercase().as_str() {
            "y" | "yes" | "now" => break true,
            "n" | "no" => break false,
            "" => {
                // Treat empty input as "no" for convenience
                println!("  (Treating empty input as 'no')");
                break false;
            },
            _ => {
                // Invalid input - inform user and loop to retry
                println!("  Invalid input '{}'. Please enter 'y' for yes or 'n' for no.",
                    use_now_input.trim());
                continue;
            }
        }
    };

    // Get start timestamp based on user choice
    let start_timestamp: u64 = if use_now {
        // Use current UTC time
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map_err(|e| {
                ThisProjectError::InvalidData(format!("System time error: {}", e))
            })?;

        let timestamp = now.as_secs();

        // Display the current time for confirmation
        let (year, month, day, hour, minute, second) = timestamp_to_utc_components(timestamp as i64);
        println!("\nCurrent UTC time selected: {:04}-{:02}-{:02} {:02}:{:02}:{:02}",
            year, month, day, hour, minute, second);

        debug_log!("Using current UTC timestamp: {}", timestamp);
        timestamp
    } else {
        // Get custom start date from user
        println!("\nEnter project start date:");

        // Year input with retry loop
        let year: i32 = loop {
            println!("Enter start year (YYYY, {} to 2100):", current_year);
            print!("> ");
            io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

            let mut year_input = String::new();
            io::stdin().read_line(&mut year_input).map_err(|e| ThisProjectError::IoError(e))?;

            // Handle empty input
            if year_input.trim().is_empty() {
                println!("  Year cannot be empty. Please enter a valid year.");
                continue;
            }

            // Try to parse the year
            match year_input.trim().parse::<i32>() {
                Ok(parsed_year) => {
                    // Validate year range
                    if parsed_year < current_year || parsed_year > 2100 {
                        println!("  Year must be between {} and 2100. You entered: {}",
                            current_year, parsed_year);
                        continue;
                    }
                    debug_log!("Parsed year: {}", parsed_year);
                    break parsed_year;
                },
                Err(_) => {
                    println!("  Invalid year format '{}'. Please enter a 4-digit year.",
                        year_input.trim());
                    continue;
                }
            }
        };

        // Month input with retry loop
        let month: u32 = loop {
            println!("Enter start month (1-12):");
            print!("> ");
            io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

            let mut month_input = String::new();
            io::stdin().read_line(&mut month_input).map_err(|e| ThisProjectError::IoError(e))?;

            // Handle empty input
            if month_input.trim().is_empty() {
                println!("  Month cannot be empty. Please enter a value between 1 and 12.");
                continue;
            }

            // Try to parse the month
            match month_input.trim().parse::<u32>() {
                Ok(parsed_month) => {
                    // Validate month range
                    if parsed_month < 1 || parsed_month > 12 {
                        println!("  Month must be between 1 and 12. You entered: {}", parsed_month);
                        continue;
                    }
                    debug_log!("Parsed month: {}", parsed_month);
                    break parsed_month;
                },
                Err(_) => {
                    println!("  Invalid month format '{}'. Please enter a number between 1 and 12.",
                        month_input.trim());
                    continue;
                }
            }
        };

        // Day input with retry loop
        let max_day = get_days_in_month(year, month);
        let day: u32 = loop {
            println!("Enter start day (1-{}):", max_day);
            print!("> ");
            io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

            let mut day_input = String::new();
            io::stdin().read_line(&mut day_input).map_err(|e| ThisProjectError::IoError(e))?;

            // Handle empty input
            if day_input.trim().is_empty() {
                println!("  Day cannot be empty. Please enter a value between 1 and {}.", max_day);
                continue;
            }

            // Try to parse the day
            match day_input.trim().parse::<u32>() {
                Ok(parsed_day) => {
                    // Validate day range
                    if parsed_day < 1 || parsed_day > max_day {
                        println!("  Day must be between 1 and {} for {}/{}. You entered: {}",
                            max_day, year, month, parsed_day);
                        continue;
                    }
                    debug_log!("Parsed day: {}", parsed_day);
                    break parsed_day;
                },
                Err(_) => {
                    println!("  Invalid day format '{}'. Please enter a number between 1 and {}.",
                        day_input.trim(), max_day);
                    continue;
                }
            }
        };

        // Optional time input with retry loop
        let (hour, minute) = loop {
            println!("\nYou've entered the date: {}-{:02}-{:02}", year, month, day);
            println!("Would you like to specify a specific time of day?");
            println!("  - Enter 'y' to set hour and minute");
            println!("  - Enter 'n' or press Enter to use midnight (00:00:00)");
            print!("> ");
            io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

            let mut time_choice = String::new();
            io::stdin().read_line(&mut time_choice).map_err(|e| ThisProjectError::IoError(e))?;

            match time_choice.trim().to_lowercase().as_str() {
                "y" | "yes" => {
                    println!("\nSetting time of day for {}-{:02}-{:02}:", year, month, day);

                    // Get hour with retry loop
                    let hour: u32 = loop {
                        println!("Enter hour (0-23, 24-hour format):");
                        println!("  Examples: 0 = midnight, 12 = noon, 23 = 11 PM");
                        print!("> ");
                        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

                        let mut hour_input = String::new();
                        io::stdin().read_line(&mut hour_input).map_err(|e| ThisProjectError::IoError(e))?;

                        // Handle empty input
                        if hour_input.trim().is_empty() {
                            println!("  Hour cannot be empty. Please enter a value between 0 and 23.");
                            continue;
                        }

                        // Try to parse the hour
                        match hour_input.trim().parse::<u32>() {
                            Ok(parsed_hour) => {
                                if parsed_hour > 23 {
                                    println!("  Hour must be between 0 and 23. You entered: {}", parsed_hour);
                                    continue;
                                }
                                break parsed_hour;
                            },
                            Err(_) => {
                                println!("  Invalid hour format '{}'. Please enter a number between 0 and 23.",
                                    hour_input.trim());
                                continue;
                            }
                        }
                    };

                    // Get minute with retry loop
                    let minute: u32 = loop {
                        println!("Enter minute (0-59):");
                        print!("> ");
                        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

                        let mut minute_input = String::new();
                        io::stdin().read_line(&mut minute_input).map_err(|e| ThisProjectError::IoError(e))?;

                        // Handle empty input
                        if minute_input.trim().is_empty() {
                            println!("  Minute cannot be empty. Please enter a value between 0 and 59.");
                            continue;
                        }

                        // Try to parse the minute
                        match minute_input.trim().parse::<u32>() {
                            Ok(parsed_minute) => {
                                if parsed_minute > 59 {
                                    println!("  Minute must be between 0 and 59. You entered: {}", parsed_minute);
                                    continue;
                                }
                                break parsed_minute;
                            },
                            Err(_) => {
                                println!("  Invalid minute format '{}'. Please enter a number between 0 and 59.",
                                    minute_input.trim());
                                continue;
                            }
                        }
                    };

                    println!("  Time set to {:02}:{:02} (24-hour format)", hour, minute);
                    break (hour, minute);
                },
                "n" | "no" | "" => {
                    // Use default midnight time
                    println!("  Using default time: 00:00 (midnight)");
                    break (0, 0);
                },
                _ => {
                    println!("  Invalid choice '{}'. Please enter 'y' for yes or 'n' for no.",
                        time_choice.trim());
                    continue;
                }
            }
        };

        // Use the accurate timestamp conversion function
        let timestamp = utc_components_to_timestamp(year, month, day, hour, minute, 0)?;

        // Confirm the selected start time with full clarity
        println!("\nProject start date and time confirmed:");
        println!("  Date: {:04}-{:02}-{:02} (YYYY-MM-DD)", year, month, day);
        println!("  Time: {:02}:{:02}:00 UTC (HH:MM:SS)", hour, minute);
        println!("  Full: {:04}-{:02}-{:02} {:02}:{:02}:00 UTC", year, month, day, hour, minute);

        // Confirm the selected start time
        println!("\nProject start time: {:04}-{:02}-{:02} {:02}:{:02}:00 UTC",
            year, month, day, hour, minute);

        debug_log!("Calculated start timestamp: {}", timestamp);
        timestamp as u64
    };

    // Duration input with retry loop
    let days: u64 = loop {
        println!("\nProject Schedule: Enter project duration in days (1-3650):");
        print!("> ");
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut days_input = String::new();
        io::stdin().read_line(&mut days_input).map_err(|e| ThisProjectError::IoError(e))?;

        // Handle empty input
        if days_input.trim().is_empty() {
            println!("  Duration cannot be empty. Please enter a number between 1 and 3650.");
            continue;
        }

        // Try to parse the days
        match days_input.trim().parse::<u64>() {
            Ok(parsed_days) => {
                // Validate days range
                if parsed_days == 0 || parsed_days > 3650 {
                    println!("  Duration must be between 1 and 3650 days. You entered: {}", parsed_days);
                    continue;
                }
                debug_log!("Parsed days: {}", parsed_days);
                break parsed_days;
            },
            Err(_) => {
                println!("  Invalid duration format '{}'. Please enter a number between 1 and 3650.",
                    days_input.trim());
                continue;
            }
        }
    };

    // Calculate end timestamp and duration
    let seconds_per_day: u64 = 24 * 60 * 60;
    let duration_seconds = days * seconds_per_day;
    debug_log!("Calculated duration in seconds: {}", duration_seconds);

    let end_timestamp = start_timestamp + duration_seconds;
    debug_log!("Calculated end timestamp: {}", end_timestamp);

    // Display summary
    let (start_year, start_month, start_day, start_hour, start_minute, start_second) =
        timestamp_to_utc_components(start_timestamp as i64);
    let (end_year, end_month, end_day, end_hour, end_minute, end_second) =
        timestamp_to_utc_components(end_timestamp as i64);

    println!("\nProject Schedule Summary:");
    println!("  Start: {:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC",
        start_year, start_month, start_day, start_hour, start_minute, start_second);
    println!("  End:   {:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC",
        end_year, end_month, end_day, end_hour, end_minute, end_second);
    println!("  Duration: {} days ({} seconds)", days, duration_seconds);

    // Final validation (should never fail with proper input validation)
    if end_timestamp < start_timestamp {
        return Err(ThisProjectError::InvalidInput("End time cannot be before start time".into()));
    }

    let result = vec![
        start_timestamp,
        end_timestamp,
        duration_seconds
    ];
    debug_log!("Returning schedule info: {:?}", result);

    Ok(result)
}


/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa3_users() -> Result<String, ThisProjectError> {
    println!("Enter User Statement, Users: Stakeholders & Needs & Goals Evaluation (of users): Who are users? What are their needs?");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Pending: Users & Stakeholder Needs & Goals Evaluation".to_string();
    }

    Ok(input.to_string())
}

/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa4_features() -> Result<String, ThisProjectError> {
    println!("Enter Feature Statement: Features: User-Features & Subfeatures/Under-The-Hood Features -> From a user-story standpoint, what is this project making? Under-the-hood, what is this projet making?");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Pending: User-Features & Subfeatures/Under-The-Hood Features".to_string();
    }

    Ok(input.to_string())
}

/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa5_mvp() -> Result<String, ThisProjectError> {
    println!("Enter MVP Statement: MVP: 'MVP's (Minimum Viable Products); Tools & 'Tool Stack / Tech Stack'");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Pending: MVP & Techstack".to_string();
    }

    Ok(input.to_string())
}

/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa6_feedback() -> Result<String, ThisProjectError> {
    println!("Enter Feedback Statement: Feedback: Tests, Communication, Signals, Documentation & Iteration, Organizational, System, and 'Ecological' Effects, (~agile) -> Based on what signals will you define failure and orient to measure productivity.");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Pending: MVP & Techstack".to_string();
    }

    Ok(input.to_string())
}

/*
Message-Post Q&A functions
*/

/// Gets user input for message post integer validation ranges
///
/// # Returns
/// * `Result<Option<Vec<(i32, i32)>>, ThisProjectError>` - Vector of integer range tuples or None
fn q_and_a_get_message_post_integer_ranges() -> Result<Option<Vec<(i32, i32)>>, ThisProjectError> {

    // Section Blurb
    println!("\n\nMessage-Posts: optional modular customization of the Message-Post section of this node.");
    println!("for example, using this message post for: elections/votes/poles, surveys, questionnaires, data-collection for analysis, etc.\n");

    // Question for User
    println!("Integer-Choices, if applicable:");
    println!("For preset answers/choices for Message-Posts, such as poles or questionnaires with options taking the \"multile-choice\" form: 1. breakfast  2. second-breakfast 3. supper");
    println!("where the user enters only the integer (commonly a letter for \"multile-choice\")");
    println!("to indicate that they are selecting the option that corresponds to that integer (commonly a letter):");
    println!("Enter the range (or ranges) of how many integer-only options the user can select from.");
    println!("I.e. enter a list of integer ranges that the user will be able select from, using integers, dashes, and commas: Format: min1-max1,min2-max2,");
    println!("Example -> 1-10,20-30,50-100   E.g. for 1. breakfast  2. second-breakfast 3. supper, the format would be -> 1-3");
    println!("Write-in options are dealt with below, this for one or more ranges of values where the user only enters the integer of their selection.");
    println!("...or press Enter to skip if this format does not apply to your project-node.");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        return Ok(None);
    }

    // Parse the ranges
    let mut ranges = Vec::new();
    for range_str in input.split(',') {
        let parts: Vec<&str> = range_str.trim().split('-').collect();
        if parts.len() != 2 {
            return Err(ThisProjectError::InvalidInput(format!("Invalid range format: {}", range_str)));
        }

        let min = parts[0].parse::<i32>()
            .map_err(|_| ThisProjectError::InvalidInput(format!("Invalid minimum value: {}", parts[0])))?;
        let max = parts[1].parse::<i32>()
            .map_err(|_| ThisProjectError::InvalidInput(format!("Invalid maximum value: {}", parts[1])))?;

        if min > max {
            return Err(ThisProjectError::InvalidInput(format!("Minimum {} is greater than maximum {}", min, max)));
        }

        ranges.push((min, max));
    }

    Ok(Some(ranges))
}

/// Gets user input for message post integer-string validation ranges
///
/// Prompts the user to enter integer ranges for integer-string pair options.
/// These are used for write-in choices where users provide both an integer
/// selection and a string value (e.g., "3:lilac" for a color choice).
///
/// # Input Format
/// - Single integers: "5" (interpreted as range 5-5)
/// - Ranges: "5-10" (range from 5 to 10)
/// - Multiple values: "2,5-10,12" (single value 2, range 5-10, single value 12)
/// - Empty input skips this configuration
///
/// # Returns
/// * `Result<Option<Vec<(i32, i32)>>, ThisProjectError>` - Vector of integer range tuples for int-string pairs or None
///
/// # Errors
/// * `ThisProjectError::InvalidInput` - If the input format is invalid
/// * `ThisProjectError::IoError` - If there's an I/O error reading input
fn q_and_a_get_message_post_int_string_ranges() -> Result<Option<Vec<(i32, i32)>>, ThisProjectError> {

    println!("Integer:Write-In choices, if applicable:");
    println!("For write-in answers/choices for Message-Posts, such as the third part of this form: 1. mustard-yellow  2. pink 3. write in your choice of colour");
    println!("Or the third AND fourth parts of this form: 1. blue  2. yellow  3. write in: your choice of colour  4. write in: exceptional reason to avoid colour");
    println!("Here the user enters BOTH an integer AND (after a colon) their write-in character-string -> integer:string -> 3:lilac");
    println!("As with integer-only above, these can be single, continuous ranges, or (lists) discontinuous options (ranges or singles)");
    println!("If applicable, enter integer ranges for integer-string pair options (format: min-max,min-max,... or single values like 5 or press Enter to skip):");
    println!("Example: 2,5-10,12");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        return Ok(None);
    }

    // Parse the ranges with support for single integers
    let mut ranges = Vec::new();

    // Split by comma to handle multiple entries
    for range_str in input.split(',') {
        let trimmed = range_str.trim();

        // Check if it contains a dash (range) or is a single value
        if trimmed.contains('-') {
            // Handle range format (e.g., "5-10")
            let parts: Vec<&str> = trimmed.split('-').collect();

            // Validate that we have exactly 2 parts
            if parts.len() != 2 {
                return Err(ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Invalid range format: '{}'. Expected format: 'min-max'", trimmed)
                ));
            }

            // Parse minimum value
            let min = parts[0].parse::<i32>()
                .map_err(|_| ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Invalid minimum value: '{}'", parts[0])
                ))?;

            // Parse maximum value
            let max = parts[1].parse::<i32>()
                .map_err(|_| ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Invalid maximum value: '{}'", parts[1])
                ))?;

            // Validate that min <= max
            if min > max {
                return Err(ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Minimum {} is greater than maximum {}", min, max)
                ));
            }

            ranges.push((min, max));
        } else {
            // Handle single integer (e.g., "5" becomes "5-5")
            let single_value = trimmed.parse::<i32>()
                .map_err(|_| ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Invalid integer value: '{}'", trimmed)
                ))?;

            // Add as a range where min equals max
            ranges.push((single_value, single_value));
        }
    }

    Ok(Some(ranges))
}

/// Gets user input for maximum string length in integer-string pairs
///
/// # Returns
/// * `Result<Option<usize>, ThisProjectError>` - Maximum string length or None
fn q_and_a_get_message_post_max_string_length() -> Result<Option<usize>, ThisProjectError> {
    println!("Enter maximum string length (max number of write-in characters) for integer-string pairs (or press Enter to skip):");
    println!("Example: 42");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        return Ok(None);
    }

    let max_length = input.parse::<usize>()
        .map_err(|_| ThisProjectError::InvalidInput(format!("Invalid maximum string length: {}", input)))?;

    Ok(Some(max_length))
}

/// Gets user input for whether message posts should be public
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether posts are public or None
fn q_and_a_get_message_post_is_public() -> Result<Option<bool>, ThisProjectError> {
    println!("Should message posts be public? -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(None);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(Some(true)),
        "no" | "n" | "false" | "0" => Ok(Some(false)),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}

/// Gets user input for whether user confirmation is required before posting
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether user confirmation is required or None
fn q_and_a_get_message_post_user_confirms() -> Result<Option<bool>, ThisProjectError> {
    println!("Require user confirmation before posting messages?  -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(None);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(Some(true)),
        "no" | "n" | "false" | "0" => Ok(Some(false)),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}


/// Gets user input for whether user confirmation is required before posting
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether user confirmation is required or None
fn q_and_a_get_message_post_gpgtoml_required() -> Result<Option<bool>, ThisProjectError> {
    println!("Require all message post are gpgtoml encrypted?  -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(None);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(Some(true)),
        "no" | "n" | "false" | "0" => Ok(Some(false)),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}


/// Gets user input for whether user confirmation is required before posting
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether user confirmation is required or None
fn q_and_a_get_corenode_gpgtoml() -> Result<bool, ThisProjectError> {
    println!("This Node is gpgtoml encrypted?  -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(false);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(true),
        "no" | "n" | "false" | "0" => Ok(false),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}



/// Gets user input for message post start date with component-based input
///
/// This function provides multiple input options:
/// - "now" - Uses current UTC time
/// - Component-based input - Guides user through entering year, month, day, hour, minute
/// - Skip option - Returns None if user doesn't want to set a start date
///
/// The function validates each component and converts the final date/time to a UTC POSIX timestamp.
///
/// # Returns
/// * `Ok(Some(i64))` - Start date as UTC POSIX timestamp if user provided valid input
/// * `Ok(None)` - If user chose to skip
/// * `Err(ThisProjectError)` - If input/output operations fail or validation fails
///
/// # Example Flow
/// ```text
/// Enter start date for accepting posts:
/// - Type "now" for current UTC time
/// - Type "custom" to enter a specific date
/// - Press Enter to skip
/// > now
/// Start date set to current UTC time: 2024-01-15 14:30:45
/// Timestamp: 1705329045
/// ```
fn q_and_a_get_message_post_start_date() -> Result<Option<i64>, ThisProjectError> {
    // Log function entry
    debug_log("Starting q_and_a_get_message_post_start_date()");

    // Display options to user
    println!("Enter start date for accepting posts:");
    println!("  - Type \"now\" for current UTC time");
    println!("  - Type \"custom\" to enter a specific date");
    println!("  - Press Enter to skip");
    print!("> ");

    // Ensure prompt is displayed before reading input
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    // Read user choice
    let mut choice = String::new();
    io::stdin().read_line(&mut choice).map_err(|e| ThisProjectError::IoError(e))?;

    let choice = choice.trim().to_lowercase();

    // Handle user choice
    match choice.as_str() {
        "" => {
            // User pressed Enter - skip setting start date
            debug_log("User chose to skip start date");
            Ok(None)
        },
        "now" => {
            // Use current UTC time
            handle_now_option()
        },
        "custom" => {
            // Guide through component-based input
            handle_custom_date_input()
        },
        _ => {
            // Invalid option
            Err(ThisProjectError::InvalidInput(
                format!("Invalid option '{}'. Please choose 'now', 'custom', or press Enter to skip.", choice)
            ))
        }
    }
}

/// Handles the "now" option by getting current UTC time
///
/// # Returns
/// * `Ok(Some(i64))` - Current UTC timestamp
/// * `Err(ThisProjectError)` - If system time retrieval fails
fn handle_now_option() -> Result<Option<i64>, ThisProjectError> {
    debug_log("User selected 'now' option");

    // Get current system time
    let now = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| {
            ThisProjectError::InvalidData(format!("System time error: {}", e))
        })?;

    let timestamp = now.as_secs() as i64;

    // Calculate and display human-readable UTC time
    let (year, month, day, hour, minute, second) = timestamp_to_utc_components(timestamp);

    println!("\nStart date set to current UTC time:");
    println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:{:02}",
        year, month, day, hour, minute, second);
    println!("  Timestamp: {}", timestamp);

    debug_log!("Current UTC timestamp: {}", timestamp);

    Ok(Some(timestamp))
}

/// Handles custom date input by guiding user through component entry
///
/// # Returns
/// * `Ok(Some(i64))` - Custom date as UTC timestamp
/// * `Err(ThisProjectError)` - If input validation fails
fn handle_custom_date_input() -> Result<Option<i64>, ThisProjectError> {
    debug_log("User selected custom date input");

    // Get current year for validation
    let current_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| {
            ThisProjectError::InvalidData(format!("System time error: {}", e))
        })?
        .as_secs() as i64;

    let (current_year, _, _, _, _, _) = timestamp_to_utc_components(current_timestamp);

    // Year input and validation
    println!("\nEnter start year (YYYY, e.g., {})", current_year);
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut year_input = String::new();
    io::stdin().read_line(&mut year_input).map_err(|e| ThisProjectError::IoError(e))?;

    let year: i32 = year_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid year: '{}'", year_input.trim()))
    })?;

    // Validate year range (current year - 10 to current year + 10)
    if year < current_year - 10 || year > current_year + 10 {
        return Err(ThisProjectError::InvalidInput(
            format!("Year must be between {} and {}", current_year - 10, current_year + 10)
        ));
    }
    debug_log!("Parsed year: {}", year);

    // Month input and validation
    println!("Enter start month (1-12):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut month_input = String::new();
    io::stdin().read_line(&mut month_input).map_err(|e| ThisProjectError::IoError(e))?;

    let month: u32 = month_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid month: '{}'", month_input.trim()))
    })?;

    if month < 1 || month > 12 {
        return Err(ThisProjectError::InvalidInput("Month must be between 1 and 12".into()));
    }
    debug_log!("Parsed month: {}", month);

    // Day input and validation
    let max_day = get_days_in_month(year, month);
    println!("Enter start day (1-{}):", max_day);
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut day_input = String::new();
    io::stdin().read_line(&mut day_input).map_err(|e| ThisProjectError::IoError(e))?;

    let day: u32 = day_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid day: '{}'", day_input.trim()))
    })?;

    if day < 1 || day > max_day {
        return Err(ThisProjectError::InvalidInput(
            format!("Day must be between 1 and {} for {}/{}", max_day, year, month)
        ));
    }
    debug_log!("Parsed day: {}", day);

    // Hour input and validation
    println!("Enter start hour (0-23, 24-hour format):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut hour_input = String::new();
    io::stdin().read_line(&mut hour_input).map_err(|e| ThisProjectError::IoError(e))?;

    let hour: u32 = hour_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid hour: '{}'", hour_input.trim()))
    })?;

    if hour > 23 {
        return Err(ThisProjectError::InvalidInput("Hour must be between 0 and 23".into()));
    }
    debug_log!("Parsed hour: {}", hour);

    // Minute input and validation
    println!("Enter start minute (0-59):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut minute_input = String::new();
    io::stdin().read_line(&mut minute_input).map_err(|e| ThisProjectError::IoError(e))?;

    let minute: u32 = minute_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid minute: '{}'", minute_input.trim()))
    })?;

    if minute > 59 {
        return Err(ThisProjectError::InvalidInput("Minute must be between 0 and 59".into()));
    }
    debug_log!("Parsed minute: {}", minute);

    // Note about timezone
    println!("\nNote: Time will be interpreted as UTC");

    // Calculate timestamp from components
    let timestamp = utc_components_to_timestamp(year, month, day, hour, minute, 0)?;

    // Display confirmation
    println!("\nStart date set to:");
    println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:00",
        year, month, day, hour, minute);
    println!("  Timestamp: {}", timestamp);

    debug_log!("Successfully created start date timestamp: {}", timestamp);

    Ok(Some(timestamp))
}

/// Determines the number of days in a given month, accounting for leap years
///
/// # Arguments
/// * `year` - The year (used for leap year calculation)
/// * `month` - The month (1-12)
///
/// # Returns
/// * `u32` - Number of days in the month
fn get_days_in_month(year: i32, month: u32) -> u32 {
    match month {
        1 | 3 | 5 | 7 | 8 | 10 | 12 => 31,
        4 | 6 | 9 | 11 => 30,
        2 => {
            // Check for leap year
            if is_leap_year(year) {
                29
            } else {
                28
            }
        },
        _ => unreachable!("Month already validated to be 1-12"),
    }
}

/// Checks if a given year is a leap year
///
/// # Arguments
/// * `year` - The year to check
///
/// # Returns
/// * `bool` - true if leap year, false otherwise
fn is_leap_year(year: i32) -> bool {
    (year % 4 == 0 && year % 100 != 0) || (year % 400 == 0)
}

/// Converts UTC date/time components to a Unix timestamp
///
/// # Arguments
/// * `year` - Year (e.g., 2024)
/// * `month` - Month (1-12)
/// * `day` - Day of month (1-31)
/// * `hour` - Hour (0-23)
/// * `minute` - Minute (0-59)
/// * `second` - Second (0-59)
///
/// # Returns
/// * `Ok(i64)` - Unix timestamp (seconds since 1970-01-01 00:00:00 UTC)
/// * `Err(ThisProjectError)` - If date is invalid
fn utc_components_to_timestamp(
    year: i32,
    month: u32,
    day: u32,
    hour: u32,
    minute: u32,
    second: u32
) -> Result<i64, ThisProjectError> {
    // Validate inputs
    if year < 1970 {
        return Err(ThisProjectError::InvalidInput("Year must be 1970 or later".into()));
    }

    // Calculate days since epoch (1970-01-01)
    let mut days: i64 = 0;

    // Add days for complete years
    for y in 1970..year {
        days += if is_leap_year(y) { 366 } else { 365 };
    }

    // Add days for complete months in current year
    for m in 1..month {
        days += get_days_in_month(year, m) as i64;
    }

    // Add remaining days
    days += (day - 1) as i64;

    // Convert to seconds and add time components
    let seconds_per_day: i64 = 24 * 60 * 60;
    let seconds_per_hour: i64 = 60 * 60;
    let seconds_per_minute: i64 = 60;

    let timestamp = days * seconds_per_day
        + (hour as i64) * seconds_per_hour
        + (minute as i64) * seconds_per_minute
        + (second as i64);

    debug_log!("Converted date components to timestamp: {}", timestamp);

    Ok(timestamp)
}

/// Converts a Unix timestamp to UTC date/time components
///
/// This function performs the reverse operation of utc_components_to_timestamp,
/// breaking down a timestamp into human-readable date and time components.
///
/// # Arguments
/// * `timestamp` - Unix timestamp (seconds since 1970-01-01 00:00:00 UTC)
///
/// # Returns
/// * `(year, month, day, hour, minute, second)` - Tuple of date/time components
fn timestamp_to_utc_components(timestamp: i64) -> (i32, u32, u32, u32, u32, u32) {
    // Constants for time calculations
    let seconds_per_day: i64 = 24 * 60 * 60;
    let seconds_per_hour: i64 = 60 * 60;
    let seconds_per_minute: i64 = 60;

    // Calculate total days since epoch
    let total_days = timestamp / seconds_per_day;
    let remaining_seconds = timestamp % seconds_per_day;

    // Calculate time components from remaining seconds
    let hour = (remaining_seconds / seconds_per_hour) as u32;
    let minute = ((remaining_seconds % seconds_per_hour) / seconds_per_minute) as u32;
    let second = (remaining_seconds % seconds_per_minute) as u32;

    // Calculate year by iterating from 1970
    let mut year = 1970;
    let mut days_counted: i64 = 0;

    loop {
        let days_in_year = if is_leap_year(year) { 366 } else { 365 };
        if days_counted + days_in_year > total_days {
            break;
        }
        days_counted += days_in_year;
        year += 1;
    }

    // Calculate remaining days in the current year
    let mut days_in_year = (total_days - days_counted) as u32;

    // Calculate month and day
    let mut month = 1;
    loop {
        let days_in_month = get_days_in_month(year, month);
        if days_in_year < days_in_month {
            break;
        }
        days_in_year -= days_in_month;
        month += 1;
        if month > 12 {
            // This shouldn't happen with valid timestamps, but handle it gracefully
            month = 12;
            days_in_year = get_days_in_month(year, 12) - 1;
            break;
        }
    }

    // Day is 1-based (days_in_year is 0-based)
    let day = days_in_year + 1;

    (year, month, day, hour, minute, second)
}

// /// Gets user input for message post end date
// ///
// /// # Returns
// /// * `Result<Option<i64>, ThisProjectError>` - End date as UTC POSIX timestamp or None
// fn q_and_a_get_message_post_end_date() -> Result<Option<i64>, ThisProjectError> {
//     println!("Enter end date for accepting posts (format: YYYY-MM-DD HH:MM:SS or press Enter to skip):");
//     println!("Example: 2024-12-31 23:59:59");

//     let mut input = String::new();
//     io::stdout().flush()?;
//     io::stdin().read_line(&mut input)?;

//     let input = input.trim();
//     if input.is_empty() {
//         return Ok(None);
//     }


// /// Handles custom end date input by guiding user through component entry
// ///
// /// # Arguments
// /// * `start_date_timestamp` - Optional start date timestamp for validation
// ///
// /// # Returns
// /// * `Ok(Some(i64))` - Custom end date as UTC timestamp
// /// * `Err(ThisProjectError)` - If input validation fails
// fn q_and_a_get_message_post_end_date(start_date_timestamp: Option<i64>) -> Result<Option<i64>, ThisProjectError> {
//     debug_log("User selected custom end date input");

//     // Get current year for validation
//     let current_timestamp = SystemTime::now()
//         .duration_since(UNIX_EPOCH)
//         .map_err(|e| {
//             ThisProjectError::InvalidData(format!("System time error: {}", e))
//         })?
//         .as_secs() as i64;

//     let (current_year, _, _, _, _, _) = timestamp_to_utc_components(current_timestamp);

//     // Calculate minimum year based on start date if provided
//     let min_year = if let Some(start_ts) = start_date_timestamp {
//         let (start_year, _, _, _, _, _) = timestamp_to_utc_components(start_ts);
//         start_year
//     } else {
//         current_year - 10
//     };

//     // Year input and validation
//     println!("\nEnter end year (YYYY, e.g., {})", current_year);
//     if let Some(start_ts) = start_date_timestamp {
//         let (start_year, _, _, _, _, _) = timestamp_to_utc_components(start_ts);
//         println!("  (Must be {} or later based on start date)", start_year);
//     }
//     print!("> ");
//     io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

//     let mut year_input = String::new();
//     io::stdin().read_line(&mut year_input).map_err(|e| ThisProjectError::IoError(e))?;

//     let year: i32 = year_input.trim().parse().map_err(|_| {
//         ThisProjectError::InvalidInput(format!("Invalid year: '{}'", year_input.trim()))
//     })?;

//     // Validate year range
//     if year < min_year || year > current_year + 50 {
//         return Err(ThisProjectError::InvalidInput(
//             format!("Year must be between {} and {}", min_year, current_year + 50)
//         ));
//     }
//     debug_log!("Parsed year: {}", year);

//     // Month input and validation
//     println!("Enter end month (1-12):");
//     print!("> ");
//     io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

//     let mut month_input = String::new();
//     io::stdin().read_line(&mut month_input).map_err(|e| ThisProjectError::IoError(e))?;

//     let month: u32 = month_input.trim().parse().map_err(|_| {
//         ThisProjectError::InvalidInput(format!("Invalid month: '{}'", month_input.trim()))
//     })?;

//     if month < 1 || month > 12 {
//         return Err(ThisProjectError::InvalidInput("Month must be between 1 and 12".into()));
//     }
//     debug_log!("Parsed month: {}", month);

//     // Day input and validation
//     let max_day = get_days_in_month(year, month);
//     println!("Enter end day (1-{}):", max_day);
//     print!("> ");
//     io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

//     let mut day_input = String::new();
//     io::stdin().read_line(&mut day_input).map_err(|e| ThisProjectError::IoError(e))?;

//     let day: u32 = day_input.trim().parse().map_err(|_| {
//         ThisProjectError::InvalidInput(format!("Invalid day: '{}'", day_input.trim()))
//     })?;

//     if day < 1 || day > max_day {
//         return Err(ThisProjectError::InvalidInput(
//             format!("Day must be between 1 and {} for {}/{}", max_day, year, month)
//         ));
//     }
//     debug_log!("Parsed day: {}", day);

//     // Hour input and validation
//     println!("Enter end hour (0-23, 24-hour format):");
//     print!("> ");
//     io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

//     let mut hour_input = String::new();
//     io::stdin().read_line(&mut hour_input).map_err(|e| ThisProjectError::IoError(e))?;

//     let hour: u32 = hour_input.trim().parse().map_err(|_| {
//         ThisProjectError::InvalidInput(format!("Invalid hour: '{}'", hour_input.trim()))
//     })?;

//     if hour > 23 {
//         return Err(ThisProjectError::InvalidInput("Hour must be between 0 and 23".into()));
//     }
//     debug_log!("Parsed hour: {}", hour);

//     // Minute input and validation
//     println!("Enter end minute (0-59):");
//     print!("> ");
//     io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

//     let mut minute_input = String::new();
//     io::stdin().read_line(&mut minute_input).map_err(|e| ThisProjectError::IoError(e))?;

//     let minute: u32 = minute_input.trim().parse().map_err(|_| {
//         ThisProjectError::InvalidInput(format!("Invalid minute: '{}'", minute_input.trim()))
//     })?;

//     if minute > 59 {
//         return Err(ThisProjectError::InvalidInput("Minute must be between 0 and 59".into()));
//     }
//     debug_log!("Parsed minute: {}", minute);

//     // Note about timezone
//     println!("\nNote: Time will be interpreted as UTC");

//     // Calculate timestamp from components
//     let end_timestamp = utc_components_to_timestamp(year, month, day, hour, minute, 0)?;

//     // Validate that end date is after start date
//     if let Some(start_ts) = start_date_timestamp {
//         if end_timestamp <= start_ts {
//             let (start_year, start_month, start_day, start_hour, start_minute, start_second) =
//                 timestamp_to_utc_components(start_ts);

//             return Err(ThisProjectError::InvalidInput(
//                 format!(
//                     "End date must be after start date ({:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC)",
//                     start_year, start_month, start_day, start_hour, start_minute, start_second
//                 )
//             ));
//         }

//         // Calculate and display duration
//         let duration_seconds = end_timestamp - start_ts;
//         let duration_days = duration_seconds / (24 * 60 * 60);
//         let duration_hours = (duration_seconds % (24 * 60 * 60)) / (60 * 60);

//         println!("\nDuration: {} days, {} hours", duration_days, duration_hours);
//     }

//     // Display confirmation
//     println!("\nEnd date set to:");
//     println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:00",
//         year, month, day, hour, minute);
//     println!("  Timestamp: {}", end_timestamp);

//     debug_log!("Successfully created end date timestamp: {}", end_timestamp);

//     Ok(Some(end_timestamp))
// }

    /// Gets user input for message post end date with multiple input methods
///
/// This function provides options for entering an end date:
/// - Duration-based input - Specify duration from start date (requires start date)
/// - Component-based input - Enter specific date/time components
/// - Skip option - Returns None if user doesn't want to set an end date
///
/// The function validates all inputs and ensures the end date is after the start date.
///
/// # Arguments
/// * `start_date_timestamp` - Optional start date timestamp for validation and duration calculation
///
/// # Returns
/// * `Ok(Some(i64))` - End date as UTC POSIX timestamp if user provided valid input
/// * `Ok(None)` - If user chose to skip
/// * `Err(ThisProjectError)` - If input/output operations fail or validation fails
///
/// # Example Flow
/// ```text
/// Enter end date for accepting posts:
/// - Type "duration" to specify duration from start date
/// - Type "custom" to enter a specific date
/// - Press Enter to skip
/// > duration
/// Enter duration from start date:
/// Years (press Enter for 0):
/// Months (press Enter for 0):
/// Weeks (press Enter for 0): 2
/// Days (press Enter for 0):
/// Hours (press Enter for 0):
/// Minutes (press Enter for 0):
///
/// End date set to: 2024-01-29 14:30:00 UTC (2 weeks from start)
/// ```
fn q_and_a_get_message_post_end_date(start_date_timestamp: Option<i64>) -> Result<Option<i64>, ThisProjectError> {
    // Log function entry
    debug_log("Starting q_and_a_get_message_post_end_date()");

    // Display options to user
    println!("\nEnter end date for accepting posts:");

    // Only show duration option if start date exists
    if start_date_timestamp.is_some() {
        println!("  - Type \"duration\" to specify duration from start date");
    }

    println!("  - Type \"custom\" to enter a specific date");
    println!("  - Press Enter to skip");

    // If start date exists, show it for reference
    if let Some(start_ts) = start_date_timestamp {
        let (year, month, day, hour, minute, second) = timestamp_to_utc_components(start_ts);
        println!("\n  Note: Start date is {:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC",
            year, month, day, hour, minute, second);
    }

    print!("> ");

    // Ensure prompt is displayed before reading input
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    // Read user choice
    let mut choice = String::new();
    io::stdin().read_line(&mut choice).map_err(|e| ThisProjectError::IoError(e))?;

    let choice = choice.trim().to_lowercase();

    // Handle user choice
    match choice.as_str() {
        "" => {
            // User pressed Enter - skip setting end date
            debug_log("User chose to skip end date");
            Ok(None)
        },
        "duration" => {
            // Check if start date exists
            match start_date_timestamp {
                Some(start_ts) => handle_duration_based_end_date(start_ts),
                None => Err(ThisProjectError::InvalidInput(
                    "Cannot specify duration without a start date. Please use 'custom' option instead.".into()
                ))
            }
        },
        "custom" => {
            // Guide through component-based input
            handle_custom_end_date_input(start_date_timestamp)
        },
        _ => {
            // Invalid option
            let mut error_msg = format!("Invalid option '{}'. Please choose ", choice);
            if start_date_timestamp.is_some() {
                error_msg.push_str("'duration', 'custom', or press Enter to skip.");
            } else {
                error_msg.push_str("'custom' or press Enter to skip.");
            }
            Err(ThisProjectError::InvalidInput(error_msg))
        }
    }
}

/// Handles duration-based end date calculation
///
/// Guides user through entering duration components and calculates end date
/// from the provided start date.
///
/// # Arguments
/// * `start_timestamp` - Start date timestamp to calculate from
///
/// # Returns
/// * `Ok(Some(i64))` - Calculated end date timestamp
/// * `Err(ThisProjectError)` - If input validation fails
fn handle_duration_based_end_date(start_timestamp: i64) -> Result<Option<i64>, ThisProjectError> {
    debug_log("User selected duration-based end date");

    println!("\nEnter duration from start date:");
    println!("(Press Enter to skip any unit, entering 0 has the same effect)");

    // Years input
    print!("\nYears (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut years_input = String::new();
    io::stdin().read_line(&mut years_input).map_err(|e| ThisProjectError::IoError(e))?;

    let years: u32 = if years_input.trim().is_empty() {
        0
    } else {
        years_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid years: '{}'", years_input.trim()))
        })?
    };

    if years > 100 {
        return Err(ThisProjectError::InvalidInput("Years must be 100 or less".into()));
    }

    // Months input
    print!("Months (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut months_input = String::new();
    io::stdin().read_line(&mut months_input).map_err(|e| ThisProjectError::IoError(e))?;

    let months: u32 = if months_input.trim().is_empty() {
        0
    } else {
        months_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid months: '{}'", months_input.trim()))
        })?
    };

    if months > 12 * 100 { // Reasonable upper limit
        return Err(ThisProjectError::InvalidInput("Months value is too large".into()));
    }

    // Weeks input
    print!("Weeks (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut weeks_input = String::new();
    io::stdin().read_line(&mut weeks_input).map_err(|e| ThisProjectError::IoError(e))?;

    let weeks: u32 = if weeks_input.trim().is_empty() {
        0
    } else {
        weeks_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid weeks: '{}'", weeks_input.trim()))
        })?
    };

    // Days input
    print!("Days (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut days_input = String::new();
    io::stdin().read_line(&mut days_input).map_err(|e| ThisProjectError::IoError(e))?;

    let days: u32 = if days_input.trim().is_empty() {
        0
    } else {
        days_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid days: '{}'", days_input.trim()))
        })?
    };

    // Hours input
    print!("Hours (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut hours_input = String::new();
    io::stdin().read_line(&mut hours_input).map_err(|e| ThisProjectError::IoError(e))?;

    let hours: u32 = if hours_input.trim().is_empty() {
        0
    } else {
        hours_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid hours: '{}'", hours_input.trim()))
        })?
    };

    // Minutes input
    print!("Minutes (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut minutes_input = String::new();
    io::stdin().read_line(&mut minutes_input).map_err(|e| ThisProjectError::IoError(e))?;

    let minutes: u32 = if minutes_input.trim().is_empty() {
        0
    } else {
        minutes_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid minutes: '{}'", minutes_input.trim()))
        })?
    };

    // Validate that at least some duration was specified
    if years == 0 && months == 0 && weeks == 0 && days == 0 && hours == 0 && minutes == 0 {
        return Err(ThisProjectError::InvalidInput(
            "Duration must be greater than zero. At least one time unit must be specified.".into()
        ));
    }

    // Calculate end timestamp
    // Note: For months and years, we need to handle them specially due to varying lengths
    let (start_year, start_month, start_day, start_hour, start_minute, start_second) =
        timestamp_to_utc_components(start_timestamp);

    // Calculate target date components
    let mut target_year = start_year + years as i32;
    let mut target_month = start_month + months;

    // Handle month overflow
    while target_month > 12 {
        target_month -= 12;
        target_year += 1;
    }

    // For day calculation, we need to be careful about month boundaries
    let mut target_day = start_day;

    // Adjust day if it would be invalid in the target month
    let max_day_in_target_month = get_days_in_month(target_year, target_month);
    if target_day > max_day_in_target_month {
        target_day = max_day_in_target_month;
    }

    // Convert to timestamp for the year/month adjusted date
    let intermediate_timestamp = utc_components_to_timestamp(
        target_year, target_month, target_day, start_hour, start_minute, start_second
    )?;

    // Now add weeks, days, hours, and minutes as seconds
    let seconds_per_minute: i64 = 60;
    let seconds_per_hour: i64 = 60 * 60;
    let seconds_per_day: i64 = 24 * 60 * 60;
    let seconds_per_week: i64 = 7 * seconds_per_day;

    let additional_seconds =
        (weeks as i64 * seconds_per_week) +
        (days as i64 * seconds_per_day) +
        (hours as i64 * seconds_per_hour) +
        (minutes as i64 * seconds_per_minute);

    let end_timestamp = intermediate_timestamp + additional_seconds;

    // Build duration description
    let mut duration_parts = Vec::new();
    if years > 0 { duration_parts.push(format!("{} year{}", years, if years == 1 { "" } else { "s" })); }
    if months > 0 { duration_parts.push(format!("{} month{}", months, if months == 1 { "" } else { "s" })); }
    if weeks > 0 { duration_parts.push(format!("{} week{}", weeks, if weeks == 1 { "" } else { "s" })); }
    if days > 0 { duration_parts.push(format!("{} day{}", days, if days == 1 { "" } else { "s" })); }
    if hours > 0 { duration_parts.push(format!("{} hour{}", hours, if hours == 1 { "" } else { "s" })); }
    if minutes > 0 { duration_parts.push(format!("{} minute{}", minutes, if minutes == 1 { "" } else { "s" })); }

    let duration_description = duration_parts.join(", ");

    // Display the calculated end date
    let (end_year, end_month, end_day, end_hour, end_minute, end_second) =
        timestamp_to_utc_components(end_timestamp);

    println!("\nEnd date set to:");
    println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:{:02}",
        end_year, end_month, end_day, end_hour, end_minute, end_second);
    println!("  Duration: {} from start date", duration_description);
    println!("  Timestamp: {}", end_timestamp);

    debug_log!("Successfully calculated end date with duration: {}", duration_description);

    Ok(Some(end_timestamp))
}


/// Handles custom end date input by guiding user through component entry
///
/// # Arguments
/// * `start_date_timestamp` - Optional start date timestamp for validation
///
/// # Returns
/// * `Ok(Some(i64))` - Custom end date as UTC timestamp
/// * `Err(ThisProjectError)` - If input validation fails
fn handle_custom_end_date_input(start_date_timestamp: Option<i64>) -> Result<Option<i64>, ThisProjectError> {
    debug_log("User selected custom end date input");

    // Get current year for validation
    let current_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| {
            ThisProjectError::InvalidData(format!("System time error: {}", e))
        })?
        .as_secs() as i64;

    let (current_year, _, _, _, _, _) = timestamp_to_utc_components(current_timestamp);

    // Calculate minimum year based on start date if provided
    let min_year = if let Some(start_ts) = start_date_timestamp {
        let (start_year, _, _, _, _, _) = timestamp_to_utc_components(start_ts);
        start_year
    } else {
        current_year - 10
    };

    // Year input and validation
    println!("\nEnter end year (YYYY, e.g., {})", current_year);
    if let Some(start_ts) = start_date_timestamp {
        let (start_year, _, _, _, _, _) = timestamp_to_utc_components(start_ts);
        println!("  (Must be {} or later based on start date)", start_year);
    }
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut year_input = String::new();
    io::stdin().read_line(&mut year_input).map_err(|e| ThisProjectError::IoError(e))?;

    let year: i32 = year_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid year: '{}'", year_input.trim()))
    })?;

    // Validate year range
    if year < min_year || year > current_year + 50 {
        return Err(ThisProjectError::InvalidInput(
            format!("Year must be between {} and {}", min_year, current_year + 50)
        ));
    }
    debug_log!("Parsed year: {}", year);

    // Month input and validation
    println!("Enter end month (1-12):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut month_input = String::new();
    io::stdin().read_line(&mut month_input).map_err(|e| ThisProjectError::IoError(e))?;

    let month: u32 = month_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid month: '{}'", month_input.trim()))
    })?;

    if month < 1 || month > 12 {
        return Err(ThisProjectError::InvalidInput("Month must be between 1 and 12".into()));
    }
    debug_log!("Parsed month: {}", month);

    // Day input and validation
    let max_day = get_days_in_month(year, month);
    println!("Enter end day (1-{}):", max_day);
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut day_input = String::new();
    io::stdin().read_line(&mut day_input).map_err(|e| ThisProjectError::IoError(e))?;

    let day: u32 = day_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid day: '{}'", day_input.trim()))
    })?;

    if day < 1 || day > max_day {
        return Err(ThisProjectError::InvalidInput(
            format!("Day must be between 1 and {} for {}/{}", max_day, year, month)
        ));
    }
    debug_log!("Parsed day: {}", day);

    // Hour input and validation
    println!("Enter end hour (0-23, 24-hour format):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut hour_input = String::new();
    io::stdin().read_line(&mut hour_input).map_err(|e| ThisProjectError::IoError(e))?;

    let hour: u32 = hour_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid hour: '{}'", hour_input.trim()))
    })?;

    if hour > 23 {
        return Err(ThisProjectError::InvalidInput("Hour must be between 0 and 23".into()));
    }
    debug_log!("Parsed hour: {}", hour);

    // Minute input and validation
    println!("Enter end minute (0-59):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut minute_input = String::new();
    io::stdin().read_line(&mut minute_input).map_err(|e| ThisProjectError::IoError(e))?;

    let minute: u32 = minute_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid minute: '{}'", minute_input.trim()))
    })?;

    if minute > 59 {
        return Err(ThisProjectError::InvalidInput("Minute must be between 0 and 59".into()));
    }
    debug_log!("Parsed minute: {}", minute);

    // Note about timezone
    println!("\nNote: Time will be interpreted as UTC");

    // Calculate timestamp from components
    let end_timestamp = utc_components_to_timestamp(year, month, day, hour, minute, 0)?;

    // Validate that end date is after start date
    if let Some(start_ts) = start_date_timestamp {
        if end_timestamp <= start_ts {
            let (start_year, start_month, start_day, start_hour, start_minute, start_second) =
                timestamp_to_utc_components(start_ts);

            return Err(ThisProjectError::InvalidInput(
                format!(
                    "End date must be after start date ({:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC)",
                    start_year, start_month, start_day, start_hour, start_minute, start_second
                )
            ));
        }

        // Calculate and display duration
        let duration_seconds = end_timestamp - start_ts;
        let duration_days = duration_seconds / (24 * 60 * 60);
        let duration_hours = (duration_seconds % (24 * 60 * 60)) / (60 * 60);

        println!("\nDuration: {} days, {} hours", duration_days, duration_hours);
    }

    // Display confirmation
    println!("\nEnd date set to:");
    println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:00",
        year, month, day, hour, minute);
    println!("  Timestamp: {}", end_timestamp);

    debug_log!("Successfully created end date timestamp: {}", end_timestamp);

    Ok(Some(end_timestamp))
}

//     // Parse the date string into a timestamp
//     // This is a simplified example - you might want to use a proper date parsing library
//     // For now, let's accept a Unix timestamp directly
//     println!("For now, please enter a Unix timestamp (seconds since 1970-01-01):");
//     let mut timestamp_input = String::new();
//     io::stdin().read_line(&mut timestamp_input)?;

//     let timestamp = timestamp_input.trim().parse::<i64>()
//         .map_err(|_| ThisProjectError::InvalidInput(format!("Invalid timestamp: {}", timestamp_input.trim())))?;

//     Ok(Some(timestamp))
// }



// /// Gets schedule information and converts
// /// to required format of create_core_node()
// fn get_schedule_info() -> Result<Vec<u64>, ThisProjectError> {
//     debug_log("starting get_schedule_info()")
//     println!("Enter project duration in days:");
//     let mut days = String::new();
//     io::stdin().read_line(&mut days)?;
//     let days: u64 = days.trim().parse().map_err(|_|
//         ThisProjectError::InvalidInput("Invalid number of days".into()))?;

//     println!("Enter start year (YYYY):");
//     let mut year = String::new();
//     io::stdin().read_line(&mut year)?;
//     let year: u64 = year.trim().parse().map_err(|_|
//         ThisProjectError::InvalidInput("Invalid year".into()))?;

//     println!("Enter start month (1-12):");
//     let mut month = String::new();
//     io::stdin().read_line(&mut month)?;
//     let month: u64 = month.trim().parse().map_err(|_|
//         ThisProjectError::InvalidInput("Invalid month".into()))?;

//     println!("Enter start day (1-31):");
//     let mut day = String::new();
//     io::stdin().read_line(&mut day)?;
//     let day: u64 = day.trim().parse().map_err(|_|
//         ThisProjectError::InvalidInput("Invalid day".into()))?;

//     let seconds_per_day: u64 = 24 * 60 * 60;
//     let days_since_epoch = (year - 1970) * 365 + ((month - 1) * 30) + (day - 1);
//     let start_timestamp = days_since_epoch * seconds_per_day;

//     let duration_seconds = days * seconds_per_day;
//     let end_timestamp = start_timestamp + duration_seconds;

//     Ok(vec![
//         start_timestamp,
//         end_timestamp,
//         duration_seconds
//     ])
// }

// // TODO Under Construction
// /// Creates a new (core)Node directory, subdirectories, and metadata files.
// /// Handles errors and returns a Result to indicate success or failure.
// ///
// /// # Arguments
// ///
// /// * `team_channel_name` - The name of the new team channel.
// /// * `owner` - The username of the channel owner.
// /// * 'path_to_node' - ?
// ///
// /// # Returns
// ///
// /// * `Result<(), ThisProjectError>` - `Ok(())` on success, or a `ThisProjectError`
// ///   describing the error.
// fn create_core_node(
//     team_channel_name: String,
//     owner: String,
//     // nodepath: PathBuff,
// ) -> Result<(), ThisProjectError> {
//     /*
//     TODO
//     1. integrate path
//     2.
//     3. Q&A for the planning fields
//     - allow default agenda-process-policy to be:
//     "Agile, Kahneman-Tversky, Definiition-Studies"
//     - ask for user-features, speicifc user-tools,
//     and sub-feature goals
//     - scope...
//     1. stand-alone or part of larger project
//     2. MVP goals
//     3.
//     - ask person for 'days' convert that duration
//     to seconds
//     - ask person for start perhaps year month day
//     (could be three questions) convert that
//     to posix time and use duration to get the
//     finish-date
//     4. add planning fields to corenode new impl fn
//         impl CoreNode {

//             fn new(


//     // project module items as task-ish thing
//     agenda_process: String,
//     goals_features_subfeatures_tools_targets: String,
//     scope: String,
//     pa2_schedule: Vec<u64>, // Vec<u64>,?

//     */
//     let team_channels_dir = Path::new("project_graph_data/team_channels");
//     let new_channel_path = team_channels_dir.join(&team_channel_name);

//     // 1. Create Directory Structure (with error handling)
//     fs::create_dir_all(new_channel_path.join("message_posts_browser"))?; // Propagate errors with ?
//     fs::create_dir_all(new_channel_path.join("task_browser"))?; // task browser directory
//     // for i in 1..=3 { // Using numbers
//     //     let col_name = format!("{}_col{}", i, i);
//     //     let col_path = new_channel_path.join("task_browser").join(col_name);
//     //     fs::create_dir_all(&col_path)?; // Create default task browser column directories for new channel
//     // }

//     let col_name = "1_planning";
//     let col_path = new_channel_path.join("task_browser").join(col_name);
//     fs::create_dir_all(&col_path)?; // Create default task browser column directories for new channel

//     let col_name = "1_started";
//     let col_path = new_channel_path.join("task_browser").join(col_name);
//     fs::create_dir_all(&col_path)?; // Create default task browser column directories for new channel

//     let col_name = "3_done";
//     let col_path = new_channel_path.join("task_browser").join(col_name);
//     fs::create_dir_all(&col_path)?; // Create default task browser column directories for new channel


//     // 2. Create and Save 0.toml Metadata (with error handling)
//     let metadata_path = new_channel_path.join("message_posts_browser/0.toml"); // Simplified path
//     let metadata = NodeInstMsgBrowserMetadata::new(&team_channel_name, owner.clone());
//     save_toml_to_file(&metadata, &metadata_path)?; // Use ? for error propagation

//     // Generate collaborator port assignments (simplified):
//     let mut abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();

//     // Add owner to collaborators list and port assignments:
//     // This makes it possible to create CoreNode and ensures the owner has port assignments
//     let mut collaborators = Vec::new();
//     collaborators.push(owner.clone());
//     debug_log!("create_new_team_channel(): owner 'added' to collaborators");

//     // let mut rng = rand::rng(); // Move RNG outside the loop for fewer calls

//     // Load the owner's data
//     let owner_data = read_one_collaborator_addressbook_toml(&owner)?;

//     // Simplified port generation (move rng outside loop):
//     // Assign random ports to owner:  Only owner for new channel.
//     let mut rng = rand::rng(); // Move RNG instantiation outside the loop

//     // let ready_port = rng.random_range(40000..60000) as u16; // Adjust range if needed
//     // let tray_port = rng.random_range(40000..60000) as u16; // Random u16 port number
//     // let gotit_port = rng.random_range(40000..60000) as u16; // Random u16 port number
//     // let abstract_ports_data = AbstractTeamchannelNodeTomlPortsData {
//     //     user_name: owner.clone(),
//     //     ready_port,
//     //     intray_port: tray_port,
//     //     gotit_port,
//     // };
//     // debug_log!("create_new_team_channel(): owner's abstract_ports_data created");


//     // // Store in the HashMap with "owner_owner" key. If more than one user this key can become unique.
//     // abstract_collaborator_port_assignments.insert(
//     //     format!("{}_{}", owner.clone(), owner), // Key derived from collaborator names
//     //     vec![ReadTeamchannelCollaboratorPortsToml { collaborator_ports: vec![abstract_ports_data] }],
//     // );
//     // debug_log!("create_new_team_channel(): owner 'added' to abstract_collaborator_port_assignments");


//     // 3. Create and Save CoreNode (handling Result)
//     // node.toml file should be created after the directory structure is in place
//     // This is done during first-time initialization so there should be salt list for the owner user (if not exit!)
//     let new_node_result = CoreNode::new(
//         team_channel_name.clone(),         // node_name
//         team_channel_name,                 // description_for_tui
//         new_channel_path.clone(),          // directory_path
//         owner,                             // owner
//         collaborators,                    // teamchannel_collaborators_with_access
//         HashMap::new(), // for ports
//     );

//     match new_node_result {  // Handle result of CoreNode::new
//         Ok(new_node) => {
//             new_node.save_node_to_clearsigned_file()?; // Then save the node
//             Ok(()) // Return Ok(()) to indicate success
//         }
//         Err(e) => {
//              debug_log!("Error creating CoreNode: {}", e);
//             Err(e) // Return the error if CoreNode creation fails
//         }
//     }

// }


/// Recursively moves all contents from the source directory to the destination directory.
/// Deletes the source directory if it is empty after moving all its contents.
/// use std::fs;
/// use std::path::Path;
///
/// e.g.
/// // Call the function to move the directory
/// if let Err(error) = move_directory__from_path_to_path("path/to/old/directory", "path/to/new/directory") {
///     eprintln!("An error occurred: {}", error);
/// }
fn move_directory__from_path_to_path<SourceDirectory: AsRef<Path>, DestinationDirectory: AsRef<Path>>(
    source_directory: SourceDirectory,
    destination_directory: DestinationDirectory,
) -> std::io::Result<()> {
    let source_path = source_directory.as_ref();
    let destination_path = destination_directory.as_ref();

    // Iterate through all entries in the source directory
    for entry_result in fs::read_dir(source_path)? {
        let entry = entry_result?;
        let file_type = entry.file_type()?;

        // If the entry is a directory, create it in the destination directory and move its contents
        if file_type.is_dir() {
            fs::create_dir_all(destination_path.join(entry.file_name()))?;
            move_directory__from_path_to_path(entry.path(), destination_path.join(entry.file_name()))?;
        }
        // If the entry is a file, move it to the destination directory
        else {
            fs::rename(entry.path(), destination_path.join(entry.file_name()))?;
        }
    }

    // Remove the source directory if it is empty
    fs::remove_dir(source_path)?;
    Ok(())
}


/// gpg get public key long from public key-id
/// use std::process::Command;
/// use std::io::{self, Write};
fn get_gpg_armored_public_key_via_key_id(key_id: &str) -> io::Result<String> {
    /*
   // Prompt the user for the key ID
    print!("Enter the GPG key ID: ");
    if let Err(e) = io::stdout().flush() {
        eprintln!("Failed to flush stdout: {}", e);
        return;
    }

    let mut key_id = String::new();
    if let Err(e) = io::stdin().read_line(&mut key_id) {
        eprintln!("Failed to read line: {}", e);
        return;
    }

    let key_id = key_id.trim(); // Remove any trailing newline or whitespace

    match get_gpg_armored_public_key_via_key_id(key_id) {
        Ok(armored_key) => {
            println!("Armored Public Key:\n{}", armored_key);
        }
        Err(e) => {
            eprintln!("Error: {}", e);
        }
    }

    */
    // Construct the GPG command to export the public key in armored format
    let output = StdCommand::new("gpg")
        .arg("--armor")
        .arg("--export")
        .arg(key_id)
        .output()?;

    // Check if the command was successful
    if output.status.success() {
        // Convert the output to a string
        let armored_key = String::from_utf8_lossy(&output.stdout).to_string();
        Ok(armored_key)
    } else {
        // If the command failed, return an error
        Err(io::Error::new(
            io::ErrorKind::Other,
            format!("Failed to export public key: {}", String::from_utf8_lossy(&output.stderr)),
        ))
    }
}


fn gpg_clearsign_file_to_sendbytes(
    file_path: &Path,
) -> Result<Vec<u8>, ThisProjectError> {
    // 1. Create a unique temporary file path in the OS temp directory.
    let mut temp_dir = std::env::temp_dir();
    let temp_file_name = format!("uma_temp_{}.toml", get_current_unix_timestamp()); // Or use a UUID for stronger uniqueness
    temp_dir.push(temp_file_name);

    // 2. Copy the original file to the temporary location.
    fs::copy(file_path, &temp_dir)?;

    // 3. Clearsign the temporary file, capturing the output.  Redirect stderr for error handling.
    let clearsign_output = StdCommand::new("gpg")
        .arg("--clearsign")
        .arg("--output")
        .arg("-") // Redirect to stdout
        .arg(&temp_dir)
        .stderr(std::process::Stdio::piped())
        .output()?;

    // Handle potential GPG errors.
    if !clearsign_output.status.success() {
        let stderr = String::from_utf8_lossy(&clearsign_output.stderr);
        return Err(ThisProjectError::GpgError(format!(
            "GPG clearsign failed: {}",
            stderr
        )));
    }
    let clearsigned_bytes = clearsign_output.stdout;

    // 4. Clean up the temporary file.
    fs::remove_file(&temp_dir)?; // TODO Handle potential error

    debug_log!(
        "(inHRCD)gpg_clearsign_file_to_sendbytes clearsigned_bytes {:?}",
        clearsigned_bytes
    );

    // 5. Return the encrypted, clearsigned bytes.
    Ok(clearsigned_bytes)
}

fn gpg_encrypt_to_bytes(data: &[u8], recipient_public_key: &str) -> Result<Vec<u8>, ThisProjectError> {
    debug_log!(
        "(inHRCD) STARTING @-|i|- gpg_encrypt_to_bytes() data {:?}",
        data
    );

    // 1. Create a temporary file for the public key.
    let mut temp_key_file = std::env::temp_dir();
    temp_key_file.push("uma_temp_key.asc");
    let mut file = File::create(&temp_key_file)?;
    file.write_all(recipient_public_key.as_bytes())?;

    debug_log!("(inHRCD) gpg_encrypt_to_bytes() temp_key_file path {:?}", temp_key_file);

    // 2. GPG encrypt, reading the recipient key from the temporary file.
    let mut gpg = StdCommand::new("gpg")
        .arg("--encrypt")
        .arg("--recipient-file")
        .arg(&temp_key_file)
        .stdin(Stdio::piped())       // Correct usage for stdin
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .spawn()?;


    // Write data to stdin.
    if let Some(mut stdin) = gpg.stdin.take() {
        stdin.write_all(data)?;
    } else {
        // Consider a better error type...
        return Err(ThisProjectError::GpgError("Failed to open GPG's stdin".into()));
    };

    let output = gpg.wait_with_output()?;

    debug_log!(
        "(inHRCD) gpg_encrypt_to_bytes() output {:?}",
        output
    );

    // 3. Clean up the temporary key file.
    remove_file(temp_key_file)?;

    if output.status.success() {
        Ok(output.stdout)
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(ThisProjectError::GpgError(format!("GPG encryption failed: {}", stderr)))
    }
}

/// Decrypts GPG-encrypted data from a byte slice using a provided GPG private key.
///
/// # Purpose
/// This function takes encrypted data as bytes and a GPG private key, and attempts to decrypt
/// the data using the GPG command-line tool. It handles the decryption process by creating
/// temporary files and using GPG in a non-interactive, batch mode.
///
/// # Security Considerations
/// - Temporary files are created and immediately deleted after use
/// - Uses batch mode to prevent interactive prompts
/// - Minimizes potential security risks associated with key handling
///
/// # Arguments
/// * `data` - A byte slice containing the encrypted data to be decrypted
/// * `your_gpg_key` - A string containing the GPG private key used for decryption
///
/// # Returns
/// * `Ok(Vec<u8>)` - The decrypted data as a vector of bytes if decryption is successful
/// * `Err(ThisProjectError)` - An error if decryption fails, with details about the failure
///
/// # Errors
/// This function can return errors in several scenarios:
/// - Invalid or incorrect GPG key
/// - Corrupted encrypted data
/// - GPG command-line tool not installed or accessible
/// - Insufficient permissions
/// - Temporary file creation or deletion failures
///
/// # Example
/// ```rust
/// let encrypted_data: &[u8] = // ... some encrypted bytes
/// let private_key: &str = // ... GPG private key
/// match gpg_decrypt_from_bytes(encrypted_data, private_key) {
///     Ok(decrypted_data) => {
///         // Use decrypted data
///         println!("Decryption successful!");
///     },
///     Err(e) => {
///         // Handle decryption error
///         eprintln!("Decryption failed: {:?}", e);
///     }
/// }
/// ```
///
/// # Notes
/// - Requires GPG to be installed on the system
/// - Temporary files are created in the system's temporary directory
/// - The function uses non-interactive GPG mode to prevent hanging on prompts
///
/// # Performance
/// - Creates temporary files for key and encrypted data
/// - Spawns a GPG subprocess for decryption
/// - Recommended for moderate-sized encrypted data
///
/// # Thread Safety
/// - Not guaranteed to be thread-safe due to temporary file creation
/// - Should be used with caution in multi-threaded contexts
fn gpg_decrypt_from_bytes(data: &[u8], your_gpg_key: &str) -> Result<Vec<u8>, ThisProjectError> {
    debug_log("gpg_decrypt_from_bytes()-1. Start! ");

    // 1. Create temporary files
    let mut temp_key_file = std::env::temp_dir();
    temp_key_file.push("uma_temp_privkey.asc");
    fs::write(&temp_key_file, your_gpg_key)?;

    let mut temp_encrypted_file = std::env::temp_dir();
    temp_encrypted_file.push("uma_temp_encrypted.gpg");
    fs::write(&temp_encrypted_file, data)?;

    // 2. Run GPG decryption
    let mut child = StdCommand::new("gpg")
        .arg("--decrypt")
        .arg("--batch")  // Non-interactive mode
        .arg("--yes")    // Assume yes to prompts
        .arg("--quiet")  // Minimal output
        .arg("--no-tty") // No terminal interaction
        .arg("-") // Read from stdin
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .spawn()?;

    // Write the encrypted data to the child process's standard input
    if let Some(stdin) = child.stdin.as_mut() {
        stdin.write_all(data)?;
        stdin.flush()?;
    }

    let output = child.wait_with_output()?;

    debug_log!("gpg_decrypt_from_bytes()-4. output {:?}", output);

    // 3. Remove temporary files (important for security)
    fs::remove_file(temp_key_file)?;
    fs::remove_file(temp_encrypted_file)?;

    // 4. Handle output and errors
    if output.status.success() {
        Ok(output.stdout)
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(ThisProjectError::GpgError(format!("GPG decryption failed: {}", stderr)))
    }
}

fn extract_clearsign_data(clearsigned_data: &[u8]) -> Result<Vec<u8>, ThisProjectError> {
    let clearsigned_string = String::from_utf8_lossy(clearsigned_data);

    // Split at the beginning of the signature
    let parts: Vec<&str> = clearsigned_string
        .split("-----BEGIN PGP SIGNATURE-----")
        .collect();

    if parts.len() < 2 {
        return Err(ThisProjectError::GpgError("Invalid clearsigned data: Missing signature".into()));
    }

    // Extract the message part (before the signature)
    let message_part = parts[0];

    // Split the message part by lines and skip the PGP header lines
    let message_lines: Vec<&str> = message_part
        .lines()
        .skip_while(|line|
            line.starts_with("-----BEGIN PGP SIGNED MESSAGE-----") ||
            line.starts_with("Hash:") ||
            line.trim().is_empty()
        )
        .collect();

    // Join the remaining lines
    let message_content = message_lines.join("\n");

    Ok(message_content.as_bytes().to_vec())
}

// TODO: this may be mostly right: directing to readcopy .toml?
// or... readcopy clearsigned toml?
// or... new struct serialized to .toml?
/// Prepares file contents for secure sending by clearsigning and encrypting them.
///
/// This function reads the contents of the file at the given `file_path`,
/// clearsigns the content using GPG to ensure integrity and non-repudiation,
/// and then encrypts the clearsigned content using the provided
/// `recipient_public_key` for confidentiality.
///
/// # Arguments
///
/// * `file_path`: The path to the file whose contents should be processed.
/// * `recipient_public_key`: The recipient's GPG public key used for encryption.
///
/// # Returns
///
/// * `Ok(Vec<u8>)`: A vector of bytes containing the encrypted, clearsigned file content on success.
/// * `Err(ThisProjectError)`: An error if file reading, clearsigning, or encryption fails.
fn wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes(
    file_path: &Path,
    recipient_public_key: &str
) -> Result<Vec<u8>, ThisProjectError> {

    // 1. Clearsign the file contents.
    let clearsigned_content = gpg_clearsign_file_to_sendbytes(file_path)?;

    // 2. Encrypt the clearsigned content.
    let encrypted_content = gpg_encrypt_to_bytes(&clearsigned_content, recipient_public_key)?;

    debug_log!(
        "(in HRCD) wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes  encrypted_content {:?}",
        &encrypted_content
    );

    Ok(encrypted_content)
}

/// string-mod: remove_non_alphanumeric
/// takes a string slice (&str) as input and returns a new String that
/// contains only the ASCII alphanumeric characters from the input string.
/// The original string is not modified.
///
fn remove_non_alphanumeric(s: &str) -> String {
    s.chars().filter(|c| c.is_ascii_alphanumeric()).collect()
}

// /// save for every member with access in channel...
// fn write_newfile_sendq_flag(
//     recipients_list: Vec<String>,
//     file_path: Path,
// ) {
//     team_channel_name = get_current_team_channel_name_from_nav_path();
//     // e.g. sync_data/teamtest/new_file_path_flags/bob}

//     // // maybe iterate through recipients_list

//     // 1. make paths (for each participant in list)
//     // make parent path if not yet exists

//     // 2. save files to paths

// }



/// Writes a new file send queue flag for each recipient in the given list.
///
/// Creates a flag file for each recipient in the `recipients_list` under the directory:
/// `sync_data/{team_channel_name}/sendqueue_updates/{recipient_name}/{timestamp_flagfile_name}.txt`,
/// where `filename` is the sanitized filename of `file_path`.
///
/// # Arguments
///
/// * `recipients_list`: A vector of recipient usernames.
/// * `file_path`: The path to the file to be added to the send queue.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on success, or a `ThisProjectError` if an error occurs during directory or file creation.
fn write_newfile_sendq_flag(
    recipients_list: &[String], // Use a slice for efficiency
    file_path: &Path, // Use a reference to avoid unnecessary cloning
) -> Result<(), ThisProjectError> {
    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

    let timestamp_flagfile_name = get_current_unix_timestamp();

    for recipient in recipients_list {
        let mut flag_path = PathBuf::from("sync_data");
        flag_path.push(&team_channel_name);
        flag_path.push("sendqueue_updates");
        flag_path.push(recipient);
        flag_path.push(format!("{}.txt", timestamp_flagfile_name));

        if let Some(parent_dir) = flag_path.parent() {
            create_dir_all(parent_dir)?;
        }

        let file_path_string = file_path.to_string_lossy(); // For writing to the flag file

        // Create flag file (empty file acts as a flag). Handle potential errors.
        match File::create(&flag_path) {
            Ok(mut file) => {
                if let Err(e) = file.write_all(file_path_string.as_bytes()) {
                    debug_log!(
                        "write_newfile_sendq_flag(): Error writing file path to flag file: {}",
                        e
                    );
                    return Err(e.into());  // Or handle error appropriately
                } else {
                    debug_log!("write_newfile_sendq_flag(): Flag file created: {:?} contents: {:?}", flag_path, file_path_string);

                }
            },
            Err(e) => {
                debug_log!(
                    "write_newfile_sendq_flag(): Error creating flag file: {}",
                    e
                );
                return Err(e.into());
            }
        }
    }
    Ok(())
}

/// Reads all new file send queue flags and cleans up the flag files.
///
/// This function reads all flag files in the directory
/// `sync_data/{team_channel_name}/sendqueue_updates/{remote_collaborator_name}/`
/// and returns the file paths contained within those flags as a vector.
/// After reading, it deletes all flag files to ensure they are processed only once.
///
/// # Arguments
///
/// * `remote_collaborator_name`: The name of the remote collaborator.
/// * `team_channel_name`: The name of the team channel.
///
/// # Returns
///
/// * `Result<Vec<PathBuf>, ThisProjectError>`: A vector of file paths on success, or a `ThisProjectError` if an error occurs during directory access or file operations.
fn read_all_newfile_sendq_flags_w_cleanup(
    remote_collaborator_name: &str,
    team_channel_name: &str,
) -> Result<Vec<PathBuf>, ThisProjectError> {
    let mut flag_dir = PathBuf::from("sync_data");
    flag_dir.push(team_channel_name);
    flag_dir.push("sendqueue_updates");
    flag_dir.push(remote_collaborator_name);

    let mut file_paths = Vec::new();

    // 1. Read all flag files and collect paths: Check if directory exists
    if flag_dir.exists() { // Only proceed if the directory exists
        match fs::read_dir(&flag_dir) {
            Ok(entries) => {
                for entry in entries.flatten() {  // Flatten to handle potential errors directly
                    let flag_file_path = entry.path();
                    if flag_file_path.is_file() {
                        match fs::read_to_string(&flag_file_path) {
                            Ok(file_path_str) => {
                                let file_path = PathBuf::from(file_path_str.trim()); //Important: trim whitespace!
                                file_paths.push(file_path);
                            }
                            Err(e) => {
                                debug_log!("Error reading flag file: {} - {}", flag_file_path.display(), e);
                                // Choose whether to continue or return an error:
                                return Err(e.into()); // Or continue;
                            }
                        }

                        // 2. Delete the flag file immediately after reading (cleanup): Handle errors
                        if let Err(e) = fs::remove_file(&flag_file_path) {
                            debug_log!("Error removing flag file: {} - {}", flag_file_path.display(), e);
                            // Handle the remove error if needed
                            // return Err(e.into()); // Or continue;
                        }
                    }
                }
            }
            Err(e) => {
                debug_log!(
                    "read_all_newfile_sendq_flags_w_cleanup: Error reading directory: {}",
                    e
                );
                return Err(e.into());
            }
        }


        // // 3. Remove directory if empty:  Handle errors
        // if fs::read_dir(&flag_dir)?.next().is_none() { // Directory is now empty
        //     if let Err(e) = fs::remove_dir(&flag_dir) { // Just remove the directory, not recursively
        //         debug_log!(
        //             "read_all_newfile_sendq_flags_w_cleanup: Error removing empty directory: {}",
        //             e
        //         );
        //         // Handle error, e.g., continue or return
        //         return Err(e.into());  // Or continue;
        //     }
        // }
    }


    Ok(file_paths)  // Return Ok with file paths or handle not existing as needed
}


// /// Add New Message File
// /// 1. create message .toml
// /// 2. save .toml to team-channel messages path
// /// 3. save that path as
// ///
// fn add_im_message(
//     incoming_file_path: &Path,
//     owner: &str,
//     text: &str,
//     signature: Option<String>,
//     graph_navigation_instance_state: &GraphNavigationInstanceState, // Pass local_user_metadata here
// ) -> Result<(), io::Error> {

//     // 1. Parse for {to:user} syntax
//     let mut recipients_list = graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access.clone();
//     if let Some(to_clause) = text.find("{to:") {
//         if let Some(end_brace) = text[to_clause..].find('}') {
//             let recipient_name = text[to_clause + 4..to_clause + end_brace].trim();
//             recipients_list.clear(); // Clear default list: restrict to listed recipient only

//             // 2. Check if recipient in team channel list and is not sender.
//             if graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access.contains(&recipient_name.to_string()) && recipient_name != owner {
//                 recipients_list.push(recipient_name.to_string()); // Add only the specified recipient
//             } else {
//                 // Log if user not found
//                 debug_log!("'to:' but Recipient '{}' not found in channel or is sender.", recipient_name);
//             }
//         }
//     }

//     // separate name and path
//     let parent_dir = if let Some(parent) = incoming_file_path.parent() {
//         parent
//     } else {
//         Path::new("")
//     };

//     // Now you can use `parent_dir` as needed
//     // For example, you can check if it's an empty string
//     if parent_dir == Path::new("") {
//         debug_log("The path has no parent directory.");
//     } else {
//         debug_log(&format!("parent directory  {:?}", parent_dir));
//     }

//     // Read 0.toml to get this instant messager browser room's settings
//     let metadata_path = parent_dir.join("0.toml"); // Assuming path is the message_posts_browser directory
//     let metadata_string = fs::read_to_string(metadata_path)?;
//     let metadata: NodeInstMsgBrowserMetadata = toml::from_str(&metadata_string)
//     .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("TOML deserialization error: {}", e)))?;

//     // Extract node name and file path
//     let node_name = metadata.node_name;
//     let filepath_in_node = metadata.path_in_node;
//     let message = MessagePostFile::new(
//         owner, // owner: &str,
//         &node_name, // node_name: &str, , // Add node name as a parameter
//         &filepath_in_node, // filepath_in_node: &str, , // Add filepath_in_node as a parameter
//         text, // text_message: &str,
//         signature, // signature: Option<String>,
//         graph_navigation_instance_state, // graph_navigation_instance_state: &GraphNavigationInstanceState,  // gets uma.toml data
//         recipients_list.clone(),
//         false, // messagepost_gpgtoml
//     );

//     // TODO: save updates here...
//     let toml_data = toml::to_string(&message).map_err(|e| {
//         io::Error::new(io::ErrorKind::Other, format!("TOML serialization error: {}", e))
//     })?; // Wrap TOML error in io::Error
//     fs::write(incoming_file_path, toml_data)?;


//     // Write update flag for each possible remote collaborator
//     // sync_data/teamtest/new_file_path_flags/bob
//     // sync_data/teamtest/new_file_path_flags/charlotte
//     // etc.
//     let _ = write_newfile_sendq_flag(
//         &recipients_list,
//         &incoming_file_path,
//     );

//     Ok(())
// }


/*

// Example usage (in file receiving):

// ... after receiving and decrypting a node file ...

// 1. Create lookup table:
let node_id_to_path = create_node_id_to_path_lookup(&team_channel_path)?;


// 2. Access node data (must match `node_unique_id_str` from `create_node_id_to_path_lookup`):
let node_unique_id_str = received_toml.get("node_unique_id").and_then(Value::as_str).map(|s| s.to_owned()).unwrap_or_default();
if let Some(existing_path) = node_id_to_path.get(&node_unique_id_str) {
    // Node exists, handle move/replace:

    // 3. Remove old node directory
    std::fs::remove_dir_all(existing_path)?;

    // ... (your node saving logic)
} else {
    // Node is new, save it:
    // ... (your node saving logic)

}
*/
/// Creates a lookup table of node unique IDs to their full file paths.
///
/// This function iterates through the team channel directory, identifies node directories (those containing a `node.toml` file),
/// extracts the node's unique ID from the `node.toml`, and stores the ID and full file path in a HashMap.
///
/// # Arguments
///
/// * `team_channel_path`: The path to the team channel directory.
///
/// # Returns
///
/// * `Result<HashMap<String, PathBuf>, ThisProjectError>`:  A HashMap mapping node unique IDs to their paths, or a `ThisProjectError` if an error occurs.
fn create_node_id_to_path_lookup(
    team_channel_path: &Path,
) -> Result<HashMap<String, PathBuf>, ThisProjectError> {
    let mut node_lookup: HashMap<String, PathBuf> = HashMap::new();

    for entry in WalkDir::new(team_channel_path) {
        let entry = entry?;
        let path = entry.path();

        if path.is_dir() { // A. Nodes only (directories)
            let node_toml_path = path.join("node.toml");
            if node_toml_path.exists() {
                // Found a node directory
                let toml_string = std::fs::read_to_string(&node_toml_path)?;

                // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                let toml_value: Value = toml::from_str(&toml_string)?;

                // B. Extract node unique ID
                // let node_unique_id = toml_value.get("node_unique_id").and_then(Value::as_integer).unwrap_or(0) as u64;

                // Updated to get unique_id as hex_string:
                let node_unique_id_str = toml_value.get("node_unique_id").and_then(Value::as_str).map(|s| s.to_owned()).unwrap_or_default();
                if node_unique_id_str.is_empty() {
                    continue; // Skip this node if no valid ID
                }


                // C. Get full file path
                let full_path = path.to_path_buf();

                // Add to lookup table:
                node_lookup.insert(node_unique_id_str, full_path);
            }
        }
    }

    Ok(node_lookup)
}


// // early alpha, maybe entirely wrong!
// // use std::collections::HashMap;
// // use std::fs::{self, DirEntry, File};  // Import DirEntry and File
// // use std::io;
// // use std::path::{Path, PathBuf};
// // use toml::Value; // Import the Value type
// // // ... other imports (e.g., for your tiny_tui)
// /// t is for task
// fn display_task_browser(current_node_path: &Path) -> bool {
//     let task_browser_dir = current_node_path.join("task_browser");

//     let mut columns: HashMap<String, HashMap<u32, PathBuf>> = HashMap::new();
//     let mut column_entries: Vec<DirEntry> = Vec::new(); // Correct type

//     // 1. Column Discovery and Default Creation
//     if let Ok(entries) = fs::read_dir(&task_browser_dir) {
//         for entry in entries.flatten() {
//             if entry.path().is_dir() && entry.file_name().to_string_lossy().starts_with("#_") {
//                 column_entries.push(entry);
//             }
//         }
//     }


//     // Create default columns if none exist:  Create DirEntry objects
//     if column_entries.is_empty() {
//         for default_col in ["#_plan", "#_started", "#_done"] {
//             let path = task_browser_dir.join(default_col);
//             fs::create_dir_all(&path).expect("Failed to create default column directory");

//             // Manually create DirEntry (workaround for read_dir not returning defaults immediately after creation):
//             let entry = fs::read_dir(&task_browser_dir).unwrap().find(|entry| {
//                 entry.as_ref().unwrap().file_name().to_string_lossy() == default_col
//             }).unwrap(); // safe unwrap inside this specific context.

//             // column_entries.push(entry);
//             column_entries.push(entry.expect("REASON"));

//         }
//     }

//     column_entries.sort_by_key(|entry| entry.file_name());

//     // Create HashMap and populate task data
//     for entry in column_entries {
//         let column_name = entry.file_name().to_string_lossy()[2..].to_string(); // Remove "#_"
//         let column_dir = task_browser_dir.join(entry.file_name()); // For task iteration inside this column
//         let mut task_map: HashMap<u32, PathBuf> = HashMap::new();
//         let mut task_counter = 1;

//         // Load tasks for this column:
//         if let Ok(task_entries) = fs::read_dir(column_dir) {
//             for task_entry in task_entries.flatten() {
//                 if task_entry.path().is_dir() { // tasks are directories, not files
//                     let task_path = task_entry.path();
//                     task_map.insert(task_counter, task_path);
//                     task_counter += 1;
//                 }
//             }
//         }

//         columns.insert(column_name, task_map);
//     }

//     // 3. Display and Interaction
//     // ... (Use tiny_tui or other method to display columns and tasks)

//     loop {
//         // ... (Display the task browser TUI using the 'columns' HashMap) ...
//         let input = tiny_tui::get_input().expect("Failed to get input");

//         if let Ok(task_number) = input.parse::<u32>() {
//             // Find the task based on number:
//             for (column_name, task_map) in &columns {
//                 if let Some(task_path) = task_map.get(&task_number) {

//                     //Example: View Task Details
//                     let node_toml_path = task_path.join("node.toml");
//                     let toml_string = fs::read_to_string(node_toml_path).expect("Failed to read TOML");
//                     let toml_value: Value = toml::from_str(&toml_string).expect("Failed to parse TOML");
//                     println!("Task Details:\n{:#?}", toml_value);  //Use {:#?} for pretty print

//                     // ... (Handle other task interactions: edit, move, etc.)...
//                     break; // Task found, exit inner loop
//                 }
//             }


//         } else if input.to_lowercase() == "q" || input.to_lowercase() == "quit" {
//              break; //Exit the task browser loop
//         } else {
//             // Handle other commands or invalid input
//              println!("Invalid command or task number.");
//         }
//     }
//     return false;
// }

/// Finds the path to a GPG public key file (`.asc` extension) in the specified directory.
///
/// Returns `Ok(Some(path))` if a `.asc` file is found, `Ok(None)` if no `.asc` file is found,
/// and `Err(_)` if there's an error reading the directory.
fn find_gpg_public_key_file(directory: &Path) -> Result<Option<PathBuf>, ThisProjectError> {
    let entries = fs::read_dir(directory)?;

    for entry in entries {
        let entry = entry?; // Handle potential errors during directory iteration
        let path = entry.path();
        if path.is_file() && path.extension().map_or(false, |ext| ext == "asc") {
            return Ok(Some(path));
        }
    }

    Ok(None) // No .asc file found
}

// fn get_local_owner_user_name() -> String {
//     let uma_toml_path = Path::new("uma.toml");
//     // let user_metadata = toml::from_str::<toml::Value>(&std::fs::read_to_string(uma_toml_path)?)?;
//     let user_metadata = toml::from_str::<toml::Value>(&std::fs::read_to_string(uma_toml_path)?)
//     .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("TOML deserialization error: {}", e)))?;
//     let local_owner_username = user_metadata["uma_local_owner_user"].as_str().unwrap().to_string();

//     local_owner_username
// }

// OLD relative path
// fn get_local_owner_username() -> String {  // Returns String directly
//     debug_log("starting get_local_owner_username()");
//     let uma_toml_path = Path::new("uma.toml");

//     let toml_string = read_to_string(uma_toml_path).unwrap_or_else(|e| {
//         eprintln!("Error reading uma.toml: {}", e); // Log the error
//         std::process::exit(1); // Or handle differently, but exit if no config is a show stopper.
//     });

//     let toml_value: toml::Value = toml::from_str(&toml_string).unwrap_or_else(|e| {
//         eprintln!("Error parsing uma.toml: {}", e);
//         std::process::exit(1);  // If your application cannot continue without a username...
//     });

//     toml_value["uma_local_owner_user"]
//         .as_str()
//         .unwrap_or_else(|| {
//             eprintln!("'uma_local_owner_user' not found in uma.toml"); // Handle the error
//             std::process::exit(1);
//         })
//         .to_string()
// }

/// Retrieves the local owner username from the uma.toml configuration file.
///
/// # Returns
///
/// A String containing the username if successful, or an empty string if any error occurs.
fn get_local_owner_username() -> String {
    debug_log!(
        "___ Step 1: Reading LOCAL OWNER USER's name from {}",
        UMA_TOML_CONFIGFILE_PATH_STR,
    );

    // Get absolute path to uma.toml configuration file
    let absolute_uma_toml_path = match make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(
        UMA_TOML_CONFIGFILE_PATH_STR
        ) {
        Ok(path) => path,
        Err(e) => {
            println!("Error: ___ Failed to locate uma.toml configuration file: {}", e);
            return String::new(); // Return empty string on error
        }
    };

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = match absolute_uma_toml_path.to_str() {
        Some(path_str) => path_str,
        None => {
            println!("Error: __ Unable to convert UMA TOML path to string");
            return String::new(); // Return empty string on error
        }
    };

    // Read LOCAL OWNER USER's name from uma.toml
    match read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ) {
        Ok(username) => {
            debug_log!("___ LOCAL OWNER USER's name is: {}", username);
            username  // Return the username string on success
        },
        Err(e) => {
            println!("Error: ___ Failed to read LOCAL OWNER USER's name: {}", e);
            String::new()  // Return empty string on error
        }
    }
}

// TODO maybe various updatesand fixes, how files read, paths
// TODO doc string needed here...
fn export_addressbook() -> Result<(), ThisProjectError> {
    debug_log("start export_addressbook()");

    // 1. Get local owner's username
    // 1. Get local owner's username
    // Read uma_local_owner_user from uma.toml
    // maybe add gpg and make this a separate function TODO
    // Load UMA configuration from uma.toml
    // let uma_toml_path = Path::new("uma.toml");

    // // For exe-parent-relative Absolute paths:
    // 1. Get local owner's username (from exe-parent absolute path file)
    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("___ Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            io::Error::new(io::ErrorKind::InvalidData, error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "__ Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            io::Error::new(io::ErrorKind::InvalidData, error_msg)
        })?;


    // // let user_metadata = toml::from_str::<toml::Value>(&std::fs::read_to_string(uma_toml_path)?)?;
    // // let user_metadata = toml::from_str::<toml::Value>(&std::fs::read_to_string(uma_toml_path)?)
    // let user_metadata = toml::from_str::<toml::Value>(&std::fs::read_to_string(absolute_uma_toml_path_str)?)
    // .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("TOML deserialization error: {}", e)))?;
    // let local_owner_username = user_metadata["uma_local_owner_user"].as_str().unwrap().to_string();


    // Read LOCAL OWNER USER's name from uma.toml
    let local_owner_username = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("___ Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    debug_log!("export_addressbook() local_owner_username is: {}", local_owner_username);

    // 2. Construct paths
    let address_book_export_dir = PathBuf::from("invites_updates/addressbook_invite/export");
    let key_file_path = address_book_export_dir.join("key.asc");
    let collaborator_file_path = PathBuf::from(COLLABORATOR_ADDRESSBOOK_PATH_STR)
        .join(format!("{}__collaborator.toml", local_owner_username));

    // 3. Read public key (early return on error).  Handles NotFound.
    let public_key_string = match read_to_string(&key_file_path) {
        Ok(key) => key,
        Err(e) if e.kind() == std::io::ErrorKind::NotFound => {
            debug_log!("Public key file ('key.asc') not found. Skipping address book export.");
            return Ok(()); // Return Ok if the file isn't found, not continuing.
        },
        Err(e) => return Err(ThisProjectError::IoError(e)),
    };

    // 4. Clearsign collaborator file
    let clearsign_output = StdCommand::new("gpg")
        .arg("--sign")
        .arg(&collaborator_file_path)
        .output()?;


    // Error handling: (exit early on error)
    if !clearsign_output.status.success() {
        let stderr = String::from_utf8_lossy(&clearsign_output.stderr);
        return Err(ThisProjectError::GpgError(format!("GPG clearsign failed: {}", stderr)));
    }
    let clearsigned_data = clearsign_output.stdout;

    // 5. Encrypt clearsigned data
    let encrypted_data = encrypt_with_gpg(&clearsigned_data, &public_key_string)?;

    // 6. Create export directory if it doesn't exist
    let export_dir = PathBuf::from("invites_updates/addressbook_invite/export");
    create_dir_all(&export_dir)?;

    // 7. Write encrypted data to file. Use a timestamp to avoid overwriting.
    let export_file_path = export_dir.join(format!(
        "{}_addressbook_{}.gpgtoml",
        local_owner_username,
        get_current_unix_timestamp() // Or use a UUID
    ));
    let mut file = File::create(&export_file_path)?;
    file.write_all(&encrypted_data)?;

    debug_log("export complete");

    Ok(())
}

/// ## State, Initialization & Network
/// If as a vignette, let's look at a brief walkthrough of Alice starting up Uma as she embarks on a build with Bob.
///
/// 1. Alice starts Uma
/// 2. Uma run initialization:
/// Initialization checks:
/// - is this the first time (here we will assume it is not the first setup)
/// (perhaps, is there a hash-salt to check the uma.toml configuration file)
/// - node-graph navigation is set up as starting from square one: location is ~home_square_one=true, because Alice has not yet picked which team_channel she wants to use/sync-with/view/join/enter however said.
/// - a mostly blank ~GraphNavigationState is filled-in (or filled-out)
/// - CWD (current working directory (path)) is set to home_square_one, which is not in any team_channel
/// - a basic home_square_one TUI is displayed showing what team_channels Alice can join/view/enter etc. (ones she has been invited to and has been sent and has loaded the team_channel configuration files for)
/// - Uma listens for Alice's 'command' which can be the number of a listed team_channel (to go to) or options such as log-view, quit, help, make a new team, etc.
/// - Alice picks alice_and_bobs_best_team_ever channel, option: "1"
/// Now Uma needs to do three important things:
/// 1. Uma needs to update graph navigation as with any 'move' within the dungeon-of-rooms of graph nodes.
/// 2. Uma needs change from being at home-base-square-one (no context for 'state') to being in a channel with users and configurations: there is now 'state' to fill-in for the ~graph_navigation_state.
/// 3. Uma needs to set up the uma_network, which in particular involves:
/// - getting the 'actual list' of collaborators in that team-channel to connect with (which is an intersection of the team-owner's (potential) team-members list and Alice's actual whole 'address-book' of all real contacts on all teams.
/// - uma_network needs the port-assignments from the team_channel toml (set by the team-owner, so there is no port-collision or source-of-truth mixup)
/// - uma_network needs the ip (ipv6, ipv4, etc.) for each collaborator, which comes from that collaborator-owned toml (and probably that collaborator's public gpg key)
///
/// Note: If Alice returns to home, all this 'state' is deleted and Uma returns to home-square-one as if she restarted the program. (In fact...it might even be easiest to literally restart to make that process clean.)
///
/// ip availability is also read and recorded in sync-state stored
/// as a combined-index that included type data (hopefully works with other signal types too)
/// return true for online, false for offline
fn initialize_uma_application() -> Result<bool, Box<dyn std::error::Error>> {
    // Welcome to Uma Land!!
    debug_log("Staring initialize_uma_application()");

    // --- 1. CHECK FOR & SETUP uma.toml ---
    // let uma_toml_path = Path::new("uma.toml");


    // Check for uma.toml file relative to the executable's directory
    let uma_toml_path_result = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(
        UMA_TOML_CONFIGFILE_PATH_STR
    );

    // // Handle the result appropriately
    // let uma_toml_path = match uma_toml_path_result {
    //     Ok(file_path) => {
    //         // File exists, we can proceed with using it
    //         debug_log!("Found uma.toml at: {:?}", file_path);
    //         file_path
    //     },
    //     Err(io_error) => {
    //         if io_error.kind() == std::io::ErrorKind::NotFound {
    //             // File doesn't exist - handle this specific case
    //             return Err(format!("Configuration file uma.toml not found in executable directory").into());
    //         } else if io_error.kind() == std::io::ErrorKind::InvalidInput {
    //             // Path exists but is a directory
    //             return Err(format!("uma.toml exists but is a directory, not a file").into());
    //         } else {
    //             // Other I/O errors
    //             return Err(format!("Error accessing uma.toml: {}", io_error).into());
    //         }
    //     }
    // };

    // This will pass an empty 'uma_toml_path' ahead if initial setup is needed
    let uma_toml_path = match uma_toml_path_result {
        Ok(file_path) => {
            // Path is valid (whether file exists or not)
            debug_log!("Determined uma.toml path at: {:?}", file_path);
            file_path
        },
        Err(io_error) => {
            // Only treat certain errors as fatal
            if io_error.kind() == std::io::ErrorKind::InvalidInput {
                // Path exists but is a directory
                return Err(format!("uma.toml exists but is a directory, not a file").into());
            } else if io_error.kind() == std::io::ErrorKind::NotFound {
                // For first-time setup, NotFound is expected - construct the default path
                let mut default_path = std::env::current_exe().map_err(|e|
                    format!("Failed to determine executable path: {}", e)
                )?;
                default_path.pop(); // Remove executable name
                default_path.push(UMA_TOML_CONFIGFILE_PATH_STR);
                debug_log!("Using default uma.toml path: {:?}", default_path);
                default_path
            } else {
                // Other I/O errors
                return Err(format!("Error accessing uma.toml: {}", io_error).into());
            }
        }
    };

    // looks to see if setup is needed
    if !uma_toml_path.exists() {
        /*
        This uses the struct method 'new' to make a standard
        default but name-less file
        then Q&A user into sets that owner-name.

        either way, 'owner' needs to be available
        if a new chanel needs to be created (as the owner)
        */
        // Prompt for owner and create uma.toml
        println!("Welcome to the Uma Collaboration Tools.");
        println!("Please enter your username.");
        println!("This nickname will be the local-owner-user for this Uma 'instance.'");
        println!("Changing 'uma_local_owner_user = ___' in uma.toml");
        println!("will change the local-owner-user when running Uma.");
        println!("Please enter your username:");

        // let mut owner_input = String::new();
        // io::stdin().read_line(&mut owner_input).unwrap();  // TODO remove this unwrap!!!!!!!!!!!!!!!!!!!!!

        // let owner = owner_input.trim().to_string();

        // let local_user_metadata = LocalUserUma::new(owner); // Create LocalUserUma

        // if let Err(e) = local_user_metadata.save_owner_to_file(&uma_toml_path) {
        //     eprintln!("Failed to create uma.toml: {}", e);
        //     // Handle the error (e.g., exit gracefully)
        //     return Ok(false);
        // }


        // // Get armored public key, using key-id (full fingerprint in)
        // let mut full_fingerprint_key_id_string = String::new();
        // match q_and_a_user_selects_gpg_key_full_fingerprint() {
        //     Ok(temp_fullfingerprint_key_idstring) => {

        //         println!("Selected key id (full fingerprint in): {}", temp_fullfingerprint_key_idstring);
        //         full_fingerprint_key_id_string = temp_fullfingerprint_key_idstring;
        // }
        //     Err(e) => eprintln!("Error selecting full_fingerprint_key_id_string: {}", e.to_string()),
        // }

        // Initialize Uma configuration
        // println!("Welcome to the Uma Collaboration Tools.");
        // println!("Please enter your username.");
        // println!("This nickname will be the local-owner-user for this Uma 'instance.'");
        // println!("Changing 'uma_local_owner_user = ___' in uma.toml");
        // println!("will change the local-owner-user when running Uma.");
        // println!("Please enter your username:");

        // Read owner username with error handling
        let mut owner_input = String::new();
        if let Err(e) = io::stdin().read_line(&mut owner_input) {
            eprintln!("Failed to read username input: {}", e);
            return Ok(false);
        }
        let owner = owner_input.trim().to_string();

        // Validate owner input
        if owner.is_empty() {
            eprintln!("Username cannot be empty");
            return Ok(false);
        }

        // Get GPG key fingerprint
        let full_fingerprint_key_id_string = match q_and_a_user_selects_gpg_key_full_fingerprint() {
            Ok(fingerprint) => {
                println!("Selected key id (full fingerprint): {}", fingerprint);
                fingerprint
            }
            Err(e) => {
                eprintln!("Error selecting GPG key fingerprint: {}", e);
                return Ok(false);
            }
        };

        // Create LocalUserUma instance with both required fields
        let local_user_metadata = LocalUserUma::new(owner, full_fingerprint_key_id_string);

        // Save configuration to uma.toml file
        if let Err(e) = local_user_metadata.save_to_uma_toml_file(&uma_toml_path) {
            eprintln!("Failed to create uma.toml: {}", e);
            return Ok(false);
        }

        debug_log!("uma.toml created successfully!");
    }





    // // ... 2. Load user metadata from the now-existing uma.toml
    // let user_metadata = match toml::from_str::<LocalUserUma>(&fs::read_to_string(&uma_toml_path)?) {
    //     Ok(metadata) => {
    //         debug_log!("uma.toml loaded successfully!");
    //         metadata
    //     },
    //     Err(e) => {
    //         eprintln!("Failed to load or parse uma.toml: {}", e);
    //         return Ok(false);
    //     }
    // };

    // // Set the uma_local_owner_user from the loaded metadata
    // let uma_local_owner_user = user_metadata.uma_local_owner_user;


    // Read only the owner username from uma.toml
    let uma_local_owner_user = match LocalUserUma::read_owner_from_file() {
        Ok(owner) => {
            debug_log!("Owner username loaded successfully: {}", owner);
            owner
        },
        Err(e) => {
            eprintln!("Failed to read owner username from uma.toml: {}", e);
            return Ok(false);
        }
    };

    // // ... 2. Load user metadata from the now-existing uma.toml
    // let user_metadata = match toml::from_str::<LocalUserUma>(&fs::read_to_string(uma_toml_path)?) {
    //     Ok(metadata) => {
    //         debug_log!("uma.toml loaded successfully!");
    //         metadata
    //     },
    //     Err(e) => {
    //         eprintln!("Failed to load or parse uma.toml: {}", e);
    //         return Ok(false);
    //     }
    // };


    // TODO
    // // --- 3. CHECK FOR PORT COLLISIONS ---
    // // You can now safely access user_metadata.uma_local_owner_user if needed
    // if let Err(e) = check_all_ports_in_team_channels() {
    //     eprintln!("Error: {}", e);
    //     debug_log!("Error: {}", e);
    //     return;
    // }

    // // ... 4. CREATE DIRECTORIES ---


    // old relative path version, depricated
    // // Check if the data directory exists
    // let project_graph_directory = Path::new("project_graph_data");
    // if !project_graph_directory.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(project_graph_directory).expect("Failed to create project_graph_data directory");
    // }


    // using path relative to exe-parent:
    // Ensure directory exists relative to the executable
    let project_graph_directory_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("project_graph_data");

    // Handle any errors that might occur during directory creation or verification
    let project_graph_directory = match project_graph_directory_result {
        Ok(directory_path) => directory_path,
        Err(io_error) => {
            // Log the error and handle appropriately for your application
            return Err(format!("Failed to ensure project graph directory exists: {}", io_error).into());
        }
    };

    debug_log!("IUA: project_graph_directory -> {:?}", project_graph_directory);


    // // Check if the data directory exists
    // let invite_parent_folder = Path::new("import_export_invites");
    // if !invite_parent_folder.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(invite_parent_folder).expect("Failed to create import_export_invites directory");
    // }


    // // Check if the data directory exists
    // let library_clearsign = Path::new("library_clearsign");
    // if !library_clearsign.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(library_clearsign).expect("Failed to create library_clearsign directory");
    // }

    // // Check if the data directory exists
    // let library_clearsignteam_channels = Path::new("library_clearsign/team_channels");
    // if !library_clearsignteam_channels.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(library_clearsignteam_channels).expect("Failed to create library_clearsignteam_channels directory");
    // }

    // // Check if the data directory exists
    // let library_clearsignaddressbook = Path::new("library_clearsign/addressbook");
    // if !library_clearsignaddressbook.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(library_clearsignaddressbook).expect("Failed to create library_clearsignaddressbook directory");
    // }

    // // Check if the data directory exists
    // let library_clearsign = Path::new("library_clearsign");
    // if !library_clearsign.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(library_clearsign).expect("Failed to create library_clearsign directory");
    // }


    // // Check if the data directory exists
    // let addressbook_invite = Path::new("invites_updates/incoming");
    // if !addressbook_invite.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(addressbook_invite).expect("Failed to create addressbook_invite directory");
    // }

    // // Check if the data directory exists
    let invites_incoming_pathbuf =  make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        "invites_updates/incoming"
    );

    // // Check if the data directory exists
    // let invites_outgoing_pathbuf = Path::new("invites_updates/outgoing");
    // if !invites_outgoing_pathbuf.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(invites_outgoing_pathbuf).expect("Failed to create invites_outgoing_pathbuf directory");
    // }

    // // Check if the data directory exists
    let invites_outgoing_pathbuf =  make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        "invites_updates/outgoing"
    );


    // // Check if the data directory exists
    // let invites_outgoing_pathbuf = Path::new("invites_updates/invites_outgoing_pathbuf/export");
    // if !invites_outgoing_pathbuf.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(invites_outgoing_pathbuf).expect("Failed to create invites_outgoing_pathbuf directory");
    // }

    // not yet working
    // export_addressbook()?;


    // TODO
    // look for a file in import_export_invites/addressbook_invite/export
    // try to read it as a gpg key
    // export your addressbook file clearsigned by you and encrypted with the public gpg key in that file

    // // relative version
    // // Check if the sync_data directory exists,
    // // and recursively erase all old files.
    // // This is 'session' state for sync which must
    // // be new each start-up session.
    // // Make a fresh session sync directory
    // // note: each 'local instance' should be specific
    // // to the location of the uma executable file
    // // more than one user may be running on a given computer
    // let sync_data_directory = Path::new("sync_data");
    // if sync_data_directory.exists() {
    //     // If the directory exists, remove it recursively
    //     if let Err(e) = remove_dir_all(sync_data_directory) {
    //         // Handle the error appropriately, e.g., log it and continue, or return an error if you want to stop initialization
    //         debug_log!("Error removing sync_data directory: {}", e);
    //         // Or: return Err(e.into()); // Or handle the error differently
    //     }
    // }
    // // Create the directory fresh for the new session.
    // fs::create_dir_all(sync_data_directory).expect("Failed to create sync_data directory");


    // Check if the sync_data directory exists relative to the executable location,
    // and recursively erase all old files.
    // This is 'session' state for sync which must
    // be new each start-up session.
    // Make a fresh session sync directory.
    // note: each 'local instance' should be specific
    // to the location of the uma executable file
    // more than one user may be running on a given computer.
    // Using executable-relative paths ensures that multiple instances running
    // from different locations won't interfere with each other's sync data.

    // Get the path to the sync_data directory relative to the executable's location
    let sync_data_directory_result = make_input_path_name_abs_executabledirectoryrelative_nocheck("sync_data");

    match sync_data_directory_result {
        Ok(sync_data_directory) => {
            // Check if the directory exists
            match abs_executable_directory_relative_exists(&sync_data_directory) {
                Ok(exists) => {
                    if exists {
                        // Directory exists, remove it recursively to start fresh
                        debug_log!("Clearing existing sync_data directory at: {}", sync_data_directory.display());
                        if let Err(remove_err) = remove_dir_all(&sync_data_directory) {
                            // Handle the error appropriately, log it and continue
                            debug_log!("Error removing sync_data directory: {}", remove_err);
                            // We'll still attempt to create the directory below
                        }
                    }

                    // Create the directory fresh for the new session, whether it was previously
                    // removed successfully or didn't exist at all
                    match fs::create_dir_all(&sync_data_directory) {
                        Ok(_) => {
                            debug_log!("Successfully created fresh sync_data directory at: {}", sync_data_directory.display());
                        },
                        Err(create_err) => {
                            // This is a more serious error as we need the directory
                            debug_log!("Critical error: Failed to create sync_data directory: {}", create_err);
                            // Depending on app requirements, you might want to handle this more severely
                            // or implement a fallback mechanism
                        }
                    }
                },
                Err(check_err) => {
                    debug_log!("Error checking if sync_data directory exists: {}", check_err);
                    // Attempt to create the directory anyway
                    if let Err(create_err) = fs::create_dir_all(&sync_data_directory) {
                        debug_log!("Critical error: Failed to create sync_data directory: {}", create_err);
                    }
                }
            }
        },
        Err(path_err) => {
            // Failed to determine the executable-relative path
            debug_log!("Error determining sync_data directory path: {}", path_err);

            // Fallback to using a relative path as a last resort
            let fallback_sync_data_directory = Path::new("sync_data");
            debug_log!("Falling back to current directory relative path for sync_data");

            if fallback_sync_data_directory.exists() {
                if let Err(remove_err) = remove_dir_all(fallback_sync_data_directory) {
                    debug_log!("Error removing fallback sync_data directory: {}", remove_err);
                }
            }

            if let Err(create_err) = fs::create_dir_all(fallback_sync_data_directory) {
                debug_log!("Critical error: Failed to create fallback sync_data directory: {}", create_err);
                // This is a critical failure point - consider how your application should handle it
            }
        }
    }

    /////////////////////
    // Log Housekeeping
    /////////////////////
    debug_log("IUA: Log Housekeeping");

    // 1. Create the archive directory if it doesn't exist, relative to the executable.
    // This directory stores archived logs and is not intended for syncing
    let archive_dir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("uma_archive/logs");

    let uma_archive_dir = match archive_dir_result {
        Ok(dir_path) => dir_path,
        Err(io_error) => {
            eprintln!("Warning: Failed to create uma_archive/logs directory: {}", io_error);
            // Create a fallback directory in case the executable-relative path fails
            let mut fallback_dir = PathBuf::new();
            fallback_dir.push("uma_archive");
            fallback_dir.push("logs");

            // Try to create the fallback directory
            if !fallback_dir.exists() {
                if let Err(e) = fs::create_dir_all(&fallback_dir) {
                    eprintln!("Critical: Failed to create fallback archive directory: {}", e);
                    // Return a sensible default to allow the program to continue
                    PathBuf::from("uma_archive/logs")
                } else {
                    fallback_dir
                }
            } else {
                fallback_dir
            }
        }
    };

    // 2. Get the current timestamp.
    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_else(|_| {
            eprintln!("Warning: System time appears to be before Unix epoch");
            std::time::Duration::from_secs(0) // Fallback to epoch if time is weird
        })
        .as_secs();

    // 3. Construct the new archive file path.
    let archived_log_path = uma_archive_dir.join(format!("uma__{}.log", timestamp));
    debug_log!("IUA archived_log_path -> {:?}", archived_log_path);

    // 4. Get the source log file path relative to the executable
    let source_log_path_result = make_input_path_name_abs_executabledirectoryrelative_nocheck("uma.log");

    match source_log_path_result {
        Ok(source_log_path) => {
            // Check if the source log file exists before trying to rename it
            if Path::new(&source_log_path).exists() {
                // Rename (move) the uma.log file to the archive directory
                if let Err(e) = fs::rename(&source_log_path, &archived_log_path) {
                    eprintln!("Failed to archive uma.log: {}", e);
                    // Handle the error, but don't stop initialization.
                }
            } else {
                // No log file to archive, this might be the first run
                eprintln!("Notice: No uma.log file found to archive");
            }
        },
        Err(io_error) => {
            // Log the error and continue
            eprintln!("Warning: Failed to determine uma.log path: {}", io_error);
            debug_log!("Could not archive log file: Failed to determine executable-relative path");
            // Do NOT attempt with a relative path - just continue the program
            // No fallback to a relative path - this would defeat the purpose
        }
    }

    // relative path version
    // /////////////////////
    // // Log Housekeeping
    // /////////////////////

    // // 1. Create the archive directory if it doesn't exist.
    // // saves archives not in the project_graph_data directory, not for sync
    // let mut uma_archive_dir = PathBuf::new(); // Start with an empty PathBuf safe path os
    // uma_archive_dir.push("uma_archive");    // Push the 'uma_archive' directory
    // uma_archive_dir.push("logs");            // Push the 'logs' subdirectory

    // if !uma_archive_dir.exists() {
    //     fs::create_dir_all(&uma_archive_dir).expect("Failed to create uma_archive directory");
    // }

    // // 2. Get the current timestamp.
    // let timestamp = SystemTime::now()
    //     .duration_since(UNIX_EPOCH)
    //     .expect("Time went backwards!")
    //     .as_secs();

    // // 3. Construct the new archive file path.
    // let archived_log_path = uma_archive_dir.join(format!("uma__{}.log", timestamp));

    // // 4. Rename (move) the uma.log file to the archive directory.
    // if let Err(e) = fs::rename("uma.log", &archived_log_path) {
    //     eprintln!("Failed to archive uma.log: {}", e); // Handle the error, but don't stop initialization.
    // }


    debug_log("next IUA runs fn  check_all_ports_in_team_channels()");

    // Check for port collisions across all team channels
    if let Err(e) = check_all_ports_in_team_channels_clearsign_validated() {
        eprintln!("Error: {}", e); // Print the error message
        debug_log!("Error: {}", e);
        // Handle the error as needed (e.g., exit UMA)
        return Ok(false);
    }

    debug_log("next IUA get_local_ip_addresses");
    get_local_ip_addresses();



    debug_log("next IUA ensure some dirs exist");


    /////////////////////////////
    // ensure directories exist
    /////////////////////////////

    // assumes 'project_graph_directory' path is exe-parent based
    // Ensure project_graph_data/team_channels directory exists
    let team_channels_dir = project_graph_directory.join("team_channels");
    if !team_channels_dir.exists() {
        fs::create_dir_all(&team_channels_dir).expect("Failed to create team_channels directory");
    }

    debug_log!("IUA: team_channels_dir -> {:?}", team_channels_dir);


    // Get the UME temp directory path with error handling
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| format!(
            "Failed to get UME temp directory path: {:?}",
            io_err
        ))?;

    // Ensure base_uma_temp_directory_path exists
    if !base_uma_temp_directory_path.exists() {
        fs::create_dir_all(&base_uma_temp_directory_path).expect("Failed to create base_uma_temp_directory_path directory");
    }

    debug_log!("IUA: base_uma_temp_directory_path -> {:?}", base_uma_temp_directory_path);

    // // using path relative to exe-parent:
    // // Ensure directory exists relative to the executable
    // let team_channelsdir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("team_channels");

    // // Handle any errors that might occur during directory creation or verification
    // let team_channels_dir = match team_channelsdir_result {
    //     Ok(directory_path) => directory_path,
    //     Err(io_error) => {
    //         // Log the error and handle appropriately for your application
    //         return Err(format!("Failed to ensure team_channels directory exists: {}", io_error).into());
    //     }
    // };


    // assumes 'project_graph_directory' path is exe-parent based
    // Ensure COLLABORATOR_ADDRESSBOOK_PATH_STR directory exists
    let collaborator_files_address_book_dir = project_graph_directory.join("collaborator_files_address_book");
    if !collaborator_files_address_book_dir.exists() {
        fs::create_dir_all(&collaborator_files_address_book_dir).expect("Failed to create collaborator_files_address_book directory");
    }

    // // using path relative to exe-parent:
    // // Ensure directory exists relative to the executable
    // let collaborator_files_addressbook_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("collaborator_files_address_book");

    // // Handle any errors that might occur during directory creation or verification
    // let collaborator_files_address_book_dir = match collaborator_files_addressbook_result {
    //     Ok(directory_path) => directory_path,
    //     Err(io_error) => {
    //         // Log the error and handle appropriately for your application
    //         return Err(format!("Failed to ensure collaborator_files_address_book directory exists: {}", io_error).into());
    //     }
    // };


    // assumes 'project_graph_directory' path is exe-parent based
    // Ensure project_graph_data/session_state_items directory exists
    let session_state_dir = project_graph_directory.join("session_state_items");
    if !session_state_dir.exists() {
        fs::create_dir_all(&session_state_dir).expect("Failed to create session_state_items directory");
    }

    // // using path relative to exe-parent:
    // // Ensure directory exists relative to the executable
    // let session_statedir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("session_state_items");

    // // Handle any errors that might occur during directory creation or verification
    // let session_state_dir = match session_statedir_result {
    //     Ok(directory_path) => directory_path,
    //     Err(io_error) => {
    //         // Log the error and handle appropriately for your application
    //         return Err(format!("Failed to ensure session_state_items exists: {}", io_error).into());
    //     }
    // };


    // assumes 'project_graph_directory' path is exe-parent basedpath
    // Ensure project_graph_data/sync_state_items directory exists
    let sync_state_dir = project_graph_directory.join("sync_state_items");
    if !sync_state_dir.exists() {
        fs::create_dir_all(&sync_state_dir).expect("Failed to create sync_state_items directory");
    }


    // // using path relative to exe-parent:
    // // Ensure directory exists relative to the executable
    // let sync_statedir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("sync_state_items");

    // // Handle any errors that might occur during directory creation or verification
    // let sync_state_dir = match sync_statedir_result {
    //     Ok(directory_path) => directory_path,
    //     Err(io_error) => {
    //         // Log the error and handle appropriately for your application
    //         return Err(format!("Failed to ensure sync_state_items directory exists: {}", io_error).into());
    //     }
    // };

    debug_log("IUA ensured some dirs existed...");
    // println!("IUA ensured some dirs existed...");


    // To stop sync from starting before a channel is entered:
    initialize_ok_to_start_sync_flag_to_false();

    // Check if there are any directories in project_graph_data/team_channels
    debug_log("let number_of_team_channels = fs::read_dir(&team_channels_dir)");

    // if !dir_at_path_is_empty_returns_false(COLLABORATOR_ADDRESSBOOK_PATH_STR) {
    debug_log!(
        "if !dir_at_path_is_empty_returns_false(Path::new({})) ",
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
    );

    // if !dir_at_path_is_empty_returns_false(Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)) {
    if !dir_at_path_is_empty_returns_false(
        &collaborator_files_address_book_dir
            ) {

        // If there are no existing users, prompt the user to add a new user
        println!("Welcome to the application!");
        println!("To get started, please add a new user.");

        // Prompt the user to enter a username
        println!("Enter a username:");
        let mut username_input = String::new(); // Use a temporary variable for input

        let username_for_function: String = match std::io::stdin().read_line(&mut username_input) {
            Ok(_) => {
                // Successfully read input, trim it, and this will be the value of username_for_function
                let trimmed = username_input.trim().to_string();
                if trimmed.is_empty() {
                    eprintln!("Username cannot be empty.");
                    // Handle empty username case, perhaps by returning or panicking
                    // For now, let's panic as an example, but you should handle it gracefully.
                    panic!("Username was empty after trimming.");
                }
                println!("Hello, (trimmed): '{}'", trimmed); // Debug: Check the trimmed value
                trimmed
            },
            Err(io_error) => {
                // Handle the error appropriately
                eprintln!("Failed to read input: {}", io_error);
                // You must return or panic here, as username_for_function needs a value.
                // Or provide a default, though that's unlikely for a username.
                panic!("Failed to read username: {}", io_error);
            }
        };

        // choice...
        // Get IP address input method
        // 3. Auto-detect IP Addresses
        let detected_addresses = get_local_ip_addresses().expect("Failed to auto-detect IP addresses");
        let mut ipv4_addresses: Option<Vec<Ipv4Addr>> = None;
        let mut ipv6_addresses: Option<Vec<Ipv6Addr>> = None;

        for addr in detected_addresses {
            match addr {
                IpAddr::V4(v4) => {
                    if ipv4_addresses.is_none() {
                        ipv4_addresses = Some(Vec::new());
                    }
                    ipv4_addresses.as_mut().unwrap().push(v4);
                }
                IpAddr::V6(v6) => {
                    if ipv6_addresses.is_none() {
                        ipv6_addresses = Some(Vec::new());
                    }
                    ipv6_addresses.as_mut().unwrap().push(v6);
                }
            }
        }

        // // Prompt the user to enter an IP address
        // println!("Enter an ipv6_addresses:");
        // let mut ipv6_address = String::new();
        // io::stdin().read_line(&mut ipv6_address).unwrap();
        // let ipv6_address: Ipv6Addr = ipv6_address.trim().parse().unwrap(); // Parse into Ipv6Addr
        // show user their gpg key id list
        // new Q&A workflow, not requiring the user to open a new terminal and use gpg cli

        // Get armored public key, using key-id (full fingerprint in)
        let mut full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => fingerprint,
            Err(e) => {
                eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
                return Ok(false);
            }
        };

        // Get armored public key, using key-id (full fingerprint in)
        let mut gpg_key_public = String::new();
        match get_gpg_armored_public_key_via_key_id(&full_fingerprint_key_id_string) {
            Ok(armored_key) => {
                println!("Armored Public Key:\n{}", armored_key);
                gpg_key_public = armored_key;
            }
            Err(e) => {
                eprintln!("Error: {}", e);
            }
        }

        println!("GPG key entered:\n{}", gpg_key_public); // Confirmation (remove in production)
        debug_log("GPG key entered");

        // // Salt List!
        debug_log("Salt List");
        // Generate salt list (4 random u128 values)
        let new_usersalt_list: Vec<u128> = (0..4)
            .map(|_| rand::rng().random())
            .collect();

        println!("Using salts: {:?}", new_usersalt_list);
        debug_log!("Using salts: {:?}", new_usersalt_list);

        // // Add a new user to Uma file system
        let _ = make_new_collaborator_addressbook_toml_file(
            username_for_function,
            new_usersalt_list,
            ipv4_addresses,
            ipv6_addresses,
            full_fingerprint_key_id_string,
            gpg_key_public,
            60,   // Example sync_interval (in seconds)
            get_current_unix_timestamp(),
        );

        // // Save the updated collaborator list to the data directory
        // let toml_data = toml::to_string(&collaborator_list).expect("Failed to serialize collaborator list");
        // fs::write(collaborator_list_file, toml_data).expect("Failed to write collaborator list file");

        debug_log("User added successfully!");
        println!("User added successfully!");
    }

    /////////////////////////////
    // Check & Make Team Channel
    /////////////////////////////
    // let number_of_team_channels = fs::read_dir(&team_channels_dir)
    //     .unwrap()
    //     .filter(|entry| entry.as_ref().unwrap().path().is_dir())
    //     .count();

    // No unwrap calls: Uses pattern matching to handle errors gracefully
    // Handles the potential error from fs::read_dir
    // Handles potential errors for each directory entry separately
    // Graceful error recovery: Continues processing entries even if some fail
    // Provides  context in error messages
    // Default value: Returns 0 if unable to read the directory
    // assigns a usize to number_of_team_channels
    // Count subdirectories with proper error handling
    let number_of_team_channels = match fs::read_dir(&team_channels_dir) {
        Ok(entries) => {
            // Filter and count only the directories, safely handling entry errors
            entries
                .filter_map(|entry_result| {
                    // Safely handle potential errors for each directory entry
                    match entry_result {
                        Ok(entry) => {
                            // Check if this entry is a directory
                            if entry.path().is_dir() {
                                Some(()) // Count this directory
                            } else {
                                None // Not a directory, don't count
                            }
                        },
                        Err(e) => {
                            println!("Error accessing directory entry: {}", e);
                            None // Skip this entry due to error
                        }
                    }
                })
                .count()
        },
        Err(e) => {
            println!("Error reading directory {}: {}", team_channels_dir.display(), e);
            0 // Default to 0 channels if directory can't be read
        }
    };


    // let number_of_team_channels = count_subdirectories_executabledirectoryrelative_default_zero(&team_channels_dir);

    if number_of_team_channels == 0 {
        // If no team channels exist, create the first one
        println!("There are no existing team channels. Let's create one.");
        println!("Enter a name for the team channel:");

        let mut team_channel_name = String::new();
        io::stdin().read_line(&mut team_channel_name).unwrap();
        let team_channel_name = team_channel_name.trim().to_string();

        // TUI Setup, TODO
        /*
        If there is an umi.toml,
        and it has tui_height/tui_height that are not 80/24
        use those new values (from umi.toml) for
        tui_height =
        tui_width =

        or maybe this gets done in the project-manager-thread (not the sink thread)
        */

        // // In initialize_uma_application, when creating the first channel:
        // // Get the owner from somewhere (e.g., user input or instance metadata)
        // let owner = "initial_owner".to_string(); // Replace with actual owner

        create_new_team_channel(team_channel_name, uma_local_owner_user.clone());
        }

        // TODO
        // maybe check for node file made?

        debug_log("after create_new_team_channel()");


    //////////////////////////////////////////////////////////////////////////
    // --- Band: Network Band Finder: IP Validity Check and Flag Setting ---
    /////////////////////////////////////////////////////////////////////////

    // let (ipv4_list, ipv6_list) = load_local_ip_lists_to_ipvec(&user_metadata.uma_local_owner_user)?;
    // let (str_ipv4list, str_ipv6list) = load_local_iplists_as_stringtype(&user_metadata.uma_local_owner_user)?;

    // // currently only using ipv6
    // let local_user_ipv6_address = find_valid_local_owner_ip_address(
    //     &ipv6_list
    // )
    //     .ok_or(ThisProjectError::NetworkError("No valid local IPv6 address found".to_string()))?;

    // // // Instead of cloning the first address, use the result of the selector:
    // // ipv6_addr_1 = Some(local_user_ipv6_address); // No need to clone or dereference as the variable now directly holds the Ipv6Addr
    // // ipv6_addr_2 = ipv6_addr_1.clone(); // Clone the selected address for ipv6_addr_2 if needed

    // // get index of valid IP v6
    // let ip_index = get_index_byof_ip(
    //     &str_ipv4list,
    //     &str_ipv6list,
    //     &local_user_ipv6_address.to_string(), // as ip_address
    // );

    // debug_log!(
    //     "Found IP/index <{:?} {:?}>",
    //     local_user_ipv6_address,
    //     ip_index
    // );


    // Network Detection or Work Offline?

    // println!("\nSign-In: You are your GPG: Who are you?");

    // // Get armored public key, using key-id (full fingerprint in)
    // let mut full_fingerprint_key_id_string = String::new();
    // match q_and_a_user_selects_gpg_key_full_fingerprint() {
    //     Ok(temp_fullfingerprint_key_idstring) => {

    //         println!("Selected key id (full fingerprint in): {}", temp_fullfingerprint_key_idstring);
    //         full_fingerprint_key_id_string = temp_fullfingerprint_key_idstring;
    // }
    //     Err(e) => eprintln!("Error selecting full_fingerprint_key_id_string: {}", e.to_string()),
    // }

    // Get armored public key, using key-id (full fingerprint in)
    let mut full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
            return Ok(false);
        }
    };

    // Call get_band__find_valid_network_index_and_type to retrieve band info and online status
    let (
        network_found_ok,
        network_type,
        network_index,
        this_ipv4,
        this_ipv6,
    ) = get_band__find_valid_network_index_and_type(
        &uma_local_owner_user,
        &full_fingerprint_key_id_string,
        );


    println!("IUA next: get_band__find_valid_network_index_and_type");
    println!(
        "IUA: network_found_ok -> {:?}",
        network_found_ok
        );
    println!(
        "IUA: network_type -> {:?}\n",
        network_type
        );


    // Handle offline mode if no network connection is found
    if !network_found_ok {  // Check the flag *before* writing/saving values to prevent corrupting or creating bad data from invalid inputs.
        debug_log!("No valid network connection found. Entering offline mode.");
        return Ok(false); // Return false to signal offline mode; do not initialize sync, do not continue processing those invalid or undefined network type and IP values. Halt immediately in this specific scenario and set `network_found_ok` boolean flag to `false` consistent with best practice for what you stated was the desired and specified handling for this exact use-case: halt Uma.
    }



    // set network data state-file(s) in sync_data/ directory:
    if let Err(e) = write_local_band__save_network_band__type_index( // Check if writing to sync data state files fails
        network_type, // network type, as String
        network_index, // network index, as u8
        this_ipv4,  //ipv4, as std::net::Ipv4Addr
        this_ipv6, // ipv6, as std::net::Ipv6Addr
    ) { // then handle that error: do not allow bad values to propagate to other parts of the system, halt uma and or handle in other specified way if this error can occur for other reasons not related to invalid IP retrieval.
        // Handle error, halt uma or do something else as per your specs if failure to save band configuration is an error distinct from failure to find a valid IP address.
        // e.g. debug_log("Error saving network configuration: {}", e);
        return Err(Box::new(e)); // Or handle the error as needed, including halting Uma with an informative message
    };

    Ok(true) // Indicate online mode only when valid IP data has been obtained, parsed, converted, and written to sync data state files correctly
}

// fn handle_numeric_input(
//     input: &str,
//     app: &mut App,
//     graph_navigation_instance_state: &GraphNavigationInstanceState,
// ) -> Result<bool, Box<dyn std::error::Error>> {
//     if let Ok(index) = input.parse::<usize>() {
//         let item_index = index - 1; // Adjust for 0-based indexing
//         if item_index < app.tui_directory_list.len() {
//             // Special handling for team channels directory
//             if app.current_path.display().to_string() == "project_graph_data/team_channels".to_string() {
//                 let selected_channel = &app.tui_directory_list[item_index];
//                 debug_log(&format!("Selected channel: {}", selected_channel));

//                 // Enable sync flag
//                 set_sync_start_ok_flag_to_true();

//                 // Update paths
//                 app.current_path = app.current_path.join(selected_channel);
//                 app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();

//                 // Update navigation state
//                 app.graph_navigation_instance_state.nav_graph_look_read_node_toml();
//             }
//             // Handle regular directory navigation
//             else {
//                 app.current_path = app.current_path.join(&app.tui_directory_list[item_index]);
//             }
//             return Ok(true);
//         }
//     }
//     Ok(false)
// }

// // use std::process::Command;
// /// Exports the user's public GPG key to a specified location for sharing
// ///
// /// # Arguments
// /// * `config_path` - Path to the uma.toml configuration file
// /// * `output_directory` - Directory where the exported key should be saved
// ///
// /// # Returns
// /// * `Result<String, ThisProjectError>` - Returns the path to the exported key file or an error
// pub fn export_public_gpg_key_converts_to_abs_path(
//     config_path: &Path,
//     output_directory: &Path,
// ) -> Result<String, ThisProjectError> {
//     // Step 1: Get username from uma.toml
//     let config_path_str = config_path.to_str()
//         .ok_or_else(|| ThisProjectError::InvalidInput("Invalid path".to_string()))?;

//     // TODO make uma.toml a clearsign toml probably
//     // let username = read_field_from_toml(config_path_str, "uma_local_owner_user");
//     let username = read_single_line_string_field_from_toml(config_path_str, "uma_local_owner_user");

//     // Step 2: Construct path to user's config file
//     let user_config_path = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
//         .join(format!("{}__collaborator.toml", username));

//     // Step 3: Get GPG key ID from user's config file
//     let user_config_path_str = user_config_path.to_str()
//         .ok_or_else(|| ThisProjectError::InvalidInput("Invalid user config path".to_string()))?;
//     let gpg_key_id = read_singleline_string_from_clearsigntoml(user_config_path_str, "gpg_publickey_id");

//     // Create the output directory if it doesn't exist
//     fs::create_dir_all(output_directory)
//         .map_err(|e| ThisProjectError::IoError(e))?;

//     // Generate the output file path
//     let output_file = output_directory.join("key.asc");

//     // Export the GPG key
//     let output = StdCommand::new("gpg")
//         .arg("--armor")
//         .arg("--export")
//         .arg(&gpg_key_id)
//         .output()
//         .map_err(|e| ThisProjectError::IoError(e))?;

//     // Check if the command was successful
//     if !output.status.success() {
//         let error_message = String::from_utf8_lossy(&output.stderr);
//         return Err(ThisProjectError::GpgError(error_message.to_string()));
//     }

//     // Write the output to a file
//     fs::write(&output_file, output.stdout)
//         .map_err(|e| ThisProjectError::IoError(e))?;



//     /*
//     Check for invitation:
//     for share key... just give instructions?

//     look here fn export_addressbook()
//     encrypt with theirs and clearsign wtih theirs?
//     ?
//     use tomlclearsign files??? yes...

//     1. is there a key in invtes_updates/incoming/gpg_key_for_invites_here
//     2. if so:
//     (look for an invite function or command with some of this code...)
//     3. get current owner user name
//     4. get current owner user addressbook path
//     5. get key-id for current owner user? or not need clearsign?
//     6. use key in folder to encrypt file at path step 4
//     6. put the result in outgoing named whateer .asc

//     */

//     // Return the path to the exported key file
//     Ok(output_file.to_string_lossy().into_owned())
// }


// // use std::fs;
// // use std::path::Path;
// // use std::process::Command as StdCommand;

// /// Exports the user's public GPG key to a specified location for sharing.
// ///
// /// This function performs the following steps:
// /// 1. Retrieves the username from the configuration file
// /// 2. Locates the corresponding collaborator file for that user
// /// 3. Extracts the GPG public key ID from the collaborator file
// /// 4. Uses GPG to export the public key in ASCII-armored format
// /// 5. Saves the exported key to the specified output directory
// ///
// /// # Arguments
// /// * `config_path` - Path to the uma.toml configuration file
// /// * `output_directory` - Directory where the exported key should be saved
// ///
// /// # Returns
// /// * `Result<String, ThisProjectError>` - Returns the path to the exported key file on success,
// ///   or an appropriate error if any step fails
// ///
// /// # Errors
// /// * `ThisProjectError::InvalidInput` - If paths cannot be converted to strings
// /// * `ThisProjectError::TomlVanillaDeserialStrError` - If reading from TOML files fails
// /// * `ThisProjectError::IoError` - If file operations fail
// /// * `ThisProjectError::GpgError` - If the GPG key export operation fails
// pub fn export_public_gpg_key_converts_to_abs_path(
//     config_path: &Path,
//     output_directory: &Path,
// ) -> Result<String, ThisProjectError> {

//     debug_log("\n\nStarting -> fn export_public_gpg_key_converts_to_abs_path()");

//     // Convert config path to string for TOML reading functions
//     let config_path_str = config_path.to_str()
//         .ok_or_else(|| ThisProjectError::InvalidInput("Cannot convert config path to string".to_string()))?;

//     // Read username from the configuration file, mapping any reading errors to our error type
//     let uma_localowneruser_username = read_single_line_string_field_from_toml(config_path_str, "uma_local_owner_user")
//         .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
//             format!("Failed to read uma_localowneruser_username from config: {}", error_message)
//         ))?;

//     debug_log!("uma_localowneruser_username {}", uma_localowneruser_username);

//     // Construct the path to the user's collaborator file, which contains their GPG key ID
//     let collaborator_files_directory = COLLABORATOR_ADDRESSBOOK_PATH_STR;
//     let collaborator_filename = format!("{}__collaborator.toml", uma_localowneruser_username);
//     let user_config_path = Path::new(collaborator_files_directory).join(collaborator_filename);

//     debug_log!("user_config_path {}", user_config_path.display());


//     // Convert the collaborator file path to string for TOML reading
//     let user_config_path_str = user_config_path.to_str()
//         .ok_or_else(|| ThisProjectError::InvalidInput("Cannot convert collaborator file path to string".to_string()))?;


//     debug_log!("user_config_path {}", user_config_path.display());

//     // Extract the GPG key ID from the collaborator file
//     let gpg_key_id = read_singleline_string_from_clearsigntoml(user_config_path_str, "gpg_publickey_id")
//         .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
//             format!("Failed to read GPG key ID from collaborator file: {}", error_message)
//         ))?;

//     // Ensure the output directory exists, creating it if necessary
//     fs::create_dir_all(output_directory)
//         .map_err(|io_error| ThisProjectError::IoError(io_error))?;

//     // Define the output file path where the exported key will be saved
//     let output_file_path = output_directory.join("key.asc");

//     debug_log!("output_file_path {}", output_file_path.display());

//     // Call GPG to export the public key in ASCII-armored format
//     let gpg_export_result = StdCommand::new("gpg")
//         .arg("--armor")           // ASCII-armored format for text-based sharing
//         .arg("--export")          // Export operation
//         .arg(&gpg_key_id)         // The key ID to export
//         .output()
//         .map_err(|io_error| ThisProjectError::IoError(io_error))?;

//     debug_log!("gpg_export_result {:?}", gpg_export_result);

//     // Verify the GPG command executed successfully
//     if !gpg_export_result.status.success() {
//         // If GPG failed, extract the error message and return it
//         let gpg_error_message = String::from_utf8_lossy(&gpg_export_result.stderr);
//         return Err(ThisProjectError::GpgError(
//             format!("GPG key export failed: {}", gpg_error_message)
//         ));
//     }

//     // Write the exported key to the output file
//     fs::write(&output_file_path, &gpg_export_result.stdout)
//         .map_err(|io_error| ThisProjectError::IoError(io_error))?;
//     /*
//     Check for invitation:
//     for share key... just give instructions?

//     look here fn export_addressbook()
//     encrypt with theirs and clearsign wtih theirs?
//     ?
//     use tomlclearsign files??? yes...

//     1. is there a key in invtes_updates/incoming/gpg_key_for_invites_here
//     2. if so:
//     (look for an invite function or command with some of this code...)
//     3. get current owner user name
//     4. get current owner user addressbook path
//     5. get key-id for current owner user? or not need clearsign?
//     6. use key in folder to encrypt file at path step 4
//     6. put the result in outgoing named whateer .asc

//     */


//     // Return the path to the exported key file as a string
//     let result_path = output_file_path.to_string_lossy().into_owned();

//     debug_log!("\n\n Ending -> fn export_public_gpg_key_converts_to_abs_path(), result_path -> {:?}", &result_path);

//     Ok(result_path)
// }


/// Exports the user's public GPG key to a specified location for sharing.
///
/// This function performs the following steps:
/// 1. Retrieves the username from the configuration file
/// 2. Locates the corresponding collaborator file for that user
/// 3. Extracts the GPG public key ID from the collaborator file
/// 4. Uses GPG to export the public key in ASCII-armored format
/// 5. Saves the exported key to the specified output directory
///
/// # Path Handling
/// IMPORTANT: Both the config_path and output_directory parameters are treated as paths
/// relative to the executable's directory location, NOT the current working directory.
/// They will be automatically converted to absolute paths based on the executable's location.
/// This ensures consistent behavior regardless of where the program is executed from.
///
/// # Arguments
/// * `config_path` - Path to the uma.toml configuration file (relative to executable directory)
/// * `output_directory` - Directory where the exported key should be saved (relative to executable directory)
///
/// # Returns
/// * `Result<String, ThisProjectError>` - Returns the path to the exported key file on success,
///   or an appropriate error if any step fails
///
/// # Errors
/// * `ThisProjectError::InvalidInput` - If paths cannot be converted to strings
/// * `ThisProjectError::TomlVanillaDeserialStrError` - If reading from TOML files fails
/// * `ThisProjectError::IoError` - If file operations fail, including if required directories don't exist
/// * `ThisProjectError::GpgError` - If the GPG key export operation fails
pub fn export_public_gpg_key_converts_to_abs_path(
    config_path: &Path,
    output_directory: &Path,
) -> Result<String, ThisProjectError> {

    debug_log("\n\nStarting -> fn export_public_gpg_key_converts_to_abs_path()");

    // Convert config_path to an absolute path relative to the executable directory
    let absolute_config_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(config_path)
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;

    // Convert config path to string for TOML reading functions
    let config_path_str = absolute_config_path.to_str()
        .ok_or_else(|| ThisProjectError::InvalidInput("Cannot convert config path to string".to_string()))?;

    // Read username from the configuration file, mapping any reading errors to our error type
    let uma_localowneruser_username = read_single_line_string_field_from_toml(config_path_str, "uma_local_owner_user")
        .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read uma_localowneruser_username from config: {}", error_message)
        ))?;

    debug_log!("uma_localowneruser_username {}", uma_localowneruser_username);

    // Convert the collaborator files directory to an absolute path based on the executable's location
    // AND verify that the directory exists (returns error if not found or not a directory)
    let addressbook_files_directory_relative = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    let addressbook_files_directory_absolute = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(
        addressbook_files_directory_relative
    ).map_err(|io_error| ThisProjectError::IoError(io_error))?;

    // Construct the path to the user's collaborator file, which contains their GPG key ID
    let collaborator_filename = format!("{}__collaborator.toml", uma_localowneruser_username);
    let user_config_path = addressbook_files_directory_absolute.join(collaborator_filename);

    debug_log!("user_config_path {}", user_config_path.display());

    // Convert the collaborator file path to string for TOML reading
    let user_config_path_str = user_config_path.to_str()
        .ok_or_else(|| ThisProjectError::InvalidInput("Cannot convert collaborator file path to string".to_string()))?;

    debug_log!("user_config_path {}", user_config_path.display());
    println!("user_config_path {}", user_config_path.display());

    // Extract the GPG key ID from the collaborator file
    let gpg_key_id = read_singleline_string_from_clearsigntoml(user_config_path_str, "gpg_publickey_id")
        .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
            format!("export_public_gpg_key_converts_to_abs_path() Failed read_singleline_string_from_clearsigntoml() to read GPG key ID from clearsigntoml collaborator file: {}", error_message)
        ))?;

    // Convert output_directory to an absolute path relative to the executable directory
    // Create the directory if it doesn't exist
    let absolute_output_directory = make_input_path_name_abs_executabledirectoryrelative_nocheck(output_directory)
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;

    // Ensure the output directory exists, creating it if necessary
    fs::create_dir_all(&absolute_output_directory)
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;

    // Define the output file path where the exported key will be saved
    let output_file_path = absolute_output_directory.join("key.asc");

    debug_log!("output_file_path {}", output_file_path.display());

    // Call GPG to export the public key in ASCII-armored format
    let gpg_export_result = StdCommand::new("gpg")
        .arg("--armor")           // ASCII-armored format for text-based sharing
        .arg("--export")          // Export operation
        .arg(&gpg_key_id)         // The key ID to export
        .output()
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;

    debug_log!("gpg_export_result {:?}", gpg_export_result);

    // Verify the GPG command executed successfully
    if !gpg_export_result.status.success() {
        // If GPG failed, extract the error message and return it
        let gpg_error_message = String::from_utf8_lossy(&gpg_export_result.stderr);
        return Err(ThisProjectError::GpgError(
            format!("GPG key export failed: {}", gpg_error_message)
        ));
    }

    // Write the exported key to the output file
    fs::write(&output_file_path, &gpg_export_result.stdout)
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;
    /*
    Check for invitation:
    for share key... just give instructions?

    look here fn export_addressbook()
    encrypt with theirs and clearsign wtih theirs?
    ?
    use tomlclearsign files??? yes...

    1. is there a key in invtes_updates/incoming/gpg_key_for_invites_here
    2. if so:
    (look for an invite function or command with some of this code...)
    3. get current owner user name
    4. get current owner user addressbook path
    5. get key-id for current owner user? or not need clearsign?
    6. use key in folder to encrypt file at path step 4
    6. put the result in outgoing named whateer .asc

    */

    // Return the path to the exported key file as a string
    let result_path = output_file_path.to_string_lossy().into_owned();

    debug_log!("\n\n Ending -> fn export_public_gpg_key_converts_to_abs_path(), result_path -> {:?}", &result_path);

    Ok(result_path)
}

// /// Exports the user's public GPG key to a specified location for sharing
// ///
// /// # Arguments
// /// * `config_path` - Path to the uma.toml configuration file
// /// * `output_directory` - Directory where the exported key should be saved
// ///
// /// # Returns
// /// * `Result<String, ThisProjectError>` - Returns the path to the exported key file or an error
// pub fn export_public_gpg_key_converts_to_abs_path(
//     config_path: &Path,
//     output_directory: &Path,
// ) -> Result<String, ThisProjectError> {
//     // Convert Path to &str for read_field_from_toml
//     let config_path_str = config_path.to_str()
//         .ok_or_else(|| ThisProjectError::InvalidInput("Invalid path".to_string()))?;

//     // Read the GPG key ID from the configuration
//     let key_id = read_field_from_toml(config_path_str, "uma_local_owner_user");

//     // Create the output directory if it doesn't exist
//     fs::create_dir_all(output_directory)
//         .map_err(|e| ThisProjectError::IoError(e))?;

//     // Generate the output file path
//     let output_file = output_directory.join("key.asc");

//     // Construct the GPG command
//     let output = Command::new("gpg")
//         .arg("--armor")
//         .arg("--export")
//         .arg(&key_id)
//         .output()
//         .map_err(|e| ThisProjectError::IoError(e))?;

//     // Check if the command was successful
//     if !output.status.success() {
//         let error_message = String::from_utf8_lossy(&output.stderr);
//         return Err(ThisProjectError::GpgError(error_message.to_string()));
//     }

//     // Write the output to a file
//     fs::write(&output_file, output.stdout)
//         .map_err(|e| ThisProjectError::IoError(e))?;

//     // Return the path to the exported key file
//     Ok(output_file.to_string_lossy().into_owned())
// }
// /// Exports the user's public GPG key to a specified location for sharing
// ///
// /// # Arguments
// /// * `config_path` - Path to the uma.toml configuration file
// /// * `output_directory` - Directory where the exported key should be saved
// ///
// /// # Returns
// /// * `Result<String, Box<dyn Error>>` - Returns the path to the exported key file or an error
// pub fn export_public_gpg_key_converts_to_abs_path(
//     config_path: &Path,
//     output_directory: &Path,
// ) -> Result<String, Box<dyn Error>> {
//     // Read the GPG key ID from the configuration
//     let key_id = read_field_from_toml(config_path, "uma_local_owner_user")?;

//     // Create the output directory if it doesn't exist
//     fs::create_dir_all(output_directory)?;

//     // Generate the output file path
//     let output_file = output_directory.join("key.asc");

//     // Construct the GPG command
//     let output = Command::new("gpg")
//         .arg("--armor")
//         .arg("--export")
//         .arg(&key_id)
//         .output()?;

//     // Check if the command was successful
//     if !output.status.success() {
//         let error_message = String::from_utf8_lossy(&output.stderr);
//         return Err(format!("GPG key export failed: {}", error_message).into());
//     }

//     // Write the output to a file
//     fs::write(&output_file, output.stdout)?;

//     // Return the path to the exported key file
//     Ok(output_file.to_string_lossy().into_owned())
// }


// use std::path::Path;
// use std::io;


// KEEP this for later
/// Process address book sharing for a specific recipient
///
/// # Arguments
/// * `recipient_name` - Name of the recipient to share with
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
fn generic_share_address_book(recipient_name: &str) -> Result<(), GpgError> {
    println!("\nProcessing address book share for recipient: {}", recipient_name);

    // Path to your address book
    let address_book_path = Path::new("address_book.toml");

    // Your GPG signing key ID (in production, this would come from config)
    println!("\nTo get your signing key ID, run: $ gpg --list-keys --keyid-format=long");
    print!("Enter your GPG signing key ID: ");
    io::stdout().flush()
        .map_err(|e| GpgError::GpgOperationError(format!("Failed to flush stdout: {}", e)))?;

    let mut signing_key_id = String::new();
    io::stdin()
        .read_line(&mut signing_key_id)
        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;
    let signing_key_id = signing_key_id.trim();

    // Validate signing key
    if signing_key_id.is_empty() {
        return Err(GpgError::ValidationError("No signing key ID provided".to_string()));
    }

    // PLACEHOLDER: In production, this would look up the recipient's public key
    // from your address book using recipient_name
    println!("\nEnter path to recipient's public key file:");
    let mut recipient_key_path_str = String::new();
    io::stdin()
        .read_line(&mut recipient_key_path_str)
        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;
    let recipient_public_key_path = Path::new(recipient_key_path_str.trim());

    // Verify the public key file exists
    if !recipient_public_key_path.exists() {
        return Err(GpgError::PathError(format!(
            "Recipient's public key not found at: {}",
            recipient_public_key_path.display()
        )));
    }

    println!("\nProcessing with:");
    println!("Your signing key ID: {}", signing_key_id);
    println!("Recipient's public key: {}", recipient_public_key_path.display());
    println!("Address book file: {}", address_book_path.display());

    // Use our existing function to clearsign and encrypt the address book
    clearsign_and_encrypt_file_for_recipient(
        address_book_path,
        signing_key_id,
        recipient_public_key_path
    )?;

    println!("\nAddress book has been clearsigned and encrypted for {}!", recipient_name);
    println!("The encrypted file is in: invites_updates/outgoing/address_book.gpgtoml");

    Ok(())
}

// /// Process address book sharing for a specific recipient
// ///
// /// This function handles the process of sharing the local owner's address book with
// /// an existing collaborator. It retrieves the necessary GPG key information,
// /// clearsigns the address book with the owner's private key (using their key ID for reference),
// /// and then encrypts it with the recipient's public key.
// ///
// /// # Arguments
// /// * `recipient_name` - Name of the recipient to share with
// ///
// /// # Returns
// /// * `Ok(())` if the operation succeeds
// /// * `Err(GpgError)` if any operation fails
// ///
// /// # Process Flow
// /// 1. Get local owner's username from configuration
// /// 2. Locate the owner's GPG key ID from their collaborator file (for signing)
// /// 3. Find the recipient's public GPG key from their collaborator file (for encryption)
// /// 4. Clearsign the address book using the owner's key ID (referencing their private key)
// /// 5. Encrypt the signed document with the recipient's public key
// /// 6. Save the encrypted file to the outgoing directory
// fn share_lou_address_book_with_existingcollaborator(recipient_name: &str) -> Result<(), GpgError> {
//     println!("\nProcessing address book share for recipient: {}", recipient_name);

//     // Create output directory if it doesn't exist
//     let output_dir = Path::new("invites_updates/outgoing");
//     fs::create_dir_all(output_dir)
//         .map_err(|e| GpgError::PathError(format!("Failed to create output directory: {}", e)))?;

//     // Get local owner username from configuration
//     let local_owner_user_name = read_single_line_string("uma.toml", "local_owner_user")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read local owner username: {}", e)))?;
//     println!("Local owner username: {}", local_owner_user_name);

//     // Path to local owner's collaborator file
//     path_to_localownerusers_addressbook_toml_share_this_file
//     let path_to_localownerusers_addressbook_toml_share_this_fil = format!(
//         "project_graph_data/collaborator_files_address_book/{}__collaborator.toml",
//         local_owner_user_name
//     );

//     // Get owner's GPG key ID - this is used to reference the private key for signing
//     // The private key itself is securely stored in the GPG keyring, not in our files
//     let owner_gpg_key_id = read_single_line_string(&path_to_localownerusers_addressbook_toml_share_this_fil, "gpg_key_id")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read owner's GPG key ID: {}", e)))?;
//     println!("Owner's GPG key ID: {}", owner_gpg_key_id);

//     // Path to recipient's collaborator file
//     let recipient_collab_path = format!(
//         "project_graph_data/collaborator_files_address_book/{}__collaborator.toml",
//         recipient_name
//     );

//     // Check if recipient's collaborator file exists
//     if !Path::new(&recipient_collab_path).exists() {
//         return Err(GpgError::PathError(format!(
//             "Recipient's collaborator file not found at: {}",
//             recipient_collab_path
//         )));
//     }

//     // Get recipient's public GPG key - this is used for encryption
//     // Public keys are safe to store and share
//     let recipient_public_gpg_key = read_multi_line_string(&recipient_collab_path, "gpg_key_public")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read recipient's public GPG key: {}", e)))?;

//     // Create a temporary file to store the recipient's public key
//     let temp_key_path = Path::new(output_dir).join(format!("{}_pubkey.asc", recipient_name));
//     fs::write(&temp_key_path, recipient_public_gpg_key)
//         .map_err(|e| GpgError::PathError(format!("Failed to write temporary key file: {}", e)))?;


//     // TODO
//     /*

//     The addressbook for the local-owner-user is found in the same place

//     println!("Local owner username: {}", local_owner_user_name);
//     // Path to local owner's collaborator file
//     let owner_collab_path = format!(
//         "project_graph_data/collaborator_files_address_book/{}__collaborator.toml",
//         local_owner_user_name
//     );
//     as the addressbook for the remote collaborate: in the directory of addressbook files.

//     */
//     // NO!
//     // // Path to the address book file
//     // let address_book_path = Path::new("address_book.toml");

//     // // Check if the address book file exists
//     // if !address_book_path.exists() {
//     //     return Err(GpgError::PathError(format!(
//     //         "Address book file not found at: {}",
//     //         address_book_path.display()
//     //     )));
//     // }

//     // println!("\nProcessing with:");
//     // println!("Your signing key ID (references your private key): {}", owner_gpg_key_id);
//     // println!("Recipient's public key file: {}", temp_key_path.display());
//     // println!("Address book file: {}", address_book_path.display());

//     // Use our existing function to clearsign and encrypt the address book
//     // The owner's key ID is used to identify which private key to use for signing
//     // The recipient's public key file is used for encryption
//     clearsign_and_encrypt_file_for_recipient(
//         path_to_localownerusers_addressbook_toml_share_this_file,
//         &owner_gpg_key_id,
//         &temp_key_path
//     )?;

//     // Clean up the temporary key file
//     if let Err(e) = fs::remove_file(&temp_key_path) {
//         eprintln!("Warning: Failed to remove temporary key file: {}", e);
//     }

//     println!("\nAddress book has been clearsigned and encrypted for {}!", recipient_name);
//     println!("The encrypted file is in: invites_updates/outgoing/address_book.gpgtoml");

//     Ok(())
// }


// /// Share the local owner user's address book with an existing collaborator
// ///
// /// This function prepares the local owner's address book file for sharing with
// /// an existing collaborator whose information is already in the system. The process:
// /// 1. Identifies the local owner's address book file
// /// 2. Clearsigns it with the owner's GPG key (proving authenticity)
// /// 3. Encrypts it with the recipient's public key (ensuring only they can read it)
// ///
// /// # Arguments
// /// * `recipient_name` - Name of the existing collaborator to share with
// ///
// /// # Returns
// /// * `Ok(())` if the operation succeeds
// /// * `Err(GpgError)` if any operation fails
// fn share_local_owner_address_book_with_existing_collaborator(recipient_name: &str) -> Result<(), GpgError> {
//     println!("\nSharing local owner's address book with existing collaborator: {}", recipient_name);

//     // Create output directory if it doesn't exist
//     let output_dir = Path::new("invites_updates/outgoing");
//     fs::create_dir_all(output_dir)
//         .map_err(|e| GpgError::PathError(format!("Failed to create output directory: {}", e)))?;

//     // Get local owner username from configuration
//     let local_owner_user_name = read_single_line_string("uma.toml", "local_owner_user")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read local owner username: {}", e)))?;
//     println!("Local owner username: {}", local_owner_user_name);

//     // Path to the local owner's address book file - THIS is the file we want to share
//     let local_owner_address_book_path = format!(
//         "project_graph_data/collaborator_files_address_book/{}__collaborator.toml",
//         local_owner_user_name
//     );

//     // Verify the address book file exists
//     if !Path::new(&local_owner_address_book_path).exists() {
//         return Err(GpgError::PathError(format!(
//             "Local owner's address book file not found at: {}",
//             local_owner_address_book_path
//         )));
//     }

//     // Get owner's GPG key ID - this is used to reference the private key for signing
//     let owner_gpg_key_id = read_singleline_string_from_clearsigntoml(&local_owner_address_book_path, "gpg_key_id")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read owner's GPG key ID: {}", e)))?;
//     println!("Owner's GPG key ID: {}", owner_gpg_key_id);

//     // Path to recipient's collaborator file
//     let recipient_collab_path = format!(
//         "project_graph_data/collaborator_files_address_book/{}__collaborator.toml",
//         recipient_name
//     );

//     // Check if recipient's collaborator file exists
//     if !Path::new(&recipient_collab_path).exists() {
//         return Err(GpgError::PathError(format!(
//             "Recipient's collaborator file not found at: {}",
//             recipient_collab_path
//         )));
//     }

//     // Get recipient's public GPG key - this is used for encryption
//     let recipient_public_gpg_key = read_singleline_string_from_clearsigntoml(&recipient_collab_path, "gpg_key_public")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read recipient's public GPG key: {}", e)))?;

//     // Create a temporary file to store the recipient's public key
//     let temp_key_path = Path::new(output_dir).join(format!("{}_pubkey.asc", recipient_name));
//     fs::write(&temp_key_path, recipient_public_gpg_key)
//         .map_err(|e| GpgError::PathError(format!("Failed to write temporary key file: {}", e)))?;

//     println!("\nProcessing with:");
//     println!("Your signing key ID (references your private key): {}", owner_gpg_key_id);
//     println!("Recipient's public key file: {}", temp_key_path.display());
//     println!("Local owner's address book file: {}", local_owner_address_book_path);

//     // Use our existing function to clearsign and encrypt the LOCAL OWNER'S address book
//     clearsign_and_encrypt_file_for_recipient(
//         Path::new(&local_owner_address_book_path),
//         &owner_gpg_key_id,
//         &temp_key_path
//     )?;

//     // Clean up the temporary key file
//     if let Err(e) = fs::remove_file(&temp_key_path) {
//         eprintln!("Warning: Failed to remove temporary key file: {}", e);
//     }

//     println!("\nLocal owner's address book has been clearsigned and encrypted for {}!", recipient_name);
//     println!("The encrypted file is in: invites_updates/outgoing/{}__collaborator.gpgtoml",
//              local_owner_user_name);

//     Ok(())
// }

// /// Share the Local Owner User's (LOU) address book with an existing collaborator
// ///
// /// This function handles the secure sharing of the LOCAL OWNER USER'S address book file
// /// with an existing collaborator whose information is already in the system.
// ///
// /// Specifically, this function:
// /// 1. Identifies the local owner user's address book file (their collaborator.toml)
// /// 2. Retrieves the local owner user's GPG key ID for signing
// /// 3. Retrieves the recipient's public GPG key for encryption
// /// 4. Clearsigns the LOCAL OWNER USER'S address book file using the owner's GPG key
// /// 5. Encrypts this signed file with the recipient's public key
// /// 6. Saves the encrypted file to the outgoing directory for sharing
// ///
// /// This enables secure sharing of contact information while ensuring:
// /// - The recipient can verify the file came from the claimed sender (via signature)
// /// - Only the intended recipient can decrypt the file (via their public key encryption)
// ///
// /// # Arguments
// /// * `recipient_name` - Name of the existing collaborator to share the LOCAL OWNER USER'S address book with
// ///
// /// # Returns
// /// * `Ok(())` if the operation succeeds
// /// * `Err(GpgError)` if any operation fails
// ///
// /// # File Flow
// /// - Source file: project_graph_data/collaborator_files_address_book/{LOCAL_OWNER_USER}__collaborator.toml
// /// - Output file: invites_updates/outgoing/{LOCAL_OWNER_USER}__collaborator.gpgtoml
// ///
// /// uses: constant Path to incoming public GPG key file
// /// const INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR: &str = "invites_updates/incoming/key.asc";
// ///
// /// For safe tmml handling as 'clearsign_toml', singleline and multiline fields
// /// from addressbook files are read with:
// /// read_singleline_string_from_clearsigntoml();
// /// read_multiline_string_from_clearsigntoml();
// fn share_lou_address_book_with_existingcollaborator(recipient_name: &str) -> Result<(), GpgError> {
//     debug_log("\nstarting -> fn share_lou_address_book_with_existingcollaborator()");
//     debug_log!("Sharing LOCAL OWNER USER'S address book with existing collaborator: {}", recipient_name);

//     // Create output directory if it doesn't exist
//     // This is where the encrypted LOCAL OWNER USER'S address book will be saved
//     let output_dir = Path::new("invites_updates/outgoing");

//     // absolute path
//     debug_log!("Output directory absolute path: {:?}", output_dir.canonicalize().unwrap_or_else(|_| output_dir.to_path_buf()));

//     debug_log!("Output directory exists? {}", output_dir.exists());

//     fs::create_dir_all(output_dir)
//         .map_err(|e| GpgError::PathError(format!("Failed to create output directory: {}", e)))?;

//     debug_log!("Output directory created successfully? {}", output_dir.exists());

//     debug_log!("output_dir {}", &output_dir.display());

//     let uma_toml_path = Path::new("uma.toml");
//     debug_log!("UMA TOML path: {:?}", uma_toml_path.canonicalize().unwrap_or_else(|_| uma_toml_path.to_path_buf()));
//     debug_log!("UMA TOML file exists: {}", uma_toml_path.exists());

//     // This should be an aboslute file path going in, probably not only "uma.toml"
//     // Get local owner username from configuration
//     // This identifies WHICH address book we will be sharing (the LOCAL OWNER USER'S)
//     let local_owner_user_name = read_single_line_string_field_from_toml("uma.toml", "local_owner_user")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read local owner username: {}", e)))?;

//     println!("Local owner username (whose address book we are sharing): {}", local_owner_user_name);

//     debug_log!("local_owner_user_name {}", &local_owner_user_name);
//     // Path to the LOCAL OWNER USER'S address book file
//     // THIS IS THE EXACT FILE WE WANT TO SHARE - the local owner's own address book
//     let local_owner_address_book_path = format!(
//         "project_graph_data/collaborator_files_address_book/{}__collaborator.toml",
//         local_owner_user_name,
//     );
//     debug_log!("local_owner_address_book_path {}", &local_owner_address_book_path);


//     // Verify the LOCAL OWNER USER'S address book file exists
//     if !Path::new(&local_owner_address_book_path).exists() {
//         return Err(GpgError::PathError(format!(
//             "LOCAL OWNER USER'S address book file not found at: {}",
//             local_owner_address_book_path
//         )));
//     } else {
//         debug_log("if !Path::new(&local_owner_address_book_path).exists() { return Err(GpgError::PathError(format!(");

//     }

//     // Get LOCAL OWNER USER'S GPG key ID - this is used to reference the private key for signing
//     // We are using the LOCAL OWNER USER'S key to sign THEIR OWN address book
//     let owner_gpg_key_id = read_singleline_string_from_clearsigntoml(&local_owner_address_book_path, "gpg_key_id")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read LOCAL OWNER USER'S GPG key ID: {}", e)))?;
//     println!("LOCAL OWNER USER'S GPG key ID (for signing their address book): {}", owner_gpg_key_id);

//     // Path to recipient's collaborator file
//     // We need this to get their public key for encryption
//     let recipient_collab_path = format!(
//         "project_graph_data/collaborator_files_address_book/{}__collaborator.toml",
//         recipient_name
//     );

//     // Check if recipient's collaborator file exists
//     if !Path::new(&recipient_collab_path).exists() {
//         return Err(GpgError::PathError(format!(
//             "Recipient's collaborator file not found at: {}",
//             recipient_collab_path
//         )));
//     }

//     // Get recipient's public GPG key - this is used for encryption
//     // We encrypt the LOCAL OWNER USER'S address book with the recipient's public key
//     // so only they can decrypt it
//     let recipient_public_gpg_key = read_multiline_string_from_clearsigntoml(&recipient_collab_path, "gpg_key_public")
//         .map_err(|e| GpgError::ValidationError(format!("Failed to read recipient's public GPG key: {}", e)))?;

//     // Create a temporary file to store the recipient's public key
//     // This is used by the GPG encryption process
//     let temp_key_path = Path::new(output_dir).join(format!("{}_pubkey.asc", recipient_name));
//     fs::write(&temp_key_path, recipient_public_gpg_key)
//         .map_err(|e| GpgError::PathError(format!("Failed to write temporary key file: {}", e)))?;

//     println!("\nProcessing with:");
//     println!("LOCAL OWNER USER'S signing key ID: {}", owner_gpg_key_id);
//     println!("Recipient's public key file: {}", temp_key_path.display());
//     println!("LOCAL OWNER USER'S address book file to be shared: {}", local_owner_address_book_path);

//     // Use our existing function to clearsign and encrypt the LOCAL OWNER USER'S address book
//     // We are:
//     // 1. Taking the LOCAL OWNER USER'S address book file as input
//     // 2. Signing it with the LOCAL OWNER USER'S private key (via their key ID)
//     // 3. Encrypting it with the recipient's public key
//     clearsign_and_encrypt_file_for_recipient(
//         Path::new(&local_owner_address_book_path),  // THE LOCAL OWNER USER'S ADDRESS BOOK
//         &owner_gpg_key_id,                         // LOCAL OWNER USER'S KEY FOR SIGNING
//         &temp_key_path                             // RECIPIENT'S PUBLIC KEY FOR ENCRYPTION
//     )?;

//     // Clean up the temporary key file
//     if let Err(e) = fs::remove_file(&temp_key_path) {
//         eprintln!("Warning: Failed to remove temporary key file: {}", e);
//     }

//     println!("\nLOCAL OWNER USER'S address book has been clearsigned and encrypted for {}!", recipient_name);
//     println!("The encrypted LOCAL OWNER USER'S address book file is saved to:");
//     println!("invites_updates/outgoing/{}__collaborator.gpgtoml", local_owner_user_name);

//     Ok(())
// }


/// Share a team channel with an existing remote collaborator
///
/// This function securely shares a team channel file with a remote collaborator
/// by clearsigning it with the local owner's GPG key and encrypting it with the
/// remote collaborator's public GPG key.
///
/// The process follows these steps:
/// note: steps also involve ready-copy making functions
/// that add-to and combine some overall steps
/// 1. Locate the team channel's node.toml file
/// 2. Read local owner username from uma.toml
/// 3. Get local owner's GPG key ID from their address book file
/// 4. Get remote collaborator's public GPG key from their address book file
/// 5. Clearsign the team channel file with local owner's GPG key
/// 6. Encrypt the clearsigned file with remote collaborator's public key
/// 7. Save the resulting encrypted file to the outgoing directory
///
/// # Arguments
/// * `remote_collaborator_username` - Username of the existing remote collaborator
/// * `team_channel_name` - Name of the team channel to share
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any step fails, with detailed error information
///
/// # File Paths
/// * Team channel file: `{exe-parent}/project_graph_data/team_channels/{team-channel-name}/node.toml`
/// * Local owner's address book: `{exe-parent}/project_graph_data/collaborator_files_address_book/{local-owner}__collaborator.toml`
/// * Remote collaborator's address book: `{exe-parent}/project_graph_data/collaborator_files_address_book/{remote-collaborator}__collaborator.toml`
/// * Output file: `{exe-parent}/invites_updates/outgoing/{team-channel-name}__team_channel__{remote-collaborator}.gpgtoml`
fn share_team_channel_with_existing_collaborator_converts_to_abs(
    remote_collaborator_username: &str,
    team_channel_name: &str
) -> Result<(), GpgError> {
    // Start debug logging for this function
    debug_log!("TCS: Starting team channel sharing process");
    debug_log!("TCS: Remote collaborator username: {}", remote_collaborator_username);
    debug_log!("TCS: Team channel name: {}", team_channel_name);

    // ======== STEP 1: Locate the team channel node.toml file ========
    debug_log!("TCS: STEP 1 - Locating team channel node.toml file");

    // Get absolute path to the team channels directory
    let relative_team_channels_directory_path = "project_graph_data/team_channels";
    let absolute_team_channels_directory_path = gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_team_channels_directory_path)
        .map_err(|e| GpgError::PathError(format!(
            "TCS: Failed to locate team channels directory: {}", e
        )))?;

    debug_log!("TCS: Team channels directory absolute path: {}",
               absolute_team_channels_directory_path.display());

    // Create path to the specific team channel directory
    let absolute_specific_team_channel_directory_path = absolute_team_channels_directory_path.join(team_channel_name);

    // // Create path to the team channel's node.toml file
    // let absolute_team_channel_node_toml_path = absolute_specific_team_channel_directory_path.join("node.toml");

    // // let absolute_team_channel_node_toml_path = absolute_specific_team_channel_directory_path.join("node.toml");



    // debug_log!("TCS: Team channel node.toml path: {}",
    //            absolute_team_channel_node_toml_path.display());

    // // todo node.toml or node.gpgtoml
    // //
    // // Verify the team channel node.toml file exists
    // if !absolute_team_channel_node_toml_path.exists() {

    //     debug_log!("TCS: Team channel node.toml file not found at: {}",
    //     absolute_team_channel_node_toml_path.display());

    //     return Err(GpgError::PathError(format!(
    //         "TCS: Team channel node.toml file not found at: {}",
    //         absolute_team_channel_node_toml_path.display()
    //     )));
    // }

    // A. Check for either node.toml or node.gpgtoml
    let node_toml_path = absolute_specific_team_channel_directory_path.join("node.toml");
    let node_gpgtoml_path = absolute_specific_team_channel_directory_path.join("node.gpgtoml");

    let node_file_path = if node_toml_path.exists() {
        debug_log!("TCS: Found node.toml");
        node_toml_path
    } else if node_gpgtoml_path.exists() {
        debug_log!("TCS: Found node.gpgtoml");
        node_gpgtoml_path
    } else {
        return Err(GpgError::PathError(
            "TCS: Neither node.toml nor node.gpgtoml found in team channel directory".to_string()
        ));
    };

    // B. Get readable temp copy (handles decryption if .gpgtoml)
    debug_log!("TCS: Getting readable copy of node file, node_file_path {:?}", node_file_path);

    // Get GPG fingerprint
    let gpg_fingerprint = LocalUserUma::read_gpg_fingerprint_from_file()
        .map_err(|e| GpgError::PathError(
            format!("TCS: Failed to read GPG fingerprint from uma.toml: {}", e)
        ))?;

    // Get temp directory
    let temp_dir = get_base_uma_temp_directory_path()
        .map_err(|e| GpgError::PathError(
            format!("TCS: Failed to get temp directory path: {}", e)
        ))?;

    // Get readable copy
    let absolute_team_channel_node_toml_path = get_pathstring_to_temp_plaintoml_verified_extracted(
        &node_file_path,
        &gpg_fingerprint,
        &temp_dir,
    ).map_err(|e| GpgError::PathError(
        format!("TCS: Failed to get readable copy of node file: {:?}", e)
    ))?;

    debug_log!("TCS: Node readcopy path: {}", absolute_team_channel_node_toml_path);

    // Now use node_readcopy_path to read fields...

    // ///////////////////

    debug_log!("TCS: Successfully verified team channel node.toml file exists");

    // ======== STEP 2: Get local owner username from uma.toml ========
    debug_log!(
        "TCS: STEP 2 - Reading local owner username from {}",
        UMA_TOML_CONFIGFILE_PATH_STR,
    );

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_uma_toml_path)
        .map_err(|e| GpgError::PathError(format!(
            "TCS: Failed to locate uma.toml configuration file: {}", e
        )))?;

    debug_log!("TCS: uma.toml absolute path: {}",
               absolute_uma_toml_path.display());

    // Convert PathBuf to string for TOML reading functions
    let absolute_uma_toml_path_string = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| GpgError::PathError(
            "TCS: Unable to convert uma.toml path to string".to_string()
        ))?;

    // Read local owner username from uma.toml configuration
    let local_owner_username = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_string,
        "uma_local_owner_user",
    ).map_err(|e| GpgError::ValidationError(format!(
        "TCS: Failed to read local owner username from uma.toml: {}", e
    )))?;

    debug_log!("TCS: Successfully read local owner username: {}", local_owner_username);

    // ======== STEP 3  read-copy ========

    ///////////////////////////////////////
    // make read-copy of .gpgtoml or .toml
    ///////////////////////////////////////
    /*
    // remove temp file
    cleanup_collaborator_temp_file(&addressbook_readcopy_path_string);
    */

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Convert the error to GpgError
            return Err(GpgError::ValidationError(format!(
                "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            )));
        }
    };

    // Get the UME temp directory path with proper GpgError conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| GpgError::ValidationError(
            format!("Failed to get UME temp directory path: {}", io_err)
        ))?;

    // Extract the addressbook path string with proper error conversion to GpgError
    let local_owner_addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &local_owner_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| {
        // Convert the error to GpgError
        GpgError::ValidationError(format!(
            "Failed to get addressbook path for user '{}': {:?}",
            local_owner_username,
            e
        ))
    })?;

    let local_owner_addressbookreadcopy_path = Path::new(&local_owner_addressbook_readcopy_path_string);


    // ======== STEP 4 Read local owner's GPG key ID  ========

    // Read local owner's GPG key ID from their address book
    let local_owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        &local_owner_addressbook_readcopy_path_string, // &str
        "gpg_publickey_id"
    ).map_err(|e| {
        debug_log!("TCS: ERROR - Failed to read GPG key ID with field name 'gpg_publickey_id'");
        GpgError::ValidationError(format!(
            "TCS: Failed to read local owner's GPG key ID from address book: {}", e
        ))
    })?;
    // remove temp file
    cleanup_collaborator_temp_file(
        &local_owner_addressbook_readcopy_path_string,
        &base_uma_temp_directory_path,
        );

    debug_log!("TCS: Successfully read local owner's GPG key ID: {}", local_owner_gpg_key_id);
    println!("Local owner's GPG key ID (for signing): {}", local_owner_gpg_key_id);

    // ======== STEP 5: Get remote collaborator's public GPG key ========
    debug_log!("TCS: STEP 5 - Getting remote collaborator's public GPG key");


    // Get the UME temp directory path with proper GpgError conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| GpgError::ValidationError(
            format!("Failed to get UME temp directory path: {}", io_err)
        ))?;

    // // read cpoy of collaborator's address book file
    // Extract the addressbook path string with proper error conversion to GpgError
    let remote_collaborator_addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &remote_collaborator_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| {
        // Convert the error to GpgError
        GpgError::ValidationError(format!(
            "Failed to get addressbook path for user '{}': {:?}",
            local_owner_username,
            e
        ))
    })?;

    /*
    // remove temp file
    cleanup_collaborator_temp_file(&remote_collaborator_addressbook_readcopy_path_string);
    */

    let remote_collaborator_addressbookreadcopy_path = Path::new(&remote_collaborator_addressbook_readcopy_path_string);

    // TODO: remove temp files upon any error

    // Read remote collaborator's public GPG key from their address book
    let remote_collaborator_public_gpg_key = read_multiline_string_from_clearsigntoml(
        &remote_collaborator_addressbook_readcopy_path_string,
        "gpg_key_public"
    ).map_err(|e| GpgError::ValidationError(format!(
        "TCS: Failed to read remote collaborator's public GPG key from address book: {}", e
    )))?;

    // remove temp file
    cleanup_collaborator_temp_file(
        &remote_collaborator_addressbook_readcopy_path_string,
        &base_uma_temp_directory_path,
        );

    debug_log!("TCS: Successfully read remote collaborator's public GPG key");

    // ======== STEP 6: Prepare output directory ========
    debug_log!("TCS: STEP 6 - Preparing output directory");

    // Get absolute path to output directory
    let relative_output_directory_path = "invites_updates/outgoing";
    let absolute_output_directory_path = gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_output_directory_path)
        .map_err(|e| GpgError::PathError(format!(
            "TCS: Failed to locate output directory: {}", e
        )))?;

    debug_log!("TCS: Output directory absolute path: {}",
               absolute_output_directory_path.display());

    // Create output directory if it doesn't exist
    fs::create_dir_all(&absolute_output_directory_path)
        .map_err(|e| GpgError::FileSystemError(e))?;

    debug_log!("TCS: Successfully created/verified output directory");

    // ======== STEP 7: Create temporary file for remote collaborator's public key ========
    debug_log!("TCS: STEP 7 - Creating temporary file for remote collaborator's public key");

    // Create path for temporary public key file
    let temporary_remote_collaborator_public_key_file_path = absolute_output_directory_path
        .join(format!("{}_tmp_pubkey.asc", remote_collaborator_username));

    debug_log!("TCS: Temporary public key file path: {}",
               temporary_remote_collaborator_public_key_file_path.display());

    // Write remote collaborator's public key to temporary file
    fs::write(&temporary_remote_collaborator_public_key_file_path, remote_collaborator_public_gpg_key)
        .map_err(|e| GpgError::FileSystemError(e))?;

    debug_log!("TCS: Successfully wrote remote collaborator's public key to temporary file");

    // ======== STEP 8: Clearsign and encrypt team channel file ========
    debug_log!("TCS: STEP 8 - Clearsigning and encrypting team channel file");

    // Display information about the process
    println!("\nProcessing with the following parameters:");
    println!("Team channel file: {}", absolute_team_channel_node_toml_path);
    println!("Local owner's GPG key ID (for signing): {}", local_owner_gpg_key_id);
    println!("Remote collaborator's public key file: {}", temporary_remote_collaborator_public_key_file_path.display());
    println!("Encrypting team channel '{}' for user '{}'", team_channel_name, remote_collaborator_username);

    let path_absoluteteam_channel_node_toml_path = Path::new(&absolute_team_channel_node_toml_path);

    // Clearsign and encrypt the team channel node.toml file
    clearsign_and_encrypt_file_for_recipient(
        &path_absoluteteam_channel_node_toml_path,
        &local_owner_gpg_key_id,
        &temporary_remote_collaborator_public_key_file_path
    )?;

    debug_log!("TCS: Successfully clearsigned and encrypted team channel file");

    // Generate the expected output file path for user information
    let expected_encrypted_output_filename = format!("{}__team_channel__{}.gpgtoml",
                                                  team_channel_name,
                                                  remote_collaborator_username);
    let expected_encrypted_output_file_path = absolute_output_directory_path.join(&expected_encrypted_output_filename);

    // ======== STEP 9: Clean up temporary files ========
    debug_log!("TCS: STEP 9 - Cleaning up temporary files");

    // Remove temporary public key file
    if let Err(e) = fs::remove_file(&temporary_remote_collaborator_public_key_file_path) {
        debug_log!("TCS: Warning - Failed to remove temporary public key file: {}", e);
        eprintln!("Warning: Failed to remove temporary public key file: {}", e);
        // Continue execution - this is not a critical error
    } else {
        debug_log!("TCS: Successfully removed temporary public key file");
    }

    // ======== STEP 10: Confirm successful completion ========
    debug_log!("TCS: STEP 10 - Confirming successful completion");

    // Verify output file exists (extra safety check)
    if !expected_encrypted_output_file_path.exists() {
        debug_log!("TCS: WARNING - Cannot find expected output file at: {}",
                   expected_encrypted_output_file_path.display());
        println!("\nProcessing completed, but cannot verify output file location.");
        println!("Please check the invites_updates/outgoing directory for the encrypted file.");
    } else {
        debug_log!("TCS: Successfully verified output file exists at: {}",
                   expected_encrypted_output_file_path.display());
        println!("\nTeam channel '{}' has been successfully shared with '{}'!",
                 team_channel_name, remote_collaborator_username);
        println!("The encrypted team channel file is saved to:");
        println!("{}", expected_encrypted_output_file_path.display());
    }

    debug_log!("TCS: Team channel sharing completed successfully");

    Ok(())
}

/// Share the Local Owner User's (LOU) address book with an existing collaborator
///
/// This function handles the secure sharing of the LOCAL OWNER USER'S address book file
/// with an existing collaborator whose information is already in the system.
///
/// Specifically, this function:
/// 1. Identifies the local owner user's address book file (their collaborator.toml)
/// 2. Retrieves the local owner user's GPG key ID for signing
/// 3. Retrieves the recipient's public GPG key for encryption
/// 4. Clearsigns the LOCAL OWNER USER'S address book file using the owner's GPG key
/// 5. Encrypts this signed file with the recipient's public key
/// 6. Saves the encrypted file to the outgoing directory for sharing
///
/// # Path Handling
/// IMPORTANT: All file and directory paths in this function are resolved relative to the
/// executable's directory location, NOT the current working directory. This ensures consistent
/// behavior regardless of where the program is executed from.
///
/// The function automatically converts all paths to absolute paths based on the executable's
/// location before performing any file operations.
///
/// # Arguments
/// * `recipient_name` - Name of the existing collaborator to share the LOCAL OWNER USER'S address book with
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
///
/// # Errors
/// * `GpgError::PathError` - If required files/directories don't exist or can't be created
/// * `GpgError::ValidationError` - If required data can't be read from configuration files
/// * `GpgError::EncryptionError` - If GPG encryption operations fail
///
/// # File Flow
/// - Source file: {EXECUTABLE_DIR}/project_graph_data/collaborator_files_address_book/{LOCAL_OWNER_USER}__collaborator.toml
/// - Output file: {EXECUTABLE_DIR}/invites_updates/outgoing/{LOCAL_OWNER_USER}__collaborator.gpgtoml
///
/// uses: constant Path to incoming public GPG key file
/// const INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR: &str = "invites_updates/incoming/key.asc";
///
/// For safe tmml handling as 'clearsign_toml', singleline and multiline fields
/// from addressbook files are read with:
/// read_singleline_string_from_clearsigntoml();
/// read_multiline_string_from_clearsigntoml();
fn share_lou_address_book_with_existingcollaborator(recipient_name: &str) -> Result<(), GpgError> {
    // 'SLABE' is an achronym for this function to idenitfy this function in logs
    debug_log("\nstarting -> SLABE share_lou_address_book_with_existingcollaborator()");
    debug_log!("SLABE Sharing LOCAL OWNER USER'S address book with existing collaborator: {}", recipient_name);

    // Create output directory using absolute path relative to executable
    let relative_output_dir = "invites_updates/outgoing";
    let absolute_output_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_output_dir)
        .map_err(|e| GpgError::PathError(format!("Failed to resolve output directory path: {}", e)))?;

    // Absolute path logging
    debug_log!("SLABE Output directory absolute path: {}", absolute_output_dir.display());
    debug_log!("SLABE Output directory exists? {}", absolute_output_dir.exists());

    // Create the output directory if it doesn't exist
    fs::create_dir_all(&absolute_output_dir)
        .map_err(|e| GpgError::PathError(format!("Failed to create output directory: {}", e)))?;

    debug_log!("SLABE Output directory created successfully? {}", absolute_output_dir.exists());
    debug_log!("SLABE absolute_output_dir {}", &absolute_output_dir.display());

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| GpgError::PathError(format!("Failed to locate uma.toml configuration file: {}", e)))?;

    debug_log!("SLABE UMA TOML absolute path: {}", absolute_uma_toml_path.display());
    debug_log!("SLABE UMA TOML file exists: {}", absolute_uma_toml_path.exists());

    // Get local owner username from configuration
    // This identifies WHICH address book we will be sharing (the LOCAL OWNER USER'S)
    // Get local owner username from configuration - REFACTORED FOR DEBUGGING
    // Convert PathBuf to string first
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| GpgError::PathError("SLABE Unable to convert UMA TOML path to string".to_string()))?;

    // Log the exact string that will be used by the TOML reader
    debug_log!("SLABE Attempting to read from UMA TOML file at path string: {}", absolute_uma_toml_path_str);

    // Now attempt to read the actual field value
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user",
    ).map_err(|e| GpgError::ValidationError(format!("SLABE Failed to read local owner username: {}", e)))?;

    debug_log!("SLABE Successfully read local_owner_user_name: {}", &local_owner_user_name);

    // let local_owner_user_name = read_single_line_string_field_from_toml(
    //     absolute_uma_toml_path.to_str().ok_or_else(|| GpgError::PathError("Unable to convert UMA TOML path to string".to_string()))?,
    //     "local_owner_user"
    // ).map_err(|e| GpgError::ValidationError(format!("Failed to read local owner username: {}", e)))?;

    println!("Local owner username (whose address book we are sharing): {}", local_owner_user_name);
    debug_log!("SLABE local_owner_user_name {}", &local_owner_user_name);

    // Get absolute path to the collaborator files directory
    let relative_collab_dir = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    let absolute_collab_dir = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_collab_dir)
        .map_err(|e| GpgError::PathError(format!("Failed to locate collaborator files directory: {}", e)))?;


    ///////////////////////////////////////
    // make read-copy of .gpgtoml or .toml
    ///////////////////////////////////////

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Convert the error to GpgError
            return Err(GpgError::ValidationError(format!(
                "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            )));
        }
    };

    // Get the UME temp directory path with proper GpgError conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| GpgError::ValidationError(
            format!("Failed to get UME temp directory path: {}", io_err)
        ))?;

    // Extract the addressbook path string with proper error conversion to GpgError
    let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &local_owner_user_name,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| {
        // Convert the error to GpgError
        GpgError::ValidationError(format!(
            "Failed to get addressbook path for user '{}': {:?}",
            local_owner_user_name,
            e
        ))
    })?;

    let addressbookreadcopy_path = Path::new(&addressbook_readcopy_path_string);

    // // Path to the LOCAL OWNER USER'S address book file (absolute path)
    // let local_owner_address_book_filename = format!("{}__collaborator.toml", local_owner_user_name);
    // let absolute_local_owner_address_book_path = absolute_collab_dir.join(&local_owner_address_book_filename);

    // debug_log!("SLABE absolute_local_owner_address_book_path {}", &absolute_local_owner_address_book_path.display());

    // // Verify the LOCAL OWNER USER'S address book file exists
    // if !absolute_local_owner_address_book_path.exists() {
    //     return Err(GpgError::PathError(format!(
    //         "SLABE LOCAL OWNER USER'S address book file not found at: {}",
    //         absolute_local_owner_address_book_path.display()
    //     )));
    // } else {
    //     debug_log("SLABE LOCAL OWNER USER'S address book file exists");
    // }

    // // Get LOCAL OWNER USER'S GPG key ID - REFACTORED FOR DEBUGGING
    // // First convert the absolute path to a string
    // let absolute_local_owner_address_book_path_str = absolute_local_owner_address_book_path
    //     .to_str()
    //     .ok_or_else(|| GpgError::PathError(
    //         format!("Unable to convert local owner address book path to string: {}",
    //                 absolute_local_owner_address_book_path.display())
    //     ))?;

    // Log the exact path string being used for TOML reading
    debug_log!("SLABE Attempting to read GPG key ID from file at path: {}", addressbook_readcopy_path_string);

    // Now attempt to read the GPG key ID field
    let owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        &addressbook_readcopy_path_string,
        "gpg_publickey_id"
    ).map_err(|e| {
        debug_log!("ERROR: SLABE Failed to read GPG key ID with field name 'gpg_key_id'");
        GpgError::ValidationError(format!("SLABE Failed to read LOCAL OWNER USER'S GPG key ID: {}", e))
    })?;

    debug_log!("SLABE Successfully read owner_gpg_key_id: {}", &owner_gpg_key_id);

    // // Get LOCAL OWNER USER'S GPG key ID - this is used to reference the private key for signing
    // // We are using the LOCAL OWNER USER'S key to sign THEIR OWN address book
    // let owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
    //     absolute_local_owner_address_book_path.to_str().ok_or_else(||
    //         GpgError::PathError("SLABE Unable to convert local owner address book path to string".to_string())
    //     )?,
    //     "gpg_key_id"
    // ).map_err(|e| GpgError::ValidationError(format!("SLABE Failed to read LOCAL OWNER USER'S GPG key ID: {}", e)))?;

    println!("LOCAL OWNER USER'S GPG key ID (for signing their address book): {}", owner_gpg_key_id);

    // TODO: this may need to be updated for read-copies and .gpgtoml option
    //
    // Path to recipient's collaborator file (absolute path)
    let recipient_collab_filename = format!("{}__collaborator.toml", recipient_name);
    let absolute_recipient_collab_path = absolute_collab_dir.join(&recipient_collab_filename);

    // Check if recipient's collaborator file exists
    if !absolute_recipient_collab_path.exists() {
        return Err(GpgError::PathError(format!(
            "Recipient's collaborator file not found at: {}",
            absolute_recipient_collab_path.display()
        )));
    }

    // Get recipient's public GPG key - this is used for encryption
    // We encrypt the LOCAL OWNER USER'S address book with the recipient's public key
    // so only they can decrypt it
    let recipient_public_gpg_key = read_multiline_string_from_clearsigntoml(
        absolute_recipient_collab_path.to_str().ok_or_else(||
            GpgError::PathError("Unable to convert recipient collaborator path to string".to_string())
        )?,
        "gpg_key_public"
    ).map_err(|e| GpgError::ValidationError(format!("Failed to read recipient's public GPG key: {}", e)))?;

    // Create a temporary file to store the recipient's public key
    // This is used by the GPG encryption process
    let temp_key_path = absolute_output_dir.join(format!("{}_pubkey.asc", recipient_name));
    fs::write(&temp_key_path, recipient_public_gpg_key)
        .map_err(|e| GpgError::PathError(format!("Failed to write temporary key file: {}", e)))?;

    println!("\nProcessing with:");
    println!("LOCAL OWNER USER'S signing key ID: {}", owner_gpg_key_id);
    println!("Recipient's public key file: {}", temp_key_path.display());
    println!(
        "LOCAL OWNER USER'S address book file to be shared: {}",
        addressbook_readcopy_path_string,
        );



    // Use our existing function to clearsign and encrypt the LOCAL OWNER USER'S address book
    // We are:
    // 1. Taking the LOCAL OWNER USER'S address book file as input
    // 2. Signing it with the LOCAL OWNER USER'S private key (via their key ID)
    // 3. Encrypting it with the recipient's public key
    clearsign_and_encrypt_file_for_recipient(
        &addressbookreadcopy_path, // THE LOCAL OWNER USER'S ADDRESS BOOK (absolute path)
        &owner_gpg_key_id,         // LOCAL OWNER USER'S KEY FOR SIGNING
        &temp_key_path,             // RECIPIENT'S PUBLIC KEY FOR ENCRYPTION (absolute path)
    )?;

    // remove temp file
    let _ = cleanup_collaborator_temp_file(
        &addressbook_readcopy_path_string,
        &base_uma_temp_directory_path,
        );

    // Clean up the temporary key file
    if let Err(e) = fs::remove_file(&temp_key_path) {
        eprintln!("Warning: Failed to remove temporary key file: {}", e);
    }

    println!("\nLOCAL OWNER USER'S address book has been clearsigned and encrypted for {}!", recipient_name);
    println!("The encrypted LOCAL OWNER USER'S address book file is saved to:");
    println!("{}", absolute_output_dir.join(format!("{}__collaborator.gpgtoml", local_owner_user_name)).display());

    // TODO check file exits?
    debug_log("SLABE end!, The encrypted LOCAL OWNER USER'S address book file was saved...");

    Ok(())
}

/// Prompts the user to choose between saving encrypted or clearsigned format
///
/// This function presents a choice to the user about how to save the validated
/// collaborator addressbook file. The encrypted format (.gpgtoml) is recommended
/// and is the default choice.
///
/// # Returns
/// * `Ok(true)` - User chose to keep encrypted .gpgtoml format (default/recommended)
/// * `Ok(false)` - User chose to save as clearsigned .toml (readable but not encrypted)
/// * `Err(GpgError)` - If there's an error reading user input
///
/// # Behavior
/// - Pressing Enter (empty input) selects the default encrypted format
/// - Any input starting with 'y' or 'Y' selects encrypted format
/// - Any input starting with 'n' or 'N' selects clearsigned format
/// - Any other input re-prompts the user
fn prompt_user_for_save_format_choice() -> Result<bool, GpgError> {
    loop {
        // Display the choice prompt with clear guidance
        println!("\n=== File Format Choice ===");
        println!("The incoming encrypted file has been successfully validated and verified.");
        println!("\nHow would you like to save this collaborator's addressbook?");
        println!();
        println!("  1. Keep encrypted .gpgtoml format (RECOMMENDED, DEFAULT)");
        println!("     - Maintains encryption at rest");
        println!("     - More secure storage");
        println!("     - Press Enter or type 'yes'");
        println!();
        println!("  2. Save as clearsigned .toml file");
        println!("     - Human-readable format");
        println!("     - Still signed but NOT encrypted");
        println!("     - Type 'no' to select this option");
        println!();
        println!("Choice: Press Enter for encrypted (default), or type 'no' for clearsigned:");

        // Read user input
        let mut user_input = String::new();
        io::stdin()
            .read_line(&mut user_input)
            .map_err(|e| {
                let error_msg = format!("Failed to read user input for format choice: {}", e);
                println!("Error: {}", error_msg);
                GpgError::ValidationError(error_msg)
            })?;

        // Trim whitespace and convert to lowercase for comparison
        let trimmed_input = user_input.trim().to_lowercase();

        // Process user choice
        match trimmed_input.as_str() {
            // Empty input (just Enter) or explicit yes = encrypted format
            "" | "y" | "yes" | "1" => {
                println!("Selected: Encrypted .gpgtoml format (recommended)");
                return Ok(true);
            },
            // Explicit no = clearsigned format
            "n" | "no" | "2" => {
                println!("Selected: Clearsigned .toml format (not encrypted)");
                return Ok(false);
            },
            // Invalid input - loop again
            _ => {
                println!("Invalid choice. Please press Enter for default, or type 'no' for clearsigned.");
                continue;
            }
        }
    }
}

/// Process an incoming encrypted collaborator addressbook file
///
/// This function handles the secure processing of a GPG-encrypted clearsigned file
/// received from a collaborator. It performs the following steps:
///
/// 1. Reads the LOCAL OWNER USER's name from uma.toml
/// 2. Locates the LOCAL OWNER USER's addressbook file to extract their GPG key ID
/// 3. Finds the encrypted file in the incoming directory (must be a single .asc/.gpg file)
/// 4. Decrypts the file using the LOCAL OWNER USER's private key (identified by the key ID)
/// 5. Verifies the clearsign signature on the decrypted content
/// 6. Extracts the remote collaborator's username from the verified content
/// 7. Saves the verified clearsigned file to the collaborator addressbook directory
/// 8. Moves the original encrypted file to the processed directory
///
/// # Key Workflow Details
/// - The LOCAL OWNER USER's GPG key ID is read from their own addressbook file
/// - This key ID is needed to identify which private key to use for decryption
/// - Both decryption and signature verification must succeed for the process to complete
///
/// # File Format Options
/// After successful validation and verification, users can choose how to save the file:
///
/// * **Encrypted Format (.gpgtoml)** - DEFAULT/RECOMMENDED
///   - Keeps the original GPG-encrypted file as received
///   - Maintains encryption at rest for better security
///   - File remains encrypted with the recipient's public key
///   - Saved as: `{REMOTE_COLLABORATOR}__collaborator.gpgtoml`
///
/// * **Clearsigned Format (.toml)** - OPTIONAL
///   - Extracts and saves the clearsigned TOML content
///   - Human-readable but NOT encrypted
///   - Still contains GPG signature for authenticity
///   - Saved as: `{REMOTE_COLLABORATOR}__collaborator.toml`
///
/// The choice is presented after verification succeeds. Pressing Enter selects
/// the default encrypted format for maximum security.
///
/// # Path Handling
/// All file and directory paths are resolved relative to the executable's directory location,
/// NOT the current working directory. This ensures consistent behavior regardless of where
/// the program is executed from.
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
///
/// # Errors
/// * `GpgError::PathError` - If required files/directories don't exist or can't be accessed
/// * `GpgError::ValidationError` - If signature verification fails or required data is missing
/// * `GpgError::GpgOperationError` - If GPG decryption or verification operations fail
///
/// # File Flow
/// - LOCAL OWNER USER's addressbook: {EXECUTABLE_DIR}/project_graph_data/collaborator_files_address_book/{LOCAL_OWNER_USER}__collaborator.toml
/// - Source encrypted file: {EXECUTABLE_DIR}/invites_updates/incoming/*.asc or *.gpg
/// - Output file: {EXECUTABLE_DIR}/project_graph_data/collaborator_files_address_book/{REMOTE_COLLABORATOR}__collaborator.toml
/// - Moved original: {EXECUTABLE_DIR}/invites_updates/processed/{original_filename}
pub fn process_incoming_encrypted_collaborator_addressbook() -> Result<(), GpgError> {
    // 'PIECA' is an acronym for this function to identify it in logs
    debug_log("\nstarting -> PIECA fn process_incoming_encrypted_collaborator_addressbook()");

    // STEP 1: Get LOCAL OWNER USER's name from uma.toml
    // This identifies which addressbook file contains our GPG key ID
    debug_log!(
        "PIECA Step 1: Reading LOCAL OWNER USER's name from {}",
        UMA_TOML_CONFIGFILE_PATH_STR
    );

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIECA Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read LOCAL OWNER USER's name from uma.toml
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("PIECA Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIECA LOCAL OWNER USER's name is: {}", local_owner_user_name);
    println!("Processing as LOCAL OWNER USER: {}", local_owner_user_name);

    // STEP 2: Locate the LOCAL OWNER USER's addressbook file and extract their GPG key ID
    debug_log!("PIECA Step 2: Locating LOCAL OWNER USER's addressbook file to get GPG key ID");

    // Get absolute path to the collaborator files directory
    let relative_collab_dir = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    let absolute_collab_dir = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_collab_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to locate collaborator files directory: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Path to the LOCAL OWNER USER's addressbook file (absolute path)
    let local_owner_address_book_filename = format!("{}__collaborator.toml", local_owner_user_name);
    let absolute_local_owner_address_book_path = absolute_collab_dir.join(&local_owner_address_book_filename);

    debug_log!("PIECA LOCAL OWNER USER's addressbook path: {}", absolute_local_owner_address_book_path.display());

    // Verify the LOCAL OWNER USER's addressbook file exists
    if !absolute_local_owner_address_book_path.exists() {
        let error_msg = format!(
            "PIECA LOCAL OWNER USER's addressbook file not found at: {}",
            absolute_local_owner_address_book_path.display()
        );
        println!("Error: {}", error_msg);
        return Err(GpgError::PathError(error_msg));
    }

    debug_log!("PIECA LOCAL OWNER USER's addressbook file exists");

    // Convert the LOCAL OWNER USER's addressbook path to string for TOML reading
    let absolute_local_owner_address_book_path_str = absolute_local_owner_address_book_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = format!(
                "PIECA Unable to convert LOCAL OWNER USER's addressbook path to string: {}",
                absolute_local_owner_address_book_path.display()
            );
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read the LOCAL OWNER USER's GPG key ID from their addressbook file
    // This is the key ID needed to identify which private key to use for decryption
    debug_log!("PIECA Attempting to read GPG key ID from LOCAL OWNER USER's addressbook file");

    let local_owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        absolute_local_owner_address_book_path_str,
        "gpg_publickey_id"
    ).map_err(|e| {
        let error_msg = format!("PIECA Failed to read LOCAL OWNER USER's GPG key ID: {}", e);
        debug_log!("ERROR: {}", error_msg);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIECA Successfully read LOCAL OWNER USER's GPG key ID: {}", local_owner_gpg_key_id);

    // STEP 3: Find the encrypted file in the incoming directory
    debug_log!("PIECA Step 3: Locating encrypted file in incoming directory");

    // Resolve the incoming directory path (relative to executable)
    let relative_incoming_dir = "invites_updates/incoming";
    let absolute_incoming_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_incoming_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to resolve incoming directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    debug_log!("PIECA Scanning for encrypted files in: {}", absolute_incoming_dir.display());

    // Loop until we find exactly one .asc or .gpg file, or user cancels
    let encrypted_file_path = loop {
        // Scan the directory for .asc or .gpg files
        let mut encrypted_files = Vec::new();

        match fs::read_dir(&absolute_incoming_dir) {
            Ok(entries) => {
                for entry in entries {
                    if let Ok(entry) = entry {
                        let path = entry.path();
                        if path.is_file() {
                            if let Some(extension) = path.extension() {
                                if extension == "asc" || extension == "gpg" {
                                    encrypted_files.push(path);
                                }
                            }
                        }
                    }
                }
            },
            Err(e) => {
                let error_msg = format!("PIECA Failed to read incoming directory: {}", e);
                println!("Error: {}", error_msg);
                return Err(GpgError::PathError(error_msg));
            }
        }

        // Process based on how many files were found
        match encrypted_files.len() {
            0 => {
                println!("No encrypted files (.asc or .gpg) found in {}", absolute_incoming_dir.display());
                println!("Please place the encrypted collaborator file in this directory.");
                println!("Press Enter to try again, or type 'exit' to cancel.");

                let mut input = String::new();
                if let Err(e) = io::stdin().read_line(&mut input) {
                    let error_msg = format!("PIECA Failed to read user input: {}", e);
                    println!("Error: {}", error_msg);
                    return Err(GpgError::ValidationError(error_msg));
                }

                if input.trim().to_lowercase() == "exit" {
                    return Err(GpgError::ValidationError("Operation cancelled by user".to_string()));
                }

                // Loop continues to check again
            },
            1 => {
                // Exactly one file found, we can proceed
                debug_log!("PIECA Found one encrypted file: {}", encrypted_files[0].display());
                println!("Found encrypted file: {}", encrypted_files[0].display());
                break encrypted_files[0].clone();
            },
            _ => {
                println!("Multiple encrypted files found in {}:", absolute_incoming_dir.display());
                for (index, file) in encrypted_files.iter().enumerate() {
                    println!("  {}. {}", index + 1, file.file_name().unwrap_or_default().to_string_lossy());
                }
                println!("Please keep only the file you want to process and remove the others.");
                println!("Press Enter to try again, or type 'exit' to cancel.");

                let mut input = String::new();
                if let Err(e) = io::stdin().read_line(&mut input) {
                    let error_msg = format!("PIECA Failed to read user input: {}", e);
                    println!("Error: {}", error_msg);
                    return Err(GpgError::ValidationError(error_msg));
                }

                if input.trim().to_lowercase() == "exit" {
                    return Err(GpgError::ValidationError("Operation cancelled by user".to_string()));
                }

                // Loop continues to check again
            }
        }
    };

    // Extract the filename for later use
    let encrypted_filename = encrypted_file_path.file_name()
        .ok_or_else(|| {
            let error_msg = "PIECA Failed to extract filename from encrypted file path".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?
        .to_string_lossy()
        .to_string();

    debug_log!("PIECA Processing encrypted file: {}", encrypted_filename);

    // STEP 4: Create processed directory for moving files after processing
    debug_log!("PIECA Step 4: Setting up processed directory");

    let relative_processed_dir = "invites_updates/processed";
    let absolute_processed_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_processed_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to resolve processed directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Create the processed directory if it doesn't exist
    fs::create_dir_all(&absolute_processed_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to create processed directory: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // STEP 5: Set up temporary directory for processing
    debug_log!("PIECA Step 5: Setting up temporary directory for decryption and verification");

    let temp_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck("temp_gpg_processing")
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to create temp directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    fs::create_dir_all(&temp_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to create temp directory: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Temporary file to hold decrypted and clearsigned content
    let temp_clearsigned_path = temp_dir.join("temp_clearsigned.toml");

    // STEP 6: Decrypt and verify the signature using the LOCAL OWNER USER's key
    debug_log!("PIECA Step 6: Decrypting file and verifying signature");
    println!("Decrypting file using LOCAL OWNER USER's key ID: {}", local_owner_gpg_key_id);
    println!("and verifying signature...");

    // Call the function that does GPG decryption and verification
    // This uses the LOCAL OWNER USER's key ID to identify which private key to use
    let decrypt_result = extract_verify_store_gpg_encrypted_clearsign_toml(
        &encrypted_file_path,
        &local_owner_gpg_key_id,
        &temp_clearsigned_path
    );

    // maybe step here to gpg if flag?

    if let Err(e) = &decrypt_result {
        let error_msg = format!("PIECA Failed to decrypt or verify file: {:?}", e);
        println!("Error: {}", error_msg);
        println!("This could mean:");
        println!("1. The file is not properly encrypted or signed");
        println!("2. The file wasn't encrypted for your GPG key");
        println!("3. You don't have the sender's public key in your keyring");

        // Clean up temp directory before returning
        if let Err(clean_err) = fs::remove_dir_all(&temp_dir) {
            debug_log!("PIECA Warning: Failed to remove temporary directory: {}", clean_err);
        }

        return Err(GpgError::GpgOperationError(error_msg));
    }

    println!("File successfully decrypted and signature verified!");
    debug_log!("PIECA Successfully decrypted and verified file");

    // // STEP 7: Extract collaborator username from the verified content
    // debug_log!("PIECA Step 7: Extracting collaborator username from verified content");

    // // Convert temporary file path to string for TOML reading
    // let temp_clearsigned_path_str = temp_clearsigned_path
    //     .to_str()
    //     .ok_or_else(|| {
    //         let error_msg = "PIECA Unable to convert temp file path to string".to_string();
    //         println!("Error: {}", error_msg);
    //         GpgError::PathError(error_msg)
    //     })?;

    // // Read the username from the clearsigned TOML
    // // This is the remote collaborator whose addressbook we just received
    // let remote_collaborator_username = read_singleline_string_from_clearsigntoml(
    //     temp_clearsigned_path_str,
    //     "user_name"
    // ).map_err(|e| {
    //     let error_msg = format!("PIECA Failed to read remote collaborator's username: {}", e);
    //     println!("Error: {}", error_msg);
    //     println!("The decrypted file doesn't contain a valid 'user_name' field.");
    //     GpgError::ValidationError(error_msg)
    // })?;

    // debug_log!("PIECA Extracted remote collaborator's username: {}", remote_collaborator_username);
    // println!("Received addressbook from collaborator: {}", remote_collaborator_username);

    // // STEP 8: Save the verified clearsigned file to the collaborator directory
    // debug_log!("PIECA Step 8: Saving verified clearsigned file to collaborator directory");

    // // Create the output filename using the extracted username
    // let output_filename = format!("{}__collaborator.toml", remote_collaborator_username);
    // let output_file_path = absolute_collab_dir.join(&output_filename);

    // debug_log!("PIECA Saving verified clearsigned file to: {}", output_file_path.display());

    // // Copy the verified clearsigned file to the collaborator directory
    // fs::copy(&temp_clearsigned_path, &output_file_path)
    //     .map_err(|e| {
    //         let error_msg = format!("PIECA Failed to save verified clearsigned file: {}", e);
    //         println!("Error: {}", error_msg);
    //         GpgError::GpgOperationError(error_msg)
    //     })?;

    // println!("Successfully saved collaborator addressbook to: {}", output_file_path.display());

    // STEP 7: Extract collaborator username from the verified content
    debug_log!("PIECA Step 7: Extracting collaborator username from verified content");

    // Convert temporary file path to string for TOML reading
    let temp_clearsigned_path_str = temp_clearsigned_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIECA Unable to convert temp file path to string".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read the username from the clearsigned TOML
    // This is the remote collaborator whose addressbook we just received
    let remote_collaborator_username = read_singleline_string_from_clearsigntoml(
        temp_clearsigned_path_str,
        "user_name"
    ).map_err(|e| {
        let error_msg = format!("PIECA Failed to read remote collaborator's username: {}", e);
        println!("Error: {}", error_msg);
        println!("The decrypted file doesn't contain a valid 'user_name' field.");
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIECA Extracted remote collaborator's username: {}", remote_collaborator_username);
    println!("Received addressbook from collaborator: {}", remote_collaborator_username);

    // STEP 7.5: Ask user for preferred save format
    debug_log!("PIECA Step 7.5: Prompting user for save format preference");

    let save_encrypted_format = prompt_user_for_save_format_choice()
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to get user format choice: {}", e);
            println!("Error: {}", error_msg);
            e
        })?;

    // STEP 8: Save the file in the user's chosen format
    debug_log!("PIECA Step 8: Saving file in {} format to collaborator directory",
              if save_encrypted_format { "encrypted .gpgtoml" } else { "clearsigned .toml" });

    // Create the output filename based on user's choice
    let output_filename = if save_encrypted_format {
        // User chose to keep the encrypted format
        format!("{}__collaborator.gpgtoml", remote_collaborator_username)
    } else {
        // User chose clearsigned format (current behavior)
        format!("{}__collaborator.toml", remote_collaborator_username)
    };

    let output_file_path = absolute_collab_dir.join(&output_filename);

    debug_log!("PIECA Saving file to: {}", output_file_path.display());

    // Save the file based on user's choice
    if save_encrypted_format {
        // Copy the original encrypted file directly (it's already been validated)
        debug_log!("PIECA Copying original encrypted .gpgtoml file");
        fs::copy(&encrypted_file_path, &output_file_path)
            .map_err(|e| {
                let error_msg = format!("PIECA Failed to save encrypted .gpgtoml file: {}", e);
                println!("Error: {}", error_msg);
                GpgError::GpgOperationError(error_msg)
            })?;
        println!("Successfully saved encrypted collaborator addressbook to: {}", output_file_path.display());
    } else {
        // Copy the verified clearsigned file (original behavior)
        debug_log!("PIECA Copying extracted clearsigned .toml file");
        fs::copy(&temp_clearsigned_path, &output_file_path)
            .map_err(|e| {
                let error_msg = format!("PIECA Failed to save clearsigned .toml file: {}", e);
                println!("Error: {}", error_msg);
                GpgError::GpgOperationError(error_msg)
            })?;
        println!("Successfully saved clearsigned collaborator addressbook to: {}", output_file_path.display());
    }

    // STEP 9: Move the original encrypted file to the processed directory
    debug_log!("PIECA Step 9: Moving original encrypted file to processed directory");

    let processed_file_path = absolute_processed_dir.join(&encrypted_filename);

    debug_log!("PIECA Moving original encrypted file to: {}", processed_file_path.display());

    // Use fs::rename to move the file
    fs::rename(&encrypted_file_path, &processed_file_path)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to move original encrypted file: {}", e);
            println!("Warning: {}", error_msg);
            GpgError::GpgOperationError(error_msg)
        })?;

    println!("Original encrypted file moved to: {}", processed_file_path.display());

    // STEP 10: Clean up the temporary directory
    debug_log!("PIECA Step 10: Cleaning up temporary directory");

    if let Err(e) = fs::remove_dir_all(&temp_dir) {
        debug_log!("PIECA Warning: Failed to remove temporary directory: {}", e);
    }

    debug_log!("PIECA Successfully processed addressbook from collaborator: {}", remote_collaborator_username);
    println!("Successfully processed addressbook from collaborator: {}", remote_collaborator_username);

    println!("Press Enter to continue...");

    // this does nothing, press enter to proceed.
    let mut input = String::new();
    let _ = io::stdin()
        .read_line(&mut input)
        .map_err(|e| format!("Failed to read input: {:?}", e));

    // OK!
    debug_log("PIECA PIECA!!");

    Ok(())
}

/// Share the Local Owner User's (LOU) address book with a new collaborator using their incoming key
///
/// This function handles the secure sharing of the LOCAL OWNER USER'S address book file
/// with a new collaborator whose public GPG key has been placed in the incoming directory.
///
/// Specifically, this function:
/// 1. Identifies the local owner user's address book file (their collaborator.toml)
/// 2. Retrieves the local owner user's GPG key ID for signing
/// 3. Uses the recipient's public key from the incoming directory for encryption
/// 4. Clearsigns the LOCAL OWNER USER'S address book file using the owner's GPG key
/// 5. Encrypts this signed file with the recipient's public key
/// 6. Saves the encrypted file to the outgoing directory for sharing
///
/// # Path Handling
/// IMPORTANT: All file and directory paths in this function are resolved relative to the
/// executable's directory location, NOT the current working directory. This ensures consistent
/// behavior regardless of where the program is executed from.
///
/// The function automatically converts all paths to absolute paths based on the executable's
/// location before performing any file operations.
///
/// This process differs from sharing with an existing collaborator because it uses
/// a public key file provided externally rather than one already in the address book.
///
/// This enables secure sharing of contact information while ensuring:
/// - The recipient can verify the file came from the claimed sender (via signature)
/// - Only the intended recipient can decrypt the file (via their public key encryption)
///
/// # Arguments
/// * `recipient_name` - Name of the new collaborator to share the LOCAL OWNER USER'S address book with
///                      (used for labeling purposes only, as their info isn't in the system yet)
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
///
/// # Errors
/// * `GpgError::PathError` - If required files/directories don't exist or can't be created
/// * `GpgError::ValidationError` - If required data can't be read from configuration files
/// * `GpgError::EncryptionError` - If GPG encryption operations fail
///
/// # File Flow
/// - Source file: {EXECUTABLE_DIR}/project_graph_data/collaborator_files_address_book/{LOCAL_OWNER_USER}__collaborator.toml
/// - Recipient key: {EXECUTABLE_DIR}/invites_updates/incoming/key.asc (must be placed there before calling this function)
/// - Output file: {EXECUTABLE_DIR}/invites_updates/outgoing/{LOCAL_OWNER_USER}__collaborator.gpgtoml
///
/// # Dependencies
/// - Uses constant INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR for the location of the incoming key
/// - For safe toml handling as 'clearsign_toml', fields from addressbook files are read with:
///   - read_singleline_string_from_clearsigntoml() for single-line fields
///   - read_multiline_string_from_clearsigntoml() for multi-line fields
fn share_lou_addressbook_with_incomingkey() -> Result<(), GpgError> {
    println!("\nSharing LOCAL OWNER USER'S address book with new collaborator.");
    println!("Using their public key from incoming directory");
    debug_log("\nstarting -> SLABIK fn share_lou_addressbook_with_incomingkey()");

    // Create output directory using absolute path relative to executable
    let relative_output_dir = "invites_updates/outgoing";
    let absolute_output_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_output_dir)
        .map_err(|e| GpgError::PathError(format!("SLABIK Failed to resolve output directory path: {}", e)))?;

    debug_log!("SLABIK Output directory absolute path: {}", absolute_output_dir.display());
    debug_log!("SLABIK Output directory exists? {}", absolute_output_dir.exists());

    // Create the output directory if it doesn't exist
    fs::create_dir_all(&absolute_output_dir)
        .map_err(|e| GpgError::PathError(format!("Failed to create output directory: {}", e)))?;

    debug_log!("SLABIK Output directory created successfully? {}", absolute_output_dir.exists());

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| GpgError::PathError(format!("SLABIK Failed to locate uma.toml configuration file: {}", e)))?;

    debug_log!("SLABIK UMA TOML absolute path: {}", absolute_uma_toml_path.display());
    debug_log!("SLABIK UMA TOML file exists: {}", absolute_uma_toml_path.exists());

    // Get local owner username from configuration - REFACTORED FOR DEBUGGING
    // Convert PathBuf to string first
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| GpgError::PathError("SLABIK Unable to convert UMA TOML path to string".to_string()))?;

    // Log the exact string that will be used by the TOML reader
    debug_log!("SLABIK Attempting to read from UMA TOML file at path string: {}", absolute_uma_toml_path_str);

    // Now attempt to read the actual field value
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| GpgError::ValidationError(format!("Failed to read local owner username: {}", e)))?;

    debug_log!("SLABIK Successfully read local_owner_user_name: {}", &local_owner_user_name);
    println!("Local owner username (whose address book we are sharing): {}", local_owner_user_name);

    // Get absolute path to the collaborator files directory
    let relative_collab_dir = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    let absolute_collab_dir = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_collab_dir)
        .map_err(|e| GpgError::PathError(format!("SLABIK Failed to locate collaborator files directory: {}", e)))?;

    debug_log!("SLABIK Collaborator directory absolute path: {}", absolute_collab_dir.display());

    // Path to the LOCAL OWNER USER'S address book file (absolute path)
    let local_owner_address_book_filename = format!("{}__collaborator.toml", local_owner_user_name);
    let absolute_local_owner_address_book_path = absolute_collab_dir.join(&local_owner_address_book_filename);

    debug_log!("SLABIK Absolute local owner address book path: {}", absolute_local_owner_address_book_path.display());

    // Verify the LOCAL OWNER USER'S address book file exists
    if !absolute_local_owner_address_book_path.exists() {
        return Err(GpgError::PathError(format!(
            "LOCAL OWNER USER'S address book file not found at: {}",
            absolute_local_owner_address_book_path.display()
        )));
    }

    debug_log!("SLABIK LOCAL OWNER USER'S address book file exists: {}", absolute_local_owner_address_book_path.exists());

    // Get LOCAL OWNER USER'S GPG key ID - REFACTORED FOR DEBUGGING
    // First convert the absolute path to a string
    let absolute_local_owner_address_book_path_str = absolute_local_owner_address_book_path
        .to_str()
        .ok_or_else(|| GpgError::PathError(
            format!("SLABIK Unable to convert local owner address book path to string: {}",
                    absolute_local_owner_address_book_path.display())
        ))?;

    // Log the exact path string being used for TOML reading
    debug_log!("SLABIK Attempting to read GPG key ID from file at path: {}", absolute_local_owner_address_book_path_str);

    // Now attempt to read the GPG key ID field
    let owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        absolute_local_owner_address_book_path_str,
        "gpg_publickey_id"
    ).map_err(|e| {
        debug_log!("ERROR: SLABIK Failed to read GPG key ID with field name 'gpg_publickey_id'");
        GpgError::ValidationError(format!("SLABIK Failed to read LOCAL OWNER USER'S GPG key ID: {}", e))
    })?;

    debug_log!("SLABIK Successfully read owner_gpg_key_id: {}", &owner_gpg_key_id);
    println!("LOCAL OWNER USER'S GPG key ID (for signing their address book): {}", owner_gpg_key_id);

    // Path to recipient's public key file in the incoming directory with absolute path
    let relative_incoming_key_path = INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR;
    let absolute_recipient_public_key_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_incoming_key_path)
        .map_err(|e| GpgError::PathError(format!(
            "Recipient's public key not found at: {} - Error: {}",
            relative_incoming_key_path, e
        )))?;

    debug_log!("SLABIK Absolute recipient public key path: {}", absolute_recipient_public_key_path.display());
    debug_log!("SLABIK Recipient public key file exists: {}", absolute_recipient_public_key_path.exists());

    println!("\nProcessing with:");
    println!("LOCAL OWNER USER'S signing key ID: {}", owner_gpg_key_id);
    println!("Recipient's public key file: {}", absolute_recipient_public_key_path.display());
    println!("LOCAL OWNER USER'S address book file to be shared: {}", absolute_local_owner_address_book_path.display());

    // Use our existing function to clearsign and encrypt the LOCAL OWNER USER'S address book
    // We are:
    // 1. Taking the LOCAL OWNER USER'S address book file as input
    // 2. Signing it with the LOCAL OWNER USER'S private key (via their key ID)
    // 3. Encrypting it with the recipient's public key from the incoming directory
    clearsign_and_encrypt_file_for_recipient(
        &absolute_local_owner_address_book_path,   // THE LOCAL OWNER USER'S ADDRESS BOOK (absolute path)
        &owner_gpg_key_id,                        // LOCAL OWNER USER'S KEY FOR SIGNING
        &absolute_recipient_public_key_path       // RECIPIENT'S PUBLIC KEY FOR ENCRYPTION (absolute path)
    )?;

    // Get the output file path for display
    let absolute_output_file_path = absolute_output_dir.join(format!("{}__collaborator.gpgtoml", local_owner_user_name));

    println!("\nLOCAL OWNER USER'S address book has been clearsigned and encrypted.");
    println!("The encrypted LOCAL OWNER USER'S address book file is saved to:");
    println!("{}", absolute_output_file_path.display());

    println!("\nImportant: After sending this file to the recipient, you may want to add them");
    println!("to your address book using their public key from: {}", absolute_recipient_public_key_path.display());

    println!("Press Enter to continue...");
    // this does nothing, press enter to proceed.
    let mut input = String::new();
    let _ = io::stdin()
        .read_line(&mut input)
        .map_err(|e| format!("Failed to read input: {:?}", e));

    debug_log!("\nSLABIK  Completed fn share_lou_addressbook_with_incomingkey() successfully");
    Ok(())
}

/// Process an incoming encrypted team channel file
///
/// This function handles the secure processing of a GPG-encrypted clearsigned team channel file
/// received from a remote collaborator. It performs the following steps:
///
/// 1. Reads the LOCAL OWNER USER's name from uma.toml
/// 2. Locates the LOCAL OWNER USER's addressbook file to extract their GPG key ID
/// 3. Finds the encrypted file in the incoming teamchannels directory (must be a single .asc/.gpg file)
/// 4. Decrypts the file using the LOCAL OWNER USER's private key (identified by the key ID)
/// 5. Extracts the team channel owner's name from the decrypted content
/// 6. Locates the team channel owner's addressbook file to extract their GPG public key
/// 7. Verifies the clearsign signature using the team channel owner's public key
/// 8. Extracts the team channel name from the verified content
/// 9. Creates the team channel directory structure and prompts for save format
/// 10. Saves the team channel file in the user's chosen format (encrypted or clearsigned)
/// 11. Moves the original encrypted file to the processed directory
///
/// # Path Handling
/// All file and directory paths are resolved relative to the executable's directory location,
/// NOT the current working directory. This ensures consistent behavior regardless of where
/// the program is executed from.
///
/// # File Format Options
/// After successful validation and verification, users can choose how to save the team channel file:
///
/// * **Encrypted Format (node.gpgtoml)** - DEFAULT/RECOMMENDED
///   - Keeps the original GPG-encrypted file as received
///   - Maintains encryption at rest for better security
///   - File remains encrypted with the recipient's public key
///   - Saved as: `{TEAM_CHANNEL_NAME}/node.gpgtoml`
///
/// * **Clearsigned Format (node.toml)** - OPTIONAL
///   - Saves the clearsigned TOML content
///   - Human-readable but NOT encrypted
///   - Still contains GPG signature for authenticity
///   - Saved as: `{TEAM_CHANNEL_NAME}/node.toml`
///
/// The choice is presented after verification succeeds. Pressing Enter selects
/// the default encrypted format for maximum security. Only one file format is saved
/// based on the user's choice (unlike earlier versions that saved both).
///

/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
///
/// # Errors
/// * `GpgError::PathError` - If required files/directories don't exist or can't be accessed
/// * `GpgError::ValidationError` - If signature verification fails or required data is missing
/// * `GpgError::GpgOperationError` - If GPG decryption or verification operations fail
pub fn process_incoming_encrypted_teamchannel() -> Result<(), GpgError> {
    // 'PIET' is an acronym for this function to identify it in logs
    debug_log!("\nStarting -> PIET fn process_incoming_encrypted_teamchannel()");

    // STEP 1: Get LOCAL OWNER USER's name from uma.toml
    debug_log!("
        PIET Step 1: Reading LOCAL OWNER USER's name from {}",
        UMA_TOML_CONFIGFILE_PATH_STR,
    );

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIET Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read LOCAL OWNER USER's name from uma.toml
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("PIET Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIET LOCAL OWNER USER's name is: {}", local_owner_user_name);
    println!("Processing as LOCAL OWNER USER: {}", local_owner_user_name);

    // STEP 2: Locate the LOCAL OWNER USER's addressbook file and extract their GPG key ID
    debug_log!("PIET Step 2: Locating LOCAL OWNER USER's addressbook file to get GPG key ID");

    // Get absolute path to the collaborator files directory
    let relative_collab_dir = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    let absolute_collab_dir = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_collab_dir)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to locate collaborator files directory: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Path to the LOCAL OWNER USER's addressbook file (absolute path)
    let local_owner_address_book_filename = format!("{}__collaborator.toml", local_owner_user_name);
    let absolute_local_owner_address_book_path = absolute_collab_dir.join(&local_owner_address_book_filename);

    debug_log!("PIET LOCAL OWNER USER's addressbook path: {}", absolute_local_owner_address_book_path.display());

    // Verify the LOCAL OWNER USER's addressbook file exists
    if !absolute_local_owner_address_book_path.exists() {
        let error_msg = format!(
            "PIET LOCAL OWNER USER's addressbook file not found at: {}",
            absolute_local_owner_address_book_path.display()
        );
        println!("Error: {}", error_msg);
        return Err(GpgError::PathError(error_msg));
    }

    debug_log!("PIET LOCAL OWNER USER's addressbook file exists");

    // Convert the LOCAL OWNER USER's addressbook path to string for TOML reading
    let absolute_local_owner_address_book_path_str = absolute_local_owner_address_book_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = format!(
                "PIET Unable to convert LOCAL OWNER USER's addressbook path to string: {}",
                absolute_local_owner_address_book_path.display()
            );
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read the LOCAL OWNER USER's GPG key ID from their addressbook file
    debug_log!("PIET Attempting to read GPG key ID from LOCAL OWNER USER's addressbook file");

    let local_owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        absolute_local_owner_address_book_path_str,
        "gpg_publickey_id"
    ).map_err(|e| {
        let error_msg = format!("PIET Failed to read LOCAL OWNER USER's GPG key ID: {}", e);
        debug_log!("ERROR: {}", error_msg);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIET Successfully read LOCAL OWNER USER's GPG key ID: {}", local_owner_gpg_key_id);

    // STEP 3: Find the encrypted file in the incoming teamchannels directory
    debug_log!("PIET Step 3: Locating encrypted file in incoming teamchannels directory");

    // Resolve the incoming teamchannels directory path (relative to executable)
    let relative_incoming_dir = "invites_updates/incoming";
    let absolute_incoming_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_incoming_dir)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to resolve incoming teamchannels directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Create the directory if it doesn't exist
    if let Err(e) = fs::create_dir_all(&absolute_incoming_dir) {
        let error_msg = format!("PIET Failed to create incoming teamchannels directory: {}", e);
        println!("Error: {}", error_msg);
        return Err(GpgError::GpgOperationError(error_msg));
    }

    debug_log!("PIET Scanning for encrypted files in: {}", absolute_incoming_dir.display());

    // Loop until we find exactly one .asc or .gpg file, or user cancels
    let encrypted_file_path = loop {
        // Scan the directory for .asc or .gpg files
        let mut encrypted_files = Vec::new();

        match fs::read_dir(&absolute_incoming_dir) {
            Ok(entries) => {
                for entry in entries {
                    if let Ok(entry) = entry {
                        let path = entry.path();
                        if path.is_file() {
                            if let Some(extension) = path.extension() {
                                if extension == "asc" || extension == "gpg" {
                                    encrypted_files.push(path);
                                }
                            }
                        }
                    }
                }
            },
            Err(e) => {
                let error_msg = format!("PIET Failed to read incoming teamchannels directory: {}", e);
                println!("Error: {}", error_msg);
                return Err(GpgError::GpgOperationError(error_msg));
            }
        }

        // Process based on how many files were found
        match encrypted_files.len() {
            0 => {
                println!("No encrypted files (.asc or .gpg) found in {}", absolute_incoming_dir.display());
                println!("Please place the encrypted team channel file in this directory.");
                println!("Press Enter to try again, or type 'exit' to cancel.");

                let mut input = String::new();
                if let Err(e) = io::stdin().read_line(&mut input) {
                    let error_msg = format!("PIET Failed to read user input: {}", e);
                    println!("Error: {}", error_msg);
                    return Err(GpgError::ValidationError(error_msg));
                }

                if input.trim().to_lowercase() == "exit" {
                    return Err(GpgError::ValidationError("Operation cancelled by user".to_string()));
                }

                // Loop continues to check again
            },
            1 => {
                // Exactly one file found, we can proceed
                debug_log!("PIET Found one encrypted file: {}", encrypted_files[0].display());
                println!("Found encrypted file: {}", encrypted_files[0].display());
                break encrypted_files[0].clone();
            },
            _ => {
                println!("Multiple encrypted files found in {}:", absolute_incoming_dir.display());
                for (index, file) in encrypted_files.iter().enumerate() {
                    println!("  {}. {}", index + 1, file.file_name().unwrap_or_default().to_string_lossy());
                }
                println!("Please keep only the file you want to process and remove the others.");
                println!("Press Enter to try again, or type 'exit' to cancel.");

                let mut input = String::new();
                if let Err(e) = io::stdin().read_line(&mut input) {
                    let error_msg = format!("PIET Failed to read user input: {}", e);
                    println!("Error: {}", error_msg);
                    return Err(GpgError::ValidationError(error_msg));
                }

                if input.trim().to_lowercase() == "exit" {
                    return Err(GpgError::ValidationError("Operation cancelled by user".to_string()));
                }

                // Loop continues to check again
            }
        }
    };

    // Extract the filename for later use
    let encrypted_filename = encrypted_file_path.file_name()
        .ok_or_else(|| {
            let error_msg = "PIET Failed to extract filename from encrypted file path".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?
        .to_string_lossy()
        .to_string();

    debug_log!("PIET Processing encrypted file: {}", encrypted_filename);

    // STEP 4: Create processed directory for moving files after processing
    debug_log!("PIET Step 4: Setting up processed directory");

    let relative_processed_dir = "invites_updates/processed";
    let absolute_processed_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_processed_dir)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to resolve processed directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Create the processed directory if it doesn't exist
    if let Err(e) = fs::create_dir_all(&absolute_processed_dir) {
        let error_msg = format!("PIET Failed to create processed directory: {}", e);
        println!("Error: {}", error_msg);
        return Err(GpgError::GpgOperationError(error_msg));
    }

    // STEP 5: Set up temporary directory for processing
    debug_log!("PIET Step 5: Setting up temporary directory for decryption and verification");

    let temp_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck("temp_gpg_processing")
        .map_err(|e| {
            let error_msg = format!("PIET Failed to create temp directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    if let Err(e) = fs::create_dir_all(&temp_dir) {
        let error_msg = format!("PIET Failed to create temp directory: {}", e);
        println!("Error: {}", error_msg);
        return Err(GpgError::GpgOperationError(error_msg));
    }

    // Temporary file to hold decrypted (but not yet verified) content
    let temp_decrypted_path = temp_dir.join("temp_decrypted.toml");

    // STEP 6: Decrypt the file using the LOCAL OWNER USER's key
    debug_log!("PIET Step 6: Decrypting file using LOCAL OWNER USER's key");
    println!("Decrypting file using LOCAL OWNER USER's key ID: {}", local_owner_gpg_key_id);

    // Decrypt the file without verification at this stage
    let decrypt_result = decrypt_gpgfile_to_output(
        &encrypted_file_path,
        &temp_decrypted_path
    );

    if let Err(e) = &decrypt_result {
        let error_msg = format!("PIET Failed to decrypt file: {:?}", e);
        println!("Error: {}", error_msg);
        println!("This could mean:");
        println!("1. The file is not properly encrypted or signed");
        println!("2. The file wasn't encrypted for your GPG key");
        println!("3. You don't have the sender's public key in your keyring");

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    debug_log!("PIET Successfully decrypted file");

    // STEP 7: Extract team channel owner from decrypted (but not yet verified) content
    debug_log!("PIET Step 7: Extracting team channel owner from decrypted content");

    // Convert temporary file path to string for TOML reading
    let temp_decrypted_path_str = temp_decrypted_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIET Unable to convert temp file path to string".to_string();
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            GpgError::PathError(error_msg)
        })?;

    // Read the team channel owner from the decrypted content
    // Note: Reading from unverified content, but we need it to find the right public key for verification
    let unverified_content = match fs::read_to_string(&temp_decrypted_path) {
        Ok(content) => content,
        Err(e) => {
            let error_msg = format!("PIET Failed to read decrypted content: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            return Err(GpgError::GpgOperationError(error_msg));
        }
    };

    // Parse to find the owner field in the clearsigned content
    let team_channel_owner = unverified_content.lines()
        .find_map(|line| {
            if line.trim().starts_with("owner =") {
                let parts: Vec<&str> = line.split('=').collect();
                if parts.len() >= 2 {
                    let value = parts[1].trim();
                    // Remove quotes if present
                    let clean_value = value.trim_matches('"').trim_matches('\'');
                    Some(clean_value.to_string())
                } else {
                    None
                }
            } else {
                None
            }
        })
        .ok_or_else(|| {
            let error_msg = "PIET Failed to find owner field in decrypted content".to_string();
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            GpgError::ValidationError(error_msg)
        })?;

    debug_log!("PIET Extracted team channel owner: {}", team_channel_owner);
    println!("PIET Team channel owned by: {}", team_channel_owner);

    // STEP 8: Get team channel owner's public key for verification
    debug_log!("PIET Step 8: Getting team channel owner's public key for verification");

    // // TODO maybe needs to be updated for readcopy and .gpg-option
    // // Path to the team channel owner's addressbook file
    // let team_channel_owner_address_book_filename = format!("{}__collaborator.toml", team_channel_owner);
    // let absolute_team_channel_owner_address_book_path = absolute_collab_dir.join(&team_channel_owner_address_book_filename);

    // debug_log!("PIET Team channel owner's addressbook path: {}", absolute_team_channel_owner_address_book_path.display());

    // // Verify the team channel owner's addressbook file exists
    // if !absolute_team_channel_owner_address_book_path.exists() {
    //     let error_msg = format!(
    //         "PIET Team channel owner's addressbook file not found at: {}",
    //         absolute_team_channel_owner_address_book_path.display()
    //     );
    //     println!("Error: {}", error_msg);
    //     println!("You need to import the team channel owner's addressbook first.");

    //     // Clean up temp directory before returning
    //     let _ = fs::remove_dir_all(&temp_dir);

    //     return Err(GpgError::PathError(error_msg));
    // }

    // A. Check for either node.toml or node.gpgtoml
    // let node_toml_path = absolute_specific_team_channel_directory_path.join("node.toml");
    let cl_team_channel_owner_address_book_filename = format!("{}__collaborator.toml", team_channel_owner);
    let cl_absolute_team_channel_owner_address_book_path = absolute_collab_dir.join(&cl_team_channel_owner_address_book_filename);

    // let node_gpgtoml_path = absolute_specific_team_channel_directory_path.join("node.gpgtoml");
    let gpg_team_channel_owner_address_book_filename = format!("{}__collaborator.gpgtoml", team_channel_owner);
    let gpg_absolute_team_channel_owner_address_book_path = absolute_collab_dir.join(&gpg_team_channel_owner_address_book_filename);


    let absolute_team_channel_owner_address_book_path = if cl_absolute_team_channel_owner_address_book_path.exists() {
        debug_log!("PIET: Found .toml");
        cl_absolute_team_channel_owner_address_book_path
    } else if gpg_absolute_team_channel_owner_address_book_path.exists() {
        debug_log!("PIET: Found .gpgtoml");
        gpg_absolute_team_channel_owner_address_book_path
    } else {
        debug_log("PIET: Neither .toml nor .gpgtoml found in  directory");
        return Err(GpgError::PathError(
            "PIET: Neither .toml nor .gpgtoml found in  directory".to_string()
        ));
    };

    // B. Get readable temp copy (handles decryption if .gpgtoml)
    debug_log!("PIET: Getting readable copy of file");

    // Get GPG fingerprint
    let gpg_fingerprint = LocalUserUma::read_gpg_fingerprint_from_file()
        .map_err(|e| GpgError::PathError(
            format!("PIET: Failed to read GPG fingerprint from uma.toml: {}", e)
        ))?;

    // Get temp directory
    let temp_dir = get_base_uma_temp_directory_path()
        .map_err(|e| GpgError::PathError(
            format!("PIET: Failed to get temp directory path: {}", e)
        ))?;

    // Get readable copy
    let absolute_team_channel_owner_address_book_path_str = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &absolute_team_channel_owner_address_book_path,
        &gpg_fingerprint,
        &temp_dir,
    ).map_err(|e| GpgError::PathError(
        format!("PIET: Failed to get readable copy of node file: {:?}", e)
    ))?;

    debug_log!("PIET: Node readcopy path: {}", absolute_team_channel_owner_address_book_path_str);

    // Now use node_readcopy_path to read fields...

    // ////////////////////////

    // // Convert the team channel owner's addressbook path to string for TOML reading
    // let absolute_team_channel_owner_address_book_path_str = absolute_team_channel_owner_address_book_path
    //     .to_str()
    //     .ok_or_else(|| {
    //         let error_msg = format!(
    //             "PIET Unable to convert team channel owner's addressbook path to string: {}",
    //             absolute_team_channel_owner_address_book_path.display()
    //         );
    //         println!("Error: {}", error_msg);

    //         // Clean up temp directory before returning
    //         let _ = fs::remove_dir_all(&temp_dir);

    //         GpgError::PathError(error_msg)
    //     })?;

    // Read the team channel owner's public GPG key from their addressbook
    let team_channel_owner_public_key = read_multiline_string_from_clearsigntoml(
        &absolute_team_channel_owner_address_book_path_str,
        "gpg_key_public"
    ).map_err(|e| {
        let error_msg = format!("PIET Failed to read team channel owner's public GPG key: {}", e);
        println!("Error: {}", error_msg);

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIET Successfully read team channel owner's public GPG key");

    // Create temporary file for the team channel owner's public key
    let temp_public_key_path = temp_dir.join("temp_public_key.asc");

    // Write public key to temporary file
    if let Err(e) = fs::write(&temp_public_key_path, team_channel_owner_public_key) {
        let error_msg = format!("PIET Failed to write team channel owner's public key to temp file: {}", e);
        println!("Error: {}", error_msg);

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    // STEP 9: Verify the clearsign signature using team channel owner's public key
    debug_log!("PIET Step 9: Verifying clearsign signature using team channel owner's public key");
    println!("Verifying signature using team channel owner's public key...");

    // Temporary file to hold verified content
    let temp_verified_path = temp_dir.join("temp_verified.toml");

    // Verify the clearsign signature
    let verify_result = verify_clearsigned_file_and_extract_content_to_output(
        &temp_decrypted_path,
        &temp_public_key_path,
        &temp_verified_path
    );

    if let Err(e) = &verify_result {
        let error_msg = format!("PIET Failed to verify clearsign signature: {:?}", e);
        println!("Error: {}", error_msg);
        println!("The signature could not be verified with the team channel owner's public key.");

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    println!("Signature successfully verified!");
    debug_log!("PIET Successfully verified clearsign signature");

    // STEP 10: Extract team channel name from verified content
    debug_log!("PIET Step 10: Extracting team channel name from verified content");

    // Convert verified file path to string for TOML reading
    let temp_verified_path_str = temp_verified_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIET Unable to convert verified file path to string".to_string();
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            GpgError::PathError(error_msg)
        })?;

    // Read the team channel name from the verified content
    let team_channel_name = read_single_line_string_field_from_toml(
        temp_verified_path_str,
        "node_name"
    ).map_err(|e| {
        let error_msg = format!("PIET Failed to read team channel name from verified content: {}", e);
        println!("Error: {}", error_msg);
        println!("The verified file doesn't contain a valid 'team_channel_name' field.");

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIET Extracted team channel name: {}", team_channel_name);
    println!("Imported team channel name: {}", team_channel_name);

    // TODO: STEP 11: Check for port conflicts with existing team channels
    // This is intentionally left as a placeholder for future implementation
    debug_log!("PIET Step 11: TODO - Check for port conflicts with existing team channels");

    // STEP 12: Create team channel directory structure
    debug_log!("PIET Step 12: Creating team channel directory structure");

    // Get absolute path to team channels directory
    let relative_team_channels_dir = "project_graph_data/team_channels";
    let absolute_team_channels_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_team_channels_dir)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to resolve team channels directory path: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            GpgError::PathError(error_msg)
        })?;

    // Create the team channels directory if it doesn't exist
    if let Err(e) = fs::create_dir_all(&absolute_team_channels_dir) {
        let error_msg = format!("PIET Failed to create team channels directory: {}", e);
        println!("Error: {}", error_msg);

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    // Create specific team channel directory
    let absolute_specific_team_channel_dir = absolute_team_channels_dir.join(&team_channel_name);

    // Create the specific team channel directory if it doesn't exist
    if let Err(e) = fs::create_dir_all(&absolute_specific_team_channel_dir) {
        let error_msg = format!("PIET Failed to create specific team channel directory: {}", e);
        println!("Error: {}", error_msg);

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    debug_log!("PIET Created team channel directory: {}", absolute_specific_team_channel_dir.display());

    // // Create paths for node.toml and node.gpg in the team channel directory
    // let node_toml_path = absolute_specific_team_channel_dir.join("node.toml");
    // let node_gpg_path = absolute_specific_team_channel_dir.join("node.gpgtoml");

    // // STEP 13: Save verified content as node.toml
    // debug_log!("PIET Step 13: Saving verified content as node.toml");

    // // Copy verified content to node.toml
    // if let Err(e) = fs::copy(&temp_verified_path, &node_toml_path) {
    //     let error_msg = format!("PIET Failed to save node.toml: {}", e);
    //     println!("Error: {}", error_msg);

    //     // Clean up temp directory before returning
    //     let _ = fs::remove_dir_all(&temp_dir);

    //     return Err(GpgError::GpgOperationError(error_msg));
    // }

    // debug_log!("PIET Saved node.toml to: {}", node_toml_path.display());

    // // STEP 14: Save original encrypted file as node.gpg
    // debug_log!("PIET Step 14: Saving original encrypted file as node.gpg");

    // // Copy original encrypted file to node.gpg
    // if let Err(e) = fs::copy(&encrypted_file_path, &node_gpg_path) {
    //     let error_msg = format!("PIET Failed to save node.gpg: {}", e);
    //     println!("Error: {}", error_msg);

    //     // Clean up temp directory before returning
    //     let _ = fs::remove_dir_all(&temp_dir);

    //     return Err(GpgError::GpgOperationError(error_msg));
    // }

    // debug_log!("PIET Saved node.gpg to: {}", node_gpg_path.display());

    // STEP 12.5: Ask user for preferred save format
    debug_log!("PIET Step 12.5: Prompting user for save format preference");

    let save_encrypted_format = prompt_user_for_save_format_choice()
        .map_err(|e| {
            let error_msg = format!("PIET Failed to get user format choice: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            e
        })?;

    // STEP 13: Save the team channel file in the user's chosen format
    debug_log!("PIET Step 13: Saving team channel file in {} format",
              if save_encrypted_format { "encrypted .gpgtoml" } else { "clearsigned .toml" });

    // Determine the output filename based on user's choice
    let node_filename = if save_encrypted_format {
        // User chose to keep the encrypted format
        "node.gpgtoml"
    } else {
        // User chose clearsigned format
        "node.toml"
    };

    let node_file_path = absolute_specific_team_channel_dir.join(node_filename);

    debug_log!("PIET Saving team channel file to: {}", node_file_path.display());

    // Save the file based on user's choice
    if save_encrypted_format {
        // Copy the original encrypted file directly (it's already been validated)
        debug_log!("PIET Copying original encrypted .gpgtoml file");

        if let Err(e) = fs::copy(&encrypted_file_path, &node_file_path) {
            let error_msg = format!("PIET Failed to save encrypted node.gpgtoml: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            return Err(GpgError::GpgOperationError(error_msg));
        }

        println!("Successfully saved encrypted team channel file to: {}", node_file_path.display());
        debug_log!("PIET Saved node.gpgtoml to: {}", node_file_path.display());
    } else {
        // Copy the verified clearsigned content
        debug_log!("PIET Copying extracted clearsigned .toml file");

        // First, we need to copy the clearsigned content (not just the extracted TOML)
        // The temp_decrypted_path contains the clearsigned version
        if let Err(e) = fs::copy(&temp_decrypted_path, &node_file_path) {
            let error_msg = format!("PIET Failed to save clearsigned node.toml: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            return Err(GpgError::GpgOperationError(error_msg));
        }

        println!("Successfully saved clearsigned team channel file to: {}", node_file_path.display());
        debug_log!("PIET Saved node.toml to: {}", node_file_path.display());
    }

    // STEP 14 is now removed - we no longer save both formats


    // STEP 15: Move original encrypted file to processed directory
    debug_log!("PIET Step 15: Moving original encrypted file to processed directory");

    let processed_file_path = absolute_processed_dir.join(&encrypted_filename);

    // Move the original file to the processed directory
    if let Err(e) = fs::rename(&encrypted_file_path, &processed_file_path) {
        let error_msg = format!("PIET Failed to move original encrypted file: {}", e);
        println!("Warning: {}", error_msg);

        // This is a non-critical error, so we'll just log it and continue
        debug_log!("PIET Warning: {}", error_msg);
    } else {
        debug_log!("PIET Moved original encrypted file to: {}", processed_file_path.display());
    }

    // STEP 16: Clean up temporary directory
    debug_log!("PIET Step 16: Cleaning up temporary directory");

    if let Err(e) = fs::remove_dir_all(&temp_dir) {
        debug_log!("PIET Warning: Failed to remove temporary directory: {}", e);
        println!("Warning: Failed to clean up temporary files: {}", e);
        // This is a non-critical error, so we'll just log it and continue
    }

    // STEP 17: Report success to user
    debug_log!("PIET Step 17: Reporting success to user");
    println!("\nTeam channel successfully imported!");
    println!("Team channel name: {}", team_channel_name);
    println!("Team channel owner: {}", team_channel_owner);
    println!("Files saved to: {}", absolute_specific_team_channel_dir.display());

    debug_log!("PIET Successfully completed team channel import process");

    // Wait for user acknowledgment
    println!("\nPress Enter to continue...");
    let mut input = String::new();
    let _ = io::stdin().read_line(&mut input);

    Ok(())
}

/// TODO needs extensive doc string
/// TODO needs absolute file paths, see:  src/manage_absolute_executable_directory_relative_paths.rs
///
/// Invite Wizard
///
/// to inspect files use ```gpg --decrypt FILENAME.THINGY```
///
pub fn invite_wizard() -> Result<(), GpgError> {
    /*
    1. Export your public gpg key to share [Done]
    2. make clearsigned version of your own addressbook .toml
       get user name
       use user name to get their gpg key from their addressbook file
       gpg encrypt the clearsign file
       A. new remote collaborator: separate gpg file
       B. existing addressbook file for them
    3. make clearsigned version of this team-channel if you are owner
       get user name
       use user name to get their gpg key from their addressbook file
       gpg encrypt the clearsign file

       TODO:
       maybe activate HOME reboot-uma command to keep 'out of band'

       invite update
    */
    println!(">> Invite/Update Wizard <<");
    println!("\nThere are three steps...");
    println!("1. sharing gpg");
    println!("2. sharing address-book file");
    println!("3. sharing team-channel");
    println!("4. update a team-channel that you own");  // update_core_node()
    println!("\nQ: Which step do you want to do now?");
    println!("(Enter: number + enter)");

    let mut input = String::new();
    io::stdin().read_line(&mut input).expect("invite-wiz: failed to read line");

    let mainchoice: u32 = match input.trim().parse() {
        Ok(num) => num,
        Err(_) => {
            // println!("\nThere are three steps...");
            // println!("1. share gpg");
            // println!("2. share address-book file");
            // println!("3. share team-channel (if you own it)");
            println!("Please try again entering a number ->");
            return Ok(());
        }
    };

    match mainchoice {
        1 => {
            println!("\n\n-- Option 1: share a public gpg key --");

            // later function makes the path absolute relative
            let relative_uma_toml_path = Path::new(UMA_TOML_CONFIGFILE_PATH_STR);

            // // Get absolute path to uma.toml configuration file
            // let relative_uma_toml_path = "uma.toml";
            // let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
            //     .map_err(|e| {
            //         let error_msg = format!("___ Failed to locate uma.toml configuration file: {}", e);
            //         println!("Error: {}", error_msg);
            //         GpgError::PathError(error_msg)
            //     })?;

            // later function makes the path absolute relative
            let output_dir = Path::new("invites_updates/outgoing");

            // let relative_output_dir = "invites_updates/outgoing";
            // let absolute_output_dir = gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_output_dir)
            //     .map_err(|e| {
            //         let error_msg = format!("invite wizard! Failed to convert 'invites_updates/outgoing' path: {}", e);
            //         println!("Error: {}", error_msg);
            //         GpgError::PathError(error_msg)
            //     })?;

            // this function makes the path absolute relative
            match export_public_gpg_key_converts_to_abs_path(
                &relative_uma_toml_path,
                &output_dir,
                ) {
                Ok(key_path) => println!("\nOK! GPG key exported successfully to: {}", key_path),
                Err(e) => eprintln!("invite wizard! Failed to export GPG key: {}", e),
            }

            // Pause and wait for the user to press Enter
            println!("\nHit enter to proceed...");
            let mut input = String::new();
            io::stdin().read_line(&mut input).expect("Failed to read line");

        },

        2 => {
            println!("\n\n-- Option 2: Sharing an Address-Book-File --");
            println!("\nFROM you, TO them, <-outgoing->");
            println!("Are you sharing your address book file with...");
            println!(" 1. an existing remote-collaborator? or ");
            println!(" 2. a new remote-collaborator?");
            println!(" ");
            println!("Or: FROM them TO you, ->incoming<- ");
            println!(" 3. Do you want to import an address-book-file");
            println!("    being shared with you (by a remote collaborator)?");
            println!(" ");
            println!("(Enter: number + enter)");

            // Re-read another input for subchoice, kind of like... peanut butter...in a sand witch.
            let mut sub_input = String::new();
            io::stdin()
                .read_line(&mut sub_input)
                .map_err(|e| GpgError::GpgOperationError(format!("Failed to read subchoice: {}", e)))?;

            let subchoice: u32 = match sub_input.trim().parse() {
                Ok(num) => num,
                Err(_) => {
                    println!("Please try again entering a number.");
                    return Ok(());
                }
            };

            match subchoice {
                1 => {
                    println!(" --- to existing remote collaborator --- ");
                    println!("What is the user-name of the existing");
                    println!("remote collaborator? (Enter: name + enter)");
                    /*
                        The file where the user's gpg key is located is found here:

                        ```path
                        project_graph_data/collaborator_files_address_book/USERNAMEHERE__collaborator.toml
                        ```


                        within the file, the gpg key (public) is found:
                        gpg_key_public = """KEYHERE"""

                        clearsign read toml?

                    // For toml and clearsigntoml
                    mod read_toml_field;
                    use crate::read_toml_field::{
                        read_field_from_toml,
                        read_basename_fields_from_toml,
                        read_single_line_string,
                        read_multi_line_string,
                        read_integer_array,
                        read_singleline_string_from_clearsigntoml,
                    };

                    reading addressbook files ALW
                    pub fn read_singleline_string_from_clearsigntoml(path_to_clearsigntoml_with_gpgkey: &str, field_name: &str) -> Result<String, String> {
                    */
                    let mut username_of_remote_collaborator = String::new();
                    io::stdin()
                        .read_line(&mut username_of_remote_collaborator)
                        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;

                    debug_log!("wiz: username_of_remote_collaborator -> {}", username_of_remote_collaborator);

                    share_lou_address_book_with_existingcollaborator(username_of_remote_collaborator.trim())?;
                    }
                2 => {
                    println!(" --- to new remote collaborator --- ");
                    println!("Please put the remote collaborator's gpg key.asc file");
                    println!(" in this path (in this directory) -> ");
                    println!(" ");
                    println!("```path ");
                    println!("invites_updates/incoming/key.asc ");
                    println!("``` ");
                    println!(" ");
                    println!("Then, press Enter when this is done.\n");
                    let mut username_of_remote_collaborator = String::new();
                    io::stdin()
                        .read_line(&mut username_of_remote_collaborator)
                        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;

                    share_lou_addressbook_with_incomingkey()?;

                    }
                    /*
                    ```path
                    project_graph_data/collaborator_files_address_book/USERNAMEHERE__collaborator.toml
                    ```
                    */

                3 => {
                    println!(" --- FROM a remote collaborator, TO you --- ");
                    println!("Please put their FILENAME.gpgtoml file in the");
                    println!("```path");
                    println!("invites_updates/incoming/ ");
                    println!("```");
                    println!("directory (folder)");
                    println!("Press enter when this is done.");

                    // this does nothing, press enter to proceed.
                    let mut input = String::new();
                    let _ = io::stdin()
                        .read_line(&mut input)
                        .map_err(|e| format!("Failed to read input: {:?}", e));

                    let _ = process_incoming_encrypted_collaborator_addressbook();
                    /*
                    logic to target that directory...
                    // 1. Scans the incoming directory for .asc files
                    // 2. If exactly one file is found, proceeds with processing
                    // 3. If multiple files are found, prompts the user to clean up the directory
                    // 4. Decrypts the file and verifies the clearsignature
                    // 5. Extracts the collaborator's username from the clearsigned content
                    // 6. Saves the validated clearsigned file to the collaborator address book directory
                    // 7. Moves the original encrypted file to the processed directory
                    */
                    }
                // Handle cases where subchoice is 0 or  4
                _ => {
                    println!("Invalid option. Please select 1, 2, or 3.");
                }
            }
        },
        3 => {
            /*
            1. Team Channel files, clearsigned, and gpg encrypted.
            ideally: channel_name...
            just channel_name.toml?
            gpg+clearsigned+toml
            clearsigned with who's key?
            get key from addressbook?

            team channel only read...at start?

            v1: plain toml...
            simple_clearsign_gpgencrypt(path_in, path_out):
            get file
            clearsign with yours
            gpg sign with theirs
            put in outgoing

            new function: multi-file clearsign validate
            multi-file clearsign read...fields

            read_gpg_multifile_clearsign_stringline
            read_gpg_multifile_clearsign_int_array
            read_gpg_multifile_clearsign_multiline_string

            read_gpg_multifile_clearsign_stringline
            read_gpg_multifile_clearsign_int_array
            read_gpg_multifile_clearsign_multiline_string

            and unpack file:
            use your keyid
            use their key: read and get public key...
            make team-channel folder
            make team-channel node.toml

            */
            println!("\n\n-- Option 3: Sharing a Team-Channel --");
            println!("\n 1. Do you wish to share a Team-Channel that you own");
            println!("    with an existing remote-collaborator?");
            println!(" ");
            println!("Or ");
            println!(" 2. Are you looking to import a Team-Channel");
            println!("    being shared with you (by a remote collaborator/owner)?");
            println!(" ");
            println!("(Enter: number + enter)");

            // Re-read another input for subchoice, kind of like... peanut butter...in a sand witch.
            let mut sub_input = String::new();
            io::stdin()
                .read_line(&mut sub_input)
                .map_err(|e| GpgError::GpgOperationError(format!("Failed to read subchoice: {}", e)))?;

            let subchoice: u32 = match sub_input.trim().parse() {
                Ok(num) => num,
                Err(_) => {
                    println!("Please try again entering a number.");
                    return Ok(());
                }
            };

            match subchoice {
                1 => {
                    println!(" --- to existing remote collaborator --- ");
                    println!("What is remote colaborator's name?");
                    println!("(Enter: name + enter)");
                    /*
                        The file where the user's gpg key is located is found here:

                        ```path
                        project_graph_data/collaborator_files_address_book/USERNAMEHERE__collaborator.toml
                        ```

                        within the file, the gpg key (public) is found:
                        gpg_key_public = """KEYHERE"""

                        clearsign read toml?

                    // For toml and clearsigntoml
                    mod read_toml_field;
                    use crate::read_toml_field::{
                        read_field_from_toml,
                        read_basename_fields_from_toml,
                        read_single_line_string,
                        read_multi_line_string,
                        read_integer_array,
                        read_singleline_string_from_clearsigntoml,
                    };

                    reading addressbook files ALW
                    pub fn read_singleline_string_from_clearsigntoml(path_to_clearsigntoml_with_gpgkey: &str, field_name: &str) -> Result<String, String> {
                    */
                    let mut remotecollaborator_username_input = String::new();
                    io::stdin()
                        .read_line(&mut remotecollaborator_username_input)
                        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;
                    debug_log!("wiz: remote_collaborator_username -> {}", remotecollaborator_username_input);
                    // share_lou_address_book_with_existingcollaborator(username_of_remote_collaborator.trim())?;
                    // Ensure the team_channel_name is completely trimmed of all whitespace
                    let remote_collaborator_username = remotecollaborator_username_input.trim().trim_end_matches(|c| c == '\n' || c == '\r');

                    // TODO function here to get the remote collaborator's gpg key to finally gpg encrypt with
                    debug_log!("remote_collaborator_username: '{}'", remote_collaborator_username);

                    println!("What is the Team-Channel-Name?");
                    println!("(Enter: name + enter)");

                    let mut team_channel_name_input = String::new();
                    io::stdin()
                        .read_line(&mut team_channel_name_input)
                        .map_err(|e| GpgError::GpgOperationError(format!("wiz: Failed to read input: {}", e)))?;


                    // Ensure the team_channel_name is completely trimmed of all whitespace
                    let team_channel_name = team_channel_name_input.trim().trim_end_matches(|c| c == '\n' || c == '\r');

                    // Additional debug to check exact content
                    debug_log!("Menu: Raw team channel name: '{}'", team_channel_name);
                    debug_log!("Menu: Team channel name length: {}", team_channel_name.len());

                    debug_log!("wiz: name_of_teamchannel -> {}", team_channel_name);

                    /*
                    1. make sure the node.toml file is at
                    {exe-parent}/project_graph_data/team_channels/{team-channel-name}/node.toml
                    2. clearsign it with your own gpg-key-id
                    3. gpg encrypt the clearsign file with the reamote collaborators public key
                    4. put the resulting file in
                    ```path
                    exe-parent/invites_updates/incoming/
                    ```
                    */
                    let _ = share_team_channel_with_existing_collaborator_converts_to_abs(
                        &remote_collaborator_username,
                        &team_channel_name,
                    );

                    }

                2 => {
                    println!(" --- FROM a remote-collaborator & team-channel-owner, TO you --- ");
                    println!("Please put their FILENAME.SUFFIX file, as the only file, in the");
                    println!("```path");
                    println!("invites_updates/incoming/ ");
                    println!("```");
                    println!("directory (folder)");
                    println!("Press enter when this is done.");

                    // this does nothing, press enter to proceed.
                    let mut input = String::new();
                    let _  = io::stdin()
                        .read_line(&mut input)
                        .map_err(|e| format!("Failed to read input: {:?}", e));

                    /*
                    logic to target that directory...
                    1. Scans the incoming directory for .asc file (or any gpg suffix)
                    2. If exactly one file is found, proceeds with processing
                    3. If multiple files are found, prompts the user to clean up the directory press enter to proceed (not loop))
                    4. Decrypts the file (with local owner key-id, standard process) and next verifies the clearsignature:
                    5. Extracts the collaborator's username from the clearsigned content
                    6. gets the collaborator's gpg key from an addressbook file
                    7. uses that to verify the clearsign
                    TODO STEP: checks all team-channel ports for a colission and
                    gives a warning (press enter to proceed, not quit) if collision (not a breaking issue)
                    8. if verified, saves file in two versions: node.toml (clearsign toml); and gpg-encrypted .asc
                    - Saves the validated clearsigned file to the collaborator address book directory
                    (note: the name is always simply node.toml)
                    - Moves the original encrypted file to the processed directory

                    9. Make team-channel folders etc.
                    The current plan is to leave this step minimal
                    and have file-sync fill in whatever is inside.
                    - make directory based on field name
                    - put node.toml file/gpg-file in the dir



                    */

                    //
                    let _ = process_incoming_encrypted_teamchannel();

                    }

                // Handle cases where subchoice is 0 or  4
                _ => {
                    println!("Invalid option. Please select 1, 2, or 3.");
                }
            }
/*
    somewhere around here:
    1. pick node
    2.
    println!("4. update a team-channel that you own");  // update_core_node()
*/
            // Similar implementation to share_address_book() but with team channel file
            // Would use the same clearsign_and_encrypt_file_for_recipient() function
        },
        _ => {
            return Err(GpgError::GpgOperationError("Invalid choice".to_string()));
        }

        _ => println!("Invalid choice."),
    }
    Ok(())
}

fn handle_command_main_mode(
    input: &str,
    app: &mut App,
    graph_navigation_instance_state: &GraphNavigationInstanceState
) -> Result<bool, io::Error> {
    /*
    For input command mode
    quit
    command-list/legend
    */

    debug_log(&format!("HCMM handle_command_main_mode(), input->{:?}", input));
    // First, try to handle numeric input
    if let Ok(index) = input.trim().parse::<usize>() {
        let item_index = index - 1; // Adjust for 0-based indexing
        if item_index < app.tui_directory_list.len() {
            // Special handling for team channels directory

            debug_log!("HCMM app.current_path.display().to_string()->{:?}", app.current_path.display().to_string());


            // =====
            // The setting options and factors here are:
            // there are (may be) some bootstrapping steps
            // for the first time you enter a team-channel
            // and are not on home-base
            //
            // is_in_teamchannels_homebase (bool) is whether you are in home-base:
            // "project_graph_data/team_channels"
            //
            // reserved strings: (cannot be name of node)
            // uma
            // project_graph_data
            // team_channels
            // ======
            /*
             * HCMM app.current_path.display().to_string()->"/home/oops/code/uma_productivity_collaboration_tool/target/debug/project_graph_data/team_channels"
             */

            let starting_in_teamchannels_homebase: bool;

            // Get the last two components as an iterator
            let last_two: Vec<_> = app.current_path.iter().rev().take(2).collect();
            let last_two: Vec<_> = last_two.into_iter().rev().collect();

            // Convert to strings for comparison
            let last_two_strs: Vec<String> = last_two
                .into_iter()
                .filter_map(|c| c.to_str())
                .map(|s| s.to_string())
                .collect();

            // Join with "/" for comparison
            let last_two_joined = last_two_strs.join("/");

            if last_two_joined == "project_graph_data/team_channels" {
                println!("Path matches the last two components!");
                starting_in_teamchannels_homebase = true;
            } else {
                println!("HCMM Path does not match.");
                starting_in_teamchannels_homebase = false;
            }

            // if app.current_path.display().to_string() == "project_graph_data/team_channels".to_string() {
            if starting_in_teamchannels_homebase {

                let selected_channel = app.tui_directory_list[item_index].clone();
                debug_log(&format!("HCMM Selected channel: {}", selected_channel));


                app.current_path = app.current_path.join(&selected_channel);
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();


                // Simply call the method without trying to handle its result
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml();

                // // current_node_directory_path
                // debug_log(&format!("HCMM current_node_directory_path: {:?}", app.graph_navigation_instance_state.current_node_directory_path));


                // bootstrap: now you are in a channel, start sync
                let set_sync_result = set_sync_start_ok_flag_to_true();

                #[cfg(debug_assertions)]
                debug_log!("HCMM set_sync_result->{:?}", set_sync_result);

            } else {

                // Regular directory navigation
                app.current_path = app.current_path.join(&app.tui_directory_list[item_index]);
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();

                // try?
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

            }
            return Ok(false);  // Continue main loop
        }
    }
    // Then handle text commands:
    let parts: Vec<&str> = input.trim().split_whitespace().collect();
    if let Some(command) = parts.first() {

        match command.to_lowercase().as_str() {
            "h" | "help" => {
                debug_log("Help!");
                // Display help information
                // TODO help wizard or blurb?
            }

            "sharegpg" | "exportgpg" | "requestinvite" => {
                debug_log("Export public GPG Command:");

                // paths are always the same
                // TODO make paths constants
                let uma_config_path = Path::new(UMA_TOML_CONFIGFILE_PATH_STR);
                let output_dir = Path::new("invites_updates/outgoing");

                match export_public_gpg_key_converts_to_abs_path(&uma_config_path, &output_dir) {
                    Ok(key_path) => println!("GPG key exported successfully to: {}", key_path),
                    Err(e) => eprintln!("Failed to export GPG key: {}", e),
                }
            }

            "invite" | "update" => {
                debug_log("invite / update wizard");
                /*
                */
                let _ = invite_wizard();
            }

            "addnode" | "add_node" | "newnode" | "new" | "node" | "task" | "addtask" | "add_task" | "add" => {
                debug_log("Command: Add Node");
                // TODO trim down excess terms above

                debug_log!("app.current_path {:?}", app.current_path);

                let _ = create_core_node(
                    app.current_path.clone(), // node_path: PathBuf,
                    app.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access.clone(),  // teamchannel_collaborators_with_access: Vec<String>,
                );
            }

            "bigger" | "big" | "bg" => {
                app.tui_height = (app.tui_height + 1).max(1);  // Height cannot be less than 1
                app.tui_width = (app.tui_width + 1).max(1);  // Width cannot be less than 1
                // ... re-render
            }

            "smaller" | "small" | "sm" => {
                app.tui_height = (app.tui_height - 1).max(1);
                app.tui_width = (app.tui_width - 1).max(1);
                // ... re-render
            }

            "v" | "vote" => {
                debug_log("Vote!");
                // Display help information
            }
            // "p" | "paralax" => {
            //     debug_log("!@#");
            //     // Display help information
            // }
            "collaborator" => {
                debug_log("make node!");
                // add_collaborator_qa(&graph_navigation_instance_state);
                let _ = add_collaborator_qa();
            }

           "d" | "datalab" | "data" => {
                debug_log("Help!");
                // Display help information
            }

           "l" | "log" | "logmode" | "debug" | "debuglog" | "showlog" => {
            debug_log("Starting log mode...ctrl+c to exit");

                // this takes a path n the form of a string
                // as input, outputs size etc.
                // fs::metadata(INPUT_PATH)
                // Get absolute path to uma.toml configuration file

                let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
                let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
                    .map_err(|e| {
                        let error_msg = format!("___ Failed to locate uma.toml configuration file: {}", e);
                        println!("Error: {}", error_msg);
                        io::Error::new(io::ErrorKind::InvalidData, error_msg)
                    })?;

                // Convert PathBuf to string for TOML reading
                let absolute_uma_toml_path_str = absolute_uma_toml_path
                    .to_str()
                    .ok_or_else(|| {
                        let error_msg = "__ Unable to convert UMA TOML path to string".to_string();
                        println!("Error: {}", error_msg);
                        io::Error::new(io::ErrorKind::InvalidData, error_msg)
                    })?;

                // Read log_mode_refresh from uma.toml
                let log_mode_refresh = read_float_f32_field_from_toml(
                    absolute_uma_toml_path_str,
                    "log_mode_refresh"
                ).map_err(|e| {
                    let error_msg = format!(" Failed to read log_mode_refresh: {}", e);
                    println!("Error: {}", error_msg);
                    io::Error::new(io::ErrorKind::InvalidData, error_msg)
                })?;

                debug_log!("log_mode_refresh: {:?}", log_mode_refresh);

                let mut last_log_file_size = fs::metadata(absolute_uma_toml_path_str)
                    .map(|metadata| metadata.len())
                    .unwrap_or(0); // Get initial size, or 0 if error

                // bootstrap, first print
                // File size has changed, read and display new contents
                match fs::read_to_string(absolute_uma_toml_path_str) {
                    Ok(log_contents) => {
                        println!("{}", log_contents); // Print to console for now
                    }
                    Err(e) => {
                        eprintln!("Failed to read uma.log: {}", e);
                    }
                }

                loop { // Enter the refresh loop

                    // Check for file size changes
                    let current_log_file_size = fs::metadata(absolute_uma_toml_path_str)
                        .map(|metadata| metadata.len())
                        .unwrap_or(0);
                    if current_log_file_size != last_log_file_size {

                        // 1. Read and display the log contents.
                        // File size has changed, read and display new contents
                        match fs::read_to_string(absolute_uma_toml_path_str) {
                            Ok(log_contents) => {
                                print!("\x1B[2J\x1B[1;1H"); // Clear the screen
                                println!("{}", log_contents);
                                // Update the last_log_file_size after reading
                                last_log_file_size = current_log_file_size;
                            }
                            Err(e) => {
                                eprintln!("Failed to read uma.log: {}", e);
                            }
                        }
                    }


                    // // 1. Read and display the log contents.
                    // match fs::read_to_string("uma.log") {
                    //     Ok(log_contents) => {
                    //         println!("{}", log_contents); // Print to console for now
                    //     }
                    //     Err(e) => {
                    //         eprintln!("Failed to read uma.log: {}", e);
                    //     }
                    // }

                    // // 1. Read the log_mode_refresh value from uma.toml.
                    // let uma_toml_path = Path::new("uma.toml");
                    // let user_metadata = match toml::from_str::<LocalUserUma>(&fs::read_to_string(uma_toml_path)?) {
                    //     Ok(metadata) => metadata,
                    //     Err(e) => {
                    //         debug_log!("Error reading or parsing uma.toml: {}", e);
                    //         eprintln!("Error reading or parsing uma.toml: {}", e);
                    //         return Ok(false); // Or handle the error differently (e.g., use a default value)
                    //     }
                    // };


                    // 2. Sleep for a short duration.
                    // thread::sleep(Duration::from_secs(log_mode_refresh));
                    thread::sleep(Duration::from_secs_f32(log_mode_refresh)); // Use from_secs_f32

                    // // 3. Check for 'esc' key press to exit.
                    // if let Ok(input) = tiny_tui::get_input() {
                    //     if input == "esc" {
                    //         debug_log("Exiting debug log view.");
                    //         break; // Exit the loop
                    //     }
                    // }
                }
            }
           "storyboard" | "mudd" => {
                debug_log("storyboard");
                // Display help information
            }
            "b" | "back" => {
                debug_log("back mode started");
                app.input_mode = InputMode::MainCommand;
                debug_log("changed to command mode");

                if app.current_path != PathBuf::from("project_graph_data/team_channels") {
                    // Only move back if not at the root of project_graph_data/team_channels
                    debug_log!(
                        "before pop handle_command_main_mode(), app.current_path {:?}",
                        &app.current_path
                    );

                    app.current_path.pop();
                    debug_log!(
                        "after pop handle_command_main_mode(), app.current_path {:?}",
                        &app.current_path
                    );

                    app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone(); // Update full path after popping.
                    app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // Update internal state too.
                    tiny_tui::render_list(
                        &app.tui_directory_list,
                        &app.current_path,
                        // Projecpa1_process
                        // Project Areas
                        &app.graph_navigation_instance_state.pa1_process,
                        &app.graph_navigation_instance_state.pa2_schedule,
                        &app.graph_navigation_instance_state.pa3_users,
                        &app.graph_navigation_instance_state.pa4_features,
                        &app.graph_navigation_instance_state.pa5_mvp,
                        &app.graph_navigation_instance_state.pa6_feedback,
                        );
                    app.update_directory_list()?;

                } else {
                  debug_log("back, but at root!");
                }
            }
            "home" => {
                /*
                For a clean reset, 'home' quits and restarts,
                ensuring all processes are clean.
                */
                debug_log("Home command received.");

                let _ = quit_set_continue_uma_to_false();

                // //////////////////////////
                // // Enable sync flag here!
                // //////////////////////////
                // TODO: ? also set in initializae-uma?
                // debug_log("About to set sync flag to true! (handle_command_main_mode(), home)");
                // initialize_ok_to_start_sync_flag_to_false();  //TODO turn on to use sync !!! (off for testing)

                // // 1. Reset the current path
                // let mut app_data_dir = PathBuf::from("project_graph_data");
                // app_data_dir.push("team_channels");
                // app.current_path = app_data_dir;
                // debug_log(&format!("Current path reset to: {:?}", app.current_path));

                // // 2. Purge state in GraphNavigationInstanceState
                // app.graph_navigation_instance_state.active_team_channel = String::new();
                // app.graph_navigation_instance_state.current_full_file_path = PathBuf::new();
                // // ... Clear other channel-specific data (e.g., current_node_* fields, collaborator_ports) ...
                // debug_log("GraphNavigationInstanceState - Channel specific data purged.");

                // // 3. Reset the home_square_one flag
                // app.graph_navigation_instance_state.home_square_one = true;
                // debug_log("home_square_one flag set to true.");

                // // 4.  (Optional) Clear the TUI list to reflect the home screen
                // app.tui_directory_list.clear();
                // debug_log("TUI directory list cleared.");

                // 5. (Optional) Trigger a TUI refresh
                // (not needed for default 'current path' print)
                // ... (Your TUI refresh logic) ...
                // debug_log("TUI refresh triggered (if implemented).");
            }


            /*
            Message Mode Handler: Dual-Interface Message Viewing System

            This handler serves two primary functions:
            1. Launches a separate passive-view terminal for real-time message monitoring
            2. Enters the interactive message browsing mode in the main terminal
            /
            # Process Flow:
            1. Path Handling:
               - Clones current directory path
               - Appends "message_posts_browser" subdirectory
               - Validates directory existence (returns Ok(false) if not found)
            /
            2. Passive View Terminal Launch (Linux):
               - Creates a new gnome-terminal instance
               - Passes the current Uma executable path and message directory
               - Uses format: "gnome-terminal -- [uma_path] --passive_message_mode [message_dir]"
               - Launches independently (non-blocking)
            /
            3. Main Terminal Setup:
               - Sets input mode to InsertText
               - Updates current path to message browser directory
               - Initializes message browser interface
            /
            # Directory Structure:
            ```text
            current_path/
             message_posts_browser/
                 0.toml (metadata)
                 1__user1.toml (messages)
                 2__user2.toml (messages)
            ```
            /
            # Error Handling:
            - Checks for message directory existence
            - Safely handles executable path conversion
            - Uses Result for error propagation
            /
            # Platform Support:
            - Linux: Uses gnome-terminal for passive view
            - Other platforms: TBD
            /
            # Dependencies:
            - std::process::Command for terminal launching
            - std::env for executable path
            - PathBuf for path manipulation
            /
            # Safety:
            - No unwrap() calls
            - Safe string conversions via to_string_lossy()
            - Proper error propagation
            /
            # Notes:
            - Passive view terminal operates independently
            - Main terminal maintains interactive mode
            - Message directory must exist before operation
            /
            /
            Passive Message View Mode

            This code implements a separate terminal-window passive message viewer
            that runs independently from the main Uma application.
            /
            # Launch Process:
            1. Triggered when user enters "m" in main Uma application
            2. Creates new terminal window running a separate Uma process
            3. New process runs in passive-view mode (--passive_message_mode)
            /
            # Implementation Details:
            ```rust
            // Main Process (Original Uma Terminal):
            // Launches new terminal for passive view, then continues normal operation
            let mut message_path = app.current_path.clone();
            message_path.push("message_posts_browser");

            // New terminal command structure:
            StdCommand::new("gnome-terminal")
                .arg("--")
                .arg(uma_path_str)               // Path to Uma executable
                .arg("--passive_message_mode")   // Tells Uma to run in passive mode
                .arg(&message_path_str)          // Path to message directory
                .spawn()?;
            ```
            /
            # Key Components:
            1. Directory Validation:
               - Checks if message directory exists before launching
               - Returns Ok(false) if directory not found
            /
            2. Path Handling:
               - Clones and modifies current path
               - Adds "message_posts_browser" subdirectory
               - Converts paths to strings safely using to_string_lossy()
            /
            3. Process Launch:
               - Uses gnome-terminal on Linux
               - Launches Uma in new process with --passive_message_mode flag
               - New process is independent (non-blocking)
            /
            # Command Line Arguments:
            When launched in passive mode, Uma receives:
            1. --passive_message_mode flag
            2. Path to message directory
            /
            # Safety & Error Handling:
            - Safe path conversions
            - No unwrap() calls
            - Proper error propagation with Result
            - Directory existence validation
            /
            # Operational Flow:
            1. User enters "m" in main Uma
            2. New terminal launches with Uma in passive mode
            3. Original Uma continues with normal message operations
            4. New terminal operates independently for message viewing
            /
            # Important Notes:
            - This is a view-only mode
            - No connection maintained between terminals
            - Original Uma process continues independently
            - Passive view must be manually closed when done
            */
            "m" | "message" => {
                debug_log("m selected");

                /////////////////
                // Passive View
                /////////////////
                let mut message_path = app.current_path.clone();
                message_path.push("message_posts_browser");

                debug_log!("message_path {:?}", message_path);

                // Check if directory exists
                if !message_path.exists() {
                    println!("handle comand 'm', Message directory not found!");
                    return Ok(false);  // Changed to match expected return type
                }

                let message_path_str = message_path.to_string_lossy().into_owned();

                #[cfg(target_os = "linux")]
                {
                    if let Ok(uma_path) = env::current_exe() {
                        if let Some(uma_path_str) = uma_path.to_str() {
                            StdCommand::new("gnome-terminal")
                                .arg("--")
                                .arg(uma_path_str)
                                .arg("--passive_message_mode")
                                .arg(&message_path_str)
                                .spawn()?;
                        }
                    }
                }

                debug_log(&format!("handle command 'm' app.current_path {:?}", app.current_path));
                // app.input_mode = InputMode::InsertText;
                // app.current_path = app.current_path.join("message_posts_browser");

                // debug_log!(
                //     "app.current_path after joining 'message_posts_browser': {:?}",
                //     app.current_path
                // );

                // // Enter Browser of Messages
                // app.load_im_messages();

                // TODO experimental state refresh
                app.enter_modal_message_posts_browser(app.current_path.clone())?;
            }

            "t" | "task" | "tasks" => {
                debug_log("t selected: task browser launching");

                /////////////////
                // Passive View
                /////////////////
                let mut task_path = app.current_path.clone();
                task_path.push("task_browser");

                // Check if directory exists
                if !task_path.exists() {
                    println!("Task directory not found!");
                    return Ok(false);
                }

                let task_path_str = task_path.to_string_lossy().into_owned();

                #[cfg(target_os = "linux")]
                {
                    if let Ok(uma_path) = env::current_exe() {
                        if let Some(uma_path_str) = uma_path.to_str() {
                            StdCommand::new("gnome-terminal")
                                .arg("--")
                                .arg(uma_path_str)
                                .arg("--passive_task_mode")
                                .arg(&task_path_str)
                                .spawn()?;
                        }
                    }
                }


                debug_log(&format!("app.current_path {:?}", app.current_path));
                app.input_mode = InputMode::InsertText;

                // TODO Assuming you have a way to get the current node's name:
                let current_node_name = app.current_path.file_name().unwrap().to_string_lossy().to_string();

                app.current_path = app.current_path.join("task_browser");
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                debug_log!(
                    "app.current_path after joining 'task_browser': {:?}",
                    app.current_path
                );

                // Enter Browser of Tasks
                app.enter_task_browser();

            }
            "q" | "quit" | "exit" => {
                debug_log("quit");
                no_restart_set_hard_reset_flag_to_false();
                quit_set_continue_uma_to_false();

                return Ok(true); // Signal to exit the loop
            }
            _ => {
                // Display error message (e.g., "Invalid command")
                debug_log(" 'other' commend? _ => {...");
                // if app.is_in_task_browser_directory() {
                if app.is_in_message_posts_browser_directory() {

                    if app.handle_task_action(input) { // Exit if handle_task_action returns true.
                        app.current_path.pop(); // Leave task browser directory
                    };
                // Stay within the task browser function and mode otherwise.
                } else {
                // ... Handle other command input as usual ...
                }
            }
            // ... (handle other commands)

        }
    }
    debug_log("end handle_command_main_mode()");
    return Ok(false); // Don't exit by default
}


fn task_mode_handle__commands(
    input: &str,
    app: &mut App,
    graph_navigation_instance_state: &GraphNavigationInstanceState
) -> Result<bool, io::Error> {
    /*
    For input command mode
    quit
    command-list/legend
    */

    debug_log(&format!("fn task_mode_handle__commands(), input->{:?}", input));

    let parts: Vec<&str> = input.trim().split_whitespace().collect();
    if let Some(command) = parts.first() {
        match command.to_lowercase().as_str() {
            "h" | "help" => {
                debug_log("Help!");
                // Display help information
            }

            "bigger" | "big" | "bg" => {
                app.tui_height = (app.tui_height + 1).max(1);  // Height cannot be less than 1
                app.tui_width = (app.tui_width + 1).max(1);  // Width cannot be less than 1
                // ... re-render
            }

            "smaller" | "small" | "sm" => {
                app.tui_height = (app.tui_height - 1).max(1);
                app.tui_width = (app.tui_width - 1).max(1);
                // ... re-render
            }

            "home" => {
                /*
                For a clean reset, 'home' quits and restarts,
                ensuring all processes are clean.
                */
                debug_log("Home command received.");
                quit_set_continue_uma_to_false();
            }

            "q" | "quit" | "exit" => {
                debug_log("quit");
                no_restart_set_hard_reset_flag_to_false();
                quit_set_continue_uma_to_false();

                return Ok(true); // Signal to exit the loop
            }
            _ => {
                // Display error message (e.g., "Invalid command")
                debug_log(" 'other' commend? _ => {...");

            }
            // ... (handle other commands)

        }
    }
    debug_log("end fn task_mode_handle__commands()");
    return Ok(false); // Don't exit by default
}


fn extract_last_path_section(current_path: &PathBuf) -> Option<String> {
    current_path.file_name().and_then(|os_str| os_str.to_str().map(|s| s.to_string()))
}

/// Determines the next available message file path.
///
/// Finds the highest existing message number in the given directory,
/// *ignoring usernames*, and returns a `PathBuf` for the next available file,
/// formatted as `{next_number}__{username}.toml`.
///
/// Handles empty directories and non-message files by starting from 1.
///
/// # Arguments
///
/// * `current_path`: The directory containing message files.
/// * `username`: The username for the *new* file.
///
/// # Returns
///
/// * `PathBuf`: Path to the next available message file.
fn get_next_message_file_path(current_path: &Path, username: &str) -> PathBuf {
    let mut max_number = 0;

    debug_log!(
        "get_next_message_file_path(): Starting. current_path: {:?}, username: {}",
        current_path, username
    );


    if let Ok(entries) = fs::read_dir(current_path) {
        for entry in entries.flatten() {
            if let Some(file_name) = entry.file_name().to_str() {
                if let Some((number_str, _rest)) = file_name.split_once("__") { // Ignore the rest of the filename
                    if let Ok(number) = number_str.parse::<u32>() {
                        max_number = max_number.max(number);
                    }
                }
            }
        }
    }

    let next_number = max_number + 1;
    let file_name = format!("{}__{}.toml", next_number, username);
    let file_path = current_path.join(file_name);


    debug_log!(
        "get_next_message_file_path(): Returning file_path: {:?}",
        file_path
    );
    file_path
}

// /// Loads collaborator data from a TOML file based on the username.
// ///
// /// This function uses `read_one_collaborator_addressbook_toml` to deserialize the collaborator data.
// ///
// /// # Arguments
// ///
// /// * `username` - The username of the collaborator whose data needs to be loaded.
// ///
// /// # Errors
// ///
// /// This function returns a `Result<CollaboratorTomlData, ThisProjectError>` to handle potential errors:
// ///  - `ThisProjectError::IoError`: If the collaborator file is not found or if there is an error reading the file.
// ///  - `ThisProjectError::TomlDeserializationError`: If there is an error parsing the TOML data.
// ///
// /// # Example
// ///
// /// ```
// /// let collaborator = get_addressbook_file_by_username("alice").unwrap(); // Assuming alice's data exists
// /// println!("Collaborator: {:?}", collaborator);
// /// ```
// fn get_addressbook_file_by_username(username: &str) -> Result<CollaboratorTomlData, ThisProjectError> {
//     debug_log!("Starting get_addressbook_file_by_username(username),  for -> '{}'", username);
//     // debug_log!("Starting get_addressbook_file_by_username(username),  for -> '{}'", username);

//     // Debug the directory structure
//     let base_dir = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR);
//     debug_log!("Base directory path: {:?}", base_dir);
//     debug_log!("Base directory exists: {}", base_dir.exists());

//     // Check current working directory
//     debug_log!("Current working directory: {:?}", std::env::current_dir()?);

//     // Construct and check the specific file path
//     let file_path = base_dir.join(format!("{}__collaborator.toml", username));
//     debug_log!("Looking for file at: {:?}", file_path);
//     debug_log!("File exists: {}", file_path.exists());

//     // Try to list files in the directory if it exists
//     if base_dir.exists() {
//         debug_log!("Contents of collaborator_files_address_book directory:");
//         match std::fs::read_dir(base_dir) {
//             Ok(entries) => {
//                 for entry in entries {
//                     if let Ok(entry) = entry {
//                         debug_log!("Found file: {:?}", entry.path());
//                     }
//                 }
//             },
//             Err(e) => debug_log!("Could not read directory contents: {}", e),
//         }
//     }
//     // Use read_one_collaborator_addressbook_toml to read and deserialize the data
//     match read_one_collaborator_addressbook_toml(username) {
//         Ok(loaded_collaborator) => {
//             debug_log!("Collaborator file found ok.");
//             Ok(loaded_collaborator)
//         }
//         Err(e) => {
//             debug_log!("Collaborator file not found: {:?}", e);
//             Err(e) // Propagate the error from read_one_collaborator_addressbook_toml
//         }
//     }
// }

// Version for clearsign toml only?
/// Loads collaborator data from a TOML file based on the username.
///
/// This function locates and loads a collaborator's data file using executable-relative
/// paths, ensuring consistent file access regardless of the current working directory.
/// The file is expected to be named "{username}__collaborator.toml" and located
/// in the project_graph_data/collaborator_files_address_book directory relative
/// to the executable's location.
///
/// # Arguments
///
/// * `username` - The username of the collaborator whose data needs to be loaded.
///
/// # Returns
///
/// * `Result<CollaboratorTomlData, ThisProjectError>` - The deserialized collaborator data
///   or an error detailing what went wrong.
///
/// # Errors
///
/// This function returns a `Result<CollaboratorTomlData, ThisProjectError>` to handle potential errors:
///  - `ThisProjectError::IoError`: If the collaborator file is not found or if there is an error reading the file.
///  - `ThisProjectError::TomlDeserializationError`: If there is an error parsing the TOML data.
///  - `ThisProjectError::PathResolutionError`: If the executable-relative path cannot be determined.
///
/// # Example
///
/// ```
/// let collaborator = get_addressbook_file_by_username("alice")?;
/// println!("Loaded collaborator data for: {}", collaborator.user_name);
/// ```
fn get_addressbook_file_by_username(
    username: &str,
    full_fingerprint_key_id_string: &str,
    ) -> Result<CollaboratorTomlData, ThisProjectError> {
    debug_log!("Starting GAFbU: get_addressbook_file_by_username for username -> '{}'", username);

    // Get the executable-relative base directory path
    let base_dir = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
        COLLABORATOR_ADDRESSBOOK_PATH_STR
    ) {
        Ok(path) => path,
        Err(e) => {
            debug_log!("GAFbU: Failed to resolve collaborator directory path: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    };

    debug_log!("GAFbU: Base directory path (executable-relative): {:?}", base_dir);

    // Check if base directory exists
    let base_exists = base_dir.exists();
    debug_log!("GAFbU: Base directory exists: {}", base_exists);

    // Construct the specific file path
    let file_name = format!("{}__collaborator.toml", username);
    let file_path = base_dir.join(&file_name);
    debug_log!("GAFbU: Looking for collaborator file at: {:?}", file_path);

    // Check if file exists
    let file_exists = file_path.exists();
    debug_log!("GAFbU: Collaborator file exists: {}", file_exists);

    // If directory exists but file doesn't, list contents to help debugging
    if base_exists && !file_exists {
        debug_log!("GAFbU: Contents of collaborator_files_address_book directory:");
        match std::fs::read_dir(&base_dir) {
            Ok(entries) => {
                let mut found_files = false;
                for entry in entries {
                    if let Ok(entry) = entry {
                        debug_log!("- Found file: {:?}", entry.path().file_name().unwrap_or_default());
                        found_files = true;
                    }
                }
                if !found_files {
                    debug_log!("GAFbU: (directory is empty)");
                }
            },
            Err(e) => debug_log!("ERROR GAFbU: Could not read directory contents: {}", e),
        }
    }

    // Update the read_one_collaborator_addressbook_toml function to also use executable-relative paths
    // Since we don't see its implementation, we'll assume it's a function we need to call
    match read_one_collaborator_addressbook_toml(
        username,
        &full_fingerprint_key_id_string,
        ) {
        Ok(loaded_collaborator) => {
            debug_log!("GAFbU: Successfully loaded collaborator data for '{}'", username);
            Ok(loaded_collaborator)
        }
        Err(e) => {
            debug_log!("ERROR GAFbU: Failed to load collaborator file for '{}': {:?}", username, e);
            Err(e) // Propagate the error
        }
    }
}

/// Used to make a random hex string
/// to store the u128 salt for salted pearson hash
/// in the toml file as hex-string
fn generate_random_salt() -> String {
    let mut rng = rand::rng();
    let salt: u128 = rng.random(); // Generate a random u128
    format!("0x{:X}", salt) // Convert to hexadecimal string with "0x" prefix
}

/// Moves a task (node) from one column to another in the task browser.
/// Updates all relevant paths in node.toml files.
///
/// # Arguments
///
/// * `path_lookup_table` - HashMap containing path lookups by number
///
/// # Returns
///
/// * `Result<(), ThisProjectError>` - Success or error status
fn move_task(
    next_path_lookup_table: &HashMap<usize, PathBuf>
) -> Result<(), ThisProjectError> {
    debug_log("starting move_task()");
    // 1. Get source task number
    println!("Enter task number to move:");
    let task_num = get_user_input_number()?;

    // Get source path from lookup
    let source_path = match next_path_lookup_table.get(&task_num) {
        Some(path) => path.clone(),
        None => return Err(ThisProjectError::InvalidData(
            format!("Task number {} not found", task_num)
        )),
    };
    debug_log!("move_task(), Source path: {:?}", source_path);

    // 2. Get destination column number
    println!("Enter destination column number:");
    let dest_num = get_user_input_number()?;

    // Get destination path from lookup
    let dest_path = match next_path_lookup_table.get(&dest_num) {
        Some(path) => path.clone(),
        None => return Err(ThisProjectError::InvalidData(
            format!("Destination column {} not found", dest_num)
        )),
    };
    debug_log!("move_task(), Destination path: {:?}", dest_path);

    // 3. Perform the move operation
    move_node_directory(source_path, dest_path)?;
    debug_log!(
        "ending move_task()"
        );
    Ok(())
}

/// Helper function to get numeric input from user
fn get_user_input_number() -> Result<usize, ThisProjectError> {
    let mut input = String::new();
    io::stdin().read_line(&mut input)?;
    input.trim().parse::<usize>().map_err(|_|
        ThisProjectError::InvalidData("Invalid number".into())
    )
}

// /*
// This may be garbage:
// For Task Mode:
// 1. Link to tasks: view node 2nd layer deep using links in graph nav struct

// 2. Move task(node) to new directory
// Maybe use the lookup-number directory to get the path of the item to move.

// - command "move"
// - a Q&A interface:
// Q: Move what task?
// A: int
// (maybe get path from next-path lookup dict)

// Q: move to what column?
// A: int
// (this can also be from the lookup path dict)


// Moving a task involves:
// 1. move_from_path = (from next path lookup table)
// 2. move_to_directory_path = (from next path lookup table)
// 3. in move_from_path directory, change "directory_path" node.toml field to be move_to_directory_path
// 4. recursively move the whole directory to the new location...
// (note: internal nodes? local path? full path?)
// 5. resetting the file paths of all nested nodes (unless those are relative...)
// - iterate through new directory path recursively
// - look for node.toml files
// - set node_path to that absolute path

// why is this reading the file BEFORE the move?

// Why is the using path recorded IN the file,
// instead of the literal path to that file?

// Why is there no doc-string?
// */
// /// Moves a node directory and updates all internal paths
// fn move_node_directory(
//     source_path: PathBuf,
//     dest_path: PathBuf
// ) -> Result<(), ThisProjectError> {
//     debug_log("Starting move_node_directory()");

//     debug_log!("Moving node from {:?} to {:?}", source_path, dest_path);

//     // 1. Read the source node.toml
//     let node_toml_path = source_path.join("node.toml");
//     let mut node = load_core_node_from_toml_file(&node_toml_path)
//         .map_err(|e| ThisProjectError::InvalidData(e))?;

//     // 2. Update the node's directory path
//     node.directory_path = dest_path.clone();

//     // 3. Create the new directory
//     let new_node_path = dest_path.join(source_path.file_name().unwrap());
//     fs::create_dir_all(&new_node_path)?;

//     // 4. Move the directory contents
//     move_directory_contents(&source_path, &new_node_path)?;

//     // 5. Update paths in all nested node.toml files
//     update_nested_node_paths(&new_node_path)?;

//     // 6. Remove the old directory
//     fs::remove_dir_all(source_path)?;

//     Ok(())
// }

// /// Updates paths in all nested node.toml files
// fn update_nested_node_paths(
//     dir_path: &Path
// ) -> Result<(), ThisProjectError> {
//     debug_log("starting update_nested_node_paths()");
//     for entry in fs::read_dir(dir_path)? {
//         let entry = entry?;
//         let path = entry.path();

//         if path.is_dir() {
//             update_nested_node_paths(&path)?;
//         } else if path.file_name().unwrap() == "node.toml" {
//             let mut node = load_core_node_from_toml_file(&path)
//                 .map_err(|e| ThisProjectError::InvalidData(e))?;
//             node.directory_path = path.parent().unwrap().to_path_buf();
//             save_toml_to_file(&node, &path)?;
//         }
//     }
//     Ok(())
// }

// /// Recursively moves directory contents
// fn move_directory_contents(
//     from: &Path,
//     to: &Path
// ) -> Result<(), ThisProjectError> {
//     debug_log("starting move_directory_contents()");
//     for entry in fs::read_dir(from)? {
//         let entry = entry?;
//         let path = entry.path();
//         let destination = to.join(path.file_name().unwrap());

//         if path.is_dir() {
//             fs::create_dir_all(&destination)?;
//             move_directory_contents(&path, &destination)?;
//         } else {
//             fs::copy(&path, &destination)?;
//         }
//     }
//     Ok(())
// }

// /// Moves a node directory and updates its metadata.
// ///
// /// This function moves a node's directory from the `source_path` to the `dest_path`.
// /// It updates the `directory_path` field in the node's `node.toml` file to reflect
// /// the new location. The function uses the `source_path`, not path within the struct.
// /// It handles directory creation, moving, and file updates efficiently.
// ///
// /// # Arguments
// ///
// /// * `source_path`: The current path to the node's directory.
// /// * `dest_path`: The intended path for the moved node's directory.
// ///
// /// # Returns
// ///
// /// * `Result<(), ThisProjectError>`: `Ok(())` if the move is successful; otherwise, a `ThisProjectError` is returned.
// fn move_node_directory(
//     source_path: PathBuf,
//     dest_path: PathBuf,
// ) -> Result<(), ThisProjectError> {
//     debug_log!("Starting move_node_directory()");
//     debug_log!("Moving node from {:?} to {:?}", source_path, dest_path);

//     // 1. Construct the new node path (where the moved node will be located).
//     let new_node_path = dest_path.join(source_path.file_name().unwrap());
//     debug_log!("move_node_directory: new_node_path is: {:?}", new_node_path);

//     // 2. Create the new directory, including all parents.
//     fs::create_dir_all(&new_node_path)?;
//     debug_log!("move_node_directory: created new_node_path: {:?}", new_node_path);

//     // 3. Recursively move the source directory's contents to the new directory.
//     move_directory_contents(&source_path, &new_node_path)?;
//     debug_log!("move_node_directory: contents moved to: {:?}", new_node_path);

//     // 4. Update node.toml (use full path)
//     // (The old path is already deleted by move_directory_contents)
//     update_node_path_in_toml(&new_node_path)?;
//     debug_log!("move_node_directory: updated node.toml paths");

//     // 5. Remove the old directory.
//     fs::remove_dir_all(source_path.clone())?;
//     // fs::remove_dir_all(source_path)?;
//     debug_log!("move_node_directory: removed source_path at : {:?}", source_path);

//     Ok(())
// }


// /// Updates the directory_path in node.toml
// /// Does NOT attempt to move anything
// fn update_node_path_in_toml(new_node_path: &Path) -> Result<(), ThisProjectError> {
//     debug_log!("starting update_node_path_in_toml(), for path: {:?}", new_node_path);

//     let node_toml_path = new_node_path.join("node.toml");

//     // 1. Read node.toml file:
//     let mut node = load_core_node_from_toml_file(&node_toml_path)
//         .map_err(|e| ThisProjectError::InvalidData(e))?;

//     // 2. Check if directory path is already the new path:
//     if node.directory_path == new_node_path {
//         debug_log!(
//             "skipping: update_node_path_in_toml(): node_toml.directory_path is already = {:?}, so no change required",
//             node.directory_path
//         );
//         return Ok(());
//     }

//     debug_log!("update_node_path_in_toml: old-node.directory_path: {:?}", node.directory_path);

//     // 3. Set new node.directory_path:
//     node.directory_path = new_node_path.to_path_buf();
//     debug_log!("update_node_path_in_toml: new-node.directory_path: {:?}", node.directory_path);

//     // 4. Write node.toml file:
//     save_toml_to_file(&node, &node_toml_path)?; // No need to use new_node_path again

//     debug_log!("Successfully updated node.toml directory path.");
//     Ok(())
// }

// /// Recursively moves directory contents
// fn move_directory_contents(
//     from: &Path,
//     to: &Path
// ) -> Result<(), ThisProjectError> {
//     debug_log("starting move_directory_contents()");
//     for entry in fs::read_dir(from)? {
//         let entry = entry?;
//         let path = entry.path();
//         let destination = to.join(path.file_name().unwrap());

//         if path.is_dir() {
//             fs::create_dir_all(&destination)?;
//             move_directory_contents(&path, &destination)?;
//         } else {
//             fs::copy(&path, &destination)?;
//         }
//     }
//     Ok(())
// }

/// Moves a node directory and updates its metadata.
///
/// This function moves a node's directory from the `source_path` to the `dest_path`.
/// It updates the `directory_path` field in the node's `node.toml` file to reflect
/// the new location. The function uses the `source_path`, not path within the struct.
/// It handles directory creation, moving, and file updates efficiently.
///
/// # Arguments
///
/// * `source_path`: The current path to the node's directory.
/// * `dest_path`: The intended path for the moved node's directory.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` if the move is successful; otherwise, a `ThisProjectError` is returned.
fn move_node_directory(
    source_path: PathBuf,
    dest_path: PathBuf,
) -> Result<(), ThisProjectError> {
    debug_log!("Starting move_node_directory()");
    debug_log!("Moving node from {:?} to {:?}", source_path, dest_path);

    // 1. Construct the new node path (where the moved node will be located).
    let new_node_path = dest_path.join(source_path.file_name().unwrap());
    debug_log!("move_node_directory: new_node_path is: {:?}", new_node_path);

    // 2. Create the new directory, including all parents.
    fs::create_dir_all(&new_node_path)?;
    debug_log!("move_node_directory: created new_node_path: {:?}", new_node_path);


    // let original_node_toml_path = new_node_path.push("node.toml");
    let mut original_node_toml_path = source_path.clone();
    original_node_toml_path.push("node.toml");

    // 3. Update node.toml (use full path)
    // Option 1: Using to_string_lossy() (safest for paths that might contain non-UTF-8 characters)
    let mut new_node_path_string = dest_path.to_string_lossy().into_owned();

    debug_log!(
        "next: match safe_update_toml_field(\n{:?},\n{:?},\n{:?},\n)",
        &original_node_toml_path,   // path to .toml
        &new_node_path_string, // new value
        "directory_path",      // name of field
    );

    match safe_update_toml_field(
        &original_node_toml_path,        // path to .toml
        &new_node_path_string, // new value
        "directory_path",     // name of field
    ) {
        Ok(_) => println!("Successfully updated TOML file"),
        Err(e) => eprintln!("Error: {}", e)
    }


    // 4. Recursively move the source directory's contents to the new directory.
    move_directory_contents(&source_path, &new_node_path)?;
    debug_log!("move_node_directory: contents moved to: {:?}", new_node_path);




    debug_log!("move_node_directory: updated node.toml paths");

    // 5. Remove the old directory.
    fs::remove_dir_all(source_path.clone())?;
    debug_log!("move_node_directory: removed source_path at : {:?}", source_path);

    Ok(())
}

/// TODO update for clearsign...just load_core_node_from_toml_file?
/// Updates the directory_path in node.toml
/// Does NOT attempt to move anything
fn update_node_path_in_toml(new_node_path: &Path) -> Result<(), ThisProjectError> {
    debug_log!("starting update_node_path_in_toml(), for path: {:?}", new_node_path);

    let node_toml_path = new_node_path.join("node.toml");

    // 1. Read node.toml file:
    let mut node = load_core_node_from_toml_file(&node_toml_path)
        .map_err(|e| ThisProjectError::InvalidData(e))?;

    // 2. Check if directory path is already the new path:
    if node.directory_path == new_node_path {
        debug_log!(
            "skipping: update_node_path_in_toml(): node_toml.directory_path is already = {:?}, so no change required",
            node.directory_path
        );
        return Ok(());
    }

    debug_log!("update_node_path_in_toml: old-node.directory_path: {:?}", node.directory_path);

    // 3. Set new node.directory_path:
    node.directory_path = new_node_path.to_path_buf();
    debug_log!("update_node_path_in_toml: new-node.directory_path: {:?}", node.directory_path);

    // 4. Write node.toml file:
    save_toml_to_file(&node, &node_toml_path)?; // No need to use new_node_path again

    debug_log!("Successfully updated node.toml directory path.");
    Ok(())
}

/// Updates a specified field in a TOML file with a new value.
///
/// # Arguments
///
/// * `path` - A PathBuf containing the path to the TOML file
/// * `new_string` - A string slice containing the new value to be set
/// * `field` - A string slice containing the name of the field to update
///
/// # Returns
///
/// * `io::Result<()>` - Ok(()) on success, or an error if the operation fails
///
/// # Example
///
/// ```
/// # use std::fs;
/// # use std::path::PathBuf;
/// # fs::write("example.toml", "field = \"old_value\"").unwrap();
/// let path = PathBuf::from("example.toml");
/// let result = update_toml_field(&path, "new_value", "field");
/// # fs::remove_file("example.toml").unwrap();
/// ```
pub fn update_toml_field(
    path: &PathBuf,
    new_string: &str,
    field: &str
) -> io::Result<()> {
    // Read the entire file content using PathBuf's as_path() method
    let content = fs::read_to_string(path.as_path())?;

    // Create a temporary file with the same name plus .tmp
    let temp_path = path.with_extension("tmp");
    let mut temp_file = File::create(&temp_path)?;

    let mut field_found = false;

    // Process each line
    for line in content.lines() {
        let trimmed = line.trim();
        if trimmed.starts_with(field) && trimmed.contains('=') {
            // Write the new line for the matching field
            writeln!(temp_file, "{} = \"{}\"", field, new_string)?;
            field_found = true;
        } else {
            // Write the original line
            writeln!(temp_file, "{}", line)?;
        }
    }

    // If field wasn't found, append it
    if !field_found {
        writeln!(temp_file, "{} = \"{}\"", field, new_string)?;
    }

    // Ensure all data is written
    temp_file.flush()?;

    // Replace the original file with the temporary file
    fs::rename(temp_path, path)?;

    Ok(())
}

/// A safer wrapper function that includes additional error checking.
///
/// # Arguments
///
/// * `path` - A PathBuf containing the path to the TOML file
/// * `new_string` - A string slice containing the new value to be set
/// * `field` - A string slice containing the name of the field to update
///
/// # Returns
///
/// * `Result<(), String>` - Ok(()) on success, or an error message if the operation fails
///
/// Example Use:
/// ```
/// use std::path::PathBuf;
/// let config_path = PathBuf::from("config.toml");
/// match safe_update_toml_field(&config_path, "alice", "user_name") {
///     Ok(_) => println!("Successfully updated TOML file"),
///     Err(e) => eprintln!("Error: {}", e)
/// }
/// ```
pub fn safe_update_toml_field(
    path: &PathBuf,
    new_string: &str,
    field: &str
) -> Result<(), String> {

    debug_log("starting safe_update_toml_field()");

    debug_log!(
        "in safe_update_toml_field(\n{:?},\n{:?},\n{:?},\n)",
        &path,   // path to .toml
        &new_string, // new value
        "field",      // name of field
    );

    // Validate inputs
    if field.is_empty() {
        return Err("Error: safe_update_toml_field() Field name cannot be empty".to_string());
    }

    if !path.exists() {
        return Err(format!("Error: safe_update_toml_field() File not found: {}", path.display()));
    }

    update_toml_field(path, new_string, field)
        .map_err(|e| format!("Error: safe_update_toml_field() Failed to update TOML file: {}", e))
}

/// Recursively moves directory contents
fn move_directory_contents(
    from: &Path,
    to: &Path
) -> Result<(), ThisProjectError> {
    debug_log("starting move_directory_contents()");
    for entry in fs::read_dir(from)? {
        let entry = entry?;
        let path = entry.path();
        let destination = to.join(path.file_name().unwrap());

        if path.is_dir() {
            fs::create_dir_all(&destination)?;
            move_directory_contents(&path, &destination)?;
        } else {
            // Now, move the file instead of copying it
            fs::rename(&path, &destination)?;
        }
    }
    Ok(())
}

/// Loads connection data for members of the currently active team channel.
/// On success, returns a `HashSet` of `MeetingRoomSyncDataset` structs,
/// each containing connection
/// data for a collaborator in the current team channel (excluding the current user).
/// As a headline this makes an ip-whitelist or ip-allowlist but the overall process is bigger.
/// This should include 'yourself' so all connection data are there, so you know your ports
///
/// Note: this likely should also include the collabortor's last-received-timestamp (and the previous one)
/// this will also need a bootstrap where at first...there is no last timestamp.
///
/// Note: making the allow_lists requires information from more than one source:
/// =uma.toml
/// =project_graph_data/session_items/current_node_teamchannel_collaborators_with_access.toml
/// =/project_graph_data/collaborator_files_address_book/NAME__collaborator.toml
///
/// step 1: get team_channel list of (and data about) all possible team_channel_members
///     from externalized session state item doc @:
///     project_graph_data/session_items/current_node_teamchannel_collaborators_with_access.toml
///     The 6-port assignments come from this source.
///
/// step 2: get /collaborator_files_address_book data @:
///     .../project_graph_data/collaborator_files_address_book/ directory
///     as: NAME__collaborator.toml
///
/// step 3: Remove any collaborator from that 'possible list' whose information
///     is not in the .../project_graph_data/collaborator_files_address_book directory
///     as: NAME__collaborator.toml
///     The ipv4 and ipv6 lists come from this source.
///
/// step 4: make a session dataset for: teamchannel_connection_data
///     - allowlisted collaborators
///         - names
///         - ip lists
///         - ports
///
/// (note: members should have a list of ipv4, ipv6 addresses, not just one)
///
/// sample: project_graph_data/collaborator_files_address_book/alice__collaborator.toml
/// [[collaborator]]
/// user_name = "alice"
/// ipv4_addresses = ["24.0.189.112", "24.0.189.112"]
/// ipv6_addresses = ["2601:80:4803:9490::2e79","2601:80:4803:9490::2e79"]
/// gpg_key_public = "304A9A525A5D00D6AD269F765C3E7C56E5A3D0D8"
/// sync_interval = 5000
///
/// Do NOT read all data from all collaborators.
/// Ethical Data Access: The function only accesses the collaborator data that
/// is absolutely necessary for building the session_connection_allowlist for the current channel.
///
/// sample node.toml
/// node_name = "teamtest"
/// description_for_tui = "teamtest"
/// node_unique_id = 1728307130
/// directory_path = "project_graph_data/team_channels/teamtest"
/// order_number = 5
/// priority = "Medium"
/// owner = "initial_owner"
/// updated_at_timestamp = 1728307130
/// expires_at = 1728393530
/// children = []
/// teamchannel_collaborators_with_access = ["alice", "bob"]
///
/// # abstract_collaborator_port_assignments
/// [abstract_collaborator_port_assignments.alice_bob]
/// collaborator_ports = [
///     { name = "alice", ready_port = 50001, intray_port = 50002, gotit_port = 50003 },
///     { name = "bob", ready_port = 50004, intray_port = 50005, gotit_port = 50006 },
/// ]
///
/// [abstract_collaborator_port_assignments.alice_charlotte]
/// collaborator_ports = [
///     { name = "alice", ready_port = 50007, intray_port = 50008, gotit_port = 50009 },
///     { name = "charlotte", ready_port = 50010, intray_port = 50011, gotit_port = 50012 },
/// ]
///
/// [abstract_collaborator_port_assignments.bob_charlotte]
/// collaborator_ports = [
///     { name = "bob", ready_port = 50013, intray_port = 50014, gotit_port = 50015 },
///     { name = "charlotte", ready_port = 50016, intray_port = 50017, gotit_port = 50018 },
/// ]
///
/// maybe detects any port collisions,
/// excluding those who collide with senior members
/// or returning an error if found.
fn make_sync_meetingroomconfig_datasets(uma_local_owner_user: &str) -> Result<HashSet<MeetingRoomSyncDataset>, MyCustomError> {
    debug_log!("MSMD Entering the make_sync_meetingroomconfig_datasets() function...");

    // --- 1. find node.toml ---
    /*
    1. Find Path to team-channel node.toml,
    which contains the port assignments
    and the list of (all possible) team-members
    (collaborators with access to that channel,
    though perhaps not shared yet with you)
    */
    // get path, derive name from path
    // let channel_dir_path_str = read_state_string("current_node_directory_path.txt")?; // read as string first

    // get path, derive name from path
    let channel_dir_path_str = match read_state_string("current_node_directory_path.txt") {
        Ok(path) => {
            debug_log!("MSMD 1. Channel directory path (from session state): {:?}", path);
            path
        }
        Err(e) => {
            debug_log!(
                "MSMD ERROR: Failed to read 'current_node_directory_path.txt': {}. \
                 This may be due to missing file, permission issues, or malformed content.",
                e
            );
            return Err(MyCustomError::from(format!(
                "MSMD ERROR: Failed to read channel directory path: {}. \
                 Ensure the file exists and is accessible.",
                e
            )));
        }
    };


    debug_log!("MSMD 1. Channel directory path (from session state): {:?}", channel_dir_path_str);

    // use absolute file path
    let channel_dir_path = PathBuf::from(channel_dir_path_str);

    // A. Print the absolute path of the channel directory
    match channel_dir_path.canonicalize() {
        Ok(abs_path) => debug_log!("MSMD 1. Absolute channel directory path: {:?}", abs_path),
        Err(e) => debug_log!("MSMD Error 1. getting absolute path of channel directory: {}", e),
    }

    // todo: add either-or .toml .gpgtoml
    // A. Check for either node.toml or node.gpgtoml
    let node_toml_path = channel_dir_path.join("node.toml");
    let node_gpgtoml_path = channel_dir_path.join("node.gpgtoml");

    let raw_channelnodetoml_path = if node_toml_path.exists() {
        debug_log!("TCS: Found node.toml");
        node_toml_path
    } else if node_gpgtoml_path.exists() {
        debug_log!("TCS: Found node.gpgtoml");
        node_gpgtoml_path
    } else {
        return Err(MyCustomError::from(
            "TCS: Neither node.toml nor node.gpgtoml found in team channel directory".to_string()
        ));
    };

    // Get GPG fingerprint
    let gpg_fingerprint = LocalUserUma::read_gpg_fingerprint_from_file()
        .map_err(|e| MyCustomError::from(
            format!("TCS: Failed to read GPG fingerprint from uma.toml: {}", e)
        ))?;
        // .map_err(|e| Err(MyCustomError::from(
        //     format!("TCS: Failed to read GPG fingerprint from uma.toml: {}", e)
        // ))?;

    // Get temp directory
    let temp_dir = get_base_uma_temp_directory_path()
        .map_err(|e| MyCustomError::from(
            format!("TCS: Failed to get temp directory path: {}", e)
        ))?;
        // .map_err(|e| Err(MyCustomError::from(
        //     format!("TCS: Failed to get temp directory path: {}", e)
        // )))?;

    // Get readable copy
    let channel_node_tomlpath_string
        = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &raw_channelnodetoml_path,
        &gpg_fingerprint,
        &temp_dir,
    ).map_err(|e| MyCustomError::from(
        format!("TCS: Failed to get readable copy of node file: {:?}", e)
    ))?;
    // ).map_err(|e| GpgError::PathError(
    //     format!("TCS: Failed to get readable copy of node file: {:?}", e)
    // ))?;

    debug_log!("TCS: channel_node_tomlpath_string
        : {}", channel_node_tomlpath_string
    );

    // Construct the path to node.toml
    // let channel_node_tomlpath_string
    //  = channel_dir_path.join("node.toml");

    debug_log!("MSMD 1. Channel node.toml path: {:?}", channel_node_tomlpath_string
    );

    let channel_node_toml_path = Path::new(
        &channel_node_tomlpath_string
    );

    // B. Print the absolute path of the node.toml file
    match channel_node_toml_path.canonicalize() {
        Ok(abs_path) => debug_log!("MSMD 1. Absolute channel_dir_path node.toml path: {:?}", abs_path),
        Err(e) => debug_log!("MSMD Error 1. getting absolute path of channel_dir_path node.toml: {}", e),
    }

    // --- 2. Load/Read node.toml ---
    // Read that (node toml) data into an organized 'struct' of variables
    // Read node.toml data with fn load_core_node_from_toml_file()
    // loading the fields into an organized struct with datatypes
    let teamchannel_nodetoml_data: CoreNode = match load_core_node_from_toml_file(&channel_node_toml_path) {
        Ok(node) => {
            debug_log!("MSMD 2. Successfully read channel node.toml");
            node // ???
        },
        Err(e) => {
            debug_log!("MSMD Error 2. reading channel node.toml: {:?}", channel_node_toml_path);
            debug_log!("MSMD Error 2. details: {}", e);
            return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e))); // Convert the error
        }
    };
    debug_log!("MSMD 2. teamchannel_nodetoml_data->{:?}", teamchannel_nodetoml_data);

    // --- 3. Empty Table for Later ---
    // Create an (empty) lookup-table (hash-set) to put all the meeting-room-data-sets in.
    // This will contain the local-port-assignments for each desk.
    let mut sync_config_data_set: HashSet<MeetingRoomSyncDataset> = HashSet::new();
    debug_log!("MSMD 3. sync_config_data_set->{:?} <should be empty, ok>", &sync_config_data_set);

    // --- 4. Team-Channel Memebers ---
    // Get team member names from team_channel node
    // (Example of derived-functional definitions:
    // compile this from the list of port-assignments,
    // rather than having multiple 'sources of truth' for members)
    // let collaborators_names_array = teamchannel_nodetoml_data.teamchannel_collaborators_with_access;
    // derive list functionally from port-assignemnt list
    let collaborators_names_array = match get_collaborator_names_from_node_toml(&channel_node_toml_path) {
        Ok(names) => names,
        Err(e) => {
            debug_log!("MSMD Error 4. getting collaborator names: {}", e);
            return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e)));
        }
    };
    debug_log!("MSMD 4. collaborators_names_array->{:?}", collaborators_names_array);

    // --- 5. raw-abstract port-assignments ---
    // Get the raw-abstract port-assignments
    // from the team_channel node
    // let abstract_collaborator_port_assignments = teamchannel_nodetoml_data.abstract_collaborator_port_assignments;
    // debug_log!(
    //     "5. abstract_collaborator_port_assignments->{:?}",
    //     &abstract_collaborator_port_assignments
    // );


    ////////////////////////////////
    // Extract Owner for Key Lookup
    ////////////////////////////////
    let owner_name_of_toml_field_key_to_read = "owner";
    debug_log!(
        "LCNFTF: Reading file owner from field '{}' for security validation",
        owner_name_of_toml_field_key_to_read
    );

    // get node_owners_public_gpg_key

    let file_owner_username = match read_single_line_string_field_from_toml(
        &channel_node_tomlpath_string,  // TODO convert to string?
        owner_name_of_toml_field_key_to_read,
    ) {
        Ok(username) => {
            if username.is_empty() {
                // Convert to String error instead of GpgError
                return Err(MyCustomError::from(format!(
                    "MSMD: Field '{}' is empty in TOML file. File owner is required for security validation.",
                    owner_name_of_toml_field_key_to_read
                )));
            }
            username
        }
        Err(e) => {
            // Convert to String error instead of GpgError
            return Err(MyCustomError::from(format!(
                "MSMD: Failed to read file owner from field '{}': {}",
                owner_name_of_toml_field_key_to_read, e
            )));
        }
    };
    println!("MSMD: File owner: '{}'", file_owner_username);
    debug_log!("MSMD: File owner: '{}'", file_owner_username);

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            debug_log!("MSMD Error 5. getting abstract_collaborator_port_assignments: {}", e);
            return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e)));
        }
    };


    // Get the UME temp directory path with error handling
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| format!(
            "MSMD: Failed to get UME temp directory path: {:?}",
            io_err
        ))?;

    // Extract the addressbook path string with inline error conversion
    let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_owner_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| format!(
        "MSMD: Failed to get addressbook path for user '{}': {:?}",
        file_owner_username,
        e
    ))?;

    // Define cleanup closure
    let cleanup_closure = || {
        let _ = cleanup_collaborator_temp_file(
            &channel_node_tomlpath_string,
            &base_uma_temp_directory_path,
            );
        let _ = cleanup_collaborator_temp_file(
            &addressbook_readcopy_path_string,
            &base_uma_temp_directory_path,
            );
    };

    /*
    pub fn read_abstract_ports_from_clearsigntoml_without_publicgpgkey(
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
    ) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, String> {
    */

    // let abstract_collaborator_port_assignments = match get_abstract_port_assignments_from_node_toml(&channel_node_toml_path) {
    //     Ok(names) => names,
    //     Err(e) => {
    //         debug_log!("MSMD Error 5. getting abstract_collaborator_port_assignments: {}", e);
    //         return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e)));
    //     }
    // };

    let abstract_collaborator_port_assignments = match read_abstract_ports_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,
        &channel_node_tomlpath_string
    ) {
        Ok(names) => names,
        Err(e) => {
            debug_log!("MSMD Error 5. getting abstract_collaborator_port_assignments: {}", e);
            return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e)));
        }
    };

    debug_log!(
        "MSMD 5. abstract_collaborator_port_assignments->{:?}",
        &abstract_collaborator_port_assignments
    );

    // --- 6. filtered collaborators array ---
    // filter-pass: remove non-contacts from list
    //    - remove self
    //    - remove duplicates
    //    - remove names not in address-book
    let mut filtered_collaboratorsarray = collaborators_names_array.clone();

    // 6.1  Remove Self (don't try to call yourself on the phone)
    filtered_collaboratorsarray.retain(|name| name != &uma_local_owner_user);

    // 6.2  Remove Duplicates
    filtered_collaboratorsarray.sort();
    filtered_collaboratorsarray.dedup();

    // 6.3  Actual Meeting Contacts
    // Remove Names Not in your Address Book
    // the team-owner invites people to the team
    // each collaborator invites you to connect with them
    // filtered_collaboratorsarray.retain(|name| {
    //     let addressbook_toml_file_path = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
    //         .join(format!("{}__collaborator.toml", name));
    //     addressbook_toml_file_path.exists()
    // });


    filtered_collaboratorsarray.retain(|name| {
        let addressbook_dir = get_addressbook_directory_path().unwrap_or_else(|_| {
            // Handle error if needed, e.g., return an empty PathBuf or panic
            debug_log(
                "MSMD addressbook_dir not found..."
            );

            PathBuf::new()
        });
        let addressbook_toml_file_path = addressbook_dir.join(format!("{}__collaborator.toml", name));
        let addressbook_gpgtoml_file_path = addressbook_dir.join(format!("{}__collaborator.gpgtoml", name));
        addressbook_toml_file_path.exists() || addressbook_gpgtoml_file_path.exists()
    });



    debug_log!(
        "MSMD 6. filtered_collaboratorsarray->{:?}",
        &filtered_collaboratorsarray
    );

    // // TODO this perhaps shou be a parameter for this functions
    // // maybe in uma.toml
    // // Get armored public key, using key-id (full fingerprint in)
    // let mut full_fingerprint_key_id_string = String::new();
    // match q_and_a_user_selects_gpg_key_full_fingerprint() {
    //     Ok(temp_fullfingerprint_key_idstring) => {

    //         println!("Selected key id (full fingerprint in): {}", temp_fullfingerprint_key_idstring);
    //         full_fingerprint_key_id_string = temp_fullfingerprint_key_idstring;
    // }
    //     Err(e) => eprintln!("Error selecting full_fingerprint_key_id_string: {}", e.to_string()),
    // }


    // // Get armored public key, using key-id (full fingerprint in)
    // let mut full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
    //     Ok(fingerprint) => fingerprint,
    //     Err(e) => {
    //         eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
    //         return Ok(false);
    //     }
    // };

    // Get armored public key, using key-id (full fingerprint in)
    let full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            eprintln!("MSMD Failed to read GPG fingerprint from uma.toml: {}", e);
            debug_log!("MSMD Failed to read GPG fingerprint from uma.toml: {}", e);
            return Err(MyCustomError::from(format!(
                "MSMD Failed to read GPG fingerprint from uma.toml: {}", e
            )));
        }
    };

    // --- Get local user's salt list ---
    let local_user_salt_list = match get_addressbook_file_by_username(
        uma_local_owner_user,
        &full_fingerprint_key_id_string,
        ) {
        Ok(data) => data.user_salt_list,
        Err(e) => {
            debug_log!("MSMD Error loading local user's salt list: {}", e);
            // return Err(e);
            return Err(e.into()); // Convert ThisProjectError to MyCustomError
        }
    };

    // --- 7. Iterate through the filtered address-book-name-list ---
    // Go through the list make a set of meeting room information for each team-member,
    // so that you (e.g. Alice) can sync with other team members.
    for collaborator_name in filtered_collaboratorsarray { // collaborator_data is now a String
        debug_log!("MSMD 7. Processing collaborator: {}", collaborator_name);

        // --- 8. get (that team member's) addressbook file by (their) username ---
        // using get_addressbook_file_by_username()
        // which loads the NAME__collaborator.toml from the collaborator_files_address_books directory
        // (owned by that collaborator, it is their own gpg signed data)
        let these_collaboratorfiles_toml_data = match get_addressbook_file_by_username(
            &collaborator_name,
            &full_fingerprint_key_id_string,
            ) {
            Ok(these_collaboratorfiles_toml_data) => these_collaboratorfiles_toml_data,
            Err(e) => {
                // This is where you'll most likely get the "No such file or directory" error
                debug_log!("MSMD Error 8. loading collaborator {}. File might be missing. Error: {}", collaborator_name, e);
                return Err(e.into()); // Convert ThisProjectError to MyCustomError
            }
        };
        debug_log!(
            "MSMD 8. Collaborator data these_collaboratorfiles_toml_data: {:?}",
            &these_collaboratorfiles_toml_data
        );

        // --- 9. extract data or drop collaborator from list ---
        // TODO addresses plural?
        /*
        what are all the fields of information to get?
        ipv6
        ipv4
        (is there some other type of address too?)
        gpg
        sync rate?
        */
        // IPvX...what else?
        // (If not available, drop this person from the list)
        let ipv6_address = match these_collaboratorfiles_toml_data
            .ipv6_addresses.clone()
            .and_then(|v| v.first().cloned())
        {
            Some(addr) => {
                debug_log!(
                    "MSMD 9. IPv6 address for {}: {}",
                    collaborator_name, addr
                );
                addr // ?
            },
            None => {
                debug_log!("MSMD WARNING: 9. No IPv6 address found for {}. Skipping this collaborator.", collaborator_name);
                continue; // Skip to the next collaborator in the loop
            }
        };
        debug_log!(
            "MSMD 9. ipv6_address {:?}->",
            &ipv6_address
        );

        // TODO Alpha under construction
        // --- 10. Translate abstract port assignments to local role-specific structs ---
        // let role_based_ports = translate_port_assignments()
        /*
        Make local port assignments: Translate abstract port assignments to local role-specific structs
        per real remote collaborator:

        Instance-Role-Specific Local-Meeting-Room-Struct
        This is no longer an abstract set of data that can be used
        in different ways in different instances,
        this is now one of those specific instances
        with local roles and one local way of using those data.
        The abstract port-assignments will be converted
        into a disambiguated and clarified specific local
        instance roles set of port assignments, namely,
        local_user_role, remote_collaborator_role
        */
        debug_log("MSMD 10. Starting translate_port_assignments()");
        let role_based_ports = translate_port_assignments(
            uma_local_owner_user,
            &collaborator_name,
            abstract_collaborator_port_assignments.clone(), // Clone to avoid ownership issues
        )?;
        debug_log!(
            "MSMD 10. role_based_ports {:?}->",
            &role_based_ports
        );
        /*
        abstract format is:
        # meeting rooms, abstract_collaborator_port_assignments
        [abstract_collaborator_port_assignments.alice_bob]
        collaborator_ports = [
            { name = "alice", ready_port = 50001, intray_port = 50002, gotit_port = 50003 },
            { name = "bob", ready_port = 50004, intray_port = 50005, gotit_port = 50006 },
        ]
        */

        // --- Get remote collaborator's salt list ---
        // let remote_collaborator_salt_list = match get_addressbook_file_by_username(collaborator_name.clone()) {
        let remote_collaborator_salt_list = match get_addressbook_file_by_username(
            &collaborator_name.clone(),
            &full_fingerprint_key_id_string,
            ) {
            Ok(data) => data.user_salt_list,
            Err(e) => {
                debug_log!("MSMD Error loading remote_collaborator_salt_list user's salt list: {}", e);
                // return Err(e);
                return Err(e.into()); // Convert ThisProjectError to MyCustomError
            }
        };

        // --- 11. Construct MeetingRoomSyncDataset (struct) ---
        // Assemble this one meeting room data-bundle from multiple sources
        // - from node.toml data
        // - from addressbook data
        // - from Instance-Role-Specific Local-Meeting-Room-Struct
        let meeting_room_sync_data = MeetingRoomSyncDataset {
            local_user_name: uma_local_owner_user.to_string(),  // TODO source?
            local_user_salt_list: local_user_salt_list.clone(), // Include the local salt list
            local_user_ipv6_addr_list: these_collaboratorfiles_toml_data.ipv6_addresses.clone().unwrap_or_default(), // Assuming you want to use the first IPv6 address for the local user
            // local_user_ipv6_addr_list: these_collaboratorfiles_toml_data.ipv6_addresses.expect("REASON"), // Assuming you want to use the first IPv6 address for the local user
            local_user_ipv4_addr_list: these_collaboratorfiles_toml_data.ipv4_addresses.clone().unwrap_or_default(), // Get IPv4 addresses or an empty vector
            // local_user_ipv4_addr_list: these_collaboratorfiles_toml_data.ipv4_addresses.expect("REASON"), // Assuming you want to use the first
            local_user_gpg_publickey_id: these_collaboratorfiles_toml_data.gpg_publickey_id.clone(),
            local_user_public_gpg: these_collaboratorfiles_toml_data.gpg_key_public.clone(),
            local_user_sync_interval: these_collaboratorfiles_toml_data.sync_interval,

            local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: role_based_ports.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,
            localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: role_based_ports.localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip,
            local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: role_based_ports.local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip,

            remote_collaborator_name: collaborator_name.clone(), // TODO source?
            remote_collaborator_salt_list: remote_collaborator_salt_list,
            remote_collaborator_ipv6_addr_list: these_collaboratorfiles_toml_data.ipv6_addresses.unwrap_or_default(), // Get ip addresses or empty vector
            remote_collaborator_ipv4_addr_list: these_collaboratorfiles_toml_data.ipv4_addresses.unwrap_or_default(), // Get IP addresses or empty vector
            // remote_collaborator_ipv6_addr_list: these_collaboratorfiles_toml_data.ipv6_addresses.expect("REASON"), // Get ip addresses or empty vector
            // remote_collaborator_ipv4_addr_list: these_collaboratorfiles_toml_data.ipv4_addresses.expect("REASON"), // Get IP addresses or empty vector
            remote_collaborator_gpg_publickey_id: these_collaboratorfiles_toml_data.gpg_publickey_id,
            remote_collaborator_public_gpg: these_collaboratorfiles_toml_data.gpg_key_public,
            remote_collaborator_sync_interval: these_collaboratorfiles_toml_data.sync_interval,

            remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: role_based_ports.remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip,
            remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: role_based_ports.remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip,
            remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: role_based_ports.remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip,
        };

        // --- 12. add meeting room to set-of-rooms-table ---
        // add this one meeting room data-bundle to the larger set
        sync_config_data_set.insert(meeting_room_sync_data.clone());
        debug_log!(
            "MSMD 12. Created MeetingRoomSyncDataset: {:?}",
            meeting_room_sync_data
        );

    } // End of collaborator loop

    debug_log!("MSMD Done: 12,13: sync_config_data_set created: {:?}", sync_config_data_set);

    // 13. after iterating, return full set of meeting-rooms
    Ok(sync_config_data_set)
}

/// Implementation of the Pearson hashing algorithm
///
/// This is a non-cryptographic hash function that produces an 8-bit hash value.
/// It's useful for:
/// - Hash tables
/// - Data integrity checks
/// - Fast execution on 8-bit processors
///
/// Features:
/// - Simple implementation
/// - Fast execution
/// - No simple class of inputs that produce collisions
/// - Two strings differing by one character never collide
///
/// Reference: Pearson, Peter K. (1990). "Fast Hashing of Variable-Length Text Strings"
///
/// Generate a permutation table using a non-linear transformation
/// This is done at compile time using const fn
const fn generate_pearson_permutation_table() -> [u8; 256] {
    let mut table = [0u8; 256];
    let mut i = 0;
    while i < 256 {
        // Non-linear transformation: multiply by prime number 167 and add 13
        // Then mask with 0xFF to keep it within u8 range
        table[i as usize] = ((i * 167 + 13) & 0xFF) as u8;
        i += 1;
    }
    table
}

// The permutation table is computed once at compile time
const PERMUTATION_TABLE: [u8; 256] = generate_pearson_permutation_table();

/// Computes the Pearson hash of the input bytes
///
/// # Arguments
///
/// * `input` - A slice of bytes to hash
///
/// # Returns
///
/// * An 8-bit hash value as u8
///
/// # Example
///
/// ```
/// let text = "Hello, World is the first onasei!";
/// let hash = pearson_hash6(text.as_bytes());
/// println!("Hash: {}", hash);
/// ```
pub fn pearson_hash_base(input: &[u8]) -> Result<u8, std::io::Error> {
    // Check if input is empty
    if input.is_empty() {
        return Err(std::io::Error::new(
            std::io::ErrorKind::InvalidInput,
            "Input cannot be empty"
        ));
    }

    // Initialize hash to 0
    let mut hash: u8 = 0;

    // For each byte in the input
    for &byte in input {
        // XOR the current byte with the hash, use result as index into permutation table
        hash = PERMUTATION_TABLE[(hash ^ byte) as usize];
    }

    Ok(hash)
}

/// Converts a Pearson hash (Vec<u8>) to a hexadecimal string.
///
/// # Arguments
///
/// * `hash`: The Pearson hash as a `Vec<u8>`.
///
/// # Returns
///
/// * `String`: The hexadecimal representation of the hash.
fn pearson_hash_to_hex_string(hash: &[u8]) -> String {
    hash.iter()
        .map(|&byte| format!("{:02x}", byte)) // Format each byte as two hex digits
        .collect()
}

/// Converts a hexadecimal string to a Pearson hash (Vec<u8>).
///
/// Returns an error if the input string is not a valid hexadecimal representation.
///
/// # Arguments
///
/// * `hex_string`: The hexadecimal string.
///
/// # Returns
///
/// * `Result<Vec<u8>, String>`: The Pearson hash as a `Vec<u8>`, or an error message.
fn hex_string_to_pearson_hash(hex_string: &str) -> Result<Vec<u8>, String> {
    debug_log("starting hex_string_to_pearson_hash()");

    if hex_string.len() % 2 != 0 {
        return Err("Invalid hex string: Length must be even".to_string());
    }

    let mut hash = Vec::with_capacity(hex_string.len() / 2);
    for i in (0..hex_string.len()).step_by(2) {
        let hex_byte = &hex_string[i..i + 2];
        match u8::from_str_radix(hex_byte, 16) {
            Ok(byte) => hash.push(byte),
            Err(_) => return Err(format!("Invalid hex string: Invalid byte: {}", hex_byte)),
        }
    }
    debug_log("end of hex_string_to_pearson_hash");
    Ok(hash)
}


// TODO not used?
/// Retrieves the salt list for a collaborator from their TOML configuration file.
///
/// This function reads the collaborator's TOML file located at
/// `project_graph_data/collaborator_files_address_book/{collaborator_name}__collaborator.toml`,
/// parses the TOML data, and extracts the `user_salt_list`.  It handles potential errors during file
/// reading, TOML parsing, and data extraction.
///
/// # Arguments
///
/// * `collaborator_name`: The name of the collaborator.
///
/// # Returns
///
/// * `Result<Vec<u128>, ThisProjectError>`:  A `Result` containing the collaborator's salt list (`Vec<u128>`) on success, or a `ThisProjectError` if any error occurs.
///
/// use with:let remote_collaborator_salt_list = get_saltlist_for_collaborator(NAME)?;
///
fn get_saltlist_for_collaborator(collaborator_name: &str) -> Result<Vec<u128>, ThisProjectError> {
    // 1. Construct File Path (using PathBuf)
    let file_path = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
        .join(format!("{}__collaborator.toml", collaborator_name));

    // 2. Read File (handling potential errors)
    let toml_string = std::fs::read_to_string(&file_path)?;

    // 3. Parse TOML
    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = toml::from_str(&toml_string)?;

    // 4. Extract Salt List (handling missing/invalid data)
    let salt_list_result: Result<Vec<u128>, ThisProjectError> = match toml_value.get("user_salt_list") {
        Some(Value::Array(arr)) => {
            arr.iter()
                .map(|val| { // Iterate each item in the array
                    if let Value::String(hex_string) = val {
                        u128::from_str_radix(hex_string.trim_start_matches("0x"), 16)
                            .map_err(|_| ThisProjectError::InvalidData(format!("Invalid salt format in file for: {}", collaborator_name))) // clearer error message
                    } else {
                        Err(ThisProjectError::InvalidData(format!("Invalid salt format in file for: {}", collaborator_name))) // clearer error message
                    }
                }).collect() // Collect results
        },
        _ => Err(ThisProjectError::InvalidData(format!("Missing or invalid 'user_salt_list' in collaborator file for: {}", collaborator_name))), // Handle missing field or type mismatch
    };
    salt_list_result // Return the salt list Result
}

// TODO useful sometime, if not now
/// Calculates a list of Pearson hashes for a given input string using a provided salt list.
///
/// This function takes an input string, converts it to bytes, and calculates a Pearson hash for the
/// byte representation combined with each salt in the provided salt list. The resulting hashes are
/// returned as a `Vec<u8>`.
///
/// # Arguments
///
/// * `input_string`: The string to hash.
/// * `salt_list`: A slice of `u128` salt values.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`: A `Result` containing the list of calculated Pearson hashes on success,
///   or a `ThisProjectError` if an error occurs during hash calculation.
fn calculate_pearson_hashlist_for_string(
    input_string: &str,
    salt_list: &[u128],
) -> Result<Vec<u8>, ThisProjectError> {
    let input_bytes = input_string.as_bytes();
    let mut hash_list = Vec::new();

    for salt in salt_list {
        let mut salted_data = Vec::new();
        salted_data.extend_from_slice(input_bytes);
        salted_data.extend_from_slice(&salt.to_be_bytes());

        let hash = pearson_hash_base(&salted_data)?;
        hash_list.push(hash);
    }

    Ok(hash_list)
}

/// Verifies the Pearson hashes in a ReadySignal against a provided salt list.
///
/// This function calculates the expected hashes based on the `rt`, `rst`, and `re` fields of the `ReadySignal`
/// and the provided `salt_list`. It then compares the calculated hashes to the `rh` field of the `ReadySignal`.
///
/// # Arguments
///
/// * `ready_signal`: The ReadySignal to verify.
/// * `salt_list`: The list of salts to use for hash calculation.
///
/// # Returns
///
/// * `bool`: `true` if all hashes match, `false` otherwise.
/// Verifies the Pearson hashes in a ReadySignal against a provided salt list.
///
/// This function calculates the expected hashes based on the `rt`, `rst`, and `re` fields of the `ReadySignal`
/// and the provided `salt_list`. It then compares the calculated hashes to the `rh` field of the `ReadySignal`.
///
/// # Arguments
///
/// * `ready_signal`: The ReadySignal to verify.
/// * `salt_list`: The list of salts to use for hash calculation.
///
/// # Returns
///
/// * `bool`: `true` if all hashes match, `false` otherwise.
///
/// In this version of the function, the match expression for the
/// pearson_hash_base call returns false by default in the case
/// of an error. Additionally, the function checks if the index i
/// is within the bounds of the rh field before accessing it. If
/// the index is out-of-bounds, the function returns false.
///
/// By returning false by default in the case of any errors, the
/// function ensures that the caller can easily determine whether
/// the hashes are valid or not.
fn verify_readysignal_hashes(
    ready_signal: &ReadySignal,
    salt_list: &[u128]
) -> bool {
    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(&ready_signal.rt.to_be_bytes());
    data_to_hash.extend_from_slice(&ready_signal.rst.to_be_bytes());
    data_to_hash.extend_from_slice(&ready_signal.b.to_be_bytes());

    for (i, salt) in salt_list.iter().enumerate() {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());
        let calculated_hash = match pearson_hash_base(&salted_data) {
            Ok(hash) => hash,
            Err(e) => {
                debug_log!("verify_readysignal_hashes(), Error calculating Pearson hash: {}", e);
                return false; // Error during hash calculation
            }
        };

        if i >= ready_signal.rh.len() {
            debug_log!("verify_readysignal_hashes(),  Out-of-bounds index error when accessing rh field");
            return false; // Out-of-bounds index error
        }

        // comparing each index to each index: fail-checking step-wise
        if calculated_hash != ready_signal.rh[i] { // Compare with the received hash
            debug_log!(
                "failed in verify_readysignal_hashes(), hash != hash: ready_signal.rh->{:?} != calculated_hash->{:?}, all ready_signal.rh->{:?}",
                ready_signal.rh[i],
                calculated_hash,
                ready_signal.rh,
            );
            return false; // Hash mismatch
        }
    }

    // All hashes match
    true
}

// TODO maybe replace with simpler file-flag system: ~no stub-file no flag
/// Waits until either UMA should halt or synchronization is enabled.
///
/// This function implements a loop that checks two conditions:
/// 1. If UMA should halt (continue_uma.txt contains "0")
/// 2. If synchronization is enabled (ok_to_start_sync_flag.txt contains "1")
///
/// If UMA should halt, the function exits immediately.
/// If synchronization is enabled, the function exits to allow syncing to proceed.
/// Otherwise, it sleeps for the specified duration and checks again.
///
/// # Arguments
///
/// * `wait_this_many_seconds` - Number of seconds to wait between checks
fn sync_flag_ok_or_wait(wait_this_many_seconds: u64) {
    // check for quit
    loop {
        // // 1. Read the 'continue_uma.txt' file
        // let file_content = match fs::read_to_string(CONTINUE_UMA_PATH_STR) {
        //     Ok(content) => content,
        //     Err(_) => {
        //         debug_log("Error reading 'continue_uma.txt'. Continuing..."); // Handle the error (e.g., log it) but continue for now
        //         continue; // Skip to the next loop iteration
        //     }
        // };

        // // 2. break loop if continue=0
        // if file_content.trim() == "0" {
        //     debug_log("'continue_uma.txt' is 0. sync_flag_ok_or_wait Exiting loop.");
        //     break;
        // }

        // Read the 'continue_uma.txt' file and check if we should exit
        if should_halt_uma() {
            debug_log("wlpl 'continue_uma.txt' is 0. we_love_projects_loop() Exiting loop.");
            break;
        }

        // let is_sync_enabled = fs::read_to_string(SYNC_START_OK_FLAG_PATH_STR)
        //     .unwrap_or("0".to_string())
        //     .trim() == "1";

        // if is_sync_enabled {
        //     debug_log("Synchronization flag is '1'. Proceeding...");
        //     break; // Exit the loop
        // } else {
        //     // debug_log("Synchronization flag is '0'. Waiting...");
        //     thread::sleep(Duration::from_secs(wait_this_many_seconds)); // Wait for 3 seconds
        // }


        // Get the absolute path to the sync flag file
        let sync_flag_path = match get_sync_start_ok_flag_path() {
            Ok(path) => path,
            Err(e) => {
                debug_log!("Error resolving path to sync flag from get_sync_start_ok_flag_path(): {}", e);
                // Continue with the default value of "0" (assume syncing is disabled)
                thread::sleep(Duration::from_secs(wait_this_many_seconds));
                continue;
            }
        };

        // debug_log!(
        //     "sync_flag_ok_or_wait(), sync_flag_path -> {:?}",
        //     sync_flag_path,
        //     );

        // Read the sync flag file
        let is_sync_enabled = match fs::read_to_string(&sync_flag_path) {
            Ok(content) => content.trim() == "1",
            Err(e) => {
                debug_log!("Error reading sync flag file: {}", e);
                // Default to disabled (false) if we can't read the file
                false
            }
        };

        if is_sync_enabled {
            debug_log("Synchronization flag is '1'. Proceeding...");
            break; // Exit the loop
        } else {
            debug_log("Synchronization flag is '0'. Waiting...");
            thread::sleep(Duration::from_secs(wait_this_many_seconds)); // Wait for specified seconds
        }
    }
}

/// ### four byte array nearly 30 year timestamp v1
/// ## posix time scale notes
/// ```
/// (u1 to 1; u2 to 2; u4 to 8)
/// 1  1 			= 1 sec
/// 2  10			= 10 sec
/// (u8 to 256)
/// 3  100		= 1.67 min
/// (u16 to 65,536; 256^2)
/// 4  1000		= 16.7 minutes
/// 5  10000		= 2.7 hours
/// (u32 to 16,777,216; 256^3)
/// 6  100000		= 1.157 days / 0.165 weeks
/// 7  1000000 	= 0.381 months / 1.65 Weeks
/// 8  10000000	= 3.81 months / .317 years
/// (u64 to 4,294,967,296; 245^4)
/// 9  100000000	= 3.17 years
/// 10 1000000000	= 31.7 years
/// 11 10000000000	= 317 years
/// 12 100000000000	= 3171 years
/// ```
/// ## Compressed nonce-like timestamp freshness proxy
/// Use a four u8 byte array to get a nearly 31 year nonce timestamp
///
/// You need 8 digits: (skip the seconds digit)
/// ```
/// 10 (10sec) ->  100000000 (3.17 years)
/// +
/// some information about the 10th digit
/// ```
///
/// byte 1:
/// - digit 2 		(in the ones place)
/// - digit 3 		(in the tens place)
/// - fragment-1	(in the hundreds' place), not mod !%2
///
/// byte 2:
/// - digit 4 		(in the ones place)
/// - digit 5 		(in the tens place)
/// - fragment-2	(in the hundreds' place), not mod !%3
///
/// byte 3:
/// - digit 6 		(in the ones place)
/// - digit 7 		(in the tens place)
/// - fragment-3	(in the hundreds' place), not 0 or 4
///
/// byte 4:
/// - digit 8 		(in the ones place)
/// - digit 9 		(in the tens place)
/// - fragment-4	(in the hundreds' place), is prime
///
/// 10th digit fragments:
/// 1. not mod !%2
/// 2. not mod !%3
/// 3. not 0 or 4
/// 4. is prime
///
/// ## One Collision Case
/// The "5" value and "7" value from the compressed 10th-digit(31 year scale) collide, but at least most information from the 10th-digit could be expressed.
/// - The largest u32 number is: 16,777,216
/// - The largest u64 number is: 4,294,967,296 (Feb 7, year:2106)
/// - With the exception of 5 vs 7 in the last place, this system can mostly reflect posix time up to 9,999,999,999, (or Saturday, November 20, year:2286 5:46:39 PM) which is more than u64 can.
///
/// ### Without Bit Manipulation
/// This works without bitwise operations (fun though those are).
/// There are four u8 (unsigned 8-bit) values,
/// each of which can hold (in decimal terms)
/// up to 0-255
/// including 199
/// The hundres's place can safely be 1 or 0 (though it can be 2 also if we know the whole value is less than 255).
///
/// ## future research
/// For specified time ranges a smaller system should be possible.
/// e.g. if only months and not minutes are needed
fn generate_terse_timestamp_freshness_proxy_v4(posix_timestamp: u64) -> [u8; 4] {

    // 1. Extract relevant digits
    let digit_2 = ((posix_timestamp / 10) % 10) as u8;
    let digit_3 = ((posix_timestamp / 100) % 10) as u8;
    let digit_4 = ((posix_timestamp / 1000) % 10) as u8;
    let digit_5 = ((posix_timestamp / 10000) % 10) as u8;
    let digit_6 = ((posix_timestamp / 100000) % 10) as u8;
    let digit_7 = ((posix_timestamp / 1000000) % 10) as u8;
    let digit_8 = ((posix_timestamp / 10000000) % 10) as u8;
    let digit_9 = ((posix_timestamp / 100000000) % 10) as u8;
    let digit_10 = ((posix_timestamp / 1000000000) % 10) as u8;

    // 2. Determine 10th digit fragments
    let fragment_1 = (digit_10 % 2 != 0) as u8;
    let fragment_2 = (digit_10 % 3 != 0) as u8;
    let fragment_3 = (digit_10 != 0 && digit_10 != 4) as u8;
    let fragment_4 = (is_prime(digit_10)) as u8;

    // 3. Pack into u8 array (4 bytes, fragment in hundreds place)
    //let packed_timestamp = [
    //    (fragment_1 * 100) + (digit_2 * 10) + digit_3,
    //    (fragment_2 * 100) + (digit_4 * 10) + digit_5,
    //    (fragment_3 * 100) + (digit_6 * 10) + digit_7,
    //    (fragment_4 * 100) + (digit_8 * 10) + digit_9,
    //];

    // For readability, left to right
    let packed_timestamp = [
        (fragment_1 * 100) + (digit_9 * 10) + digit_8,
        (fragment_2 * 100) + (digit_7 * 10) + digit_6,
        (fragment_3 * 100) + (digit_5 * 10) + digit_4,
        (fragment_4 * 100) + (digit_3 * 10) + digit_2,
    ];

    packed_timestamp
}

fn is_prime(n: u8) -> bool {
    match n {
        2 | 3 | 5 | 7 => true,
        _ => false,
    }
}

/// Sends a byte slice over UDP to the specified address and port.
///
/// # Arguments
///
/// * `data`: The byte slice to send.
/// * `target_addr`: The target IP address.
/// * `port`: The target port.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`:  `Ok(())` if sending was successful, or a `ThisProjectError` if an error occurred.
fn send_data_via_udp(data: &[u8], target_addr: SocketAddr, port: u16) -> Result<(), ThisProjectError> {
    let socket = UdpSocket::bind(":::0")?; // Bind to any available port
    socket.send_to(data, SocketAddr::new(target_addr.ip(), port))?;
    debug_log!("Data sent to {}:{}", target_addr.ip(), port);
    Ok(())
}

/// Sends a `SendFile` struct to a remote collaborator's intray.
/// Now this function *only* handles sending; serialization is done elsewhere.
///
/// # Arguments
///
/// * `send_file`: The `SendFile` struct to send.
/// * `target_addr`: The target IP address.
/// * `port`: The target port.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` if the file was sent successfully, `Err(ThisProjectError)` otherwise.
fn sendfile_UDP_to_intray(
    send_file: &SendFile,
    target_addr: SocketAddr,
    port: u16,
) -> Result<(), ThisProjectError> {
    // 1. Serialize the SendFile struct.
    let serialized_data = serialize_send_file(send_file)?;

    // 2. Send the serialized data using UDP.
    send_data_via_udp(&serialized_data, target_addr, port)?;

    Ok(())
}

/// Struct for sending file to in-tray (file sync)
/// Salted-Pearson-Hash-List system for quick verification that packet is intact and sent by owner at timestamp
#[derive(Serialize, Deserialize, Debug)] // Add Serialize/Deserialize for sending/receiving
struct SendFile {
    intray_send_time: Option<u64>, // send-time: generate_terse_timestamp_freshness_proxy(); for replay-attack protection
    gpg_encrypted_intray_file: Option<Vec<u8>>, // Holds the GPG-encrypted file contents
    intray_hash_list: Option<Vec<u8>>, // N hashes of intray_this_send_timestamp + gpg_encrypted_intray_file
}

/// ReadySignal struct
/// - Contents are 'Option<T>' so that assembly and inspection can occur in steps.
/// - Terse names to reduce network traffic, as an exceptional circumstance
/// - Ready-signals are the most commonly sent and most disposable
#[derive(Serialize, Deserialize, Debug)] // Add Serialize/Deserialize for sending/receiving
struct ReadySignal {
    rt: u64, // ready signal timestamp: last file obtained timestamp
    rst: u64, // send-time: generate_terse_timestamp_freshness_proxy(); for replay-attack protection
    b: u8, // Network Index (e.g. which ipv6 in the list)
    rh: Vec<u8>, // N hashes of rt + re
}

/// Serializes a ReadySignal into a byte vector
/// Does NOT use serde.
fn serialize_ready_signal(ready_signal: &ReadySignal) -> Result<Vec<u8>, ThisProjectError> {
    let mut bytes = Vec::new();

    // Add timestamps (rt and rst)
    bytes.extend_from_slice(&ready_signal.rt.to_be_bytes());
    bytes.extend_from_slice(&ready_signal.rst.to_be_bytes());

    // Add Network band byte as u8 bytes
    bytes.extend_from_slice(&ready_signal.b.to_be_bytes());

    // Add hash list
    bytes.extend_from_slice(&ready_signal.rh);

    Ok(bytes)
}

// TODO max size check?
/// Calculates Pearson hashes for a ReadySignal's fields. Hashes `rt`, `rst`, `nt`, `ni`, and salts.
///
/// Args:
///     rt: The `rt` timestamp.
///     rst: The `rst` timestamp.
///     nt: The network type string.
///     ni: The network index.
///     local_user_salt_list: The list of salts for hashing.
///
/// Returns:
///     Result<Vec<u8>, ThisProjectError>: The calculated hash list, or an error if hashing fails.
fn calculate_ready_signal_hashes(
    rt: u64,
    rst: u64,
    band: u8,
    local_user_salt_list: &[u128],
) -> Result<Vec<u8>, ThisProjectError> {
    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(&rt.to_be_bytes());
    data_to_hash.extend_from_slice(&rst.to_be_bytes());
    data_to_hash.extend_from_slice(&band.to_be_bytes());

    let mut ready_signal_hash_list: Vec<u8> = Vec::new();
    for salt in local_user_salt_list {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());

        match pearson_hash_base(&salted_data) {
            Ok(hash) => ready_signal_hash_list.push(hash),
            Err(e) => return Err(ThisProjectError::IoError(e)), // Directly return the error
        }
    }

    Ok(ready_signal_hash_list)
}

// Define enums for each field you want to validate
#[derive(Debug, PartialEq)]
enum Timestamp {
    Valid(u64),
    Invalid,
}

#[derive(Debug, PartialEq)]
enum DocumentId {
    Valid(u64),
    Invalid,
}

// Proto struct with Option<T> for initial deserialization
#[derive(Debug)]
struct PrototGotitSignal {
    gst: Option<Timestamp>,
    di: Option<DocumentId>,
    gh: Option<Vec<u8>>,
}

/// GotItSignal struct
/// Terse names to reduce network traffic, as an esceptional circumstatnce
/// Probably does not need a nonce because repeat does nothing...
///
/// Final struct with validated data
/// use proto-struct PrototGotitSignal for loading possibly corrupted data
#[derive(Debug)]
struct GotItSignal {
    gst: u64,
    di: u64,
    gh: Vec<u8>,
}

// Converts a byte slice to a u64, handling potential errors.
fn bytes_to_u64(bytes: &[u8]) -> Result<u64, Error> {
    if bytes.len() != 8 {
        return Err(Error::new(ErrorKind::InvalidData, "Invalid byte length for u64"));
    }
    Ok(u64::from_be_bytes(bytes.try_into().unwrap()))
}

/// Calculates Pearson hash list for a GotItSignal.
/// Hashes the `gst` (send time), `di` (document ID/received timestamp), and salts.
///
/// # Arguments
///
/// * `gst`: The `gst` timestamp.
/// * `di`: The `di` timestamp (received file's timestamp).
/// * `local_user_salt_list`:  The list of salts for hashing.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`: The calculated hash list or an error.
fn calculate_gotitsignal_hashlist(
    timestamp_for_gst: u64,
    timestamp_for_di: u64,
    local_user_salt_list: &[u128],
) -> Result<Vec<u8>, ThisProjectError> {

    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(&timestamp_for_gst.to_be_bytes());
    data_to_hash.extend_from_slice(&timestamp_for_di.to_be_bytes());

    debug_log!(
        "calculate_gotitsignal_hashlist(): Data to hash: {:?}",
        &data_to_hash
    );

    let mut gotit_signal_hash_list: Vec<u8> = Vec::new();
    for salt in local_user_salt_list {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());

        match pearson_hash_base(&salted_data) {
            Ok(hash) => gotit_signal_hash_list.push(hash),
            Err(e) => {
                return Err(ThisProjectError::IoError(e));  // Return the error
            }
        }
    }
    debug_log!(
        "calculate_gotitsignal_hashlist(): Calculated Hashes: {:?}",
        &gotit_signal_hash_list
    );

    Ok(gotit_signal_hash_list)
}


/// Deserializes a byte slice into a `PrototGotitSignal`, manually handling the byte extraction.
///
/// Arguments:
///     bytes: The byte slice containing the serialized data.
///
/// Returns:
///     Result<PrototGotitSignal, Error>: A `Result` containing the `PrototGotitSignal` on success, or an `Error` if deserialization fails.
fn deserialize_proto_gotit_signal(bytes: &[u8]) -> Result<PrototGotitSignal, Error> {

    // Calculate expected lengths (assuming a u64 for both timestamp and ID)
    let timestamp_len = std::mem::size_of::<u64>();
    let id_len = std::mem::size_of::<u64>();
    let expected_min_length = timestamp_len + id_len; // Minimum length for timestamp and ID

    // Check if the byte array has enough data for at least the timestamp and document ID
    if bytes.len() < expected_min_length {
        return Err(Error::new(
            ErrorKind::InvalidData,
            "Invalid byte array length for PrototGotitSignal: too short",
        ));
    }

    // Extract timestamp
    let gst_bytes = &bytes[0..timestamp_len];
    let gst = match bytes_to_u64(gst_bytes) {
        Ok(ts) => Some(Timestamp::Valid(ts)),
        Err(_) => Some(Timestamp::Invalid),  // Or handle differently
    };

    // Extract document ID
    let di_bytes = &bytes[timestamp_len..expected_min_length];
    let di = match bytes_to_u64(di_bytes) {
        Ok(id) => Some(DocumentId::Valid(id)),
        Err(_) => Some(DocumentId::Invalid),
    };

    // Extract hash list (if any)
    let gh = if bytes.len() > expected_min_length {
        Some(bytes[expected_min_length..].to_vec())
    } else {
        None
    };

    Ok(PrototGotitSignal { gst, di, gh })
}


fn validate_and_convert_gotit_signal(proto_signal: PrototGotitSignal) -> Result<GotItSignal, String> {
    let gst = match proto_signal.gst {
        Some(Timestamp::Valid(ts)) => ts,
        _ => return Err("Invalid or missing gst".into()),
    };

    let di = match proto_signal.di {
        Some(DocumentId::Valid(id)) => id,
        _ => return Err("Invalid or missing di".into()),
    };

    // Default to an empty vector if the hash list is missing
    let gh = proto_signal.gh.unwrap_or_default();

    Ok(GotItSignal { gst, di, gh })
}

fn process_incoming_gotit_signal_bytes(bytes: &[u8]) -> Result<GotItSignal, String> {
    let proto_signal = deserialize_proto_gotit_signal(bytes)
        .map_err(|e| format!("Deserialization failed: {}", e))?; // Handle deserialization error

    validate_and_convert_gotit_signal(proto_signal)
}


#[derive(Debug, Clone)] // Add other necessary derives later
struct SendQueue {
    back_of_queue_timestamp: u64,
    // echo_send: bool, //
    items: Vec<PathBuf>,  // ordered list, filepaths
}
impl SendQueue {
    /// Adds a `PathBuf` to the *front* of the `items` vector in the `SendQueue`.
    ///
    /// # Arguments
    ///
    /// * `path`: The `PathBuf` to add to the queue.
    fn add_to_front_of_sendq(&mut self, path: PathBuf) {
        self.items.insert(0, path);
    }
}

/// unpack new node
/// saves new node.toml file, ensuring path and feature directories
/// Unpacks and saves a new node from received data.
///
/// This function takes the raw bytes of a clearsigned and decrypted `node.toml` file
/// and saves it to the specified path. It also creates the standard UMA node
/// subdirectories: "message_posts_browser" and "task_browser".
///
/// This function is used during file synchronization to create or update nodes
/// on the local file system based on data received from a remote collaborator.
/// It assumes the `extracted_clearsigned_file_data` contains valid TOML data
/// for a `CoreNode` struct.
///
/// # Arguments
///
/// * `extracted_clearsigned_file_data`: The raw bytes of the decrypted and
///   clearsigned `node.toml` file.
/// * `new_full_abs_node_directory_path`: The *full absolute path* to the
///   directory where the node should be saved. This path should *include* the
///   node directory name itself (e.g.,
///   `"project_graph_data/team_channels/my_team/my_node"`).
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on success, or a
///   `ThisProjectError` if an error occurs during file or directory creation.
///
/// # Example
///
/// ```
/// // ... (assuming you have extracted_clearsigned_file_data and new_full_abs_node_directory_path)
///
/// match unpack_new_node_save_toml_and_create_dir(&extracted_clearsigned_file_data, &new_full_abs_node_directory_path) {
///     Ok(_) => println!("Node unpacked and saved successfully."),
///     Err(e) => eprintln!("Error unpacking node: {}", e),
/// }
/// ```
fn unpack_new_node_save_toml_and_create_dir(
    extracted_clearsigned_file_data: &Vec<u8>,
    new_full_abs_node_directory_path: &Path,
) -> Result<(), ThisProjectError> {

    // 1. Make full file path
    let new_node_toml_file_path = new_full_abs_node_directory_path.join("node.toml"); // Path to the new node.toml

    // 2. Create directory if it doesn't exist
    fs::create_dir_all(new_full_abs_node_directory_path)?;

    // 3. write file from GPG clearsign extracted data as node.toml
    if let Err(e) = fs::write(
        &new_node_toml_file_path,
        &extracted_clearsigned_file_data
    ) {
        debug_log!("HLOD-InTray: Unpack Node: Failed to write message file: {:?}", e);
        // Consider returning an error here instead of continuing the loop
        return Err(ThisProjectError::from(e));
    }

    // 4. Add IM-Browser directory
    let im_browser_path = new_full_abs_node_directory_path.join("message_posts_browser");  // Construct path correctly
    create_dir_all(&im_browser_path)?;

    // 5. Add Task-Browser directory
    let task_browser_path = new_full_abs_node_directory_path.join("task_browser");  // Construct path correctly
    create_dir_all(&task_browser_path)?;

    Ok(())
}

// /// unpack new node
// /// saves new node.toml file, ensuring path and IM directory
// fn unpack_new_node_save_toml_and_create_dir(
//     toml_string: &str,
//     path: &Path,
//     dir_name: &str,  // Now this is the general name
// ) -> Result<(), std::io::Error> {
//     // 1. Create parent directories.
//     create_dir_all(path)?;

//     // 2. Create and write to node.toml.
//     let toml_path = path.join("node.toml");
//     let mut toml_file = File::create(&toml_path)?;
//     toml_file.write_all(toml_string.as_bytes())?;

//     // 3. Create associated directory.  (This is the only change)
//     let dir_path = path.join(dir_name); // No longer specifically "message_posts_browser"
//     create_dir_all(&dir_path)?;


//     // Add this to create "message_posts_browser/" next to node.toml:
//     let im_browser_path = path.join("message_posts_browser");
//     create_dir_all(&im_browser_path)?;

//     Ok(())
// }

/// Retrieves the paths of all send queue update flags for a given collaborator in a team channel.
///
/// This function reads the contents of the directory `sync_data/{team_channel_name}/sendqueue_updates/{collaborator_name}`
/// and returns a vector of `PathBuf` representing the paths to the update flag files.  It also deletes the flag files
/// after reading their contents, ensuring that flags are processed only once.
///
/// Note: each potential participant must have a separate flag.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `collaborator_name`: The name of the collaborator.
///
/// # Returns
///
/// * `Result<Vec<PathBuf>, ThisProjectError>`:  A vector of paths to update flag files on success, or a `ThisProjectError` if an error occurs.
fn get_sendq_update_flag_paths(
    team_channel_name: &str,
    collaborator_name: &str,
) -> Result<Vec<PathBuf>, ThisProjectError> {
    // 1. Construct Directory Path (using PathBuf)
    let mut queue_dir = PathBuf::from("sync_data");
    queue_dir.push(team_channel_name);
    queue_dir.push("sendqueue_updates");
    queue_dir.push(collaborator_name);

    let mut path_list: Vec<PathBuf> = Vec::new(); // Initialize path_list

    // 2. Read Directory and Collect Paths
    match read_dir(&queue_dir) {
        Ok(entries) => {
            for entry_result in entries {
                match entry_result {
                    Ok(entry) => {
                        let path = entry.path();
                        if path.is_file() {
                            // Read the file path from the queue file and delete.
                            let queue_file_path_str = match std::fs::read_to_string(&path) {
                                Ok(s) => s,
                                Err(e) => {
                                    debug_log!("Error reading queue file: {}", e);
                                    // Handle error appropriately, e.g., continue to the next file or return an error
                                    continue; // Skip this file and continue
                                }
                            };
                            let queue_file_path = PathBuf::from(queue_file_path_str);

                            debug_log!("HRCD: Removing update flag file: {:?}", path);
                            if let Err(e) = remove_file(&path) {
                                debug_log!("Error removing update flag file: {:?} - {}", path, e);
                                // Continue processing other files even if removal fails.
                                continue; // or choose to handle error
                            }

                            // Add the file path from *inside* the queue file to the path_list
                            path_list.push(queue_file_path);

                        }
                    },
                    Err(e) => {
                        debug_log!("Error reading directory entry: {}", e);
                        // Handle error as you see fit
                        return Err(ThisProjectError::IoError(e));
                    }
                }
            }
        }
        Err(e) if e.kind() == std::io::ErrorKind::NotFound => {
            // No queue files, return empty list
            debug_log!("get_sendq_update_flag_paths(): Send queue directory not found. Returning empty list.");
            return Ok(Vec::new());
        }
        Err(e) => return Err(ThisProjectError::IoError(e)),
    };


    Ok(path_list)
}

/// Converts a vector of u8 hash values into a hexadecimal string representation.
///
/// This function takes a slice of `u8` values (typically a hash) and converts it into a hexadecimal string,
/// with each byte represented by two hexadecimal characters.  The resulting string is suitable for use as a filename or identifier.
///
/// # Arguments
///
/// * `hash_array`: A slice of `u8` values representing the hash.
///
/// # Returns
///
/// * `String`: The hexadecimal string representation of the hash.
///
/// # Example
///
/// ```
/// let hash_array = [0x12, 0x34, 0x56, 0x78, 0x9a, 0xbc, 0xde, 0xf0];
/// let hex_string = hash_array_to_hex_string(&hash_array);
/// assert_eq!(hex_string, "123456789abcdef0");
/// ```
/// TODO Does this need error handling?
fn docid__hash_array_to_hex_string(hash_array: &[u8]) -> String {
    hash_array
        .iter()
        .map(|&h| format!("{:02x}", h))
        .collect::<String>()
}

/// Parses a hexadecimal string into a vector of bytes.
///
/// This function takes a hexadecimal string as input and converts it into a `Vec<u8>`.
/// It handles both uppercase and lowercase hexadecimal characters and returns an error
/// if the input string contains invalid characters or has an odd length.
///
/// # Arguments
///
/// * `hex_string`: The hexadecimal string to parse.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`: A `Result` containing the vector of bytes on success,
///   or a `ThisProjectError` if parsing fails.
fn hex_string_to_bytes(hex_string: &str) -> Result<Vec<u8>, ThisProjectError> {
    // Check for valid length (must be even)
    if hex_string.len() % 2 != 0 {
        return Err(ThisProjectError::InvalidData(
            "Invalid hex string: Odd length".into(),
        ));
    }

    let mut bytes = Vec::with_capacity(hex_string.len() / 2);
    for i in (0..hex_string.len()).step_by(2) {
        let byte_str = &hex_string[i..i + 2];
        let byte = u8::from_str_radix(byte_str, 16).map_err(|_| {
            ThisProjectError::InvalidData("Invalid hex string: Invalid characters".into())
        })?;
        bytes.push(byte);
    }
    Ok(bytes)
}

/// Gets a list of active collaborators by reading stub file names in the sync_data directory.
///
/// This function reads the names of files (which are the collaborator names)
/// within the directory:  `sync_data/{team_channel_name}/is_active/`. Each file represents an active collaborator.
/// The function handles directory reading errors and filters out entries that are not files.
///
/// # Arguments
///
/// * None
///
/// # Returns
///
/// * `Result<Vec<String>, ThisProjectError>`:  A `Result` containing a vector of active collaborator names (`Vec<String>`) on success,
///   or a `ThisProjectError` if an error occurs (e.g., during directory reading).
fn get_active_collaborator_names() -> Result<Vec<String>, ThisProjectError> {
    // 1. Get the team channel name
    let team_channel_name = match get_current_team_channel_name_from_nav_path() {
        Some(name) => name,
        None => {
            debug_log!("Error: Could not get current channel name in get_active_collaborator_names. Skipping.");
            return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
        },
    };

    // 2. Construct Path to "is_active" directory
    let is_active_dir = Path::new("sync_data")
        .join(&team_channel_name)
        .join("is_active");

    // 3. Create Vector to Hold Names
    let mut active_collaborators: Vec<String> = Vec::new(); // Initialize an empty vector

    // 4. Read Directory and Collect Names
    match read_dir(&is_active_dir) { // returns Result<ReadDir> so we match on it
        Ok(entries) => {
            // Handle potential errors inside the loop, so not all are lost in case of one error.
            for entry in entries {
                // Handle DirEntry Result
                match entry {
                    Ok(entry) => {
                        // Is it a file?
                        if entry.path().is_file() {
                            // Extract file_name as String
                            let file_name = entry.file_name(); // returns OsString which cannot be string-matched
                            let collaborator_name = file_name.to_string_lossy().into_owned();  // so convert to owned String
                            active_collaborators.push(collaborator_name);
                        }
                    },
                    Err(err) => {
                        debug_log!("Error reading entry: {}", err);
                        // Handle error appropriately.
                        // You might choose to skip the bad entry, log and return an error, or continue
                        // return Err(...); // Example, if you want to stop on first error
                    },
                }
            }
            Ok(active_collaborators) // Return vector of names on success
        }
        Err(err) => Err(ThisProjectError::IoError(err)), // Return error if directory read fails
    }
}

// /// Saves data to a file with a filename derived from a hash array.
// ///
// /// This function saves a stub file (named file with no contents) within the specified `directory`.  The filename
// /// is generated by converting the `hash_array` into a hexadecimal string using `hash_array_to_hex_string()`.
// /// if content data are needed that can be added later, but perahps nothing is needed
// ///
// /// # Arguments
// ///
// /// * `hash_array`: A slice of `u8` values used to generate the filename.
// /// * `remote_collarator_name`
// ///
// /// # Returns
// ///
// /// * `Result<(), ThisProjectError>`: `Ok(())` if the file is successfully saved,
// ///   or a `ThisProjectError` if an error occurs (e.g., during file creation or writing).
// ///
// /// # Example
// ///


fn hash_sendfile_struct_fields(
    salt_list: &[u128],
    intray_send_time: u64,
    gpg_encrypted_intray_file: &[u8], // Use a slice for efficiency
) -> Result<Vec<u8>, ThisProjectError> {
    let mut calculated_hashes = Vec::with_capacity(salt_list.len());
    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(&intray_send_time.to_be_bytes());
    data_to_hash.extend_from_slice(gpg_encrypted_intray_file);
    for salt in salt_list {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());
        match pearson_hash_base(&salted_data) {
            Ok(hash) => calculated_hashes.push(hash),
            Err(e) => {
                debug_log!("hash_sendfile_struct_fields(): Error calculating Pearson hash: {}", e);
                return Err(ThisProjectError::IoError(e));
            }
        }
    }
    Ok(calculated_hashes)
}

fn hash_checker_for_sendfile_struct(
    salt_list: &[u128],
    intray_send_time: u64,
    gpg_encrypted_intray_file: &[u8], // Use a slice
    compare_to_this_hashvec: &[u8], // Use a slice
) -> bool {
    // 1. Fail by default
    let mut all_hashes_match = false; // Initialize to false (Fail by default)

    debug_log!("HCFSS hash_checker_for_sendfile_struct(): Starting verification...");

    // 2. Calculate expected hashes
    let calculated_hashes_result = hash_sendfile_struct_fields(salt_list, intray_send_time, gpg_encrypted_intray_file);

    match calculated_hashes_result {
        Ok(calculated_hashes) => {
            // 3. Length Check
            if calculated_hashes.len() != compare_to_this_hashvec.len() {
                debug_log!("HCFSS hash_checker_for_sendfile_struct(): Hash list length mismatch. Expected: {}, Received: {}", calculated_hashes.len(), compare_to_this_hashvec.len());
            } else {
                // 4. Compare hashes one by one
                all_hashes_match = true; // Assume they match initially
                for (i, &calculated_hash) in calculated_hashes.iter().enumerate() {
                    if calculated_hash != compare_to_this_hashvec[i] {
                        debug_log!("HCFSS hash_checker_for_sendfile_struct(): Hash mismatch at index {}. Expected: {:02x}, Received: {:02x}", i, calculated_hash, compare_to_this_hashvec[i]);
                        all_hashes_match = false;
                        break;
                    }
                }
                if all_hashes_match {
                    debug_log!("HCFSS hash_checker_for_sendfile_struct(): All hashes match.");
                }
            }
        },
        Err(e) => {
             debug_log!("HCFSS error hash_checker_for_sendfile_struct():  Error calculating hashes: {:?}. Returning false.", e);
        },
    }
    debug_log!("HCFSS hash_checker_for_sendfile_struct(): Verification completed. Result: {}", all_hashes_match);

    all_hashes_match
}

/// Extracts the `updated_at_timestamp` field from a TOML file.
///
/// This function reads the TOML file at the specified path, parses it, and extracts the
/// `updated_at_timestamp` field.  It handles potential errors during file reading, TOML
/// parsing, and missing or invalid timestamp fields.
///
/// # Arguments
///
/// * `file_path`: The path to the TOML file.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`: The `updated_at_timestamp` value on success, or a
///   `ThisProjectError` if an error occurs.
fn get_updated_at_timestamp_from_toml_file(file_path: &Path) -> Result<u64, ThisProjectError> {
    // 1. Read the TOML file: Handle file read errors
    let toml_string = match std::fs::read_to_string(file_path) {
        Ok(content) => content,
        Err(e) => {
            debug_log!("Error reading TOML file {:?}: {}", file_path, e);
            return Err(ThisProjectError::from(e));
        }
    };
    debug_log!("Read TOML file: {:?}", file_path);


    // 2. Parse the TOML string: Handle TOML parsing errors
    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = match toml::from_str(&toml_string) {
        Ok(value) => value,
        Err(e) => {
            debug_log!("Error parsing TOML string: {}", e);
            return Err(ThisProjectError::from(e)); // Or handle error differently
        }
    };
    debug_log!("Parsed TOML value.");

    // 3. Extract updated_at_timestamp:  Handle missing/invalid timestamp
    let updated_at_timestamp = match toml_value.get("updated_at_timestamp") {
        Some(Value::Integer(ts)) => *ts as u64, // Convert to u64, handle overflow
        Some(_) => {
            debug_log!("'updated_at_timestamp' has invalid type");
            return Err(ThisProjectError::InvalidData(
                "'updated_at_timestamp' has invalid type".into(),
            ));
        }
        None => {
            debug_log!("'updated_at_timestamp' field not found in TOML file");
            return Err(ThisProjectError::InvalidData(
                "'updated_at_timestamp' field not found in TOML file".into(),
            ));
        }
    };
    debug_log!("Extracted timestamp: {}", updated_at_timestamp);

    Ok(updated_at_timestamp) // Return the timestamp if successful
}

/// Retrieves the .rt timestamp from the oldest pre-fail flag file.
///
/// Iterates through the `fail_retry_flags` directory, finds the oldest file (based on filename, which is the `updated_at` timestamp),
/// reads the `.rt` timestamp (the file content) from that oldest file, and returns it.
/// Deletes all flag files after reading the oldest timestamp, ensuring flags are processed only once.
/// Returns 0 if no flags are found or if an error occurs during file operations.
///
/// Directory structure: `sync_data/{team_channel_name}/fail_retry_flags/{remote_collaborator_name}/{file_updated_at_timestamp}`
///
/// # Arguments
///
/// * `remote_collaborator_name`: The name of the remote collaborator.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`: The `.rt` timestamp from the oldest flag file (or 0) on success, or a `ThisProjectError`.
fn get_oldest_sendfile_prefailflag_rt_timestamp_or_0_w_cleanup(
    remote_collaborator_name: &str,
) -> Result<u64, ThisProjectError> {
    // #[cfg(debug_assertions)]
    debug_log("GOSPrtT: get_oldest prefail: starting get_oldest_sendfile_prefailflag_rt_timestamp_or_0_w_cleanup()");

    let mut oldest_timestamp = 0u64;
    let mut oldest_file_path: Option<PathBuf> = None; // Store path to the oldest file

    // #[cfg(debug_assertions)]
    debug_log("GOSPrtT: calling get_current_team_channel_name_from_nav_path...");

    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("get_oldest prefail... Unable to get team channel name".into()))?;

    let prefail_directory = PathBuf::from("sync_data")
        .join(&team_channel_name)
        .join("fail_retry_flags")
        .join(remote_collaborator_name);

    if !prefail_directory.exists() {

        // #[cfg(debug_assertions)]
        debug_log!(
            "GOSPrtT: get_oldest...: Directory {:?} not found. Returning 0.",
            prefail_directory
        );
        return Ok(0);
    }

    // 1. Find the oldest file:
    for entry in fs::read_dir(&prefail_directory)? {
        let entry = entry?;
        let path = entry.path();

        // #[cfg(debug_assertions)]
        debug_log!(
            "GOSPrtT: get_oldest prefail... path -> {:?}",
            path
        );

        if path.is_file() {
            let file_name = path.file_name().and_then(|n| n.to_str()).ok_or(ThisProjectError::InvalidData("GOSPrtT error: Invalid flag file name".into()))?;
            let file_updated_at: u64 = file_name.parse().map_err(|_| ThisProjectError::InvalidData("GOSPrtT error: Invalid timestamp in flag file name".into()))?;

            if oldest_file_path.is_none() || file_updated_at < oldest_timestamp {
                oldest_timestamp = file_updated_at;
                oldest_file_path = Some(path.clone()); //Store the path
            }
        }
    }

    // 2. Read .rt timestamp from the oldest file (if found):
    if let Some(path) = oldest_file_path {
        match fs::read_to_string(&path) { // Read content (rt timestamp)
            Ok(content) => {
                oldest_timestamp = content.trim().parse().map_err(|_| ThisProjectError::InvalidData("Invalid .rt timestamp in flag file".into()))?;

                // #[cfg(debug_assertions)]
                debug_log!("GOSPrtT: get_oldest prefail: Oldest .rt timestamp found: {}", oldest_timestamp);
            },
            Err(e) => {
                // #[cfg(debug_assertions)]
                debug_log!("GOSPrtT error: get_oldest prefail: Error reading .rt timestamp from file {:?}: {}", path, e);
                return Err(ThisProjectError::from(e));
            }
        }
        // 3. Delete oldest flag
        // TODO alpha version: remove only oldest flag
        match fs::read_to_string(&path) { // Read content (rt timestamp)
            Ok(pathtemp) => {
                if let Err(e) = fs::remove_file(pathtemp) { // Use &path
                    // #[cfg(debug_assertions)]
                    debug_log!(
                        "GOSPrtT error: get_oldest prefail: Error removing oldest_file_path flag file {:?}: {}",
                        path,
                        e);
                    return Err(ThisProjectError::from(e)); // Or handle error as needed
                }
            },
            Err(e) => {
                // #[cfg(debug_assertions)]
                debug_log!("GOSPrtT error: get_oldest prefail: Error in remove_file {:?}: {}", path, e);
                return Err(ThisProjectError::from(e));
            }
        }

        // for entry in fs::read_dir(&prefail_directory)? {
        //     let entry = entry?;
        //     let path = entry.path();
        //     if path.is_file() {
        //         if let Err(e) = fs::remove_file(&path) { // Use &path
        //             debug_log!("get_oldest prefail: Error removing flag file {:?}: {}", path, e);
        //             return Err(ThisProjectError::from(e)); // Or handle error as needed
        //         }
        //     }

    }

    Ok(oldest_timestamp)
}


/// Sets a "pre-fail" flag file.  The filename is the file's `updated_at` timestamp.
/// The file content is the ReadySignal's `.rt` timestamp.
///
/// Directory structure: `sync_data/{team_channel_name}/fail_retry_flags/{remote_collaborator_name}/{file_updated_at_timestamp}`.
///
/// # Arguments
///
/// * `file_updated_at_time`: The file's `updated_at_timestamp`.
/// * `rt_timestamp`: The `.rt` timestamp from the ReadySignal.
/// * `remote_collaborator_name`: Remote collaborator's name.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on success, or a `ThisProjectError`.
fn set_prefail_flag_rt_timestamp__for_sendfile(
    file_updated_at_time: u64,
    mut rt_timestamp: u64,
    remote_collaborator_name: &str,
) -> Result<(), ThisProjectError> {

    /*
    edge case: if there are no files, the timestamp will be zero
    if the rt_timestamp is zero: set the flag for 1 (not zero)
    zero-return means there are no flags
    */
    if rt_timestamp == 0 {
        rt_timestamp = 1;
    }

    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

    let mut flag_file_path = PathBuf::from("sync_data")
        .join(&team_channel_name)
        .join("fail_retry_flags")
        .join(remote_collaborator_name)
        .join(file_updated_at_time.to_string());  // Filename is the file's updated_at timestamp

    // Create directory structure if it doesn't exist
    if let Some(parent) = flag_file_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Write the .rt timestamp to the file
    fs::write(flag_file_path, rt_timestamp.to_string())?;

    debug_log!(
        "Set pre-fail flag for file updated at {} with ReadySignal timestamp {}.",
        file_updated_at_time, rt_timestamp
    );
    Ok(())
}

/// Removes all pre-fail flag files for a remote collaborator.
///
/// This function removes all files within the fail_retry_flags directory for the
/// given team channel and remote collaborator. The directory structure is as
/// follows:  `sync_data/{team_channel_name}/fail_retry_flags/{remote_collaborator_name}/`.
///
/// # Arguments
///
/// * `remote_collaborator_name`: The name of the remote collaborator.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` if all files were removed
///   successfully (or if the directory doesn't exist), or a
///   `ThisProjectError` if an error occurs during directory access or file
///   removal.
fn remove_prefail_flags__for_sendfile(
    remote_collaborator_name: &str,
) -> Result<(), ThisProjectError> {
    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

    let directory = PathBuf::from("sync_data")
        .join(&team_channel_name)
        .join("fail_retry_flags")
        .join(remote_collaborator_name);

    if !directory.exists() { // Check for existance
        return Ok(()); // Or log a message: debug_log!("Directory not found: {:?}", directory);
    }

    for entry in fs::read_dir(&directory)? {  // Iterate through directory contents
        let entry = entry?;
        let path = entry.path();
        if path.is_file() { // Only remove files
            match fs::remove_file(&path) { // Use remove_file, not remove_dir_all
                Ok(_) => debug_log!("Removed flag file: {:?}", path),
                Err(e) => {
                    debug_log!("Error removing flag file: {:?} - {}", path, e);
                    // Either continue or return the error if you want to stop on the first error.
                    return Err(ThisProjectError::IoError(e));
                }
            }
        }
    }
    Ok(())
}


/// Gets the latest received file timestamp for a collaborator in a team channel, using a plain text file.
///
/// This function reads the timestamp from a plain text file at:
/// `sync_data/{team_channel_name}/latest_receivedfile_timestamps/{collaborator_name}/latest_receivedfromme_file_timestamp.txt`
/// If the file or directory structure doesn't exist, it creates them and initializes the timestamp to 0.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `collaborator_name`: The name of the collaborator.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`:  The latest received timestamp on success, or a `ThisProjectError` if an error occurs.
///
/// This is one of those values and functions that can be confusing
/// because both you and your remote collaborator have quasi-mirror-image sync systems
/// with reversed roles. Both of you are making 'latest_received' timestamps
/// and both of you are using your and their 'latest_received' timestamps,
/// which are simultanously 'the same' abstract value but very different local-context-role-specific values
///
/// the complimentary function is: get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl()
///
/// example location of use:
/// Drone Loop to Send ReadySignals  (hlod)
/// 1.2 Refresh Timestamp
fn read_latestreceivedfromme_file_timestamp_plaintextstatefile(
    collaborator_name: &str,
    team_channel_name: &str,
) -> Result<u64, ThisProjectError> {
    /*
    Wait random time in A to B range, N times
    FILE_READWRITE_N_RETRIES
    FILE_READWRITE_RETRY_SEC_PAUSE_MIN
    FILE_READWRITE_RETRY_SEC_PAUSE_max
    */

    let mut file_path = PathBuf::from("sync_data");
    file_path.push(team_channel_name);
    file_path.push("latest_receivedfile_timestamps");
    file_path.push(collaborator_name);
    file_path.push("latest_receivedfromme_file_timestamp.txt");

    // Create directory structure if it doesn't exist
    if let Some(parent) = file_path.parent() {
        create_dir_all(parent)?;
    }

    // Read or initialize the timestamp
    match read_to_string(&file_path) {
        Ok(timestamp_str) => {
            // if let Ok(timestamp) = timestamp_str.trim().parse() {
            // Parse with error handling
            match timestamp_str.trim().parse::<u64>() {
                Ok(timestamp) => Ok(timestamp),
                Err(e) => {
                    debug_log!("Error parsing timestamp from file: {}", e);
                    Err(ThisProjectError::from(e))
                }
            }
        },
        Err(e) if e.kind() == ErrorKind::NotFound => {
            debug_log!(
                "Error: glrfftptsf() getting timestamp: e'{}'e. Using0 inside read_latestreceivedfromme_file_timestamp_plaintextstatefile()",
                e,
            );
            // File not found, initialize to 0
            let mut file = File::create(&file_path)?;
            file.write_all(b"0")?; // Write zero timestamp
            Ok(0)
        }
        Err(e) => Err(ThisProjectError::IoError(e)), // Other IO errors
    }
}

/// Removes a specific pre-fail flag file based on its ID (timestamp).
/// currently gotit sign di (doc id) is the updated-at time of the file
///
/// This function attempts to remove the flag file located at:
/// `sync_data/{team_channel_name}/fail_retry_flags/{remote_collaborator_name}/{di_flag_id}`.
/// It returns an `Ok(())` if the file is successfully removed or if the file
/// doesn't exist (which isn't considered an error in this context, as the goal is
/// simply to ensure the flag is *not* present). It returns an error only if a file
/// operation other than `NotFound` occurs.
///
/// # Arguments
///
/// * `di_flag_id`: The document ID (timestamp) used as the flag file name.
/// * `remote_collaborator_name`: The remote collaborator's name.
/// * `team_channel_name`: The team channel name.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on successful removal or if the
/// file doesn't exist, or a `ThisProjectError` on other file operation errors.
fn remove_one_prefail_flag__for_sendfile(
    di_flag_id: u64,         // Use u64 directly, as the flag ID comes from a u64 timestamp.
    remote_collaborator_name: &str, // Use &str for efficiency
    team_channel_name: &str,   // Use &str for efficiency
) -> Result<(), ThisProjectError> {

    let mut flag_file_path = PathBuf::from("sync_data")
        .join(team_channel_name)
        .join("fail_retry_flags")
        .join(remote_collaborator_name);

    if !flag_file_path.exists() { // Check for existance
        return Ok(()); //
    }

    flag_file_path.push(di_flag_id.to_string());  // Use di_flag_id directly

    match remove_file(flag_file_path) {
        Ok(_) => {
            debug_log!(
                "remove_one_prefail_flag__for_sendfile(): Successfully removed flag with id: {}",
                di_flag_id
            );
            Ok(())
        }
        Err(e) if e.kind() == ErrorKind::NotFound => {
            debug_log!("remove_one_prefail_flag__for_sendfile(): Flag file not found: {}", di_flag_id);
            Ok(()) // Not an error if the file isn't found.
        }
        Err(e) => {
            debug_log!("remove_one_prefail_flag__for_sendfile(): Error removing flag file: {}", e);
            Err(ThisProjectError::IoError(e))  // Return other errors
        }
    }
}

// let timestamp_request_port = // ... port for sending "ready to receive" to collaborator
// let file_receive_port = // ...  port for receiving files from collaborator
// let receipt_confirmation_port = // ... port for sending confirmations to collaborator
fn send_data(data: &[u8], target_addr: SocketAddr) -> Result<(), io::Error> {
    let socket = UdpSocket::bind(":::0")?;
    socket.send_to(data, target_addr)?;
    Ok(())
}

/// Gets the latest received file timestamp for a collaborator in a team channel, using a plain text file.
///
/// As another thread may be reading/writing the file, there
/// is a random-wait retry system
///
/// This function reads the timestamp from a plain text file at:
/// `sync_data/{team_channel_name}/latest_receivedfile_timestamps/
/// {collaborator_name}/latest_received_from_rc_filetimestamp.txt`
/// If the file or directory structure doesn't exist,
/// it creates them and initializes the timestamp to 0.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `collaborator_name`: The name of the collaborator.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`:  The latest received timestamp on success, or a `ThisProjectError` if an error occurs.
///
/// This is one of those values and functions that can be confusing
/// because both you and your remote collaborator have quasi-mirror-image sync systems
/// with reversed roles. Both of you are making 'latest_received' timestamps
/// and both of you are using your and their 'latest_received' timestamps,
/// which are simultanously 'the same' abstract value but very different local-context-role-specific values
///
/// the complimentary function is: read_latestreceivedfromme_file_timestamp_plaintextstatefile()
///
/// example location of use:
/// Drone Loop to Send ReadySignals  (hlod)
/// 1.2 Refresh Timestamp
///
/// If the system is busy and needs to wait, just wait and retry
/// retry-wait must not be considered an 'error' to 'handled'
/// to collapse the entire system.
///
/// the complimentary function is: read_latestreceivedfromme_file_timestamp_plaintextstatefile()
fn read_rc_latest_received_from_rc_filetimestamp_plaintextstatefile(
    team_channel_name: &str,
    collaborator_name: &str,
) -> Result<u64, ThisProjectError> {
    let mut file_path = PathBuf::from("sync_data");
    file_path.push(team_channel_name);
    file_path.push("latest_receivedfile_timestamps");
    file_path.push(collaborator_name);
    file_path.push("latest_received_from_rc_filetimestamp.txt");

    let mut retries = FILE_READWRITE_N_RETRIES;

    // Retry loop
    loop {
        // Generate a random pause duration within the specified range
        let pause_duration = Duration::from_secs(rand::rng().random_range(FILE_READWRITE_RETRY_SEC_PAUSE_MIN..=FILE_READWRITE_RETRY_SEC_PAUSE_MAX));

        match read_to_string(&file_path) {
            Ok(timestamp_str) => {
                match timestamp_str.trim().parse::<u64>() {
                    Ok(timestamp) => return Ok(timestamp), // Success!
                    Err(e) => {
                        debug_log!("Error parsing timestamp from file: {}. Retrying...", e);
                    }
                }
            }
            Err(e) if e.kind() == ErrorKind::NotFound => {
                // Create directories and file if not found (only on first attempt)
                if retries == FILE_READWRITE_N_RETRIES { // Only create on the first try:
                    if let Some(parent) = file_path.parent() {
                        create_dir_all(parent)?;
                    }
                    let mut file = File::create(&file_path)?;
                    file.write_all(b"0")?;
                    return Ok(0);
                } else {
                    debug_log!("File not found. Retrying...");
                }
            }
            Err(e) => {
                debug_log!("IO error reading timestamp file: {}. Retrying...", e);
            }
        }

        if retries == 0 {
            debug_log!("Failed to read timestamp after multiple retries. Using default value 0.");
            return Ok(0); // Or return an appropriate error
        }

        retries -= 1;
        thread::sleep(pause_duration);  // Pause before retrying
    }
}

/// Gets the latest received file's `updated_at_timestamp` for a collaborator.
///
/// Crawls the team channel directory, finds TOML files owned by the collaborator,
/// extracts their `updated_at_timestamp`, and returns the latest one.  Returns 0 if no such files are found.
///
/// # Arguments
///
/// * `team_channel_name`: The team channel name.
/// * `collaborator_name`: The collaborator's name.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`: The latest `updated_at_timestamp` or an error.
fn get_latest_received_from_rc_file_timestamp(
    team_channel_name: &str,
    collaborator_name: &str,
) -> Result<u64, ThisProjectError> {
    let mut latest_timestamp = 0;
    let team_channel_path = PathBuf::from("project_graph_data/team_channels").join(team_channel_name);

    debug_log!(
        "read_latestreceivedfromme_file_timestamp_plaintextstatefile(): Starting GLRFRCFT team_channel_path: {:?}, collaborator_name: {}",
        team_channel_path, collaborator_name
    );

    // 1. Crawl the team channel directory:
    for entry in walkdir::WalkDir::new(team_channel_path) { // Use walkdir to traverse subdirectories
        let entry = entry?;
        let path = entry.path();

        // 2. Check for TOML files:
        if path.is_file() && path.extension().map_or(false, |ext| ext == "toml") {
            debug_log!("GLRFRCFT(): Found TOML file: {:?}", path);

            // 3. Read and parse the TOML file:
            // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
            match fs::read_to_string(path).and_then(|content| Ok(toml::from_str::<Value>(&content))) {
                Ok(toml_data) => {
                    debug_log!("GLRFRCFT(): Successfully parsed TOML file.");

                    // 4. Check file ownership:
                    if toml_data.clone()?.get("owner").and_then(Value::as_str) == Some(collaborator_name) {
                        debug_log!("GLRFRCFT(): File owned by collaborator.");

                        // 5. Extract and update latest_timestamp:
                        if let Some(timestamp) = toml_data?
                            .get("updated_at_timestamp")
                            .and_then(Value::as_integer)
                            .map(|ts| ts as u64)
                        {
                            debug_log!("GLRFRCFT(): Found updated_at_timestamp: {}", timestamp);

                            latest_timestamp = latest_timestamp.max(timestamp); // Keep the latest
                        } else {
                            debug_log!("GLRFRCFT(): 'updated_at_timestamp' field not found or invalid in TOML file: {:?}", path);
                        }
                    }
                }
                Err(e) => {
                    debug_log!("GLRFRCFT(): Error reading or parsing TOML file: {:?} - {}", path, e);
                    // Handle error as needed (e.g., log and continue, or return an error)
                    // return Err(ThisProjectError::from(e)); //Example: Return the error.
                    continue; // Or continue to the next file.
                }
            }
        }
    }

    debug_log!("GLRFRCFT(): End Returning latest timestamp: {}", latest_timestamp);

    Ok(latest_timestamp)
}

/// Sets the latest received file timestamp for a collaborator in a team channel, using a plain text file.
///
/// As another thread may be reading/writing the file, there
/// is a random-wait retry system
///
/// This function writes the `timestamp` to a file at the specified path, creating the directory structure if needed.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `remote_collaborator_name`: The name of the collaborator.
/// * `timestamp`: The timestamp to set.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on success, or a `ThisProjectError` if an error occurs.
fn write_save_latest_received_from_rc_file_timestamp_plaintext(
    team_channel_name: &str,
    remote_collaborator_name: &str,
    timestamp: u64,
) -> Result<(), ThisProjectError> {
    let mut file_path = PathBuf::from("sync_data");
    file_path.push(team_channel_name);
    file_path.push("latest_receivedfile_timestamps");
    file_path.push(remote_collaborator_name);
    file_path.push("latest_received_from_rc_filetimestamp.txt");

    // Create directory structure if it doesn't exist
    if let Some(parent) = file_path.parent() {
        create_dir_all(parent)?;
    }

    let mut retries = FILE_READWRITE_N_RETRIES;

    loop {
        // Random pause duration
        let pause_duration = Duration::from_secs(rand::rng().random_range(FILE_READWRITE_RETRY_SEC_PAUSE_MIN..=FILE_READWRITE_RETRY_SEC_PAUSE_MAX));

        // Attempt to write to the file
        match std::fs::write(&file_path, timestamp.to_string()) { // Note the &
            Ok(_) => return Ok(()), // Success! Exit the loop.
            Err(e) => {
                // Check if the directory structure exists and create it if it doesn't.
                // Create the directory *only* if the file write fails *and* it's due to a missing directory:
                if e.kind() == ErrorKind::NotFound && retries == FILE_READWRITE_N_RETRIES {
                    if let Some(parent) = file_path.parent() {
                        if let Err(dir_err) = create_dir_all(parent) {
                            debug_log!(
                                "Error creating directory: {}",
                                dir_err
                            ); // Log and return the error if the directory can't be created.
                            return Err(ThisProjectError::IoError(dir_err)); // Return appropriate error
                        }
                    }

                }

                // Log the error before retrying
                debug_log!(
                    "Error writing timestamp to file: {}. Retrying... in write_save_latest_received_from_rc_file_timestamp_plaintext()",
                    e
                );
            }
        }


        if retries == 0 { // Maximum retries reached. Return an error or use a default value as needed.
            debug_log!("Failed to write timestamp to file after multiple retries.");
            return Err(ThisProjectError::NetworkError("Failed to write timestamp after retries".into())); // Or return a more appropriate error
        }

        retries -= 1;
        thread::sleep(pause_duration); // Pause before the next retry
    }
}

#[derive(Debug)]
enum CompressionError {
    InvalidNetworkType,
    NetworkIndexOutOfRange,
}

/// Compresses network type and index into a single u8, strictly using 3 digits.
/// Hundreds digit: 0 for IPv4, 1 for IPv6.
/// Remaining digits (0-99): Network index.
///
/// # Arguments
///
/// * `network_type`: "ipv4" or "ipv6".
/// * `network_index`: The network index (0-99).
///
/// # Returns
///
/// * `Result<u8, CompressionError>`: The compressed byte (0-199), or an error if input is invalid.
fn compress_band_data_byte(
    network_type: &str,
    network_index: u8,
) -> Result<u8, CompressionError> {

    if network_index > 99 {
        return Err(CompressionError::NetworkIndexOutOfRange);
    }

    let hundreds_digit = match network_type {
        "ipv4" => 0,
        "ipv6" => 1,
        _ => return Err(CompressionError::InvalidNetworkType),
    };

    let band_byte = (hundreds_digit * 100) + network_index; // Combine using decimal places, not bitwise

    debug_log!("compress_band_data_byte(), band_byte: {}, (network_type, network_index) ({}, {})", band_byte, network_type, network_index);
    Ok(band_byte)
}

#[derive(Debug)]
enum DecompressionError {
    InvalidBandByte,
    InvalidIndex,
}

// Implement Display for DecompressionError to improve debug output:
impl std::fmt::Display for DecompressionError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            DecompressionError::InvalidBandByte => write!(f, "Invalid band byte value (must be 0-199)"),
            DecompressionError::InvalidIndex => write!(f, "Invalid network index (must be 0-99)"),
        }
    }
}
// Implement Error for DecompressionError for compatibility:
impl std::error::Error for DecompressionError {}

/// Decompresses network type and index from a u8 byte.
///
/// Hundreds digit: 0 for IPv4, 1 for IPv6.
/// Remaining digits (0-99):  Network index.
/// Returns an error for invalid input.  Handles errors explicitly with Result.
///
/// # Arguments
///
/// * `band_byte`: The compressed byte.
///
/// # Returns
///
/// * `Result<(String, u8), DecompressionError>`:  The network type and index, or a DecompressionError.
fn decompress_banddata_byte(band_byte: u8) -> Result<(String, u8), DecompressionError> {
    if band_byte >= 200 {
        debug_log!("decompress_banddata_byte(): Invalid band_byte: {} (must be 0-199).", band_byte);
        return Err(DecompressionError::InvalidBandByte);
    }

    let hundreds_digit = band_byte / 100;
    let network_index = band_byte % 100;

    if network_index > 99 { // Strict check as per the specification.
        debug_log!("decompress_banddata_byte(): Invalid index: {} (must be from 0-99).", network_index);
        return Err(DecompressionError::InvalidIndex); // Specific error for easier handling
    }

    let network_type = if hundreds_digit == 1 {
        "ipv6".to_string()
    } else {
        "ipv4".to_string()
    };

    debug_log!("decompress_banddata_byte(), band_byte: {}: (network_type, network_index) ({}, {})", band_byte, network_type, network_index);
    Ok((network_type, network_index)) // Valid data: return Ok(data)
}

/// Sends a ReadySignal to the specified target address, selecting the IP address based on the network type.
/// goes to: their_rmtclb_ip
///     i.e. local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
///
/// Handles hash calculation, serialization, and sending the signal via UDP.
///
/// Args:
///     local_user_salt_list: A slice of `u128` salt values for hash calculation.
///     local_user_ipv4_address: The local user's IPv4 address.
///     local_user_ipv6_address: The local user's IPv6 address.
///     target_port: The target port on the remote machine.
///     last_received_timestamp: The timestamp of the last received file.
///     network_type: A string slice representing the network type ("ipv6" or "ipv4").
///     network_index: The index of the valid IP address in the local user's IP list (included in ReadySignal, but not used for IP selection).
///
/// Returns:
///     Result<(), ThisProjectError>: `Ok(())` on success, or a `ThisProjectError` if an error occurred.
fn send_ready_signal(
    local_user_salt_list: &[u128], // to make hash
    rc_network_type_string: String, // Remote collaborator's network type (ipv4, ipv6, etc.)
    rc_ip_addr_string: String, // Remote collaborator's IP string
    target_port: u16, // local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
    last_received_timestamp: u64, // last_received_timestamp
    local_user_network_type: &str, // LOU needed for .b section
    local_user_network_index: u8,  // LOU needed for .b section
) -> Result<(), ThisProjectError> {
    debug_log!("send_ready_signal()1: Starting...");

    // for ready_signal.b
    let b_band_data = match compress_band_data_byte(
        local_user_network_type,
        local_user_network_index,
    ) {
        Ok(data) => data,
        Err(e) => {
            // Handle the error here. You could print an error message, return from the function,
            // or do something else depending on your specific needs.
            eprintln!("send_ready_signal()2: Error compressing band data: {:?}", e);
            return Ok(());
        }
    };

    // 1. Calculate hashes
    let current_timestamp = get_current_unix_timestamp();
    let hashes_result = calculate_ready_signal_hashes(
        last_received_timestamp,
        current_timestamp,
        b_band_data,
        local_user_salt_list,
    );
    let hashes = match hashes_result {
        Ok(h) => h,
        Err(e) => return Err(e),
    };

    // 2. Create ReadySignal
    let ready_signal = ReadySignal {
        rt: last_received_timestamp,
        rst: current_timestamp,
        b: b_band_data,
        rh: hashes,
    };
    debug_log!("send_ready_signal()3: ReadySignal created: {:?}", ready_signal);

    // 3. Serialize
    let serialized_signal = serialize_ready_signal(&ready_signal)?;
    debug_log!("send_ready_signal()4: ReadySignal serialized.");

    // 4. Determine target IP based on network_type:
    let send_readysignal_ip_addr = match rc_network_type_string {
        value if value == "ipv6".to_string() => {
            let ipv6_addr: Ipv6Addr = rc_ip_addr_string.parse().map_err(|_| ThisProjectError::NetworkError("Invalid IPv6 address".into()))?; // Corrected: .parse()
            IpAddr::V6(ipv6_addr)
        },
        value if value == "ipv4".to_string() => {
            let ipv4_addr: Ipv4Addr = rc_ip_addr_string.parse().map_err(|_| ThisProjectError::NetworkError("Invalid IPv4 address".into()))?; // Corrected: .parse()
            IpAddr::V4(ipv4_addr)
        },
        _ => return Err(ThisProjectError::NetworkError("send_ready_signal() error Invalid network type".into())),
    };

    let target_addr = SocketAddr::new(send_readysignal_ip_addr, target_port);

    // 5. Send the signal
    debug_log!("send_ready_signal()4: Sending ReadySignal to: {:?}", target_addr);
    send_data(&serialized_signal, target_addr)?;
    debug_log!("send_ready_signal()5: ReadySignal sent successfully.");

    Ok(())
}

// draft based on 'send ready signal' function
/// Sends a Gotit to the specified target address.
fn send_gotit_signal(
    local_user_salt_list: &[u128],
    local_user_ipv4_address: &Ipv4Addr,
    local_user_ipv6_address: &Ipv6Addr,
    network_type: &str,  // Add network type
    local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16,
    received_file_updatedat_timestamp: u64,
) -> Result<(), ThisProjectError> {
    /*
    struct GotItSignal {
        gst: Option<u64>, // send-time:
            generate_terse_timestamp_freshness_proxy(); for replay-attack protection
        di: Option<u64>, // the 'id' is updated_at file timestamp
            (because context= filesync timeline ID)
        gh: Option<Vec<u8>>, // N hashes of rt + re
    */

    let timestamp_for_gst = get_current_unix_timestamp();

    // Make hashes of gotit_signal fields:
    let gh_hashes = calculate_gotitsignal_hashlist(
        timestamp_for_gst,
        received_file_updatedat_timestamp, // as di
        local_user_salt_list,
    );

    // Create the GotItSignal struct:
    let gotit_struct = GotItSignal {
        gst: timestamp_for_gst,
        di: received_file_updatedat_timestamp,
        gh: gh_hashes?, // Include calculated hashes
    };

    // 5. Serialize the ReadySignal
    let serialized_gotitsignal_data = serialize_gotit_signal(
        &gotit_struct
    ).expect("inHLOD send_gotit_signal() err Failed to serialize ReadySignal, gotit_signal_to_send_from_this_loop");

    // --- Inspect Serialized Data ---
    debug_log!("inHLOD send_gotit_signal() serialized_gotitsignal_data: {:?}", serialized_gotitsignal_data);

    // Determine target IP based on network_type
    let detected_lou_ip_addr = match network_type {
        "ipv6" => IpAddr::V6(*local_user_ipv6_address),
        "ipv4" => IpAddr::V4(*local_user_ipv4_address),
        _ => return Err(ThisProjectError::NetworkError("Invalid network type in send_gotit_signal".into())),
    };

    let target_addr = SocketAddr::new(
        detected_lou_ip_addr,
        local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip,
    );

    // Log before sending
    debug_log!(
        "inHLOD send_gotit_signal() Attempting to send ReadySignal to {}: {:?}",
        target_addr,
        local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip
    );

    // // If sending to the first address succeeds, no need to iterate further

    if send_data(&serialized_gotitsignal_data, target_addr).is_ok() {
        debug_log("inHLOD send_gotit_signal() 6. Successfully sent GotIt to {} (first address)");
        return Ok(()); // Exit the thread
    } else {
        debug_log("inHLOD send_gotit_signal() err 6. Failed to send GotIt to {} (first address)");
        return Err(ThisProjectError::NetworkError("Failed to send ReadySignal".to_string())); // Return an error
    }

    Ok(())
}

/// Set up the local owner users in-tray desk
/// requests to recieve are sent from here
/// other people's owned docs are received here
/// gpg confirmed
/// save .toml (handle the type: content, node, etc.)
/// and 'gotit' signal sent out from here
///
/// echo_send: if any document comes in
/// automatically send out an echo-type request
/// if you get a file: auto-send an echo-request
/// a thread per 'sync-event'
///     after entering loop
///     Alice follows these steps...
///     1. Check for halt/quit uma signal
///     2. Make a sync-event thread, enter thread
///     3. set sync_event_id to be unique thread id
///     4. Creates a ReadySignal instance to be the ready signal
///     5. Serialize the ReadySignal
///     6. Send the signal @ local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip (exact ip choice pending...)
fn handle_local_owner_desk(
    local_owner_desk_setup_data: ForLocalOwnerDeskThread,
) -> Result<(), ThisProjectError> {
    /*
    TODO:
    I think there is supposed to be a thread per 'sync-event'
    Alice makes an event thread:
    Alice says ready: in the thread
    Alice waits N-miliseconds
    If no reply, kill thread.
    if there is a reply to that event unqiue ID,
    - gpg verify input (if not, kill thread)
    - save .toml etc if ok (if not, kill thread)
    - make another echo-thread (repeat)
    - if ok: send 'gotit!!' signal
    - kill thread
    */

    // TODO maybe a flag here to exit the function?
    // let mut exit_hlod = false;

    // find a valid local owner ip address
    // e.g. to pass a single ip to later functions
    // set empty and fill later or exit
    // let local_user_ipv6_address: Option<Ipv6Addr> = find_valid_local_owner_ip_address(
    //     &local_owner_desk_setup_data.local_user_ipv6_addr_list,
    //     );

    // let local_user_ipv6_address = local_user_ipv6_address.ok_or(
    //     ThisProjectError::NetworkError("No valid local IPv6 address found".to_string()),
    // )?;
    // // set empty and fill later or exit
    // let mut local_user_ipv6_address: Ipv6Addr;

    // let option_localuseripv6address = find_valid_local_owner_ip_address(
    //     &local_owner_desk_setup_data.local_user_ipv6_addr_list,
    // );

    // if let Some(option_fill) = option_localuseripv6address {
    //     // Use the valid IPv6 address
    //     local_user_ipv6_address = option_fill;

    // } else {
    //     // Handle the case where no valid IPv6 address was found
    //     return Err(ThisProjectError::NetworkError("No valid local IPv6 address found".to_string()));  // Or another appropriate error

    //     // TODO: maybe signal uma to hault
    // }

    debug_log("HLOD Starting the handle_local_owner_desk()");


    // Clone the values
    let salt_list_1 = local_owner_desk_setup_data.local_user_salt_list.clone();
    // let salt_list_2 = local_owner_desk_setup_data.local_user_salt_list.clone();

    // let readyport_1 = local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip.clone();
    // let readyport_2 = local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip.clone();
    let localowner_gotit_port = local_owner_desk_setup_data.local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip.clone();

    let remote_collaborator_name = local_owner_desk_setup_data.remote_collaborator_name.clone();

    debug_log("HLOD setup: cloned values.");

    // Instead of storing Option<&Ipv6Addr>, store the owned Ipv6Addr
    // let local_user_ipv6_address_2 = local_user_ipv6_address.clone();


    /*
    Works but moving to new more future-proofed system
    */

    // let ipv6_addr_list = local_owner_desk_setup_data.local_user_ipv6_addr_list.clone();

    // // Clone the address when extracting it
    // if let Some(addr) = ipv6_addr_list.get(0) {
    //     ipv6_addr_1 = Some(*addr); // Dereference and clone the IPv6 address
    //     ipv6_addr_2 = Some(*addr);
    // }

    /////////////////////////////////////////
    // Band: Load Network Band Configuration
    /////////////////////////////////////////
    /*
    Load from sync state files:
    - network_type
    - network_index
    - this_ipv4
    - this_ipv6

    nt/ni (typd/index) will be used for making and sending ReadySignal structs
    network Type + ipv6/ipv4 will be used to listen for files

    */



    // Load local owner band configuration data
    let (
        band_local_network_type,
        band_local_network_index,
        band_local_user_ipv4_address,
        band_local_user_ipv6_address,
    ) = match read_band__network_config_type_index_specs() {
        Ok(data) => data,
        Err(e) => {
            // Handle the error (e.g., log and return or use default values)
            debug_log!("Error reading band configuration: error -> e'{}'e ", e);
            return Err(e); // Or handle differently
        }
    };
    debug_log("HLOD setup: read_band__network_config_type_index_specs() run");

    /////////////
    // Bootstrap
    /////////////
    /*
    HLOD needs is the (ip string, type string) to use with two actions:
        their_rmtclb_ip -> local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: local_ports.ready_port,
                           localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: local_ports.intray_port,
        their_rmtclb_ip -> local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: local_ports.gotit_port,

    ready and gotit are aimed at the RC ip.
    */
    let Ok((rc_network_type_string, rc_ip_addr_string)) = hlod_udp_handshake__rc_network_type_rc_ip_addr(
        &local_owner_desk_setup_data, //: &ForLocalOwnerDeskThread,
        &band_local_network_type, //: &str,
        &band_local_user_ipv4_address, //: &Ipv4Addr,
        &band_local_user_ipv6_address, //: &Ipv6Addr,
        band_local_network_index, //: u8,
    ) else {
        // TODO, handled another way?
        return Err(ThisProjectError::NetworkError("Handshake failed".into()));
        };
    debug_log("HLOD setup: hlod_udp_handshake__rc_network_type_rc_ip_addr() run");


    // let (
    //     network_type,
    //     network_index,
    //     this_ipv4,
    //     this_ipv6,
    //     ) = read_band__network_config_type_index_specs();


    // // 1. Use find_valid_local_owner_ip_address to get a valid address or an error.
    // let local_user_ipv6_address = find_valid_local_owner_ipv6_address(
    //     &local_owner_desk_setup_data.local_user_ipv6_addr_list
    // )
    //     .ok_or(ThisProjectError::NetworkError("No valid local IPv6 address found".to_string()))?;


    // let option_ipindexint = read_sync_state_ip_availability_data();

    // let ip_index_int = match option_ipindexint {
    //     Ok(Some(Ok(ip_index))) => {
    //         match get_ip_by_index(
    //             ip_index,
    //             &local_owner_desk_setup_data.local_user_ipv4_addr_list,
    //             &local_owner_desk_setup_data.local_user_ipv6_addr_list,
    //         ) {
    //             Some(ip_addr) => ip_addr,
    //             None => {
    //                 // Handle the error case here
    //                 // Return a default value
    //                 std::net::IpAddr::V4(std::net::Ipv4Addr::new(0, 0, 0, 0))
    //             }
    //         }
    //     }
    //     _ => {
    //         // Handle the error case here
    //         // Return a default value
    //         std::net::IpAddr::V4(std::net::Ipv4Addr::new(0, 0, 0, 0))
    //     }
    // };



    // //
    // let local_user_ipv6_address = get_ip_by_index(
    //     ip_index_int, // as int_index
    //     &local_owner_desk_setup_data.local_user_ipv4_addr_list, // for ipv4_list,
    //     &local_owner_desk_setup_data.local_user_ipv6_addr_list, // for ipv6_list,
    // );





    // starting with ipv4 len and ipv6 len, see which list the ip is in,
    // and return the list item
    // challenge: the type of the output: ipv4 and ipv6 are not the same type



    // // get index of valid IP v6
    // let ip_index = get_index_byof_ip(
    //     &local_owner_desk_setup_data.local_user_ipv6_addr_list, // as ip_list
    //     &local_user_ipv6_address, // as ip_address
    // );

    // debug_log!(
    //     "Found IP/index <{:?} {:?}>",
    //     local_user_ipv6_address,
    //     ip_index
    // );

    // // set ipv6 state-file
    // // path: sync_data/ip.toml
    // write_local_band__save_network_band__type_index(
    //     ip_index.expect("REASON"),
    // );

    loop { // 1. start overall loop to (re)start whole desk
        debug_log("HLOD 1. start overall loop to (re)start whole desk");


        // 1. Create lookup table:
        let channel_dir_path_str = read_state_string("current_node_directory_path.txt")?; // read as string first
        debug_log!("HLOD 1. Channel directory path (from session state): {}", channel_dir_path_str);

        // use absolute file path
        let team_channel_path = PathBuf::from(channel_dir_path_str);
        let hashtable_node_id_to_path = create_node_id_to_path_lookup(&team_channel_path)?;

        let remote_collaborator_name_for_thread_1 = remote_collaborator_name.clone();
        let remote_collaborator_name_for_thread_2 = remote_collaborator_name.clone();
        // let salt_list_1_drone_clone = salt_list_1.clone();

        // 1.1 check for halt/quit uma signal
        if should_halt_uma() {
            debug_log!("should_halt_uma(), exiting Uma in handle_local_owner_desk()");
            break Ok(());

        }

        debug_log("HLOD calling get_current_team_channel_name_from_nav_path");
        // --- Get team channel name ---
        let team_channel_name = match get_current_team_channel_name_from_nav_path() {
            Some(name) => name,
            None => {
                debug_log!("Error: Could not get current channel name. Skipping.");
                continue; // Skip to the next loop iteration
            }
        };

        // wait, if only for testing, so thread debug prints do not ~overlap
        thread::sleep(Duration::from_millis(1000)); // Avoid busy-waiting

        debug_log!("\n (re)Start HLOD handle_local_owner_desk()");
        // Print all sync data for the desk
        debug_log!("
            HLOD handle_local_owner_desk: local_owner_desk_setup_data -> {:?}",
            &local_owner_desk_setup_data
        );

        /*
        internal "echo":
        To avoid a prolonged delay if there is a backlog of files to recieve,
        but still allow a 3-5 sec pause when there is no backlog,
        each file-recept will turn off the echo
        */
        // let mut echo_flag = false;

        // Drone Loop in a thread? TODO

        /*
        Balancing Accuracy and efficiency:
        the first time in a session the drone loop will use the full search
        to find the most recent file timestamp,
        but thereafter
        the value is saved in a quasi-state or state.
        */

        // initialization
        let mut latest_received_from_rc_file_timestamp = match get_latest_received_from_rc_file_timestamp(
            &team_channel_name, // Correct argument order.
            &remote_collaborator_name_for_thread_1,
        ) {
            Ok(temp_extractor) => temp_extractor,
            Err(e) => {
                debug_log!("HLOD Error getting timestamp via get_latest_received_from_rc_file_timestamp: e'{}'e. Using 0.", e);
                0 // Use a default timestamp (0) if an error occurs.
            }
        };
        debug_log!(
            "HLOD: latest_received_from_rc_file_timestamp -> {:?}",
            latest_received_from_rc_file_timestamp,
        );

        // initialization
        // update state: latest received timestamp
        let _ = write_save_latest_received_from_rc_file_timestamp_plaintext(
            &team_channel_name, // for team_channel_name
            &remote_collaborator_name.clone(), // for collaborator_name
            latest_received_from_rc_file_timestamp, // for timestamp
        );

        // clone to avoid closure issues:
        let band_local_network_type_clone = band_local_network_type.clone();
        let salty_the_clone_list = local_owner_desk_setup_data.local_user_salt_list.clone();

        let rc_ip_addr_string_1 = rc_ip_addr_string.clone();
        let rc_network_type_string_1 = rc_network_type_string.clone();

        // --- 1.5 Drone Loop to Send ReadySignals ---
        let _ = thread::spawn(move || {
            ////////////////////////////////////
            // Drone Loop to Send ReadySignals  (hlod)
            //////////////////////////////////
            loop {

                // 1.1 Wait (and check for exit Uma)  this waits and checks N times: for i in 0..N {
                for _ in 0..10 {
                    // break for loop ?
                    if should_halt_uma() {
                        debug_log!("should_halt_uma(), exiting Uma in handle_local_owner_desk()");
                        break;
                    }
                    thread::sleep(Duration::from_millis(1000));
                }
                // break loop loop?
                if should_halt_uma() {
                    debug_log!("HLOD should_halt_uma(), exiting Uma in handle_local_owner_desk()");
                    break;
                }

                debug_log!("\nHLOD Drone Loop Start...thanks for coming around!");

                // 1.2 Refresh Timestamp
                // get timestamp of the file you (local owner user) recieved most recently from the RC
                // remote collaborator in this team-channel.
                /*
                @
                sync_data/{team_channel}/latest_receivedfile_timestamps/bob/latest_receivedfromme_file_timestamp
                */

                latest_received_from_rc_file_timestamp = match read_rc_latest_received_from_rc_filetimestamp_plaintextstatefile(
                    &team_channel_name,
                    &remote_collaborator_name_for_thread_2,
                ) {
                    Ok(temp_extractor) => temp_extractor,
                    Err(e) => {
                        debug_log!("HLOD GotItSignal Error getting timestamp via get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl: e'{}'e. Using 0.", e);
                        0 // Use a default timestamp (0) if an error occurs.
                    }
                };
                debug_log!(
                    "HLOD drone loop (ready-signals) latest_received_from_rc_file_timestamp -> {:?}",
                    latest_received_from_rc_file_timestamp,
                );

                // 1.3 Send Ready Signal (using a function)
                let _ = send_ready_signal(
                    &salty_the_clone_list, // local_user_salt_list: &[u128],
                    rc_network_type_string_1.clone(), // local_user_ipv4_address: &Ipv4Addr,
                    rc_ip_addr_string_1.clone(), // local_user_ipv6_address: &Ipv6Addr,
                    local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,
                    latest_received_from_rc_file_timestamp, // last_received_timestamp: u64, // for rst
                    &band_local_network_type_clone, // network_type: String, // for nt
                    band_local_network_index, //network_index: u8, // for ni
                );

                // if let Some(addr_1) = ipv6_addr_1 {
                //     send_ready_signal(
                //         &salt_list_1_drone_clone,
                //         &addr_1,
                //         readyport_1,
                //         latest_received_from_rc_file_timestamp,
                //         false,
                //     );
                // }

                debug_log!("\n");
            } // end drone loop (ready-signals)
        }); // end ready_thread

        //////////////////////////////
        // 3. InTrayListerLoop Start
        ////////////////////////////

        // 3.1 intrystruct_hash_set_session_nonce = HashSet::new() as protection against replay attacks Create a HashSet to store received hashes
        let mut intrystruct_hash_set_session_nonce = HashSet::new();  // Create a HashSet to store received hashes

        // to discard duplicate files already saved
        // TODO: to scale this should be perhaps a stub-file flag
        let mut file_hash_set_session_nonce = HashSet::new();  // Create a HashSet to store received hashes

        // --- 2. Enter In-Try-loop ---
        // restarts if crashes
        // enter main loop (to handle in-tray Send-File, gotit signl sending, 'echo' ready-signal sending)
        loop { // 3.2 In-Try-loop

            // --- 3.3 Check for 'should_halt_uma' Signal ---
            if should_halt_uma() {
                debug_log!(
                    "HLOD-InTray 3.3 main loop Check for halt signal. Halting handle_local_owner_desk() for {}",
                    local_owner_desk_setup_data.remote_collaborator_name
                );
                break;
            }

            // --- 3.4 Create UDP intray socket ---
            /*
            band_local_network_type,
            band_local_user_ipv4_address,
            band_local_user_ipv6_address,
            */
            debug_log("HLOD Creating intray socket listening UDP...");
            let intray_socket = create_local_udp_socket(
                &band_local_network_type,
                &band_local_user_ipv4_address,
                &band_local_user_ipv6_address,
                local_owner_desk_setup_data.localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip,
            )?;
            debug_log!("HLOD: Intray socket created.");



            // debug_log("HLOD Creating intray socket listening UDP...");
            // let intray_socket = create_rc_udp_socket(
            //     &local_owner_desk_setup_data.local_user_ipv6_addr_list,
            //     local_owner_desk_setup_data.localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip,
            // )?;
            // debug_log!("HLOD: Intray socket created.");

            // --- 3.5 in-tray Send-File Event ---
            // "Listener"?
            // 3.5.1 Receive in-tray Send-File packet
            let mut buf = [0; 65536]; // Maximum UDP datagram size
            loop { // In-Tray-Loop
                // Check for halt signal at the beginning of the loop
                if should_halt_uma() {
                    debug_log!("HLOD-InTray: Halt signal received. Exiting.");
                    break;
                }

                match intray_socket.recv_from(&mut buf) {
                    Ok((amt, src)) => {
                    debug_log!(
                        "HLOD-InTray match intray_socket.recv_from(&mut buf) Ok((amt, src)) {:?} {:?}",
                        amt,
                        src
                    );

                    // Check for exit-signal:
                    if should_halt_uma() {
                        debug_log!(
                            "HLOD-InTray 3.5.2 main loop Check for halt signal. Halting handle_local_owner_desk() for {}",
                            local_owner_desk_setup_data.remote_collaborator_name
                        );
                        break;
                    }

                    debug_log!(
                        "HLOD-InTray 3.5.2.1 Ok((amt, src)) ready_port Signal Received {} bytes from {}",
                        amt,
                        src
                    );

                    // --- Inspect Raw Bytes ---
                    debug_log!(
                        "HLOD-InTray 3.5.2.2 Ready Signal Raw bytes received: {:?}",
                        &buf[..amt]
                    );

                    // --- Inspect Bytes as Hex ---
                    let hex_string = buf[..amt].iter()
                        .map(|b| format!("{:02X}", b))
                        .collect::<String>();
                    debug_log!(
                        "HLOD-InTray 3.5.2.3 Ready Signal Raw bytes as hex: {}",
                        hex_string
                    );

                    // --- 3.5.3 Deserialize the SendFile signal ---
                    // let incoming_intray_file_struct: SendFile = deserialize_intray_send_file_struct(&clearsigned_data)?;  // Deserialize from clearsigned data

                    let incoming_intray_file_struct: SendFile = match deserialize_intray_send_file_struct(&buf[..amt]) {
                        Ok(incoming_intray_file_struct) => {
                            debug_log("HLOD-InTray 2.3 SendFile listener: Receive File Data...do you copy, gold leader... >*<");

                            debug_log!("HLOD-InTray 2.3 Deserialize Ok(incoming_intray_file_struct) {}: Received SendFile: {:?}",
                                local_owner_desk_setup_data.remote_collaborator_name,
                                incoming_intray_file_struct
                            ); // Log the signal
                            incoming_intray_file_struct
                        },
                        Err(e) => {
                            debug_log!("HLOD-InTray 2.3 Deserialize Err Receive data Failed to parse ready signal: {}", e);
                            continue; // Continue to the next iteration of the loop
                        }
                    };

                    debug_log("##HLOD-InTray## starting checks(hound's tooth, they say) 2.4");

                    // --- 3.2 timestamp freshness checks ---
                    let current_timestamp = get_current_unix_timestamp();

                    debug_log!(
                        "HLOD 2.4.1 check timestamp freshness checks: current_timestamp -> {:?}",
                        current_timestamp
                    );

                    // 3.2.1 No Future Dated Requests
                    if incoming_intray_file_struct.intray_send_time > Some(current_timestamp + 5) { // Allow for some clock skew (5 seconds)
                        debug_log!("HLOD 2.4.2 check: Received future-dated timestamp. Discarding.");
                        continue;
                    }

                    // 3.2.2 No Requests Older Than ~10 sec
                    if current_timestamp - 10 > incoming_intray_file_struct.intray_send_time.expect("REASON") {
                        debug_log!("HLOD 2.4.3 check: Received outdated timestamp (older than 10 seconds). Discarding.");
                        continue;
                    }

                    // 3.2.3 Check .intray_hash_list hash
                    if incoming_intray_file_struct.intray_hash_list.is_none() {
                        debug_log("HLOD 2.4.4 Check: intray_hash_list hash field is empty. Drop packet and keep going.");
                        continue; // Drop packet: Restart the loop to listen for the next signal
                    }

                    // 3.2.4 Check .intray_send_time timestamp
                    if incoming_intray_file_struct.intray_send_time.is_none() {
                        debug_log("HLOD 2.4.5 Check: intray_send_time ready signal sent-at timestamp field is empty. Drop packet and keep going.");
                        continue; // Drop packet: Restart the loop to listen for the next signal
                    }

                    // --- 4 Check / Add Hash-Nonce for per-session ready-signals ---
                    // ...e.g. guarding against the few seconds of expiration-gap
                    // HLOD 4.1 Hashes
                    let incoming_intray_file_struct_hash_vec = incoming_intray_file_struct.intray_hash_list.clone().expect("intray_hash_list is none");

                    // 4.2
                    if !incoming_intray_file_struct_hash_vec.is_empty() {
                        if intrystruct_hash_set_session_nonce.contains(&incoming_intray_file_struct_hash_vec) {
                            debug_log!("HLOD 4.2 quasi nonce check: Duplicate SendFile received (hash match). Discarding.");
                            continue; // Discard the duplicate signal
                        }
                        intrystruct_hash_set_session_nonce.insert(incoming_intray_file_struct_hash_vec); // Add hash to the set
                    } else {
                        debug_log!("HLOD 4.2 quasi nonce check: SendFile received without hashes. Discarding."); // Or handle differently
                        continue;
                    }

                    // // --- 5 Hash-Check for SendFile Struct ---
                    // // HLOD 5 Drop packet when fail check
                    // if !verify_intray_sendfile_hashes( // make this function TODO
                    //     &incoming_intray_file_struct,
                    //     &local_owner_desk_setup_data.remote_collaborator_salt_list,
                    // ) {
                    //     debug_log("HLOD 5: SendFile Struct hash verification failed. Discarding signal.");
                    //     continue; // Discard the signal and continue listening
                    // }


                    // --- 5.0 Hash-Check for SendFile Struct ---
                    // HLOD 5.0 Drop packet when fail check
                    // Check the hash of the incoming file against the provided list of salts
                    if !hash_checker_for_sendfile_struct(
                        &local_owner_desk_setup_data.remote_collaborator_salt_list, // Use remote collaborator's salts
                        incoming_intray_file_struct.intray_send_time.expect("Missing intray_send_time"), // Safe unwrap, checked earlier
                        incoming_intray_file_struct.gpg_encrypted_intray_file.as_deref().expect("Missing encrypted file"), // Safe unwrap, checked earlier
                        incoming_intray_file_struct.intray_hash_list.as_deref().expect("Missing hash list")  //Safe unwrap, checked earlier

                    ) {
                        debug_log!("failed HLOD 5.0: SendFile Struct hash verification failed. Discarding signal.");
                        continue; // Discard the signal and continue listening
                    }

                    debug_log!("Passed HLOD 5.0: SendFile Struct hash verified.");

                    // // replace this block
                    // match calculate_and_verify_sendfile_hashes(
                    //     &incoming_intray_file_struct,
                    //     &local_owner_desk_setup_data.remote_collaborator_salt_list,
                    // ) {
                    //     Ok((calculated_hashes, all_hashes_match)) => {
                    //         if !all_hashes_match {
                    //             debug_log("HLOD 5: SendFile Struct hash verification failed. Discarding signal.");
                    //             continue; // Discard the signal and continue listening
                    //         }
                    //         // If all hashes match, you can use the calculated_hashes for further processing if needed
                    //     }
                    //     Err(e) => {
                    //         debug_log(&format!("Error calculating and verifying SendFile hashes: {}", e));
                    //         continue; // Discard the signal and continue listening
                    //     }
                    // }

                    // // replace with this code (incomplete)
                    // // if result is fail
                    // match hash_checker_for_sendfile_struct(
                    //     salt_list: &[u128],
                    //     incoming_intray_file_struct.intray_send_time: u64,
                    //     incoming_intray_file_struct.gpg_encrypted_intray_file: &[u8], // Use a slice
                    //     incoming_intray_file_struct.intray_hash_list// compare_to_this_hashvec: &[u8], // Use a slice
                    // ) {
                    //     Ok(all_hashes_match) => {
                    //         if !all_hashes_match {
                    //             debug_log("HLOD 5: SendFile Struct hash verification failed. Discarding signal.");
                    //             continue; // Discard the signal and continue listening
                    //         }
                    //         // If all hashes match, you can use the calculated_hashes for further processing if needed
                    //     }
                    //     Err(e) => {
                    //         debug_log(&format!("Error calculating and verifying SendFile hashes: {}", e));
                    //         continue; // Discard the signal and continue listening
                    //     }
                    // }

                    /*
                    Maybe here:

                    If message file:
                    look in Navigation-State for Messages requires gpg-encrypted
                    if not: look in file for flag

                    if node-file
                    look in file for flag

                    add steps to

                    (if not a message file or no mssage-file nav-state:  Messages requires gpg-encrypted)
                    A. save as a temp file (no os-temp, uma-data temp)
                    B. make read-copy
                    C. look for flag

                    */

                    // --- 6. HLOD decypt ---
                    // 6.1  Handle the Option<Vec<u8>> for gpg_encrypted_intray_file
                    let still_encrypted_file_blob = match &incoming_intray_file_struct.gpg_encrypted_intray_file {
                        Some(data) => data,  // Extract the Vec<u8> if Some
                        None => {
                            debug_log!("HLOD 6.1: gpg_encrypted_intray_file is None. Skipping.");
                            continue; // Or handle the None case differently (e.g., return an error)
                        }
                    };
                    debug_log!(
                        "HLOD 6.1 still_encrypted_file_blob -> {:?}",
                        still_encrypted_file_blob
                    );

                    // 6.2 *Now* decrypt the data
                    let decrypted_clearsignfile_data = match gpg_decrypt_from_bytes(
                        still_encrypted_file_blob,
                        &local_owner_desk_setup_data.local_user_gpg_publickey_id
                    ) { // Pass the extracted data
                        Ok(data) => data,
                        Err(e) => {
                            debug_log!("HLOD 6.2: GPG decryption failed: {}. Skipping.", e);
                            continue; // Skip to the next packet if decryption fails
                        }
                    };
                    debug_log!(
                        "HLOD 6.2 decrypt the data decrypted_clearsignfile_data -> {:?}",
                        decrypted_clearsignfile_data
                    );

                    // 6.3 Extract the clearsigned data
                    let extracted_clearsigned_file_data = match extract_clearsign_data(&decrypted_clearsignfile_data) {
                        Ok(data) => data,
                        Err(e) => {
                            debug_log!("HLOD 6.3: Clearsign extraction failed: {}. Skipping.", e);
                            continue;
                        }
                    };
                    debug_log!(
                        "HLOD 6.3 extracted_clearsigned_file_data -> {:?}",
                        extracted_clearsigned_file_data
                    );


                    // Section 6.4 - Extract flag - for clearsigned .toml / .gpgtoml
                    let file_str = std::str::from_utf8(&extracted_clearsigned_file_data)
                        .map_err(|_| ThisProjectError::InvalidData("Invalid UTF-8 in file content".into()))?;

                    let save_as_gpgtoml = file_str.contains("\nmessagepost_gpgtoml = true\n")
                        || file_str.contains("\ncorenode_gpgtoml = true\n");

                    debug_log!("HLOD 6.4: save_as_gpgtoml flag = {}", save_as_gpgtoml);



                    // 7 Save File into Uma Folder Structure
                    // let received_toml: Value = toml::from_slice(&extracted_clearsigned_file_data)?;
                    /*
                    1. if X then save in A place
                    2. if Y then save in B place
                    for a message file,
                    filepath_in_node = "/message_posts_browser"
                    for MVP: just add it the same way you add any message, next available number.

                    current_path = project_graph_data/team_channels/{}/message_posts_browser/

                    let incoming_file_path = get_next_message_file_path(current_path, local_owner_user);
                    */
                    // 7.1 1. Identifying Instant Message Files
                    let file_str = std::str::from_utf8(&extracted_clearsigned_file_data).map_err(|_| {
                        ThisProjectError::InvalidData("Invalid UTF-8 in file content".into())
                    })?;


                    debug_log!(
                        "HLOD 7.1 found message file, file_str -> {:?}",
                        file_str
                    );

                    // let mut incoming_file_path: PathBuf = PathBuf::from("project_graph_data/team_channels");
                    let mut incoming_file_path: PathBuf; // = PathBuf::new();

                    let team_channel_name = get_current_team_channel_name_from_nav_path()
                        .ok_or(ThisProjectError::InvalidData(
                            "Unable to get team channel name".into())
                        )?;

                    // TODO for now only handling IM and Node files
                    if file_str.contains("filepath_in_node = \"/message_posts_browser\"") {
                        debug_log!("HLOD-InTray: an instant message file.");

                        // 7.2
                        // 2. Generating File Path

                        let mut current_path = PathBuf::from("project_graph_data/team_channels");
                        current_path.push(&team_channel_name);
                        current_path.push("message_posts_browser");

                        incoming_file_path = get_next_message_file_path(
                            &current_path,
                            &local_owner_desk_setup_data.remote_collaborator_name // local user name
                        );

                        // NEW: Adjust extension based on flag
                        if save_as_gpgtoml {
                            incoming_file_path.set_extension("gpgtoml");
                        }

                        debug_log!(
                            "HLOD 7.2 got-made incoming_file_path -> {:?}",
                            incoming_file_path
                        );

                        // check: see if this same file was already saved
                        // 1. Calculate the hash of the received file content using the *local* user's salts and the *raw bytes*:
                        let received_file_hash_result = calculate_pearson_hashlist_for_string( // Use a byte-oriented hash function
                            &file_str,  // Hash the raw bytes
                            &local_owner_desk_setup_data.local_user_salt_list, // Use *local* user's salts
                        );

                        let received_file_hash = match received_file_hash_result {
                            Ok(hash) => hash,
                            Err(e) => {
                                debug_log!("Error calculating hash for received file: {}", e);
                                continue; // Skip to next file if hashing fails
                            }
                        };

                        // 2. Check for duplicates and insert the hash (as before)
                        if file_hash_set_session_nonce.contains(&received_file_hash) {
                            debug_log!("Duplicate file received (hash match). Discarding.");
                            continue; // Discard the duplicate file
                        }
                        file_hash_set_session_nonce.insert(received_file_hash); // Insert BEFORE saving

                        // 3. Saving the File
                        // MODIFIED: Choose what to save
                        let data_to_save = if save_as_gpgtoml {
                            still_encrypted_file_blob  // Save encrypted version
                        } else {
                            &decrypted_clearsignfile_data  // Save clearsigned version
                        };

                        // 3. Saving the File
                        if let Err(e) = fs::write(&incoming_file_path, data_to_save) {
                            debug_log!("HLOD-InTray: Failed to write message file: {:?}", e);
                            return Err(ThisProjectError::from(e));
                        }

                        debug_log!("7.3 HLOD-InTray: IM message file saved to: {:?}", incoming_file_path);
                        // if let Err(e) = fs::write(&incoming_file_path, &extracted_clearsigned_file_data) {
                        //     debug_log!("HLOD-InTray: Failed to write message file: {:?}", e);
                        //     // Consider returning an error here instead of continuing the loop
                        //     return Err(ThisProjectError::from(e));
                        // }

                        // debug_log!("7.3 HLOD-InTray: IM message file saved to: {:?}", incoming_file_path);


                    }

                    // HEREHERe
                    // if message file
                    // if nav-state fule
                    // if contains gpg "\ngpgtoml = true\n"
                    if file_str.contains("\nmessagepost_gpgtoml = true\n") || file_str.contains("\ncorenode_gpgtoml = true\n"){

                        // save .gpg version as .gpgtoml
                        // ...file name if message...

                    }


                    // TODO for now only handling IM and Node files
                    // TODO, don't load whole file...
                    if file_str.contains("node_unique_id = \"") {
                        debug_log!("HLOD-InTray: an Ode file. (Grecian Urn...you know.)");

                        // 7.2
                        // 2. Generating File Path
                        // attach to absolute path: TODO

                        // Extract directory_path:
                        let new_node_directory_path_result = file_str
                            .lines()  // Iterate over lines
                            .find_map(|line| { // Use find_map to extract and parse in one step
                                if line.starts_with("directory_path = \"") && line.ends_with("\"") {
                                    let path_str = &line["directory_path = \"".len()..line.len() - 1];
                                    Some(PathBuf::from(path_str))
                                } else {
                                    None
                                }
                            });

                        let node_file_path = match new_node_directory_path_result {
                            Some(path) => path,
                            None => {
                                debug_log!("'directory_path' not found or invalid format in node.toml");
                                continue; // Or handle error as you see fit
                            }
                        };

                        // get absolute path
                        let new_full_abs_node_directory_path = PathBuf::from(node_file_path);

                        // make sure path exists
                        fs::create_dir_all(&new_full_abs_node_directory_path)?;

                        debug_log!(
                            "HLOD 7.2 got-made new_full_abs_node_directory_path -> {:?}",
                            &new_full_abs_node_directory_path
                        );

                        let new_node_toml_file_path = new_full_abs_node_directory_path.join("node.toml"); // Path to the new node.toml

                        debug_log!(
                            "HLOD 7.2 got-made new_node_toml_file_path -> {:?}",
                            &new_node_toml_file_path
                        );

                        // check: see if this same file was already saved
                        // 1. Calculate the hash of the received file content using the *local* user's salts and the *raw bytes*:
                        let received_file_hash_result = calculate_pearson_hashlist_for_string( // Use a byte-oriented hash function
                            &file_str,  // Hash the raw bytes
                            &local_owner_desk_setup_data.local_user_salt_list, // Use *local* user's salts
                        );

                        let received_file_hash = match received_file_hash_result {
                            Ok(hash) => hash,
                            Err(e) => {
                                debug_log!("Error calculating hash for received file: {}", e);
                                continue; // Skip to next file if hashing fails
                            }
                        };

                        // 2. Check for duplicates and insert the hash (as before)
                        if file_hash_set_session_nonce.contains(&received_file_hash) {
                            debug_log!("Duplicate file received (hash match). Discarding.");
                            continue; // Discard the duplicate file
                        }
                        file_hash_set_session_nonce.insert(received_file_hash); // Insert BEFORE saving


                        /////////////////
                        // Move or Save
                        ////////////////
                        /*
                        1. Make a hash-table of node files' unique ID in session/team-channel: id: path lookup
                        2. check this node uniqeu ID
                        3. if this node is an existing node:
                        4. remove the old path
                        5. (re)save at the new path
                        */

                        // 2. Access node data (must match `node_unique_id_str` from `create_node_id_to_path_lookup`):
                        let node_unique_id_str_result = extract_string_from_toml_bytes(&extracted_clearsigned_file_data, "node_unique_id");
                        // ?
                        // let new_node_dir_path_str = match extract_string_from_toml_bytes(received_file_bytes, "directory_path") {
                        //     Ok(s) => s,
                        //     Err(_) => return Err(ThisProjectError::InvalidData("directory_path field missing from node file".into())),
                        // };

                        match node_unique_id_str_result {
                            Ok(node_unique_id_str) => { // Node exists, handle move/replace:
                                /*
                                Establish Variables
                                1. new node directory path (get) - Done Above
                                    new_full_abs_node_directory_path

                                2. new node file path (matke) - Done Above
                                    new_node_toml_file_path

                                Look for (opposite make/get order from above):
                                3. Old node file path (get)
                                4. old node directory path (make)

                                If no old path:
                                5A. make new directory,
                                6A. save new file

                                If old path exists:
                                5B. remove OLD node FILE (just the file, not the directory)
                                6B. save (relace) new node file in old directory
                                7. recoursively move the old directory to the NEW directory path

                                */
                                // Use the node_unique_id_str

                                // let new_node_dir_path = PathBuf::from(new_node_dir_path_str);
                                // let new_node_toml_path = new_node_dir_path.join("node.toml"); // Path to the new node.toml

                                // Get old node.toml file path (if exists)
                                if let Some(olddir_existing_node_directory_path) = hashtable_node_id_to_path.get(&node_unique_id_str) {

                                    // make old directory path
                                    let olddir_abs_node_directory_path = PathBuf::from(olddir_existing_node_directory_path);

                                    debug_log!(
                                        "HLOD 7.2 got-made olddir_abs_node_directory_path -> {:?}",
                                        &olddir_abs_node_directory_path
                                    );

                                    // for clearsigned .toml and .gpgtoml
                                    // Determine filename based on flag
                                    let node_filename = if save_as_gpgtoml {
                                        "node.gpgtoml"
                                    } else {
                                        "node.toml"
                                    };

                                    let oldfile_node_file_path = olddir_abs_node_directory_path.join(node_filename);

                                    // Choose what to save
                                    let data_to_save = if save_as_gpgtoml {
                                        still_encrypted_file_blob  // Save encrypted version
                                    } else {
                                        &decrypted_clearsignfile_data  // Save clearsigned version
                                    };

                                    // 3.2 replace (delete the old) node file
                                    if let Err(e) = fs::write(&oldfile_node_file_path, data_to_save) {
                                        debug_log!("Error writing node file: {:?} - {}", &oldfile_node_file_path, e);
                                        return Err(ThisProjectError::from(e));
                                    }


                                    // let oldfile_node_toml_file_path = olddir_abs_node_directory_path.join("node.toml"); // Path to the new node.toml

                                    // debug_log!(
                                    //     "HLOD 7.2 got-made oldfile_node_toml_file_path -> {:?}",
                                    //     &oldfile_node_toml_file_path
                                    // );

                                    // // 3.2 replace (delete the old) node.toml file (file, not directory)
                                    // // Write the received data to the OLD node.toml location, replacing it:
                                    // if let Err(e) = fs::write(&oldfile_node_toml_file_path, &extracted_clearsigned_file_data) {
                                    //     debug_log!("Error writing node.toml: {:?} - {}", &oldfile_node_toml_file_path, e);
                                    //     return Err(ThisProjectError::from(e));
                                    // }

                                    // 3.3 Move old node directory (not remove/delete) (directory, not file)
                                    // TODO HERE HERE
                                    // from olddir_abs_node_directory_path to new_full_abs_node_directory_path
                                    if let Err(error) = move_directory__from_path_to_path(&olddir_abs_node_directory_path, &new_full_abs_node_directory_path) {
                                        debug_log!("An error occurred: {}", error);
                                    }

                                    debug_log!("7.3 HLOD-InTray: moved file moved from: {:?}", &olddir_abs_node_directory_path);
                                    debug_log!("7.3 HLOD-InTray: moved-new file saved to: {:?}", &new_full_abs_node_directory_path);

                                } else {
                                    // 3. saving node as clearsigned .toml or .gpgtoml

                                    // Determine filename based on flag
                                    let node_filename = if save_as_gpgtoml {
                                        "node.gpgtoml"
                                    } else {
                                        "node.toml"
                                    };

                                    let new_node_file_path = new_full_abs_node_directory_path.join(node_filename);

                                    // Choose what to save
                                    let data_to_save = if save_as_gpgtoml {
                                        still_encrypted_file_blob  // Save encrypted version
                                    } else {
                                        &decrypted_clearsignfile_data  // Save clearsigned version
                                    };

                                    // Create directory
                                    fs::create_dir_all(&new_full_abs_node_directory_path)?;

                                    // Save file
                                    if let Err(e) = fs::write(&new_node_file_path, data_to_save) {
                                        debug_log!("Error writing node file: {:?} - {}", &new_node_file_path, e);
                                        return Err(ThisProjectError::from(e));
                                    }

                                    debug_log!("7.3 HLOD-InTray: new file saved to: {:?}", new_node_file_path);



                                    // Node is new, save it:
                                    // 3. Unpacking/Saving the File as node.toml file

                                    // match unpack_new_node_save_toml_and_create_dir(
                                    //     &extracted_clearsigned_file_data,
                                    //     &new_full_abs_node_directory_path
                                    // ) {
                                    //     Ok(_) => debug_log("Node unpacked and saved successfully."),
                                    //     Err(e) => debug_log!("Error unpacking node: {}", e),
                                    // }

                                    // debug_log!("7.3 HLOD-InTray: new file saved to: {:?}", new_full_abs_node_directory_path);

                                    // unpack_new_node_save_toml_and_create_dir(
                                    //     &extracted_clearsigned_file_data,
                                    //     &new_full_abs_node_directory_path,
                                    // );

                                    // if let Err(e) = fs::write(
                                    //     &new_node_toml_file_path,
                                    //     &extracted_clearsigned_file_data
                                    // ) {
                                    //     debug_log!("HLOD-InTray: Failed to write message file: {:?}", e);
                                    //     // Consider returning an error here instead of continuing the loop
                                    //     return Err(ThisProjectError::from(e));
                                    // }
                                }
                            }
                            Err(e) => {
                                // Handle error
                                continue;
                            }
                        }
                    }



                      /////////////
                     // Echo Base
                    /////////////
                    /*
                    After a file is received and saved
                    a miniature ReadySignal is sent out
                    using the timestamp of the 'current file' as the latest file
                    and saving that in state
                    so that the drone-loop (above) sending ready signals will also know
                    there is a new latest-date
                    */

                    // Extract timestamp
                    let received_file_updatedat_timestamp = match extract_updated_at_timestamp(
                        &extracted_clearsigned_file_data
                    ) {
                        Ok(temp_extraction_timestamp) => temp_extraction_timestamp,
                        Err(e) => {
                            debug_log!("HLOD-InTray: Error extracting timestamp: {}. Skipping.", e);
                            continue;
                        }
                    };

                    // update state: latest received timestamp
                    let _ = write_save_latest_received_from_rc_file_timestamp_plaintext(
                        &team_channel_name, // for team_channel_name
                        &local_owner_desk_setup_data.remote_collaborator_name, // for collaborator_name
                        received_file_updatedat_timestamp, // for timestamp
                    );

                    // Now you have the received_file_updatedat_timestamp timestamp
                    debug_log!("7.3 HLOD-InTray: Received file was updated_at: {}", received_file_updatedat_timestamp);
                    // println!("Received file updated at: {}", received_file_updatedat_timestamp);

                    // 1.4 Send Echo Ready Signal (using a function)
                    /*
                    struct GotItSignal {
                        gst: Option<u64>, // send-time:
                            generate_terse_timestamp_freshness_proxy(); for replay-attack protection
                        di: Option<u64>, // the 'id' is updated_at file timestamp
                            (because context= filesync timeline ID)
                        gh: Option<Vec<u8>>, // N hashes of rt + re
                    */

                    debug_log("7.3 HLOD-InTray: send_gotit_signal ");
                    let _ = send_gotit_signal(
                        &local_owner_desk_setup_data.local_user_salt_list,
                        &band_local_user_ipv4_address, // local_user_ipv4_address: &Ipv4Addr,
                        &band_local_user_ipv6_address, // local_user_ipv6_address: &Ipv6Addr,
                        &band_local_network_type, // network_type: String, // for nt
                        localowner_gotit_port,
                        received_file_updatedat_timestamp, // as di
                    );


                    //



                    // 1.4 Send Echo Ready Signal (using a function)
                    // 2nd copy for other threads
                    let rc_network_type_string_2 = rc_network_type_string.clone();
                    let rc_ip_addr_string_2 = rc_ip_addr_string.clone();

                    // TODO: how long?
                    // this lets last item run
                    thread::sleep(Duration::from_secs(5));
                    thread::sleep(Duration::from_secs(3));

                    send_ready_signal(
                        &local_owner_desk_setup_data.local_user_salt_list, // local_user_salt_list: &[u128],
                        rc_network_type_string_2, // Remote collaborator's network type (ipv4, ipv6
                        rc_ip_addr_string_2,  // Remote collaborator's IP string
                        local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,
                        received_file_updatedat_timestamp, // last_received_timestamp: u64, // for rst
                        &band_local_network_type, // network_type: String, // for nt
                        band_local_network_index, //network_index: u8, // for ni
                    )?;
                    // if let Some(addr_2) = ipv6_addr_2 {
                    //     send_ready_signal(
                    //         &salt_list_2,
                    //         &addr_2,
                    //         readyport_2,
                    //         received_file_updatedat_timestamp,
                    //         false,
                    //     );
                    // }

                // },
                // Err(_) => todo!() // end Ok((amt, src)) => { // end Ok((amt, src)) => {

                }
                Err(e) if e.kind() == std::io::ErrorKind::WouldBlock => {
                    // No data available yet.  Don't treat this as an error.
                    debug_log!("HLOD-InTray: No data available yet...WouldBlock");
                    std::thread::sleep(std::time::Duration::from_millis(100));
                    continue; // Continue to the next loop iteration
                }
                Err(e) => {
                    // A real error occurred. Log and handle it.
                    debug_log!("HLOD-InTray: Error receiving data: {}", e);
                    return Err(ThisProjectError::NetworkError(format!(
                        "Error receiving data: {}",
                        e
                    )));  // Or choose another way to handle this
                }
                }
            } // end match ready_socket.recv_from(&mut buf) {
        } // end In-Tray-Loop
        ////////////////////////
        // InTrayListerLoop End
        ////////////////////////


        // TESTING ONLY wait, if only for testing, so thread debug prints do not ~overlap
        thread::sleep(Duration::from_millis(100)); // Avoid busy-waiting

        debug_log!(
            "HLOD Exiting handle_local_owner_desk() for {}",
            local_owner_desk_setup_data.local_user_name
        ); // Add collaborator name
        debug_log(">*< Halt signal received. Exiting The Uma. Closing... handle_local_owner_desk() |o|");
    }
}


/// Vanilla serialize (no serde!)
/// Due to exceptional priority of minimizing network load:
/// terse key names are used here, these still must not collide
/// though readability is regretibly reduced.
///
/// Use With
/// let socket = UdpSocket::bind(":::0")?; /// Bind to any available IPv6 address
///
/// let ready_signal = ReadySignal {
///     id: 12345,
///     timestamp: 1673276800,
/// };
///
/// Convert the struct data to bytes:
/// let data = serialize_ready_signal(&ready_signal)?;
///
/// Send the data:
/// socket.send_to(&data, "[::1]:34254")?; /// Replace with your target address and port
/// Ok(())
// fn serialize_ready_signal(this_readysignal: &ReadySignal) -> std::io::Result<Vec<u8>> {
//     let mut bytes = Vec::new();

//     // Handle rt (timestamp) -  return an error if None:
//     if let Some(rt) = this_readysignal.rt {
//         bytes.extend_from_slice(&rt.to_be_bytes());
//     } else {
//         return Err(io::Error::new(
//             io::ErrorKind::InvalidData,
//             "Missing timestamp (rt) in ReadySignal",
//         ));
//     }

//     // Handle rst (send timestamp) - return an error if None:
//     if let Some(rst) = this_readysignal.rst {
//         bytes.extend_from_slice(&rst.to_be_bytes());
//     } else {
//         return Err(io::Error::new(
//             io::ErrorKind::InvalidData,
//             "Missing send timestamp (rst) in ReadySignal",
//         ));
//     }

//     // Handle re (echo_send) -  use a default value (false) if None:
//     let re = this_readysignal.re.unwrap_or(false); // Default to false if None
//     bytes.push(if re { 1 } else { 0 });

//     // Handle rh (hash list) - append if Some:
//     if let Some(rh) = &this_readysignal.rh {
//         bytes.extend_from_slice(rh);
//     }

//     Ok(bytes)
// }

/// Calculates Pearson hashes for a vector of byte slices.
///
/// This function iterates through the input `data_sets` and calculates the Pearson hash for each slice,
/// returning a vector of the calculated hashes.
///
/// # Arguments
///
/// * `data_sets`: A vector of byte slices to hash.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`: A `Result` containing a vector of the calculated Pearson hashes,
///   or a `ThisProjectError` if an error occurs during hash calculation.
fn calculate_pearson_hashes(data_sets: &[&[u8]]) -> Result<Vec<u8>, ThisProjectError> {
    let mut hashes = Vec::new();
    for data in data_sets {
        let hash = pearson_hash_base(data)?;
        hashes.push(hash);
    }
    Ok(hashes)
}

/// Vanilla Deserilize json signal
/// The idea of the salt-hash or salt-checksum
/// is that it is a faster and more anonymous way
/// to target the goals of packet-soundness checking
/// and spoof-protection
/// while keeping the computer and network load lite
///
///  "Data length" refers to verifying that the received byte slice
/// has enough bytes to successfully extract all the fields of the
/// ReadySignal struct. If the byte slice is too short,
///  attempting to access elements outside its bounds will lead to a "panic".
///
/// Do not attempt to use Serde crate with this function!!!
fn deserialize_ready_signal(bytes: &[u8], salt_list: &[u128]) -> Result<ReadySignal, ThisProjectError> {
    // 1. Calculate the expected minimum length, *including* the hash list.
    /*
    rt: u64, // ready signal timestamp: last file obtained timestamp
    rst: u64, // send-time: generate_terse_timestamp_freshness_proxy(); for replay-attack protection
    b: u8, // Network Index (e.g. which ipv6 in the list)
    rh: Vec<u8>, // N hashes of rt + re
    */
    // debug_log("DRS Starting deserialize_ready_signal");

    let timestamp_len = std::mem::size_of::<u64>();         // Length of a u64 (8 bytes)
    let band_index_len = std::mem::size_of::<u8>();           // Length of the band index (1 byte)
    let hash_list_len = salt_list.len() * std::mem::size_of::<u8>(); // Length of the hash list (4 bytes in current design: 4 salts * 1 byte/hash)
    let expected_len = timestamp_len * 2 + band_index_len + hash_list_len; // Total expected length

    // 2. Full Length Check
    if bytes.len() != expected_len {  // Note: Now a strict equality check
        return Err(ThisProjectError::InvalidData(format!("DRS error: Invalid byte array length for ReadySignal. Expected: {}, Received: {}", expected_len, bytes.len())));
    }

    // 3. Extract rt (receive timestamp)
    let rt = u64::from_be_bytes(bytes[0..timestamp_len].try_into().map_err(|_| ThisProjectError::InvalidData("Failed to convert rst bytes to u64".into()))?);


    // 4. Extract rst (send timestamp)
    let rst_start = timestamp_len;
    let rst_end = rst_start + timestamp_len;
    if bytes.len() < rst_end {
        return Err(ThisProjectError::InvalidData("DRS error: Data too short for rst".into()));
    }
    let rst_bytes = &bytes[rst_start..rst_end];
    let rst = u64::from_be_bytes(rst_bytes.try_into().map_err(|_| ThisProjectError::InvalidData("Failed to convert rst bytes to u64".into()))?);


    // 6. Extract b (network index) -- u8
    let b_start = rst_start + timestamp_len;
    if bytes.len() <= b_start {  // Check length *before* access
        return Err(ThisProjectError::InvalidData("DRS error: Data too short for b".into()));
    }
    let b = bytes[b_start];  // Directly access as u8

    // 7. Extract rh (hash list)  Length Check
    let rh_start = b_start + 1;  // one byte for b
    let rh_end = rh_start + hash_list_len;
    if bytes.len() < rh_end {
        return Err(ThisProjectError::InvalidData("DRS error: Data too short for rh".into()));
    }
    let rh = bytes[rh_start..rh_end].to_vec();

    Ok(ReadySignal { rt, rst, b, rh })
}

/// Deserializes a byte slice into a SendFile struct.
///
/// This function performs the reverse operation of serializing a SendFile struct.
/// It takes a byte slice as input and extracts the fields to construct a SendFile instance.
/// It includes error handling for invalid data lengths and returns a Result to indicate success or failure.
///
/// # Arguments
/// * `bytes`: The byte slice containing the serialized SendFile data.
///
/// # Returns
///
/// * `Result<SendFile, ThisProjectError>`:  A Result containing the deserialized SendFile on success, or a ThisProjectError on failure.
fn deserialize_intray_send_file_struct(bytes: &[u8]) -> Result<SendFile, ThisProjectError> {
    // 1. Check Minimum Length
    let timestamp_len = std::mem::size_of::<u64>();
    let min_length = timestamp_len; // Minimum length for just the timestamp

    debug_log!(
        "DISFS Starting deserialize_intray_send_file_struct() bytes {:?}",
        bytes
    );

    if bytes.len() < min_length {
        debug_log!("DISFS bytes.len() < min_length -> returning: Err(ThisProjectError::InvalidData(\"Invalid byte array length for SendFile\".into()))");
        return Err(ThisProjectError::InvalidData("Invalid byte array length for SendFile".into()));
    }

    debug_log!("DISFS bytes.len() >= min_length");


    // 2. Extract intray_send_time (as before)
    let intray_send_time = u64::from_be_bytes(bytes[0..timestamp_len].try_into().unwrap());

    // 3. Extract intray_hash_list  (Corrected)
    let hash_list_start = timestamp_len;
    let hash_list_end = hash_list_start + 4; // 4 u8 hashes = 4 bytes

    let intray_hash_list = if bytes.len() >= hash_list_end {
        Some(bytes[hash_list_start..hash_list_end].to_vec()) // Extract and wrap in Some()
    } else {
        None // No hash list present (handle as you see fit)
    };

    // 4. Extract gpg_encrypted_intray_file (Corrected)
    let gpg_encrypted_file_start = hash_list_end;
    let gpg_encrypted_intray_file = if bytes.len() > gpg_encrypted_file_start {
        Some(bytes[gpg_encrypted_file_start..].to_vec()) // Extract and wrap in Some()
    } else {
        None // Or handle the empty case appropriately
    };

    // ... [Construction of SendFile as before, but use Some() wrappers]
    Ok(SendFile {
        intray_send_time: Some(intray_send_time),
        gpg_encrypted_intray_file, // No need for clone, the value is already owned
        intray_hash_list,  // Use the corrected Option<Vec<u8>>
    })
}

/// Serializes a `SendFile` struct into a byte vector.
///
/// # Arguments
/// * `send_file`: The `SendFile` instance to serialize.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`:  The serialized `SendFile` data as a `Vec<u8>` on success, or a
///   `ThisProjectError` if serialization fails.
fn serialize_send_file(send_file: &SendFile) -> Result<Vec<u8>, ThisProjectError> {
    let mut serialized_data: Vec<u8> = Vec::new();

    // Add intray_send_time
    serialized_data.extend_from_slice(&send_file.intray_send_time.ok_or(ThisProjectError::InvalidData("Missing intray_send_time".into()))?.to_be_bytes());

    // Add intray_hash_list (handle Option)
    if let Some(hash_list) = &send_file.intray_hash_list {
        serialized_data.extend_from_slice(hash_list);
    } else {
        // Handle the None case. Perhaps return an error or use a default/empty hash list.
        return Err(ThisProjectError::InvalidData("intray_hash_list is None".into()));
    }

    // Add gpg_encrypted_file_contents (handle Option)
    if let Some(encrypted_file) = &send_file.gpg_encrypted_intray_file {
        serialized_data.extend_from_slice(encrypted_file);
    } else {
        return Err(ThisProjectError::InvalidData("gpg_encrypted_intray_file is None".into()));
    }

    Ok(serialized_data)
}

fn serialize_gotit_signal(signal: &GotItSignal) -> std::io::Result<Vec<u8>> {
    let mut bytes = Vec::new();

    bytes.extend_from_slice(&signal.gst.to_be_bytes()); // gst is now u64, no expect needed
    bytes.extend_from_slice(&signal.di.to_be_bytes());  // di is now u64, no expect needed
    bytes.extend_from_slice(&signal.gh);             // gh is now Vec<u8>, no Option

    Ok(bytes)
}

/// File Deserialization (Receiving):
/// Receive Bytes: Receive the byte array from the network using socket.recv_from().
/// Convert to String: Convert the byte array back to a string using String::from_utf8(). This assumes the received bytes are in ASCII encoding.
/// Parse TOML: Parse the TOML string using the toml::from_str() function to create a TOML Value or a custom struct representing the data.
/// Save to File: Write the parsed TOML data to a file using fs::write().
fn receive_toml_file(socket: &UdpSocket) -> Result<(Value, SocketAddr), ThisProjectError> {
    let mut buf = [0; 65536]; // Maximum UDP datagram size
    let (amt, src) = socket.recv_from(&mut buf)?;

    // 2. Convert to string (handling FromUtf8Error)
    let toml_string = String::from_utf8(buf[..amt].to_vec())
        .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e.utf8_error()))?;

    // 3. Parse TOML (handling toml::de::Error)
    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = toml::from_str(&toml_string)?;

    // 4. Save to file (you'll need to determine the file path)
    // ...

    Ok((toml_value, src))
}

fn get_oldest_retry_timestamp(collaborator_username: &str) -> Result<Option<u64>, io::Error> {
    let retry_flags_dir = Path::new("project_graph_data/sync_state_items")
        .join(&collaborator_username)
        .join("fail_retry_flags");

    if !retry_flags_dir.exists() {
        return Ok(None); // No retry flags exist
    }

    let mut oldest_timestamp: Option<u64> = None;

    for entry in fs::read_dir(retry_flags_dir)? {
        let entry = entry?;
        let path = entry.path();

        if path.is_file() {
            let file_name = path.file_name().unwrap().to_str().unwrap();
            if let Some((_, timestamp_str)) = file_name.split_once("__") {
                if let Ok(timestamp) = timestamp_str.parse::<u64>() {
                    if oldest_timestamp.is_none() || timestamp < oldest_timestamp.unwrap() {
                        oldest_timestamp = Some(timestamp);
                    }
                }
            }
        }
    }

    Ok(oldest_timestamp)
}

fn create_retry_flag(
    collaborator: &RemoteCollaboratorPortsData,
    file_path: &PathBuf,
    timestamp: u64,
) -> Result<PathBuf, io::Error> {
    let retry_flags_dir = Path::new("project_graph_data/sync_state_items")
        .join(&collaborator.remote_collaborator_name)
        .join("fail_retry_flags");

    fs::create_dir_all(&retry_flags_dir)?;

    // Generate a unique ID (you might use a UUID library for better uniqueness)
    let unique_id: u64 = rand::random();

    let retry_flag_file_name = format!("{}__{}.txt", unique_id, timestamp);
    let retry_flag_path = retry_flags_dir.join(retry_flag_file_name);

    // Create an empty file (the presence of the file acts as the flag)
    File::create(&retry_flag_path)?;

    Ok(retry_flag_path)
}

fn get_absolute_team_channel_path(team_channel_name: &str) -> io::Result<PathBuf> {

    // let team_channels_dir = Path::new("project_graph_data/team_channels");

    let team_channels_dir = match get_team_channels_homebase_directory_path() {
        Ok(path) => path,
        Err(e) => {
            debug_log!("in get_team_channels_homebase_directory_path()-> Failed to get absolute path: {}", e);
            return Err(e);
        }
    };

    let channel_path = team_channels_dir.join(team_channel_name);

    channel_path.canonicalize() // Get the absolute path
}


/// Safely extracts file extension as a string slice.
///
/// # Project Context
/// In the UMA system, we need to distinguish between .toml and .gpgtoml files
/// to determine if decryption is needed. This helper provides safe extension
/// extraction without unwrap or panic.
///
/// # Arguments
/// - `path` - File path to extract extension from
///
/// # Returns
/// - `Some(&str)` - Extension as string slice (e.g., "toml", "gpgtoml")
/// - `None` - No extension or invalid UTF-8
///
/// # Safety
/// Returns None instead of panicking on invalid paths or non-UTF-8 extensions.
fn get_file_extension_safe(path: &Path) -> Option<&str> {
    path.extension()
        .and_then(OsStr::to_str)
}

/// Prepares a readable TOML path from either .toml or .gpgtoml file.
///
/// # Project Context
/// In the UMA secure collaboration system, files may be stored as:
/// - Plain .toml files (readable directly)
/// - Encrypted .gpgtoml files (must be decrypted to temp directory first)
///
/// This function abstracts that difference, always returning a path to a
/// readable .toml file (either the original or a temporary decrypted copy).
/// The caller can then use standard TOML reading functions on the result.
///
/// # Arguments
/// - `file_path` - Original file path (may be .toml or .gpgtoml)
/// - `extension` - File extension ("toml" or "gpgtoml")
/// - `gpg_fingerprint` - GPG key fingerprint for decryption
/// - `temp_dir` - Base temp directory for decrypted files
///
/// # Returns
/// - `Ok(PathBuf)` - Path to readable .toml file
/// - `Err(String)` - Decryption failed or invalid extension
///
/// # Error Handling
/// Caller should skip the file and continue processing if Err is returned.
/// This is not a fatal error - just means this particular file cannot be
/// processed in this queue-building pass.
///
/// # Security Notes
/// - Temporary decrypted files are managed by the GPG infrastructure
/// - Cleanup of temp files is handled by that infrastructure
/// - This function does not validate cleanup
fn prepare_readable_toml_path(
    file_path: &Path,
    extension: &str,
    gpg_fingerprint: &str,
    temp_dir: &PathBuf,
) -> Result<PathBuf, String> {
    match extension {
        "toml" => {
            // Plain TOML file - use directly
            Ok(file_path.to_path_buf())
        }
        "gpgtoml" => {
            // Encrypted file - decrypt to temp directory
            // Returns Result<String, _>, we need Result<PathBuf, _>
            let temp_path_string = get_pathstring_to_temp_plaintoml_verified_extracted(
                file_path,
                gpg_fingerprint,
                temp_dir,
            )
            .map_err(|e| format!("PRTEP: GPG decryption failed: {:?}", e))?;

            // Convert String to PathBuf
            Ok(PathBuf::from(temp_path_string))
        }
        _ => {
            // Invalid extension (should not reach here due to earlier filtering)
            Err(format!("PRTEP: Invalid extension: {}", extension))
        }
    }
}


#[cfg(test)]
mod get_sendq_tests {
    use super::*;

    #[test]
    fn test_get_file_extension_safe_with_toml() {
        let path = Path::new("/path/to/file.toml");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some("toml"));
    }

    #[test]
    fn test_get_file_extension_safe_with_gpgtoml() {
        let path = Path::new("/path/to/file.gpgtoml");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some("gpgtoml"));
    }

    #[test]
    fn test_get_file_extension_safe_no_extension() {
        let path = Path::new("/path/to/file");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, None);
    }

    #[test]
    fn test_get_file_extension_safe_empty_extension() {
        let path = Path::new("/path/to/file.");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some(""));
    }

    // Note: Additional integration tests would require:
    // - Mock TOML files
    // - Mock GPG decryption infrastructure
    // - Mock directory structure
    // These should be added based on your testing infrastructure
}

/// Checks if a file qualifies for the send queue using incremental field reads.
///
/// # Project Context
/// In the UMA send-queue system, files are sent to collaborators based on
/// a three-tier qualification system:
///
/// 1. **Ownership**: File must be owned by the local user (security boundary)
/// 2. **Access Control**: Remote collaborator must be in the access list (permissions)
/// 3. **Freshness**: File must be newer than last successful send (efficiency)
///
/// This function implements these checks in order, stopping as soon as any
/// check fails (defensive programming + efficiency). We never read more data
/// from a file than necessary to make the qualification decision.
///
/// # Read Order (stops on first failure)
/// 1. Read "owner" field only  if no match, stop (don't read more)
/// 2. Read "teamchannel_collaborators_with_access"  if not in list, stop
/// 3. Read "updated_at_timestamp"  if too old, stop
/// 4. If all pass  return Ok(true)
///
/// # Arguments
/// - `readable_toml_path` - Path to readable .toml file (plain or decrypted)
/// - `localowneruser_name` - Expected owner name
/// - `remote_collaborator_name` - Collaborator to check access for
/// - `timestamp_threshold` - Minimum timestamp for inclusion
///
/// # Returns
/// - `Ok(true)` - File qualifies, should be added to queue
/// - `Ok(false)` - File doesn't qualify (not an error, just doesn't match criteria)
/// - `Err(String)` - File is malformed/unreadable (caller should skip file)
///
/// # Error Handling
/// A return of `Ok(false)` is not an error - it simply means the file doesn't
/// meet the criteria (e.g., owned by different user, collaborator not on list).
/// Only `Err` indicates the file itself has a problem (missing fields, parse errors).
///
/// # Performance
/// Incremental reading means:
/// - If owner doesn't match, we never read the collaborators array
/// - If collaborator not in list, we never read the timestamp
/// - Minimum I/O for disqualified files
fn check_file_qualifications(
    readable_toml_path: &PathBuf,
    localowneruser_name: &str,
    remote_collaborator_name: &str,
    timestamp_threshold: u64,
) -> Result<bool, String> {
    // Convert PathBuf to &str for TOML reading functions
    let toml_path_str = readable_toml_path
        .to_str()
        .ok_or_else(|| "CFQUAL: Path conversion to string failed".to_string())?;

    // =================================================
    // Check 1: Owner must match local user
    // =================================================

    let owner = read_single_line_string_field_from_toml(toml_path_str, "owner")
        .map_err(|e| format!("CFQUAL: Failed to read owner field: {}", e))?;

    if owner != localowneruser_name {
        // Not owned by local user - doesn't qualify (not an error)
        return Ok(false);
    }

    // =================================================
    // Check 2: Remote collaborator must have access
    // =================================================

    let collaborators = read_string_array_field_from_toml(
        toml_path_str,
        "teamchannel_collaborators_with_access",
    )
    .map_err(|e| format!("CFQUAL: Failed to read collaborators field: {}", e))?;

    if !collaborators.contains(&remote_collaborator_name.to_string()) {
        // Collaborator not in access list - doesn't qualify (not an error)
        return Ok(false);
    }

    // =================================================
    // Check 3: File must be newer than threshold
    // =================================================

    let timestamp = read_u64_field_from_toml(toml_path_str, "updated_at_timestamp")
        .map_err(|e| format!("CFQUAL: Failed to read timestamp field: {}", e))?;

    if timestamp <= timestamp_threshold {
        // File is not newer than threshold - doesn't qualify (not an error)
        return Ok(false);
    }

    // =================================================
    // All checks passed - file qualifies
    // =================================================

    Ok(true)
}


/// Gets existing send-Queue or makes a new one: to send out locally owned files: a queue of paths to those files
/// if back_of_queue_timestamp != 0 and
/// if request-time-stamp = send-q back_of_queue_timestamp -> just return timestamp
/// else: make a new timestamp
///
/// can Creates a new send queue based on the provided timestamp and collaborator name.
///
/// This function crawls through the team channel directory tree, looking for TOML files owned by the specified local_owner_user(collaborator).
/// So that the local-owner-user can send their owned files to other collaborators.
/// This function adds file paths to the send queue if the file's `updated_at_timestamp` is greater than the provided `back_of_queue_timestamp`.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `localowneruser_name`: The name of the local-owner-usercollaborator.
/// * `back_of_queue_timestamp`: The timestamp to use as the starting point for the queue. If 0, all files are added to the queue.
///
/// # Returns
///
/// * `Result<SendQueue, ThisProjectError>`: A `Result` containing the new `SendQueue` on success, or a `ThisProjectError` on failure.
fn get_or_create_send_queue(
    team_channel_name: &str,
    localowneruser_name: &str,
    remote_collaborator_name: &str,
    mut session_send_queue: SendQueue,
    ready_signal_rt_timestamp: u64,
    bootstrap_sendqueue: bool,
) -> Result<SendQueue, ThisProjectError> {
    /*

    TODO is this checking for fail-flag dates...or is the done before calling this?

    #[derive(Debug, Clone)]
    struct SendQueue {
        back_of_queue_timestamp: u64,
        // echo_send: bool, //
        items: Vec<PathBuf>,  // ordered list, filepaths
    }
    */
    // let mut back_of_queue_timestamp = session_send_queue.back_of_queue_timestamp.clone();
    debug_log!(
        "inHRCD->get_or_create_send_queue 1: start;  ready_signal_rt_timestamp -> {:?}",
        ready_signal_rt_timestamp
    );

    /*
    Conditions for making a new send_queue

    1. First Time Bootstrap

    2. Backtrack Order: If the ready_signal_rt_timestamp is older
       than session_send_queue.back_of_queue_timestamp
       indicating that the user is requesting a back-track.

    3. Prefail Flag Check: If there is a fail flag,
       remake the queue with that timestamp

    'normally' only one queue is ever made,
    and that queue most-times remains empty with nothing sent
    unless and until a new local-owned-filed is made and added to the queue
    which should be checked for ~last.
    */
    let mut make_a_new_queue_flag = false;
    if bootstrap_sendqueue {
        make_a_new_queue_flag = true;
    }
    debug_log!(
        "inHRCD->get_or_create_send_queue: bootstrap_sendqueue={:?}, make_a_new_queue_flag={:?}",
        bootstrap_sendqueue,
        make_a_new_queue_flag
    );
    /*
    It is not clear that this comparison needs to be done:
    ready_signal_rt_timestamp == session_send_queue.back_of_queue_timestamp

    because preset-fail-flags are set, moving ahead cannot be done
    unless a confirmed gotit recept (of a confirmed file recept) happens.
    changing the back_of_queue_timestamp date may have no advanstage
    (or maybe some use will be discovered, likely it is not harmful)
    */

    debug_log("inHRCD->get_or_create_send_queue  checking: ready_signal_rt_timestamp < back_of_queue_timestamp");
    // Backtrack Order
    // if remote collaborator requests a reset to an older time (ah, those were the days...)
    // set the back_of_queue_timestamp to be sent .rt time ... if the .rt is older
    if ready_signal_rt_timestamp < session_send_queue.back_of_queue_timestamp {
        session_send_queue.back_of_queue_timestamp = ready_signal_rt_timestamp;
        make_a_new_queue_flag = true;
        debug_log("inHRCD->get_or_create_send_queue: found: ready_signal_rt_timestamp < back_of_queue_timestamp, make_a_new_queue_flag = true");
    }

    ///////////////////////////////////
    // Prefail Flag Check on Isle Five
    ///////////////////////////////////
    match get_oldest_sendfile_prefailflag_rt_timestamp_or_0_w_cleanup(&remote_collaborator_name) {
        Ok(oldest_prefail_flag_rt_timestamp) => {
            // 2. Now you can compare: (zero means no timestamps exist)
            if oldest_prefail_flag_rt_timestamp != 0 {
                // 3. Reset the send queue:
                session_send_queue = SendQueue {
                    back_of_queue_timestamp: oldest_prefail_flag_rt_timestamp,
                    items: Vec::new(),
                };
                debug_log!("inHRCD->get_or_create_send_queue  Resetting send queue using timestamp from flag: {}", oldest_prefail_flag_rt_timestamp);
                debug_log("inHRCD->get_or_create_send_queue: found: prefailflag(s), make_a_new_queue_flag = true");
                make_a_new_queue_flag = true
            } else {
                debug_log("inHRCD->get_or_create_send_queue  No retry flags found. Using ReadySignal timestamp.");
                // Handle the case where no pre-fail flags were found. Perhaps use the timestamp from the ready signal?
                session_send_queue.back_of_queue_timestamp = ready_signal_rt_timestamp
            }
        }
        Err(e) => {
            // 4. Handle the error:
            debug_log!("inHRCD->get_or_create_send_queue  Error getting oldest retry timestamp: {}", e);
            // Decide how to handle the error. You might:
            // - continue; // Skip to the next iteration
            // - return Err(e); // Or wrap the error: return Err(ThisProjectError::from(e));
            // - use a default timestamp: back_of_queue_timestamp = 0;

            debug_log("inHRCD->get_or_create_send_queue: error, so: make_a_new_queue_flag = true");
            make_a_new_queue_flag = true
        }
    }

    // 1. Get the path RESULT
    let team_channel_path_result = get_absolute_team_channel_path(team_channel_name);


    // 2. HANDLE the Result from get_absolute_team_channel_path()
    let team_channel_path = match team_channel_path_result {
        Ok(path) => path,
        Err(e) => {
            debug_log!("inHRCD->get_or_create_send_queue 4: Error getting absolute team channel path: {}", e);
            return Err(e.into());  // Or handle the error differently
        }
    };


    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(format!(
                "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            ).into());
        }
    };

    // code from load_core_node...()
    // Get the UME temp directory path with proper GpgError conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| GpgError::ValidationError(
            format!("Failed to get UME temp directory path: {}", io_err)
        ))?;



    // --- 3. Make a new Queue ---
    debug_log!("inHRCD->get_or_create_send_queue 5: no crawl if false, make_a_new_queue_flag -> {:?}", make_a_new_queue_flag);

    if make_a_new_queue_flag {
        debug_log!("inHRCD->get_or_create_send_queue 5: Starting crawl of directory: {:?}", team_channel_path);

        // Operational metrics
        let mut files_encountered: usize = 0;
        let mut files_skipped: usize = 0;
        let mut files_added_to_queue: usize = 0;

        // Walk directory and process each file
        for entry in WalkDir::new(&team_channel_path) {
            files_encountered += 1;

            // Get directory entry, skip on any error
            let entry = match entry {
                Ok(e) => e,
                Err(e) => {
                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue: WalkDir entry error (skipping): {}",
                        e
                    );
                    files_skipped += 1;
                    continue;
                }
            };

            // Only process regular files
            if !entry.file_type().is_file() {
                continue;
            }

            // Get file extension safely
            let extension = match get_file_extension_safe(entry.path()) {
                Some(ext) if ext == "toml" || ext == "gpgtoml" => ext,
                _ => {
                    // Not a TOML file, skip silently
                    continue;
                }
            };

            #[cfg(debug_assertions)]
            debug_log!(
                "inHRCD->get_or_create_send_queue 6: Processing file: {:?}, extension: {}",
                entry.path(),
                extension
            );

            // Prepare readable TOML path (decrypt .gpgtoml if needed)
            let readable_path = match prepare_readable_toml_path(
                entry.path(),
                extension,
                &gpg_full_fingerprint_key_id_string,
                &base_uma_temp_directory_path,
            ) {
                Ok(p) => p,
                Err(e) => {
                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue: Failed to prepare readable path for {:?}: {} (skipping)",
                        entry.path(),
                        e
                    );
                    files_skipped += 1;
                    continue;
                }
            };

            // Check if file qualifies for send queue (incremental checks)
            match check_file_qualifications(
                &readable_path,
                localowneruser_name,
                remote_collaborator_name,
                session_send_queue.back_of_queue_timestamp,
            ) {
                Ok(true) => {
                    // File qualifies - add ORIGINAL path to queue
                    session_send_queue.items.push(entry.path().to_path_buf());
                    files_added_to_queue += 1;

                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue 10: Added to queue: {:?}",
                        entry.path()
                    );
                }
                Ok(false) => {
                    // File doesn't qualify (not an error)
                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue: File doesn't qualify: {:?}",
                        entry.path()
                    );
                }
                Err(e) => {
                    // File is malformed or unreadable
                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue: File read/parse error for {:?}: {} (skipping)",
                        entry.path(),
                        e
                    );
                    files_skipped += 1;
                }
            }
        }

        // Log metrics
        #[cfg(debug_assertions)]
        debug_log!(
            "inHRCD->get_or_create_send_queue: Crawl complete - encountered: {}, skipped: {}, added: {}",
            files_encountered,
            files_skipped,
            files_added_to_queue
        );
    }

    debug_log("inHRCD-> get_or_create_send_queue 11: calling, get_toml_file_updated_at_timestamp(), Hello?");

    // if make_a_new_queue_flag {
    //     debug_log!("inHRCD->get_or_create_send_queue 5: Starting crawl of directory: {:?}", team_channel_path);
    //     /*
    //     Make a full-new send-queue:

    //     This is a big heavy-lifting task, but it usually
    //     only needs to be done once.

    //     Only when a new send-queue is needed,
    //     get the paths of files
    //     for only files that are owned by you
    //     for only files in the current team_channel
    //     for only files where current remote collaborator is on the list of teamchannel_collaborators_with_access
    //     for only files dated after (younger than) the .rt ready_signal_rt_timestamp
    //     which is not the time the ready-signal was sent, but is
    //     the updated_at timestamp
    //     of the last received-by-them sent-by-you file.

    //     This is made less-simple by clearsigned-toml and .gpgtoml

    //     */





    //     // // ...Use the unwrapped PathBuf with WalkDir
    //     // for entry in WalkDir::new(&team_channel_path) { // Note the & for borrowing
    //     //     let entry = entry?;
    //     //     if entry.file_type().is_file() && entry.path().extension() == Some(OsStr::new("toml")) {
    //     //         debug_log!("inHRCD->get_or_create_send_queue 6: file is toml, entry -> {:?}", entry);
    //     //         // If a .toml file
    //     //         let toml_string = fs::read_to_string(entry.path())?;

    //     //         // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    //     //         let toml_value: Value = toml::from_str(&toml_string)?;

    //     //         // If owner = target collaborator
    //     //         if toml_value.get("owner").and_then(Value::as_str) == Some(localowneruser_name) {
    //     //             debug_log!("inHRCD->get_or_create_send_queue 7: file owner == colaborator name {:?}", toml_value);

    //     //             // if current remote collaborator is on the list of teamchannel_collaborators_with_access

    //     //             // 1. Get collaborators for this file (if available):
    //     //             let file_collaborators: Vec<String> = toml_value
    //     //                 .get("teamchannel_collaborators_with_access") // Must match the key in your TOML files
    //     //                 .and_then(Value::as_array)
    //     //                 .map(|arr| arr.iter().filter_map(Value::as_str).map(String::from).collect())
    //     //                 .unwrap_or_default();  // Handle case where the field is missing


    //     //             // 2. Check if remote collaborator is in the access list:
    //     //             if file_collaborators.contains(&remote_collaborator_name.to_string()) {  // Accessing remote_collaborator_name correctly here
    //     //                 debug_log!(
    //     //                     "inHRCD->get_or_create_send_queue 8, access: file_collaborators=>{:?} vs. remote_collaborator_name=>{:?}",
    //     //                     file_collaborators,
    //     //                     remote_collaborator_name,
    //     //                 );

    //     //                 // If updated_at_timestamp exists
    //     //                 if let Some(toml_updatedat_timestamp) = toml_value.get("updated_at_timestamp").and_then(Value::as_integer) {
    //     //                     debug_log!(
    //     //                         "inHRCD->get_or_create_send_queue 9: updated_at_timestamp=>{:?} vs. rt=>{:?}",
    //     //                         toml_updatedat_timestamp,
    //     //                         ready_signal_rt_timestamp,
    //     //                     );
    //     //                     let toml_updatedat_timestamp = toml_updatedat_timestamp as u64;

    //     //                     // If updated_at_timestamp > back_of_queue_timestamp (or back_of_queue_timestamp is 0)
    //     //                     // if timestamp > back_of_queue_timestamp || back_of_queue_timestamp == 0 {
    //     //                     if toml_updatedat_timestamp > session_send_queue.back_of_queue_timestamp {
    //     //                         debug_log("inHRCD->get_or_create_send_queue 10: timestamp > back_of_queue_timestamp");
    //     //                         // Add filepath to send_queue
    //     //                         session_send_queue.items.push(entry.path().to_path_buf());
    //     //                     }
    //     //                 }
    //     //             } else {
    //     //                 debug_log!(
    //     //                     "get_or_create_send_queue, Collaborator '{}' does not have access to file: {:?}",
    //     //                     remote_collaborator_name,
    //     //                     entry.path()
    //     //                 );
    //     //             }
    //     //         }
    //     //     }
    //     // }
    // }

    // debug_log("inHRCD-> get_or_create_send_queue 11: calling, get_toml_file_updated_at_timestamp(), Hello?");


    // Get update flag paths
    let newpath_list = match get_sendq_update_flag_paths(
        team_channel_name, // No & needed now
        localowneruser_name, // Correct collaborator name
    ) {
        Ok(paths) => paths,
        Err(e) => {
            debug_log!("inHRCD->get_or_create_send_queue 2: Error getting update flag paths: {}", e);
            return Err(e); // Or handle as needed
        }
    };

    // Add new paths to the front of the queue
    for this_iter_newpath in newpath_list {
        session_send_queue.add_to_front_of_sendq(this_iter_newpath); // Use the new method
    }

    //////////////
    // New Files
    //////////////
    // Check for new-file flags, add those to the queue
    // this needs to be done ~last (before sorting is ok)

    // // --- Get new file paths and add them to the send queue ---
    // let new_file_paths_result = read_all_newfile_sendq_flags_w_cleanup(
    //     remote_collaborator_name,
    //     &team_channel_name,
    // );

    // // add to sendqueue
    // match new_file_paths_result {
    //     Ok(new_file_paths) => {
    //         session_send_queue.items.extend(new_file_paths); // Extend the items Vec directly
    //     },
    //     Err(e) => {
    //         debug_log!("Error reading new file flags: {}", e);
    //         // Handle error as needed
    //     }
    // };

    // Sort the files in the queue based on their modification time
    debug_log("Sequence of queue should be yougnest last, oldest first");
    session_send_queue.items.sort_by_key(|path| {
        get_toml_file_updated_at_timestamp(path).unwrap_or(0) // Handle potential errors in timestamp retrieval
        // std::cmp::Reverse(get_toml_file_updated_at_timestamp(path).unwrap_or(0)) // puts older items' first in queue
    });

    // reverse order so oldest are at the front
    session_send_queue.items.reverse();

    debug_log!(
        "session_send_queue.items -> {:?}",
        session_send_queue.items
    );

    // remove duplicates
    session_send_queue.items = remove_duplicates_from_path_array(session_send_queue.items);

    // Remove duplicates?

    // TODO(remove this later) extra Inspection here:
    debug_log("|| Extra Insepction || get_or_create_send_queue: end: Q");
    debug_log!(
        "inHRCD->get_or_create_send_queue 12: start;  ready_signal_rt_timestamp -> {:?}",
        ready_signal_rt_timestamp
    );
    debug_log!("inHRCD->get_or_create_send_queue 13: end: Q -> {:?}", session_send_queue);

    // Testing?
    // 1.5.6 Sleep for a duration (e.g., 100ms)
    // thread::sleep(Duration::from_millis(100000));

    Ok(session_send_queue)
}



/// get latest Remote Collaborator file timestamp
/// for use by handl local owner desk
///
///
/// This is one of those values and functions that can be confusing
/// because both you and your remote collaborate have quasi-mirror-image sync systems
/// with reversed roles. Both of you are making 'latest_received' timestamps
/// and both of you are using your and their 'latest_received' timestamps,
/// which are simultanously 'the same' abstract value but very different local-context-role-specific values
///
/// note: this result should usuall be saved e.g. with
/// write_save_latest_received_from_rc_file_timestamp_plaintext()
fn get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl(
    collaborator_name: &str,
) -> Result<u64, ThisProjectError> {
    let mut last_timestamp: u64 = 0; // Initialize with 0 (for bootstrap when no files exist)
    debug_log!("get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl() started");

    let channel_dir_path_str = read_state_string("current_node_directory_path.txt")?; // read as string first
    debug_log!("get_latest_received_from_rc... 1. Channel directory path (from session state): {}", channel_dir_path_str);
    // Crawl through the team channel directory
    for entry in WalkDir::new(channel_dir_path_str) {
        let entry = entry?;
        let path = entry.path();

        if path.is_file() && path.extension() == Some(OsStr::new("toml")) {
            let toml_string = fs::read_to_string(path)?;

            // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
            let toml_value: Value = toml::from_str(&toml_string)?;

            // Check if the file is owned by the collaborator
            if toml_value.get("owner").and_then(Value::as_str) == Some(collaborator_name) {
                // Get the updated_at_timestamp
                if let Some(this_timestamp) = toml_value
                    .get("updated_at_timestamp")
                    .and_then(Value::as_integer)
                    .map(|ts| ts as u64) // Convert to u64
                {
                    debug_log!(
                        "rc: path({:?}) -> this_timestamp={:?} <-> last_timestamp{:?}",
                        path,
                        this_timestamp,
                        last_timestamp,
                    );
                    if this_timestamp > last_timestamp {
                        last_timestamp = this_timestamp;
                    }
                }
            }
        }
    }

    debug_log!(
        "get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl() -> last_timestamp {:?}",
        last_timestamp
    );

    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

    // update state: latest received timestamp
    write_save_latest_received_from_rc_file_timestamp_plaintext(
        &team_channel_name, // for team_channel_name
        &collaborator_name, // for collaborator_name
        last_timestamp, // for timestamp
    );

    Ok(last_timestamp) // Returns 0 if no matching files are found
}


/// Waits and checks indefintely until either a legitimate ready signal or exit uma
/// Retrieves SocketAddrs for the remote collaborator's ready and "got it" ports.
/// and saves remote collaborator IP band info
///
/// Continually, as when a remote collaborator may be never or belatedly online:
/// Iterates through the ipv6 and ipv4 addresses, listening for a ReadySignal. Returns SocketAddrs
/// for the ready and "got it" ports on the first valid IP. Directly uses UdpSocket::bind for
/// improved simplicity and efficiency. Does One Thing Well.
///
/// # Arguments
///
/// * `room_sync_input`: The collaborator's connection data.
///
/// # Returns
///
/// * `Result<(SocketAddr, SocketAddr), ThisProjectError>`:
/// Tuple of SocketAddrs (ready, gotit), or an error.
///
fn get_rc_band_ready_gotit_socketaddrses_hrcd(
    room_sync_input: &ForRemoteCollaboratorDeskThread,
) -> Result<(SocketAddr, SocketAddr), ThisProjectError> {
    let timeout_duration = Duration::from_secs(15);
    let mut buf = [0; 1024];

    // --- 1. Load Local Band Information (as before) ---
    debug_log("get_rc_band...HRCD: 1. load local band");
    let (
        local_network_type,
        _, // local_network_index is not used here
        local_ipv4,
        local_ipv6,
    ) = read_band__network_config_type_index_specs()?;


    // --- 2. Determine Local IP Address (as before) ---
    debug_log("get_rc_band...HRCD: 2. load local band");
    let local_ip = match local_network_type.as_str() {
        "ipv6" => IpAddr::V6(local_ipv6),
        "ipv4" => IpAddr::V4(local_ipv4),
        _ => return Err(ThisProjectError::NetworkError("get_rc_band_..._hrcd Invalid local network type".into())),
    };


    // 3. Create SocketAddr for Listening (as before)
    debug_log("get_rc_band...HRCD: 3. SocketAddr for Listening");
    let ready_socket_addr = SocketAddr::new(
        local_ip,
        room_sync_input.remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip,
    );


    // --- 4. Bind Socket (outside the loop) ---
    debug_log("get_rc_band...HRCD: 4. create_rc_udp_socket(ready_socket_addr)");
    let socket = create_rc_udp_socket(ready_socket_addr)?;

    // --- 5. Enter Loop to Continuously Listen ---
    debug_log("get_rc_band...HRCD: 5. loop");
    loop { // Main listening loop
        // 5.1 Check for UMA shutdown
        if should_halt_uma() {
            return Err(ThisProjectError::NetworkError("get_rc_band_..._hrcd UMA halt signal received during band handshake".into()));
        }

        debug_log!("get_rc_band...HRCD: 5.1 Listening for ReadySignal on: {:?}", ready_socket_addr);

        // 5.2 Set Timeout (inside loop, in case it's reset by recv)
        socket.set_read_timeout(Some(timeout_duration))?;

        // 5.3 Receive and Process
        match receive_ready_signal_with_timeout(&socket, &mut buf, &room_sync_input.remote_collaborator_salt_list) {
            Ok(Some((_, ready_signal))) => {
                debug_log("get_rc_band...HRCD: 5.3 Receive and Process");
                // Note: this Hash Verification  is already performed inside receive_ready_signal_with_timeout()
                // 5.3.1 Hash and Timestamp Verification (Perform checks *inside* the Ok case)
                // if !verify_readysignal_hashes(&ready_signal, &room_sync_input.remote_collaborator_salt_list) {
                //     debug_log!("get_rc_band_..._hrcd ReadySignal hash verification failed. Discarding and continuing to listen.");
                //     continue; // Continue to listen for a valid signal
                // }

                let current_timestamp = get_current_unix_timestamp();
                if ready_signal.rst > current_timestamp + 5 || current_timestamp - 10 > ready_signal.rst {
                    debug_log!("get_rc_band_..._hrcd Received outdated or future-dated ReadySignal. Discarding and continuing to listen.");
                    continue; // Continue listening
                }

                // --- 5.3.2 Extract and Save Remote Band Information ---
                debug_log("get_rc_band...HRCD: 5.3.2 Extract and Save Remote");
                // let (rc_network_type, rc_network_index) = decompress_banddata_byte(ready_signal.b);
                let (rc_network_type, rc_network_index) = { // Create a new inner scope here
                    let band_result = decompress_banddata_byte(ready_signal.b);
                    debug_log!(
                        "get_rc_band...HRCD: 5.3.2 Extract and Save -> band_result: {:?}",
                        band_result,
                        );

                    match band_result {
                        Ok((tempnetworktype, tempnetworkindex)) => (tempnetworktype, tempnetworkindex), // Assign values.
                        Err(e) => {
                            debug_log!("Error decompressing band data: {}. Skipping.", e);
                            continue;  // Skip to next iteration if an error occurs during decompression.
                        }
                    }
                };

                // --- Select IP for "got it" signal ---
                let rc_ip = match get_ip_from_index_and_type(
                    &room_sync_input.remote_collaborator_ipv4_addr_list,
                    &room_sync_input.remote_collaborator_ipv6_addr_list,
                    &rc_network_type,
                    rc_network_index,
                ) {
                    Some(ip) => ip,
                    None => {
                        debug_log!("get_rc_band_..._hrcd Failed to get remote collaborator IP address from received network index and type. Continuing to listen.");
                        continue; // Continue listening for valid signal
                    }
                };
                let gotit_socket_addr = SocketAddr::new(rc_ip, room_sync_input.remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip);  // Correct port from room_sync_input

                // --- Write/Save Received Band Data ---
                let team_channel_name = match get_current_team_channel_name_from_nav_path() {
                    Some(name) => name,
                    None => {
                        debug_log!("Error: get_rc_band_ Could not get current channel name. Skipping set_as_active.");
                        return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
                    },
                };

                debug_log("get_rc_band...HRCD: next: write_save_rc_bandnetwork_type_index");
                write_save_rc_bandnetwork_type_index(
                    room_sync_input.remote_collaborator_name.clone(),
                    team_channel_name,
                    rc_network_type,
                    rc_network_index,
                    local_ipv4,
                    local_ipv6,
                )?;

                // --- 5.4 Return Socket Addresses (Valid Signal Received) ---
                return Ok((ready_socket_addr, gotit_socket_addr)); // Return SocketAddrs on success
            }
            Ok(None) => {
                // 5.5 Handle timeout (Ok(None) from receive_ready_signal_with_timeout) - Just continue listening
                debug_log!("get_rc_band_..._hrcd Timeout waiting for ReadySignal. Continuing to listen.");
                continue; // Continue listening. The loop handles the timeout. No explicit error.
            },
            Err(e) => {
                debug_log!("get_rc_band_ready_gotit_socketaddrses_hrcd: Error receiving ReadySignal: {}", e);
                return Err(e); // Return any other errors
            }
        }
    } // End of main listening loop
}

/// Gets the IP address from combined IPv4/IPv6 lists based on index and type.
///
/// # Arguments
///
/// * `ipv4_list`: A slice of IPv4 addresses.
/// * `ipv6_list`: A slice of IPv6 addresses.
/// * `network_type`: The network type string.
/// * `network_index`: The index into the appropriate list.
///
/// # Returns
///
/// * `Option<IpAddr>`: The `IpAddr` at the given index and type, or `None` if the index is out of bounds or the network type is invalid.
fn get_ip_from_index_and_type(
    ipv4_list: &[Ipv4Addr],
    ipv6_list: &[Ipv6Addr],
    network_type: &str,
    network_index: u8
) -> Option<IpAddr> {
    match network_type {
        "ipv4" => ipv4_list.get(network_index as usize).map(|&ip| IpAddr::V4(ip)),
        "ipv6" => ipv6_list.get(network_index as usize).map(|&ip| IpAddr::V6(ip)),
        _ => None, // Or handle an invalid network type in another way
    }
}

/// Receives a ReadySignal with a timeout, performing hash and timestamp verification.
/// Goal purpose and scope: screening valid packets to verify a live-ip
///
/// This function now includes both hash verification and timestamp freshness checks.
///
/// # Arguments
///
/// * `socket`: The UDP socket to receive data on.
/// * `buf`: A mutable buffer to store the received data.
/// * `salt_list`: The salt list for hash verification.
///
/// # Returns
///
/// * `Result<Option<SocketAddr>, ThisProjectError>`: The sender's `SocketAddr` on success, an error, or `Ok(None)` on timeout.
fn receive_ready_signal_with_timeout( // Hash and timestamp checks moved HERE!
    socket: &UdpSocket,
    buf: &mut [u8],
    senders_salt_list: &[u128],
) -> Result<Option<(SocketAddr, ReadySignal)>, ThisProjectError> { // Changed to return the signal
    debug_log!("receive_ready_signal_with_timeout(): Starting...");

    let timeout_duration = Duration::from_secs(15);

    socket.set_read_timeout(Some(timeout_duration))?;

    match socket.recv_from(buf) {
        Ok((amt, src)) => {
            debug_log!("receive_ready_signal_with_timeout(): Received {} bytes from {}", amt, src);

            // 1. Deserialize
            let ready_signal = match deserialize_ready_signal(&buf[..amt], senders_salt_list) { // Deserialize first.  Use the passed-in senders_salt_list
                Ok(signal) => signal,
                Err(e) => {
                    debug_log!("receive_ready_signal_with_timeout():  Failed to deserialize ReadySignal: {}", e);
                    return Err(e);  // Or continue to listen for the next signal
                },
            };

            // 2. Hash Verification: PERFORM HASH CHECK HERE!
            if !verify_readysignal_hashes(&ready_signal, senders_salt_list) { // Hash verification alongside timestamp check
                debug_log!("receive_ready_signal_with_timeout(): ReadySignal hash verification failed. Discarding.");
                return Ok(None); // Or continue to listen, but return nothing.
            };
            debug_log!("receive_ready_signal_with_timeout(): ReadySignal hashes verified.");

            // 3. Timestamp Freshness Check: PERFORM TIMESTAMP CHECK HERE!
            let current_timestamp = get_current_unix_timestamp();
            if ready_signal.rst > current_timestamp + 5 || current_timestamp - 10 > ready_signal.rst {  // Freshness check, combined
                debug_log!("receive_ready_signal_with_timeout(): Received outdated or future-dated ReadySignal.  Discarding.");
                return Ok(None); // Indicate invalid signal without returning an Error.
            };
            debug_log!("receive_ready_signal_with_timeout():  ReadySignal timestamp verified.");

            // 4. Return the source address and ReadySignal if all checks pass.
            Ok(Some((src, ready_signal))) // Include ReadySignal
        },

        Err(e) if e.kind() == ErrorKind::WouldBlock => {
            debug_log!("receive_ready_signal_with_timeout(): Timeout");
            Ok(None) // Correct handling of timeout, not returning an error!
        }
        Err(e) => {
            debug_log!("receive_ready_signal_with_timeout(): Error receiving data: {}", e);
            Err(ThisProjectError::NetworkError(e.to_string()))
        },
    }
}

/// TODO: What on earth is this thing???
///
/// Gets the latest `updated_at_timestamp` from the current team channel's files.
///
/// This function crawls through the current team channel's directory and retrieves
/// the most recent `updated_at_timestamp` from the TOML files it finds.
///
/// # Returns
///
/// `Result<u64, ThisProjectError>`:  The latest timestamp, or an error if the directory read fails, a TOML file cannot be parsed, or the updated_at_timestamp is invalid.
fn get_latest_timestamp_from_team_channel_dir() -> Result<u64, ThisProjectError> {
    let mut latest_timestamp = 0u64; // Initialize to zero

    let channel_dir_path_str = match read_state_string("current_node_directory_path.txt") {
        Ok(s) => s,
        Err(e) => {
            debug_log!("Error reading channel directory path: {}", e);
            return Err(e.into()); // Or handle error differently
        }
    };

    //  Crawl through the team channel directory
    for entry in WalkDir::new(channel_dir_path_str) {
        let entry = entry?; // Check for WalkDir errors
        let path = entry.path();
        if path.is_file() && path.extension() == Some(OsStr::new("toml")) {
            match get_toml_file_updated_at_timestamp(path) {
                Ok(timestamp) => {
                    if timestamp > latest_timestamp {
                        latest_timestamp = timestamp;
                    }
                },
                Err(e) => {
                    debug_log!("Error reading or parsing TOML file: {:?} - {}", path, e);
                    // Handle the error as you see fit. Perhaps continue or return the error.
                    continue; // Skip to the next file
                },
            };
        }
    }
    Ok(latest_timestamp)
}

/// handle_remote_collaborator_meetingroom_desk (send files here)
/// very brief overview:
/// 1. listen for got-it signals and remove fail-flags (yes, their 'last' 3rd step is actually done first)
/// 2. listen for 'ready' signal
/// 3. send one send-queue item at at time & update send-queue (pop item and update back_of_queue_timestamp)
///
/// delete/rewrite:
/// ```path
/// sync_data/team_channel/collaborator_name/back_of_queue_timestamp
/// ```
///
/// Error Handling:
/// 1. Distinguish Between Error Types: Not all errors are equal. Some errors might be transient (e.g., WouldBlock indicating no data is available yet), while others might be fatal (e.g., a socket error).
/// 2. Handle Transient Errors: For transient errors, we can simply continue the loop and try to receive data again.
/// 3. Handle Fatal Errors: For fatal errors, we should log the error, potentially notify the user, and consider exiting the function or the entire sync process.
///
/// TODO add  "workflow" steps: handle_remote_collaborator_meetingroom_desk()
fn handle_remote_collaborator_meetingroom_desk(
    room_sync_input: &ForRemoteCollaboratorDeskThread,
) -> Result<(), ThisProjectError> {
    /*


    */
    loop { // 1. start overall loop to restart whole desk
        // --- 1. overall loop to restard handler in case of failure ---
        //  1.1 Check for halt signal.
        if should_halt_uma() {
            debug_log!(
                "HRCD 1.1 Check for halt signal. Halting handle_remote_collaborator_meetingroom_desk() for {}",
                room_sync_input.remote_collaborator_name
            );
            break;
        }

        debug_log!(
            "\n Started HRCD the handle_remote_collaborator_meetingroom_desk() for->{}",
            room_sync_input.remote_collaborator_name
        );
        debug_log!(
            "HRCD room_sync_input -> {:?}",
            room_sync_input
        );

        /////////////
        // Bootstrap
        /////////////

        debug_log("HRCD calling get_current_team_channel_name_from_nav_path");

        // TODO
        // setup: Get Team Channel Name
        let team_channel_name = get_current_team_channel_name_from_nav_path()
            .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

        // 1.2 Get Remote Collaborator's IP and Network Type
        debug_log("HRCD starting search for Remote Collaborator's IP");

        let (ready_socket_addr, gotit_socket_addr) =
            match get_rc_band_ready_gotit_socketaddrses_hrcd(room_sync_input) {
                Ok(addrs) => addrs,
                Err(e) => {
                    debug_log!("HRCD: Error getting SocketAddrs: {}", e);
                    return Err(e);
                }
            };

        debug_log!(
            "HRCD get_rc_band_ready_gotit_socketaddrses_hrcd: RC -> {:?} || ready_socket_addr -> {:?} || gotit_socket_addr -> {:?}",
            room_sync_input.remote_collaborator_name,
            ready_socket_addr,
            gotit_socket_addr
        );




        // 1. UPD Handshake
        // hrcd_udp_handshake(&room_sync_input);



        // --- 1.3 Create two UDP Sockets for Ready and GotIt Signals ---`
        debug_log("HRCD 1.3 Making ready_port listening UDP socket...");
        let ready_socket = create_rc_udp_socket(ready_socket_addr)?;

        debug_log("HRCD 1.3 Making gotit_port listening UDP socket...");
        let gotit_socket = create_rc_udp_socket(gotit_socket_addr)?;

        // --- 1.4 Initialize (empty for starting) Send Queue ---
        // let mut session_send_queue: Option<SendQueue> = None;
        // 1.4 Initialize Send Queue (empty, with zero timestamp)
        let mut session_send_queue = SendQueue {
            back_of_queue_timestamp: 0,
            items: Vec::new(),
        };

        debug_log!(
            // this does require &
            "HRCD 1.5.2 check: new session_send_queue.items -> {:?} (Should be empty...)",
            session_send_queue.items
        );

        let remote_collaborator_name_clone = room_sync_input.remote_collaborator_name.clone();

        // --- HRCD 1.5 Spawn a thread to handle recieving GotItSignal(s) and SendFile prefail-flag removal ---
        // let gotit_thread
        let _ = thread::spawn(move || {
            //////////////////////////////////////
            // Listen for 'I got it' GotItSignal
            ////////////////////////////////////

            loop { // gotit loop
                debug_log(
                    "HRCD Got it loop starting. GotItloop"
                );
                // 1.5.1 Check for halt-uma signal
                if should_halt_uma() {
                    debug_log!("HRCD 1.5.1 GotItloop Got It loop: Halt signal received. Exiting. in handle_remote_collaborator_meetingroom_desk");
                    break; // Exit the loop
                }

                // 1.5.2 Receive and handle "Got It" signals // under construction TODO
                let mut buf = [0; 1024];
                match gotit_socket.recv_from(&mut buf) {
                    Ok((amt, src)) => {

                        // Check for exit-signal:
                        if should_halt_uma() {
                            debug_log(
                                "HRCD 1.5.2 should_halt_uma() Halting handle_remote_collaborator_meetingroom_desk",
                            );
                            break;
                        }

                        debug_log!("HRCD 1.5.2 GotItloop Ok((amt, src)) Received {} bytes from {} on gotit port", amt, src);

                        // --- Inspect Raw Bytes ---
                        debug_log!(
                            // this does require &
                            "HRCD 1.5.2 GotItloop Raw bytes received: {:?}",
                            &buf[..amt]
                        );

                        // --- Inspect Bytes as Hex ---
                        let hex_string = buf[..amt].iter()
                            .map(|b| format!("{:02X}", b))
                            .collect::<String>();
                        debug_log!("HRCD 1.5.2 GotItloop Raw bytes as hex: {}", hex_string);

                        // Clone the values you need from room_sync_input
                        // let remote_collaborator_name = room_sync_input.remote_collaborator_name.clone();

                        // 1.5.3 Deserialize the GotItSignal
                        let gotit_signal: GotItSignal = match process_incoming_gotit_signal_bytes(&buf[..amt]) {
                            Ok(gotit_signal) => {
                                debug_log!("HRCD 1.5.3 GotItloop Ok(gotit_signal) : Received GotItSignal: {:?}",
                                    // remote_collaborator_name,
                                    gotit_signal
                                ); // Log the signal
                                gotit_signal
                            },
                            Err(e) => {
                                debug_log!("HRCD 1.5.3 GotItloop Err Receive data Failed to parse ready signal: {}", e);
                                continue; // Continue to the next iteration of the loop
                            }
                        };

                        // 1.5.4  get document_id from signal
                        let document_id = gotit_signal.di;

                        debug_log(
                            "HRCD: Done event of got-it listener."
                        );

                        // 1.5.5 check and remove filestubs with name==document_id
                        /*
                        If match
                        Remove From:
                        ```path
                        sync_data/team_channel/fail_flags/NAME-of-COLLABORATOR/DOC-ID
                        ```
                        */

                        let _ = remove_one_prefail_flag__for_sendfile(
                            document_id, // di_flag_id: String,
                            &remote_collaborator_name_clone, // remote_collaborator_name: String,
                            &team_channel_name, // team_channel_name: String,
                        );
                        // 1.5.6 update ~timestamp_of_latest_received_file_that_i_sent

                    // // 1.5.7 Sleep for a short duration (e.g., 100ms)
                    // thread::sleep(Duration::from_millis(1000));

                    },
                    Err(e) => {
                        debug_log!("HRCD 1.5 GotItloop Error receiving data on gotit_port: {}", e);
                        // You might want to handle the error more specifically here (e.g., retry, break the loop, etc.)
                        // For now, we'll just log the error and continue listening.
                        continue;
                    }
                }
            }
        }); // End of GotIt Loooooop

        // 1.6.1 zero_timestamp_counter = 0 for ready signal send-at timestamps
        let mut zero_timestamp_counter = 0;

        // 1.6.2 intrystruct_hash_set_session_nonce = HashSet::new() as protection against replay attacks Create a HashSet to store received hashes
        let mut intrystruct_hash_set_session_nonce = HashSet::new();  // Create a HashSet to store received hashes

        let mut rc_set_as_active = false;

        // For first-time bootstrap
        let mut bootstrap_sendqueue = true;


        // --- 2. Enter Main Loop ---
        // enter main loop (to handling signals, sending)
        loop {
            debug_log(
                "HRCD  2.: Starting, restarting Main loop"
            );

            // --- 2.1 Check for 'should_halt_uma' Signal ---
            if should_halt_uma() {
                debug_log!(
                    "HRCD 2.1 main loop Check for halt signal. Halting handle_remote_collaborator_meetingroom_desk() for {}",
                    room_sync_input.remote_collaborator_name
                );
                break;
            }

            // --- 2.2. Handle Ready Signal:  ---
            // "Listener"?
            // 2.2.1 Receive Ready Signal
            let mut buf = [0; 1024]; // TODO size?
            match ready_socket.recv_from(&mut buf) {
                Ok((amt, src)) => {
                    debug_log!(
                        "HRCD 2.2.1 Ok((amt, src)) ready_port Signal Received {} bytes from {}",
                        amt,
                        src
                    );

                    debug_log!(
                        "HRCD 2.2.1 check queue {:?}",
                        session_send_queue.items,
                    );

                    if should_halt_uma() {
                        debug_log!(
                            "HRCD Halting handle_local_owner_desk() for {}",
                            room_sync_input.remote_collaborator_name
                        );
                        break;
                    }

                    if !rc_set_as_active {
                        if let Err(e) = set_as_active(&room_sync_input.remote_collaborator_name) {
                            debug_log!("Error setting collaborator as active: {}", e);
                            // Handle the error appropriately (e.g., continue or return)
                            continue; // Example: skip to the next iteration
                        }

                        rc_set_as_active = true;
                        debug_log("HRCD rc_set_as_active = true")
                    }



                    // --- Inspect Raw Bytes ---
                    debug_log!(
                        "HRCD 2.2.1 Ready Signal Raw bytes received: {:?}",
                        &buf[..amt]
                    );
                                        // --- Inspect Raw Bytes ---
                    debug_log!(
                        "HRCD thread::sleep(Duration::from_secs(3));",
                    );

                    // TODO: how long?
                    // this lets last item run
                    // thread::sleep(Duration::from_secs(5));

                    // --- Inspect Bytes as Hex ---
                    let hex_string = buf[..amt].iter()
                        .map(|b| format!("{:02X}", b))
                        .collect::<String>();
                    debug_log!(
                        "HRCD 2.2.1 Ready Signal Raw bytes as hex: {}",
                        hex_string
                    );

                    // --- 2.3 Deserialize the ReadySignal ---
                    // TODO add size check to deserialize function
                    let ready_signal: ReadySignal = match deserialize_ready_signal(&buf[..amt], &room_sync_input.remote_collaborator_salt_list) {
                        Ok(ready_signal) => {
                            // println!("HRCD 2.3 Deserialize Ok(ready_signal) {}: Received ReadySignal: {:?}",
                            //     room_sync_input.remote_collaborator_name, ready_signal
                            // ); // Print to console
                            debug_log!("HRCD 2.3 Deserialize Ok(ready_signal) {}: Received ReadySignal: {:?}",
                                room_sync_input.remote_collaborator_name,
                                ready_signal
                            ); // Log the signal
                            ready_signal
                        },
                        Err(e) => {
                            debug_log!("HRCD 2.3 Deserialize Err Receive data Failed to parse ready signal: {}", e);
                            continue; // Continue to the next iteration of the loop
                        }
                    };

                    // --- 2.4 Inspect & edge cases ---
                    // - look for missing required fields e.g. timestamp
                    // - only re(is_echo_send_boolean) can be empty, all other cases must drop packet
                    // - handle edge cases such as valid echo-request...with no queue
                    // or maybe there is a queue but empty so just let it do nothing?
                    // maybe ok, make sure this works
                    /*
                        struct ReadySignal {
                            rt: Option<u64>, // ready signal timestamp: last file obtained timestamp
                            rst: Option<u64>, // send-time
                            re: Option<bool>, // echo_send
                            rh: Option<Vec<u8>>, // N hashes of rt + re [can be empty]

                        no echo signal, then re = false
                    */

                    debug_log("\n##HRCD## starting checks(plaid) 2.4");

                    // --- 2.5 Hash-Check for ReadySignal ---
                    // Drop packet when fail check
                    if !verify_readysignal_hashes(
                        &ready_signal,
                        &room_sync_input.remote_collaborator_salt_list,
                    ) {
                        debug_log("HRCD 2.5: ReadySignal hash verification failed. Discarding signal.");
                        continue; // Discard the signal and continue listening
                    }

                    // --- 2.6 Check / Add Hash-Nonce for per-session ready-signals ---
                    // ...e.g. guarding against the few seconds of expiration-gap
                    // After you deserialize the ReadySignal and before the other checks:
                    let ready_signal_hash_vec = ready_signal.rh.clone();

                    if !ready_signal_hash_vec.is_empty() {
                        if intrystruct_hash_set_session_nonce.contains(&ready_signal_hash_vec) {
                            debug_log!("HRCD 2.6 quasi nonce check: Duplicate ReadySignal received (hash match). Discarding.");
                            continue; // Discard the duplicate signal
                        }
                        intrystruct_hash_set_session_nonce.insert(ready_signal_hash_vec); // Add hash to the set
                    } else {
                        debug_log!("HRCD 2.6 quasi nonce check: ReadySignal received without hashes. Discarding."); // Or handle differently
                        continue;
                    }

                    // --- 3. Get or Create Send Queue ---

                    // 3.1 ready_signal_timestamp for send-queue
                    let rst_sent_ready_signal_timestamp = ready_signal.rst; // Unwrap the timestamp outside the match, as it's always required.

                    debug_log!(
                        "HRCD 3.1 check rst_sent_ready_signal_timestamp for send-queue: rst_sent_ready_signal_timestamp -> {:?}",
                        rst_sent_ready_signal_timestamp
                    );

                    debug_log!(
                        "HRCD 3.1 check rt: rc's last-file-received-from-you timestamp received in a readysignal. ready_signal.rt -> {:?}",
                        ready_signal.rt,
                    );

                    // --- 3.2 timestamp freshness checks ---
                    let current_timestamp = get_current_unix_timestamp();

                    debug_log!(
                        "HRCD 3.2 check timestamp freshness checks: current_timestamp -> {:?}",
                        current_timestamp,
                    );

                    // 3.2.1 No Future Dated Requests
                    if rst_sent_ready_signal_timestamp > current_timestamp + 5 { // Allow for some clock skew (5 seconds)
                        debug_log!("HRCD 3.2.1 check: Received future-dated timestamp. Discarding.");
                        continue;
                    }

                    // 3.2.2 No Requests Older Than ~10 sec
                    if current_timestamp - 10 > rst_sent_ready_signal_timestamp {
                        debug_log!("HRCD 3.2.2 check: Received outdated timestamp (older than 10 seconds). Discarding.");
                        continue;
                    }

                    // 3.2.3 only 3 0=timstamp requests per session (count them!)
                    if rst_sent_ready_signal_timestamp == 0 {
                        if zero_timestamp_counter >= 5 {
                            debug_log("HRCD 3.2.3 check: Too many zero-timestamp requests. Discarding.");
                            continue;
                        }
                        zero_timestamp_counter += 1;
                    }

                    debug_log("##HRCD## [Done] checks(plaid) 3.2.3\n");

                    // 3.2.4 look for fail-flags:

                    ////////////////////////////////
                    // Set back_of_queue_timestamp
                    //////////////////////////////

                    // --- 3.3 Get / Make Send-Queue ---
                    let this_team_channelname = match get_current_team_channel_name_from_nav_path() {
                        Some(name) => name,
                        None => {
                            debug_log("HRCD 3.3: Error: Could not get current channel name. Skipping send queue creation.");
                            continue; // Skip to the next iteration of the loop
                        }
                    };
                    debug_log!("HRCD 3.3 this_team_channelname -> {:?}", this_team_channelname);

                    // TODO currently set to always run... ok?
                    debug_log("HRCD 3.3 get_or_create_send_queue");

                    session_send_queue = get_or_create_send_queue(
                        &this_team_channelname, // for team_channel_name
                        &room_sync_input.local_user_name, // local owner user name
                        &room_sync_input.remote_collaborator_name, // remote_collaborator_name
                        session_send_queue, // for session_send_queue
                        ready_signal.rt, // for ready_signal_rt_timestamp
                        bootstrap_sendqueue,
                    )?;

                    bootstrap_sendqueue = false;

                    debug_log!(
                        "HRCD ->[]<- 3.3 Get / Make session_send_queue {:?}",
                        session_send_queue
                    );

                    /*
                    send_file_toml_to_rc_intray(
                        file_path: &PathBuf,
                        target_addr: SocketAddr,
                        port: u16,
                        collaborator_salt_list: &[u128], // Pass the salt list here
                    )

                    # Explaining:
                    ```
                    if let Some(ref mut queue) = session_send_queue {
                        while let Some(file_path) = queue.items.pop() {
                    ```

                    That code snippet represents a common pattern in Rust for
                    iterating over and processing items in a Vec (vector) while
                     also potentially modifying the vector itself (in this case,
                         by removing elements). Let's break down the logic:

                    if let Some(ref mut queue) = session_send_queue: This is a
                    conditional statement that uses pattern matching with if
                    let. session_send_queue is an Option<SendQueue>, meaning
                    it can either contain a SendQueue or be None.

                    Some(ref mut queue): This part of the pattern attempts
                     to match the Some variant of the Option. If session_send_queue
                     contains a SendQueue, the code inside the if block will
                     be executed. The ref mut creates a mutable reference to the
                      inner SendQueue, allowing you to modify it.

                    If session_send_queue is None, the if block is skipped entirely.

                    while let Some(file_path) = queue.items.pop(): This is a
                    while let loop, another form of pattern matching. queue.items
                    is a Vec<PathBuf>. pop() removes and returns
                    the last element of the vector.

                    Some(file_path): This part of the pattern attempts to match
                     the Some variant of the Option returned by pop().
                     If queue.items is not empty, pop() will return Some(PathBuf)
                     where PathBuf is the removed element. The code inside the
                     while loop will be executed, and file_path will be assigned
                     the value of the removed PathBuf.

                    Empty Vector: When queue.items becomes empty, pop() will
                    return None. This will cause the while let loop to terminate.

                    In Summary:

                    The combined if let and while let structure ensures the following:

                    The code inside the while loop only executes
                    if session_send_queue contains a SendQueue (it's not None).

                    The loop iterates over the items in the SendQueue
                    from the last element to the first,
                    removing each item as it's processed.
                    */

                    debug_log!(
                        "HRCD ->[cue]<- 4.1 Send One File from Queue, session_send_queue -> {:?}",
                        session_send_queue
                    );

                    // 4. while: Send File: Send One File from Queue
                    // if let ref mut queue = session_send_queue {
                    if let ref mut queue = session_send_queue {

                        debug_log!(
                            "HRCD 4 before le pop, queue.items -> {:?}",
                            queue.items
                        );

                        while let Some(file_path) = queue.items.pop() {

                            debug_log!(
                                "HRCD 4 after le pop, queue.items -> {:?}",
                                queue.items
                            );

                            debug_log!(
                                "HRCD 4.2 Send File: if/while let Some(file_path) = queue.items.pop()  file_path {:?}",
                                file_path
                            );

                            /*
                            Probably from raw path to file
                            get path to readcopy of toml (checked and 'unpackaged' from clearsign and gpg encrypt)
                            */
                            // Using Debug trait for more detailed error information
                            // this is in clearsigntoml module
                            /*
                            pub fn get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
                                input_toml_absolute_path: &Path,
                                gpg_full_fingerprint_key_id_string: &str, // COLLABORATOR_ADDRESSBOOK_PATH_STR
                                base_uma_temp_directory_path: &Path,
                            ) -> Result<String, GpgError> {
                             */
                             // Get armored public key, using key-id (full fingerprint in)
                             let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
                                 Ok(fingerprint) => fingerprint,
                                 // Err(e) => {
                                 //     // Since the function returns Result<CoreNode, String>, we need to return a String error
                                 //     return Err(format!(
                                 //         "LCNFTF: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                                 //         e
                                 //     ));
                                 // }
                                 Err(e) => {
                                     debug_log!( "LCNFTF: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}", e);
                                     continue; // Skip to the next file if hashing fails
                                 }
                             };

                             // // 1. Paths & Reading-Copies Part 1: node.toml path and read-copy

                             // Get the UME temp directory path with explicit String conversion
                             let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
                                 .map_err(|io_err| {
                                     let gpg_error = GpgError::ValidationError(
                                         format!("LCNFTF: Failed to get UME temp directory path: {}", io_err)
                                     );
                                     // Convert GpgError to String for the function's return type
                                     format!("LCNFTF: {:?}", gpg_error)
                                 })?;

                            // base file to send is clearsigned
                            let sendfile_readcopy_pathstring = get_pathstring_to_temp_plaintoml_verified_extracted(
                                &file_path,
                                &gpg_full_fingerprint_key_id_string,
                                &base_uma_temp_directory_path,
                            ).map_err(|e| format!("LCNFTF: Failed to get temporary read copy of TOML file: {:?}", e))?;

                            // converst from path-string to path-type path
                            let path_sendfile_readcopy_path = Path::new(&sendfile_readcopy_pathstring);

                            // 4.2.1 Get File Send Time
                            let intray_send_time = get_current_unix_timestamp();

                            // TODO maybe store files as the gpg blob
                            // Wrapper of bytes to bytes:
                            // 4.2.2 Read File Contents
                            // 4.3.1 GPG Clearsign the File (with your private key)
                            // 4.3.2 GPG Encrypt File (with their public key)
                            let file_bytes2send = wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes(
                                &path_sendfile_readcopy_path,
                                &room_sync_input.remote_collaborator_public_gpg,
                            )?;

                            debug_log(
                                "HRCD 4.2, 4.3.1, 4.3.2 done gpg wrapper"
                            );

                            // // 4.5. Calculate SendFile Struct Hashes (Using Collaborator's Salts)
                            // 4.5 calculate hashes: HRCD
                            let calculated_hrcd_sendfile_hashes = hash_sendfile_struct_fields(
                                &room_sync_input.local_user_salt_list,
                                intray_send_time,
                                &file_bytes2send,
                            );

                            // Handle the Result from hash_sendfile_struct_fields
                            let calculated_hashes = match calculated_hrcd_sendfile_hashes {
                                Ok(hashes) => hashes,
                                Err(e) => {
                                    debug_log!("HRCD 4.5 Error calculating hashes: {}", e);
                                    continue; // Skip to the next file if hashing fails
                                }
                            };

                            debug_log!(
                                "HRCD 4.5 calculated_hashes {:?}",
                                calculated_hashes
                            );

                            // 4.6. Create SendFile Struct
                            let sendfile_struct = SendFile {
                                intray_send_time: Some(intray_send_time),
                                gpg_encrypted_intray_file: Some(file_bytes2send), // Clone needed here if file_bytes2send is used later
                                intray_hash_list: Some(calculated_hashes),  // Clone here as well
                            };

                            debug_log!(
                                "HRCD 4.6 Create sendfile_struct {:?}",
                                sendfile_struct
                            );

                            debug_log!("HRCD 4.7.2 ready_signal.rt for set_prefail_flag_rt_timestamp__for_sendfile {:?}", ready_signal.rt);


                            // get updatedat value of .toml
                            let file_last_updatedat_time: u64 = get_updated_at_timestamp_from_toml_file(&path_sendfile_readcopy_path)?;


                            // 4.7.2 HRCD set_prefail_flag_rt_timestamp__for_sendfile
                            if let Err(e) = set_prefail_flag_rt_timestamp__for_sendfile(
                                file_last_updatedat_time, // for fail flag file name
                                ready_signal.rt, // for fail flag file value
                                &room_sync_input.remote_collaborator_name,
                            ) {
                                debug_log!("HRCD 4.7.2.e Error setting pre-fail flag: {}", e);
                                continue; // Handle error as you see fit
                            }
                            debug_log!("HRCD 4.7.2 prefail flag set using timestamp {:?}", &ready_signal.rt);

                            debug_log!(
                                "HRCD 4.6-7 Create sendfile_struct {:?}",
                                sendfile_struct
                            );

                            let serialized_file_struct_to_send = serialize_send_file(&sendfile_struct);

                            // --- 4.7 Send serializd-file: send UDP to intray ---
                            // 4.7.1 Send file
                            // 4.7 Send serializd-file Send if serialization was successful (handle Result)
                            match serialized_file_struct_to_send {
                                Ok(extracted_serialized_data) => {  // Serialization OK
                                    match send_data_via_udp(
                                        &extracted_serialized_data,
                                        src,
                                        room_sync_input.remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip,
                                        ) {
                                        Ok(_) => {
                                            debug_log!("HRCD 4.7 File sent successfully");
                                            // ... (Handle successful send, e.g., update timestamp log)

                                            // --- 4.7.3 Get Timestamp ---
                                            //  Timestamp Log is depricated (most likely)
                                            debug_log("HRCD calling calling get_toml_file_updated_at_timestamp(), yes...");
                                            // if let Ok(timestamp) = get_toml_file_updated_at_timestamp(&file_path) {
                                            // //     update_collaborator_sendqueue_timestamp_log(
                                            // //         // TODO: Replace with the actual team channel name
                                            // //         &this_team_channelname,
                                            // //         &room_sync_input.remote_collaborator_name,
                                            // //     )?;
                                            //     // debug_log!("HRCD 4.7.3  Updated timestamp log for {}", room_sync_input.remote_collaborator_name);
                                            // }
                                        }
                                        Err(e) => {
                                            debug_log!("Error sending data: {}", e);
                                            // Handle the send error (e.g., log, retry, etc.)
                                        }
                                    }
                                }
                                Err(e) => { // Serialization error
                                    debug_log!("Serialization error: {}", e);
                                    // Handle the serialization error (e.g., log, skip file)
                                }
                            }
                            // debugpause(30);
                            debug_log!("\nHRCD: bottom of ready_signal listener. (maybe)\n");


                        } // end of while
                    } // end of 4.4: if let Some(ref mut queue) = session_send_queue {
                    debug_log!("\nHRCD: end of inner match.\n");
                }, // end of the Ok inside the match: Ok((amt, src)) => {
                Err(e) if e.kind() == ErrorKind::WouldBlock => {
                    // TODO What is all this then?
                    // // --- 3.6 No Ready Signal, Log Periodically ---
                    // terrible idea: most people are simply not online most of the time
                    // this is not an error!!
                    // if last_debug_log_time.elapsed() >= Duration::from_secs(5) {
                    //     debug_log!("HRCD 3.6 {}: Listening for ReadySignal on port {}",
                    //                room_sync_input.remote_collaborator_name,
                    //                room_sync_input.remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip);
                    //     last_debug_log_time = Instant::now();
                    // }
                    debug_log!("HRCD Err(e) if e.kind() == ErrorKind::WouldBlock =>");
                },
                Err(e) => {
                    // --- 3.7 Handle Other Errors ---
                    debug_log!("HRCD #? {}: Error receiving data on ready_port: {} ({:?})",
                            room_sync_input.remote_collaborator_name, e, e.kind());
                    return Err(ThisProjectError::NetworkError(e.to_string()));
                }
            // thread::sleep(Duration::from_millis(100));
            } // match ready_socket.recv_from(&mut buf) {
        } // closes main loop
        debug_log!("\nHRCD: bottom of main loop.\n");
    }
    debug_log!("\nending HRCD\n");
    Ok(())
}

/// Creates a UDP socket bound to the specified address and port.
///
/// Simplifies socket creation by taking a SocketAddr directly.
/// Does one thing well.
///
/// # Arguments
///
/// * `socket_addr`: The address and port to bind to.
///
/// # Returns
///
/// * `Result<UdpSocket, ThisProjectError>`: The bound socket or an error if binding fails.
fn create_rc_udp_socket(socket_addr: SocketAddr) -> Result<UdpSocket, ThisProjectError> {
    UdpSocket::bind(socket_addr).map_err(|e| {
        ThisProjectError::NetworkError(format!("Failed to bind to UDP socket: {}", e))
    })
}

/// Creates a UDP socket bound to a locally chosen IP address and port based on the network band configuration.
///
/// This function uses the provided `band_local_network_type`, `band_local_user_ipv4_address`, and `band_local_user_ipv6_address`
/// to determine the appropriate IP address to bind to.
/// if type says ivp6 or ipv4, this function then attempts to bind
/// a UDP socket to that ip address and the specified port.
///
/// # Arguments
///
/// * `band_local_network_type`: A string slice indicating the network type ("ipv4" or "ipv6").
/// * `band_local_user_ipv4_address`: The local user's IPv4 address (used if `band_local_network_type` is "ipv4").
/// * `band_local_user_ipv6_address`: The local user's IPv6 address (used if `band_local_network_type` is "ipv6").
/// * `port`: The port number.
///
/// # Returns
///
/// * `Result<UdpSocket, ThisProjectError>`:  The created and bound UDP socket on success, or a `ThisProjectError` on failure (invalid IP, binding error, unsupported network type).
fn create_local_udp_socket(
    band_local_network_type: &str,
    band_local_user_ipv4_address: &Ipv4Addr,
    band_local_user_ipv6_address: &Ipv6Addr,
    port: u16,
) -> Result<UdpSocket, ThisProjectError> {
    let socket_addr = match band_local_network_type {
        "ipv6" => SocketAddr::new(IpAddr::V6(*band_local_user_ipv6_address), port),
        "ipv4" => SocketAddr::new(IpAddr::V4(*band_local_user_ipv4_address), port),
        _ => return Err(ThisProjectError::NetworkError("Unsupported network type".into())),
    };

    UdpSocket::bind(socket_addr).map_err(|e| {
        ThisProjectError::NetworkError(format!("Failed to bind to {} address: {}", band_local_network_type, e))
    })
}

// Result enum for the sync operation, allowing communication between threads
enum SyncResult {
    Success(u64), // Contains the new timestamp after successful sync
    Failure(ThisProjectError), // Contains an error if sync failed
}

// TODO likely need to be updated to abs-exe-parent-relative paths
/// Extracts the team channel name from the current working directory path.
///
/// Looks for the pattern "project_graph_data/team_channels/[CHANNEL_NAME]" in the absolute path
/// and returns the CHANNEL_NAME if found.
///
/// # Returns
/// * `Some(String)` - The team channel name if found
/// * `None` - If no channel name could be extracted (invalid path, missing markers, etc.)
///
/// # Example
/// ```
/// match get_current_team_channel_name_from_nav_path() {
///     Some(channel) => println!("Found channel: {}", channel),
///     None => println!("No channel found"),
/// }
/// ```
/// or:
/// let team_channel_name = match get_current_team_channel_name_from_nav_path() {
///     Some(name) => name,
///     None => {
///         debug_log!("Error: Could not get current channel name. Skipping set_as_active.");
///         return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
///     },
/// };
fn get_current_team_channel_name_from_nav_path() -> Option<String> {
    debug_log!("\nGCTCNFNP Starting: get_current_team_channel_name_from_nav_path()");

    // // Get absolute path from current directory
    // let absolute_path = match PathBuf::from(".").canonicalize() {
    //     Ok(path) => path,
    //     Err(e) => {
    //         debug_log!("Failed to get absolute path: {}", e);
    //         return None;
    //     }
    // };

    let absolute_path_string = match read_state_string("current_node_directory_path.txt") {
        Ok(path) => path,
        Err(e) => {
            debug_log!("GCTCNFNP Failed to get absolute path: {}", e);
            return None;
        }
    };

    debug_log!("GCTCNFNP Absolute path: {}", absolute_path_string);

    // Convert path to string
    // let path_str = absolute_path.to_string_lossy();

    // Define the marker we're looking for
    let marker = "project_graph_data/team_channels/";

    // Find marker position
    let position = match absolute_path_string.find(marker) {
        Some(pos) => pos,
        None => {
            debug_log!("GCTCNFNP Marker '{}' not found in path", marker);
            return None;
        }
    };

    // Extract everything after the marker
    let after_marker = &absolute_path_string[position + marker.len()..];
    debug_log!("GCTCNFNP Path after marker: {:?}", after_marker);

    // Get the first component after the marker
    let team_channel = after_marker
        .split(std::path::MAIN_SEPARATOR)
        .next()
        .map(String::from);

    // Validate and return
    match team_channel {
        Some(channel) if !channel.is_empty() => {
            debug_log!("GCTCNFNP Found team channel: {}", channel);
            Some(channel)
        }
        _ => {
            debug_log!("GCTCNFNP No valid team channel found");
            None
        }
    }
}

/// for normal mode, updates graph-navigation location and graph-state for both
/// 1. the struct
/// 2. the file-set version in .../project_graph_data/session_state_items
/// in both enter-new-node cases, in new-channel, cases, and in other cases
///
/// node.toml toml tables! store the ports: (check they are unique)
/// { collaborator_name = "bob", ready_port = 50001,
///     intray_port = 50002, gotit_port = 50003,
///     self_ready_port = 50004,
///     self_intray_port = 50005,
///     self_gotit_port = 50006 },
///
/// /// ... other imports ...
/// use std::sync::mpsc; /// For message passing between threads (if needed)
///
/// Version 2:
/// as set by node.toml in the team_channel node
///
/// for every other collaborator, you make:
/// two threds:
///     - your in-tray desk
///     - their in-tray desk
///
/// Each thred has six ports:
///     - three for each 'in-tray desk'
///
/// For each this-session-active-collaborator you keep a send-queue.
/// For one who never requested a file (who isn't online): no need to make a send-queue
///
///  Note current node members are not the same as channel members
///  a node may have narrower scope, but not broader.
///  this may especially apply to tasks only shared with relevant members
fn you_love_the_sync_team_office() -> Result<(), Box<dyn std::error::Error>> {
    /*
    "It's all fun and games until someone syncs a file."

    TODO:
    there needs to be a signal to wait to start
    the home_square_one flag may work
    */
    // --- WAIT FOR CHANNEL SELECTION ---
    sync_flag_ok_or_wait(5); // Wait for the sync flag to become "1"

    // 1.5.1 Check for halt-uma signal
    if should_halt_uma() {
        debug_log(">*< Halt signal received. Exiting The Uma. Closing... you_love_the_sync_team_office() |o|");
        return Ok(()); // Exit the function
    }

    debug_log("starting YLTSTO! UMA Sync Team Office...you_love_the_sync_team_office()");

    // // Read uma_local_owner_user from uma.toml
    // // maybe add gpg and make this a separate function TODO
    // let uma_toml_path = Path::new("uma.toml");
    // let user_metadata = toml::from_str::<toml::Value>(&fs::read_to_string(uma_toml_path)?)?;
    // let uma_local_owner_user = user_metadata["uma_local_owner_user"].as_str().unwrap().to_string();



    debug_log!(
        "YLTSTO Step 1: Reading LOCAL OWNER USER's name from {}",
        UMA_TOML_CONFIGFILE_PATH_STR,
    );

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("YLTSTO Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "YLTSTO Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read LOCAL OWNER USER's name from uma.toml
    let uma_local_owner_user = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("YLTSTO Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("YLTSTO LOCAL OWNER USER's name is, uma_local_owner_user: {}", uma_local_owner_user);



    debug_log!("\n\nStarting UMA Sync Team Office for (local owner) -> {}", &uma_local_owner_user);

    // let session_connection_allowlists = make_sync_meetingroomconfig_datasets(&uma_local_owner_user)?;
    // debug_log!("session_connection_allowlists -> {:?}", &session_connection_allowlists);

    // 1. get sync_meetingroom_config_datasets
    let sync_meetingroom_config_datasets = match make_sync_meetingroomconfig_datasets(&uma_local_owner_user) {

        Ok(room_config_datasets) => {
            debug_log!(
                "Successfully generated room_config_datasets: {:?}",
                room_config_datasets
            );
            room_config_datasets
        },
        Err(e) => {
            debug_log!("YLTSTO Error creating room_config_datasets: {}", e);
            return Err(Box::new(e)); // Return the error early
        }
    };

    // 2. Create a list for threads for each collaborator on the room_config_datasets:
    /*
    TODO explain why/how a list:
    to gather for shutdown?
    */
    let mut collaborator_threads = Vec::new();

    // 3. get sync_meetingroom_config_dataset
    // with MeetingRoomSyncDataset, ForLocalOwnerDeskThread, ForRemoteCollaboratorDeskThread

    for this_meetingroom_iter in sync_meetingroom_config_datasets {
        // Extract data from this_meetingroom_iter
        // and place each pile in a nice baggy for each desk.
        debug_log!(
            "Configuring Connection: Setting up proverbial meetingroom and desk for/with: {}",
            this_meetingroom_iter.remote_collaborator_name,
        );

        // Create sub-structs
        let data_baggy_for_owner_desk = ForLocalOwnerDeskThread {
            local_user_name: this_meetingroom_iter.local_user_name.clone(),
            remote_collaborator_name: this_meetingroom_iter.remote_collaborator_name.clone(),
            local_user_salt_list: this_meetingroom_iter.local_user_salt_list.clone(),
            remote_collaborator_salt_list: this_meetingroom_iter.remote_collaborator_salt_list.clone(),
            local_user_ipv6_addr_list: this_meetingroom_iter.local_user_ipv6_addr_list.clone(),
            local_user_ipv4_addr_list: this_meetingroom_iter.local_user_ipv4_addr_list.clone(),
            remote_collaborator_ipv6_addr_list: this_meetingroom_iter.remote_collaborator_ipv6_addr_list.clone(),
            remote_collaborator_ipv4_addr_list: this_meetingroom_iter.remote_collaborator_ipv4_addr_list.clone(),
            local_user_gpg_publickey_id: this_meetingroom_iter.local_user_gpg_publickey_id.clone(),
            local_user_public_gpg: this_meetingroom_iter.local_user_public_gpg.clone(),
            local_user_sync_interval: this_meetingroom_iter.local_user_sync_interval,
            // ready! (local)
            local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: this_meetingroom_iter.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,
            // in-tray (local)
            localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: this_meetingroom_iter.localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip,
            // got-it! (local)
            local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: this_meetingroom_iter.local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip,
        };
        let data_baggy_for_collaborator_desk = ForRemoteCollaboratorDeskThread {
            remote_collaborator_name: this_meetingroom_iter.remote_collaborator_name.clone(),
            local_user_name: this_meetingroom_iter.local_user_name.clone(),
            remote_collaborator_salt_list: this_meetingroom_iter.remote_collaborator_salt_list.clone(),
            local_user_salt_list: this_meetingroom_iter.local_user_salt_list.clone(),
            remote_collaborator_ipv6_addr_list: this_meetingroom_iter.remote_collaborator_ipv6_addr_list,
            remote_collaborator_ipv4_addr_list: this_meetingroom_iter.remote_collaborator_ipv4_addr_list,
            local_user_ipv6_addr_list: this_meetingroom_iter.local_user_ipv6_addr_list,
            local_user_ipv4_addr_list: this_meetingroom_iter.local_user_ipv4_addr_list,
            remote_collaborator_gpg_publickey_id: this_meetingroom_iter.remote_collaborator_gpg_publickey_id.clone(),
            remote_collaborator_public_gpg: this_meetingroom_iter.remote_collaborator_public_gpg.clone(),
            remote_collaborator_sync_interval: this_meetingroom_iter.remote_collaborator_sync_interval,
            // ready! (remote)
            remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: this_meetingroom_iter.remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip,
            // in-tray (remote)
            remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: this_meetingroom_iter.remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip,
            // got-it! (remote)
            remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: this_meetingroom_iter.remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip,
        };

        // Create the two "meeting room desks" for each collaborator pair:
        // Your Desk
        let owner_desk_thread = thread::spawn(move || {
            handle_local_owner_desk(data_baggy_for_owner_desk);

        });
        // Their Desk
        let collaborator_desk_thread = thread::spawn(move || {
            handle_remote_collaborator_meetingroom_desk(&data_baggy_for_collaborator_desk);
        });
        collaborator_threads.push(owner_desk_thread);
        collaborator_threads.push(collaborator_desk_thread);
    }

    // ... Handle join logic for your threads...
    for thread in collaborator_threads {
        thread.join().expect("Failed to join thread.");
    }
    debug_log!("UMA Sync Team Office closed");
    println!("UMA Sync Team Office closed");
    Ok(())
}


// Updated helper function:
fn update_current_path_and_state(app: &mut App, selected_item: String, input_mode: InputMode) {
    // if input_mode == InputMode::TaskCommand && app.is_at_task_browser_root() {
    //     app.current_path.push(selected_item);  // Only push if in TaskCommand mode and at root (for column selection).
    // } else if input_mode == InputMode::MainCommand {
    //     app.current_path.push(selected_item);  // Only push when not in task mode (directory or IM message selection).
    // }

    // Populate next_path_lookup_table:
    app.next_path_lookup_table.clear(); // Clear previous entries.

    if input_mode == InputMode::MainCommand  {
        for (i, item) in app.tui_directory_list.iter().enumerate() {
            let next_path = app.current_path.join(item);
            app.next_path_lookup_table.insert(i + 1, next_path);
        }
    }

    app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();
    app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // Always call to update state.
    debug_log!("Updated path and state. New path: {:?}", app.current_path);
}

// In handle_task_selection:
fn handle_task_selection(app: &mut App, selection: usize) -> Result<bool, io::Error> { // Now returns a bool
    if app.is_at_task_browser_root() {
        // ... Column selection:
        // todo this may be wrong
        // Update current_path using handle_selection:
        if let Some(selected_column) = app.tui_directory_list.get(selection - 1) {
            update_current_path_and_state(app, selected_column.clone(), app.input_mode.clone());  //FIX 1
            app.load_tasks(); // Refresh task browser to show tasks within the column
        } else { // Invalid selection
            app.display_error("hts Invalid column selection.");
            app.load_tasks(); //Refresh view
            return Ok(false); //Stay in task mode
        }

    } else { //Task selection
        if let Some(full_task_path) = app.get_full_task_path(selection - 1) {
            // No need to push here (current_path is already inside a column directory):
            debug_log!(
                "hts app.current_path: {:?}", app.current_path
            );
            debug_log!(
                "hts full_task_path: {:?}", full_task_path
            );
            app.current_path = full_task_path.clone(); // Update current_path directly
            app.graph_navigation_instance_state.current_full_file_path = full_task_path;

            debug_log!(
                "hts  app.graph_navigation_instance_state.current_full_file_path: {:?}",
                app.graph_navigation_instance_state.current_full_file_path
            );

            app.graph_navigation_instance_state.nav_graph_look_read_node_toml();
            return Ok(true); // Return true to signal exiting task mode

        } else {
            app.display_error("hts Invalid task number");
            app.load_tasks();
            return Ok(false); //Stay in task mode
        }
    }
    Ok(false)  // Stay in task mode by default (if no task is selected).
}

// TODO doc string needed, massive, huge.
/// Proverbial Main()
fn we_love_projects_loop() -> Result<(), io::Error> {
    /*

    setup and bootstrap
    - load data
    - start Graph Navigation Struct instance
    - do first bootstrap TUI display of team-channel choices

    Command Loop
    1. Get input
    2. process input/command
    3. show updated state
    */

    // TODO abs exe-parent path needed
    // Load UMA configuration from uma.toml
    // let uma_toml_path = Path::new("uma.toml");

   // TUI Setup, TODO
    /*
    If there is an umi.toml,
    and it has tui_height/tui_height that are not 80/24
    use those new values (from umi.toml) for
    tui_height =
    tui_width =

    or maybe this gets done in the project-manager-thread (not the sink thread)
    */


    // Step 1: Get the absolute path to the executable's parent directory
    let executable_parent_directory = match get_absolute_path_to_executable_parentdirectory() {
        Ok(path) => path,
        Err(e) => {
            debug_log(&format!("Error getting executable directory: {}", e));
            return Err(io::Error::new(
                io::ErrorKind::NotFound,
                format!("Failed to determine executable directory: {}", e)
            ));
        }
    };

    debug_log!("executable_parent_directory: {:?}", executable_parent_directory);

    // Step 2: Join the target path to the executable directory
    let target_path = executable_parent_directory.join("project_graph_data/team_channels");

    // Step 3: Verify the path exists
    let path_exists = match abs_executable_directory_relative_exists(&target_path) {
        Ok(exists) => exists,
        Err(e) => {
            debug_log(&format!("Error checking if path exists: {}", e));
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("Failed to check if path exists: {}", e)
            ));
        }
    };

    // Step 4: Canonicalize the path if it exists, otherwise error
    let current_exe_dir_relative_abs_path_canonicalized = if path_exists {
        match target_path.canonicalize() {
            Ok(canonical_path) => canonical_path,
            Err(e) => {
                debug_log(&format!("Error canonicalizing path: {}", e));
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("Failed to canonicalize path: {}", e)
                ));
            }
        }
    } else {
        debug_log(&format!("Path does not exist: {:?}", target_path));
        return Err(io::Error::new(
            io::ErrorKind::NotFound,
            format!("Path does not exist: {:?}", target_path)
        ));
    };

    debug_log!("Current executable-relative absolute path: {:?}", current_exe_dir_relative_abs_path_canonicalized);

    debug_log!("Using project path: {:?}", current_exe_dir_relative_abs_path_canonicalized);

    debug_log!(" {:?}", current_exe_dir_relative_abs_path_canonicalized);

    // getting data from uma.toml
    /*
    requires new functions:
    simple read / clearsign-read
    u8 int
    u64 int
    or... how to do?
    int out?
    */

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("___ Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            io::Error::new(io::ErrorKind::InvalidData, error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "__ Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            io::Error::new(io::ErrorKind::InvalidData, error_msg)
        })?;


    // Read LOCAL OWNER USER's name from uma.toml
    let uma_local_owner_user = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // u64
    let default_im_messages_expiration_days = read_u64_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_default_im_messages_expiration_days"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read default_im_messages_expiration_days: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // u64
    let default_task_nodes_expiration_days = read_u64_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_default_task_nodes_expiration_days"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read default_task_nodes_expiration_days: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // u8
    let tui_height = read_u8_field_from_toml(
        absolute_uma_toml_path_str,
        "tui_height"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read tui_height: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // u8
    let tui_width = read_u8_field_from_toml(
        absolute_uma_toml_path_str,
        "tui_width"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read tui_width: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;



    // node-graph navigation 'state' initial setup
    let mut graph_navigation_instance_state = GraphNavigationInstanceState {
        // local_owner_user: user_metadata["uma_local_owner_user"].as_str().unwrap().to_string(),
        // active_team_channel: String::new(), // or perhaps "None", or "Default"
        // default_im_messages_expiration_days: user_metadata["uma_default_im_messages_expiration_days"].as_integer().unwrap() as u64,
        // default_task_nodes_expiration_days: user_metadata["uma_default_task_nodes_expiration_days"].as_integer().unwrap() as u64,

        // // look into making these smaller for memory use...unless there is a reason
        // // this is not pixels, but character-lines on a single screen
        // // tui_height: user_metadata["tui_height"].as_integer().unwrap() as u8,
        // // tui_width: user_metadata["tui_width"].as_integer().unwrap() as u8,

        // // Handle missing or invalid values for tui_height and tui_width:
        // tui_height: user_metadata.get("tui_height")
        //     .and_then(Value::as_integer)
        //     .map(|height| height as u8) // Convert to u8 if valid
        //     .unwrap_or(24),  // Default to 24 if missing or invalid

        // tui_width: user_metadata.get("tui_width")
        //     .and_then(Value::as_integer)
        //     .map(|width| width as u8) // Convert to u8 if valid
        //     .unwrap_or(80), // Default to 80 if missing or invalid

        local_owner_user: uma_local_owner_user,
        active_team_channel: String::new(), // or perhaps "None", or "Default"
        default_im_messages_expiration_days: default_im_messages_expiration_days,
        default_task_nodes_expiration_days: default_task_nodes_expiration_days,

        // look into making these smaller for memory use...unless there is a reason
        // this is not pixels, but character-lines on a single screen
        // tui_height: user_metadata["tui_height"].as_integer().unwrap() as u8,
        // tui_width: user_metadata["tui_width"].as_integer().unwrap() as u8,

        // Handle missing or invalid values for tui_height and tui_width:
        tui_height: tui_height,  // Default to 24 if missing or invalid
        tui_width: tui_width, // Default to 80 if missing or invalid

        current_full_file_path: current_exe_dir_relative_abs_path_canonicalized, // Set initial absolute path
        // Initialize other fields of GraphNavigationInstanceState
        current_node_teamchannel_collaborators_with_access: Vec::new(),
        current_node_name: String::new(),
        current_node_owner: String::new(),
        current_node_description_for_tui: String::new(),
        current_node_directory_path: PathBuf::new(),
        current_node_unique_id: Vec::new(),
        current_node_members: Vec::new(),
        home_square_one: true,
        // Project Areas,
        pa1_process: String::new(),
        pa2_schedule: Vec::new(), // Vec<u64>,?
        pa3_users: String::new(),
        pa4_features: String::new(),
        pa5_mvp: String::new(),
        pa6_feedback: String::new(),
        // message-post

        // message_post_gpgtoml_required bool option
        message_post_gpgtoml_required: None,

        // Integer validation ranges as tuples (min, max) - inclusive bounds
        message_post_data_format_specs_integer_ranges_from_to_tuple_array: None,

        // Integer-string validation ranges as tuples (min, max) for the integer part
        message_post_data_format_specs_int_string_ranges_from_to_tuple_array: None,

        // Maximum string length
        message_post_max_string_length_int: None,

        // Whether posts are public or private
        message_post_is_public_bool: None,

        // Whether user confirmation is required before posting
        message_post_user_confirms_bool: None,

        // Start time for accepting posts (UTC POSIX timestamp)
        message_post_start_date_utc_posix: None,

        // End time for accepting posts (UTC POSIX timestamp)
        message_post_end_date_utc_posix: None,
    };

    // if !verify_gpg_signature(&local_user) {
    //     println!("GPG key verification failed (placeholder)");
    //     return Err(io::Error::new(io::ErrorKind::Other, "GPG Verification Failed"));
    // }

    // // Create App instance
    // let mut app = App::new(graph_navigation_instance_state.clone()); // Pass graph_navigation_instance_state

    // Create App instance
    let mut app = match App::new(graph_navigation_instance_state.clone()) {
        Ok(app) => app,
        Err(e) => {
            debug_log(&format!("Failed to initialize App: {}", e));
            return Err(e); // Or handle the error in another appropriate way
        }
    };

    // -- bootstrap: Start in MainCommand Mode ---
    app.input_mode = InputMode::MainCommand; // Initialize app in command mode

    // bootstrap: load team-channels
    app.update_directory_list()?;

    // bootstrap: TUI display:
    print!("\x1B[2J\x1B[1;1H"); // Clear the screen
    tiny_tui::simple_render_list(
        &app.tui_directory_list,
        &app.current_path,
    );


    // Start
    loop {
        // // Read the 'continue_uma.txt' file
        // let file_content = match fs::read_to_string(CONTINUE_UMA_PATH_STR) {
        //     Ok(content) => content,
        //     Err(_) => {
        //         debug_log!("Error reading 'continue_uma.txt'. Continuing..."); // Handle the error (e.g., log it) but continue for now
        //         continue; // Skip to the next loop iteration
        //     }
        // };
        // // break loop if continue=0
        // if file_content.trim() == "0" {
        //     debug_log("wlpl 'continue_uma.txt' is 0. we_love_projects_loop() Exiting loop.");
        //     break;
        // }

        // Read the 'continue_uma.txt' file and check if we should exit
        if should_halt_uma() {
            debug_log("wlpl 'continue_uma.txt' is 0. we_love_projects_loop() Exiting loop.");
            break;
        }

        // Update GraphNavigationInstanceState based on the current path
        debug_log("start loop: we_love_projects_loop()");
        debug_log!(
            "wlpl &app.current_path -> {:?}",
            &app.current_path,
        );

        debug_log!("wlpl app.input_mode {:?}", &app.input_mode);

        debug_log!(
            "wlpl &app.next_path_lookup_table -> {:?}",
            &app.next_path_lookup_table
        );

        debug_log!(
            "wlpl &app.task_display_table -> {:?}",
            &app.task_display_table
        );

        app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();

        debug_log!(
            "wlpl app.current_path.clone(); -> {:?}",
            &app.current_path.clone(),
        );

        debug_log!(
            "wlpl &app.graph_navigation_instance_state.current_full_file_path -> {:?}",
            &app.graph_navigation_instance_state.current_full_file_path,
        );

        // -- Here: this function reads state and adds current graph-node-location data
        app.graph_navigation_instance_state.nav_graph_look_read_node_toml();

        // --- this is or maybe should be part of the TUI (no state record)

        //  Check for exit signal
        if should_halt_uma() {
            debug_log("Exiting we_love_projects_loop");
            break;
        }

        /*
        Command Loop
        1. Get input
        2. process input/command
        3. show updated state


        # Main Command Loop
        1. input: getting a command from the user
	       - Q: for refresh, is there a way to separate input (input buffer?)
	       to display current user typing along with refreshed other items etc?

        2. process the command

        If int:
        - move to the path
        - check if new place is a node
        - load new path into Nav state
        - load basic display info:
        -- name
        -- description
        -- scope n schedule (user feature:, subfeatures:, days:}

        Handle commands such as T, M, etc.

        Handle change of Mode:
        (maybe all input-mode is handled not in this loop)

        3. Tui: showing the user where they are
        (loop)

        */

        // 1. get input/command
        let input = tiny_tui::get_input()?;

        // 2. handle input/command
        // If in main command mode, handle main commands:
        // ?. Update directory list (only in MainCommand mode) - MOVE THIS
        if app.input_mode == InputMode::MainCommand {
            if handle_command_main_mode(&input, &mut app, &graph_navigation_instance_state)? {
                return Ok(());
            }
            app.update_directory_list()?;

        }

        // // 2. handle input/command
        // if handle_command_main_mode(&input, &mut app, &graph_navigation_instance_state)? {
        //     return Ok(());
        // } else if app.input_mode == InputMode::MainCommand {
        //     handle_numeric_input(&input, &mut app, &graph_navigation_instance_state)?;
        // }



        // 3. Render TUI *before* input:
        if app.input_mode == InputMode::InsertText {

            debug_log("we love projects: handle_insert_text_input");

            if input == "m" {
                // pass

            } else if input == "back" {
                debug_log("escape toggled");
                // app.input_mode = InputMode::MainCommand; // Access input_mode using self
                // app.current_path.pop(); // Go back to the parent directory
                // app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone(); // Update full path after popping.
                // app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                // app.update_directory_list()?;

                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone(); // Update full path after popping.
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                tiny_tui::render_list(
                    &app.tui_directory_list,
                    &app.current_path,
                    // Project Areas
                    &app.graph_navigation_instance_state.pa1_process,
                    &app.graph_navigation_instance_state.pa2_schedule,  // str? vec<u64>?
                    &app.graph_navigation_instance_state.pa3_users,
                    &app.graph_navigation_instance_state.pa4_features,
                    &app.graph_navigation_instance_state.pa5_mvp,
                    &app.graph_navigation_instance_state.pa6_feedback,
                );
                app.update_directory_list()?;  // refresh to current cwd display items

            } else if input == "b" {
                debug_log("escape toggled");
                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                app.update_directory_list()?;  // refresh to current cwd display items
            } else if input == "q" {
                debug_log("escape toggled");
                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                app.update_directory_list()?;  // refresh to current cwd display items
            } else if !input.is_empty() {
                debug_log("!input.is_empty()");

                let local_owner_user = &app.graph_navigation_instance_state.local_owner_user; // Access using self

                // 1. final path name (.toml)
                let message_path = get_next_message_file_path(&app.current_path, local_owner_user);
                debug_log(&format!("Next message path: {:?}", message_path)); // Log the calculated message path

                // 2. make message file
                add_im_message(
                    &message_path,
                    local_owner_user,
                    input.trim(),
                    &app.graph_navigation_instance_state, // Pass using self
                ).expect("handle_insert_text_input: Failed to add message");

                app.load_im_messages(); // Access using self
            }
        }

        // 3. Render TUI *before* input:
        if app.input_mode == InputMode::TaskCommand {

            debug_log("we love projects: task mode");

            // First, try to handle numeric input
            if let Ok(index) = input.trim().parse::<usize>() {
                // Check if the index exists in the path lookup table
                if let Some(target_path) = app.next_path_lookup_table.get(&index) {
                    debug_log(&format!("Selected path from lookup table: {:?}", target_path));
                    // Regular directory navigation
                    app.current_path = target_path.clone();
                    app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();
                    app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                    app.input_mode = InputMode::MainCommand; // Access input_mode using self

                } else {
                    debug_log(&format!("Invalid index: {} not found in path lookup table", index));
                }
            }

            // // app.update_task_display()?;
            // let (headers, data) = app.update_task_display()?;
            // debug_log!(
            //     "headers -> {:?} data -> {:?}",
            //      headers,
            //      data,
            // );
            // tiny_tui::display_table(&headers, &data);

            // app.handle_tui_action(); // Remove the extra argument here

            debug_log!(
                "we_love_projects_loop() app.next_path_lookup_table {:?}",
                 app.next_path_lookup_table,
            );

            debug_log("handle_tui_action() started in we_love_projects_loop()");

            if input == "t" {

                // pass (no additional action if task mode entered)

            } else if input == "move" {
                let _ = move_task(
                    &app.next_path_lookup_table,
                );

            } else if input == "back" {
                debug_log("escape toggled");
                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone(); // Update full path after popping.
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                tiny_tui::render_list(
                    &app.tui_directory_list,
                    &app.current_path,
                    // Project Areas
                    &app.graph_navigation_instance_state.pa1_process,
                    &app.graph_navigation_instance_state.pa2_schedule,
                    &app.graph_navigation_instance_state.pa3_users,
                    &app.graph_navigation_instance_state.pa4_features,
                    &app.graph_navigation_instance_state.pa5_mvp,
                    &app.graph_navigation_instance_state.pa6_feedback,
                );
                app.update_directory_list()?;  // refresh to current cwd display items

            } else if input == "q" {
                debug_log("escape toggled");
                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                tiny_tui::render_list(
                    &app.tui_directory_list,
                    &app.current_path,
                    // Project Areas
                    &app.graph_navigation_instance_state.pa1_process,
                    &app.graph_navigation_instance_state.pa2_schedule,
                    &app.graph_navigation_instance_state.pa3_users,
                    &app.graph_navigation_instance_state.pa4_features,
                    &app.graph_navigation_instance_state.pa5_mvp,
                    &app.graph_navigation_instance_state.pa6_feedback,
                );
                app.update_directory_list()?;  // refresh to current cwd display items

            } else if !input.is_empty() {
                debug_log("!input.is_empty()");

                // let local_owner_user = &app.graph_navigation_instance_state.local_owner_user; // Access using self

                // // 1. final path name (.toml)
                // let message_path = get_next_message_file_path(&app.current_path, local_owner_user);
                // debug_log(&format!("Next message path: {:?}", message_path)); // Log the calculated message path

                // // 2. make message file
                // add_im_message(
                //     &message_path,
                //     local_owner_user,
                //     input.trim(),
                //     None,
                //     &app.graph_navigation_instance_state, // Pass using self
                // ).expect("handle_insert_text_input: Failed to add message");

                // app.load_im_messages(); // Access using self
            }
        }


        ///////////
        // Display
        ///////////

        // boostrap


        // Clear the screen
        print!("\x1B[2J\x1B[1;1H");

        // bootstrap: simple TUI display when at home screen
        debug_log!("app.current_path.to_string_lossy() -> {:?}", app.current_path.to_string_lossy());

        if app.current_path.to_string_lossy() == "project_graph_data/team_channels" {
            tiny_tui::simple_render_list(
                &app.tui_directory_list,
                &app.current_path);

        } else {

            match app.input_mode {
                InputMode::MainCommand => tiny_tui::render_list(
                    &app.tui_directory_list,
                    &app.current_path,
                    // Project Areas
                    &app.graph_navigation_instance_state.pa1_process,
                    &app.graph_navigation_instance_state.pa2_schedule,
                    &app.graph_navigation_instance_state.pa3_users,
                    &app.graph_navigation_instance_state.pa4_features,
                    &app.graph_navigation_instance_state.pa5_mvp,
                    &app.graph_navigation_instance_state.pa6_feedback,
                ),
                InputMode::TaskCommand => { /* Task list rendering logic */ },
                InputMode::InsertText => tiny_tui::simple_render_list(
                    &app.tui_textmessage_list,
                    &app.current_path,
                    // &app.graph_navigation_instance_state.agenda_process,
                    // &app.graph_navigation_instance_state.goals_features_subfeatures_tools_targets,
                    // &app.graph_navigation_instance_state.scope,
                    // &app.graph_navigation_instance_state.pa2_schedule,
                ),
            };
        }

    } // end of main loop
    debug_log("Finish: we love project loop.");
    debug_log(">*< Halt signal received. Exiting The Uma. Closing... we_love_projects_loop() |o|");

    Ok(())
}

/// Helper function to set the sync flag to a specific value
/// for set_sync_start_ok_flag_to_true()
/// for initialize_ok_to_start_sync_flag_to_false()
///
/// # Arguments
///
/// * `value` - The byte value to write to the flag file ("0" for false, "1" for true)
/// * `operation_name` - A description of the operation for logging purposes
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or failure with detailed error information
fn set_sync_flag(value: &[u8], operation_name: &str) -> Result<(), io::Error> {

    debug_log!("starting: set_sync_flag(), operation_name->{}", operation_name);

    // Get the absolute path to the flag file relative to the executable
    // let flag_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
    //     "data/flags/ok_to_start_sync_flag.txt"
    // )?;

    // // Get the absolute path to the sync flag file
    // let flag_path = match get_sync_start_ok_flag_path() {
    //     Ok(path) => path,
    //     Err(e) => {
    //         debug_log!("Error resolving path to sync flag from get_sync_start_ok_flag_path(): {}", e);
    //         PathBuf::new()
    //     }
    // };

    let mut flag_path = PathBuf::new(); // Default value if the function errors

    // TODO How to handle error in get_sync_start_ok_flag_path?
    if let Ok(path) = get_sync_start_ok_flag_path() {
        flag_path = path; // Only set if the function returns Ok
    } else {
        debug_log!("Error resolving path to sync flag from get_sync_start_ok_flag_path()");
    }


    // Ensure parent directories exist
    if let Some(parent_dir) = flag_path.parent() {
        fs::create_dir_all(parent_dir)?;
    }

    // Remove existing file if it exists
    match fs::remove_file(&flag_path) {
        Ok(_) => debug_log!("Old 'ok_to_start_sync_flag.txt' file deleted."),
        Err(e) if e.kind() == io::ErrorKind::NotFound => {
            // File doesn't exist, that's fine
        },
        Err(e) => {
            // Other errors might be important (permissions, etc.)
            debug_log!("Warning: couldn't remove old flag file: {}", e);
        }
    }

    // Create the file
    let mut file = File::create(&flag_path)
        .map_err(|e| {
            debug_log!("Failed to create 'ok_to_start_sync_flag.txt' file: {}", e);
            e
        })?;

    // Write the value
    file.write_all(value)
        .map_err(|e| {
            debug_log!("Failed to write to 'ok_to_start_sync_flag.txt' file: {}", e);
            e
        })?;

    debug_log!("Successfully {} at: {:?}", operation_name, flag_path);
    Ok(())
}

/// Sets the synchronization start flag to true ("1"), allowing synchronization to proceed.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or failure with detailed error information
///
/// # Errors
///
/// This function can fail if:
/// * Path resolution fails
/// * File creation fails (e.g., insufficient permissions)
/// * Writing to the file fails
pub fn set_sync_start_ok_flag_to_true() -> Result<(), io::Error> {
    set_sync_flag(b"1", "set sync flag to true")
}

/// Initializes the synchronization start flag to false ("0"), indicating that
/// synchronization should wait.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or failure with detailed error information
///
/// # Errors
///
/// This function can fail if:
/// * Path resolution fails
/// * File creation fails (e.g., insufficient permissions)
/// * Writing to the file fails
pub fn initialize_ok_to_start_sync_flag_to_false() -> Result<(), io::Error> {
    set_sync_flag(b"0", "initialized sync flag to false")
}

/// Sets a collaborator as "active" by creating a stub file in the sync_data directory.
///
/// This function creates an empty file (a "stub" file) in the directory:
/// `sync_data/{team_channel_name}/is_active/{collaborator_name}`. The presence of this file marks the collaborator as active
/// in the current session for the specified team channel.  The function handles directory creation and any potential errors during
/// file creation.
///
/// This flag signals to other threads and parts of uma that
/// this (remote collaborator) user is acive.
///
/// # Arguments
///
/// * `collaborator_name`: The name of the collaborator to set as active.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` if the stub file was successfully created, or a `ThisProjectError` if an error occurred.
///
/// uses:
/// use std::fs::{create_dir_all, File};
/// use std::path::PathBuf;
fn set_as_active(collaborator_name: &str) -> Result<(), ThisProjectError> {
    // 1. Get team channel name (replace with your actual implementation)
    let team_channel_name = match get_current_team_channel_name_from_nav_path() {
        Some(name) => name,
        None => {
            debug_log!("Error: Could not get current channel name. Skipping set_as_active.");
            return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
        },
    };

    // 2. Construct the directory path using PathBuf
    let mut directory_path = PathBuf::from("sync_data");
    directory_path.push(&team_channel_name);
    directory_path.push("is_active");
    directory_path.push(collaborator_name);

    // 3. Create the directory if it doesn't exist
    create_dir_all(directory_path.parent().unwrap())?;

    // 4. Create the stub file
    // The mere existence of the file (even empty) acts as the flag
    match File::create(&directory_path) {
        Ok(_) => {
            debug_log!("Collaborator '{}' set as active in channel '{}'.", collaborator_name, team_channel_name);
            Ok(())
        },
        Err(e) => {
            debug_log!("Error setting collaborator '{}' as active: {}", collaborator_name, e);
            Err(ThisProjectError::IoError(e))
        },
    }
}


// /// signal for continuing or for stoping whole Uma program with all threads
// /// Initializes the UMA continue/halt signal by creating or resetting the
// /// `continue_uma.txt` file and setting its value to "1" (continue).
// /// set to halt by `quit_set_continue_uma_to_false()`
// fn initialize_continue_uma_signal() {
//     // 1. Ensure the directory exists
//     let directory_path = Path::new(CONTINUE_UMA_PATH_STR).parent().unwrap(); // Get the parent directory
//     fs::create_dir_all(directory_path).expect("Failed to create directory for continue_uma.txt");

//     // 2. Create or overwrite the file
//     if fs::remove_file(CONTINUE_UMA_PATH_STR).is_ok() {
//         debug_log("Old 'continue_uma.txt' file deleted."); // Optional log.
//     }

//     let mut file = fs::File::create(CONTINUE_UMA_PATH_STR)
//         .expect("Failed to create 'continue_uma.txt' file.");

//     file.write_all(b"1")
//         .expect("Failed to write to 'continue_uma.txt' file.");
// }

// /// signal for continuing or for stoping whole Uma program with all threads
// fn initialize_hard_restart_signal() {
//     // 1. Ensure the directory exists
//     let directory_path = Path::new(HARD_RESTART_FLAG_PATH_STR).parent().unwrap(); // Get the parent directory
//     fs::create_dir_all(directory_path).expect("Failed to create directory for yes_hard_restart_flag.txt");

//     // 2. Create or overwrite the file
//     if fs::remove_file(HARD_RESTART_FLAG_PATH_STR).is_ok() {
//         debug_log("Old 'yes_hard_restart_flag.txt' file deleted."); // Optional log.
//     }

//     let mut file = fs::File::create(HARD_RESTART_FLAG_PATH_STR)
//         .expect("Failed to create 'yes_hard_restart_flag.txt' file.");

//     file.write_all(b"1")
//         .expect("Failed to write to 'yes_hard_restart_flag.txt' file.");
// }

// use std::fs::{self, File};
// use std::io::{self, Write};
// use std::path::PathBuf;

/// Initializes the UMA continue/halt signal by creating or resetting the
/// `continue_uma.txt` file and setting its value to "1" (continue).
///
/// This function sets up the continue/halt mechanism by writing a "1" to the
/// continue_uma.txt file, indicating that UMA should continue running.
/// It follows these steps:
///
/// 1. Resolves the absolute path to the file relative to the executable location
/// 2. Creates any necessary parent directories
/// 3. Removes any existing file (if present)
/// 4. Creates a new file with the content "1"
///
/// To halt UMA, the file can be set to "0" using `quit_set_continue_uma_to_false()`.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or an I/O error if the operation failed
///
/// # Errors
///
/// This function can fail if:
/// * The path cannot be resolved
/// * Parent directories cannot be created
/// * The file cannot be created or written to
pub fn initialize_continue_uma_signal() -> Result<(), io::Error> {
    // Get the executable-relative absolute path
    let abs_path = get_continue_uma_path()?;

    debug_log!("Initializing continue_uma signal to true (1) at: {:?}", abs_path);

    // Ensure parent directories exist
    if let Some(parent) = abs_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Try to delete the existing file if it exists
    match fs::remove_file(&abs_path) {
        Ok(_) => debug_log!("Old 'continue_uma.txt' file deleted."),
        Err(e) => {
            if e.kind() != io::ErrorKind::NotFound {
                // Log warning but continue - it's not fatal if we can't delete
                debug_log!("Warning: Could not delete old continue_uma.txt file: {}", e);
            }
        }
    }

    // Create and write to the file
    let mut file = File::create(&abs_path)?;
    file.write_all(b"1")?;

    debug_log!("Successfully initialized continue_uma signal to true (1)");
    Ok(())
}

/// Initializes the hard restart signal by creating or resetting the
/// `yes_hard_restart_flag.txt` file and setting its value to "1".
///
/// This function sets up the hard restart mechanism by writing a "1" to the
/// yes_hard_restart_flag.txt file, indicating that a hard restart is required.
/// It follows these steps:
///
/// 1. Resolves the absolute path to the file relative to the executable location
/// 2. Creates any necessary parent directories
/// 3. Removes any existing file (if present)
/// 4. Creates a new file with the content "1"
///
/// To cancel a hard restart, the file can be set to "0" using
/// `no_restart_set_hard_reset_flag_to_false()`.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or an I/O error if the operation failed
///
/// # Errors
///
/// This function can fail if:
/// * The path cannot be resolved
/// * Parent directories cannot be created
/// * The file cannot be created or written to
pub fn initialize_hard_restart_signal() -> Result<(), io::Error> {
    // Get the executable-relative absolute path
    let abs_path = get_hard_restart_flag_path()?;

    debug_log!("Initializing hard restart signal to true (1) at: {:?}", abs_path);

    // Ensure parent directories exist
    if let Some(parent) = abs_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Try to delete the existing file if it exists
    match fs::remove_file(&abs_path) {
        Ok(_) => debug_log!("Old 'yes_hard_restart_flag.txt' file deleted."),
        Err(e) => {
            if e.kind() != io::ErrorKind::NotFound {
                // Log warning but continue - it's not fatal if we can't delete
                debug_log!("Warning: Could not delete old yes_hard_restart_flag.txt file: {}", e);
            }
        }
    }

    // Create and write to the file
    let mut file = File::create(&abs_path)?;
    file.write_all(b"1")?;

    debug_log!("Successfully initialized hard restart signal to true (1)");
    Ok(())
}

// use std::fs::{self, File};
// use std::io::{self, Write};
// use std::path::PathBuf;

/// Sets a signal to stop the entire Uma program with all threads.
///
/// This function writes a "0" to the continue_uma.txt file, which is used
/// as a signal to stop the Uma program. It follows these steps:
///
/// 1. Resolves the absolute path to the continue_uma.txt file relative to the executable
/// 2. Attempts to delete any existing file (ignoring if it doesn't exist)
/// 3. Creates parent directories if they don't exist
/// 4. Creates a new file with the content "0"
///
/// The function uses a replace-not-modify workflow to avoid potential
/// file locking or partial write issues.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or an I/O error if the operation failed
///
/// # Errors
///
/// This function can fail if:
/// * The path cannot be resolved
/// * The parent directories cannot be created
/// * The file cannot be created or written to
pub fn quit_set_continue_uma_to_false() -> Result<(), io::Error> {
    // Get the executable-relative absolute path
    let abs_path = get_continue_uma_path()?;

    debug_log!("Setting continue_uma flag to false (0) at: {:?}", abs_path);

    // Try to delete the existing file if it exists
    match fs::remove_file(&abs_path) {
        Ok(_) => debug_log!("Old 'continue_uma.txt' file deleted."),
        Err(e) => {
            if e.kind() != io::ErrorKind::NotFound {
                // Log error but continue - it's not fatal if we can't delete
                debug_log!("Warning: Could not delete old continue_uma.txt file: {}", e);
            }
        }
    }

    // Ensure parent directories exist
    if let Some(parent) = abs_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Create and write to the file
    let mut file = File::create(&abs_path)?;
    file.write_all(b"0")?;

    debug_log!("Successfully set continue_uma flag to false (0)");
    Ok(())
}

/// Sets the hard restart flag to false, indicating no restart is needed.
///
/// This function writes a "0" to the yes_hard_restart_flag.txt file, which is used
/// to control program restart behavior. It follows these steps:
///
/// 1. Resolves the absolute path to the flag file relative to the executable
/// 2. Attempts to delete any existing file (ignoring if it doesn't exist)
/// 3. Creates parent directories if they don't exist
/// 4. Creates a new file with the content "0"
///
/// The function uses a replace-not-modify workflow to avoid potential
/// file locking or partial write issues.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or an I/O error if the operation failed
///
/// # Errors
///
/// This function can fail if:
/// * The path cannot be resolved
/// * The parent directories cannot be created
/// * The file cannot be created or written to
pub fn no_restart_set_hard_reset_flag_to_false() -> Result<(), io::Error> {
    // Get the executable-relative absolute path
    let abs_path = get_hard_restart_flag_path()?;

    debug_log!("Setting hard restart flag to false (0) at: {:?}", abs_path);

    // Try to delete the existing file if it exists
    match fs::remove_file(&abs_path) {
        Ok(_) => debug_log!("Old 'yes_hard_restart_flag.txt' file deleted."),
        Err(e) => {
            if e.kind() != io::ErrorKind::NotFound {
                // Log error but continue - it's not fatal if we can't delete
                debug_log!("Warning: Could not delete old yes_hard_restart_flag.txt file: {}", e);
            }
        }
    }

    // Ensure parent directories exist
    if let Some(parent) = abs_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Create and write to the file
    let mut file = File::create(&abs_path)?;
    file.write_all(b"0")?;

    debug_log!("Successfully set hard restart flag to false (0)");
    Ok(())
}

// // TODO spin these two off into a function optional_passive_mode();
// // if return true, return?
// // Get command line arguments
// let args: Vec<String> = env::args().collect();
// // Check for passive message mode
// if args.len() >= 3 && args[1] == "--passive_message_mode" {
//     let path = Path::new(&args[2]);
//     if let Err(e) = run_passive_message_mode(path) {
//         eprintln!("Error in passive message mode: {}", e);
//         process::exit(1);
//     }
//     return;
// }
// // Check for passive message mode
// if args.len() >= 3 && args[1] == "--passive_task_mode" {
//     let path = Path::new(&args[2]);
//     if let Err(e) = run_passive_task_mode(path) {
//         eprintln!("Error in passive message mode: {}", e);
//         process::exit(1);
//     }
//     return;
// }
/// Check for user input argument flag to launch int passive mode
/// - message mode passsive
/// or
/// - task mode passive
/// if so, return True (after running that mode)
/// else: return false
///
/// use in main with:
/// ```
/// if optional_passive_mode() {
///     return;
/// };
/// ```
///
fn optional_passive_mode() -> bool {
    // TODO spin these two off into a function optional_passive_mode();
    // if return true, return?
    // Get command line arguments
    let args: Vec<String> = env::args().collect();
    // Check for passive message mode
    if args.len() >= 3 && args[1] == "--passive_message_mode" {
        let path = Path::new(&args[2]);
        if let Err(e) = run_passive_message_mode(path) {
            eprintln!("Error in passive message mode: {}", e);
            process::exit(1);
        }
        return true;
    }
    // Check for passive message mode
    if args.len() >= 3 && args[1] == "--passive_task_mode" {
        let path = Path::new(&args[2]);
        if let Err(e) = run_passive_task_mode(path) {
            eprintln!("Error in passive message mode: {}", e);
            process::exit(1);
        }
        return true;
    }

    return false;
}

/*
An Appropriately Svelt Mainland:
*/
/// Initializes the UMA continue/halt signal by creating or resetting the
/// `continue_uma.txt` file and setting its value to "1" (continue).
/// set to hault by quit_set_continue_uma_to_false()
///
/// There is NO practical advantage
/// to using Arc<AtomicBool> over writing a "1" or "0" to a file.
/// The file method is simpler, more efficient,
/// and just as reliable in this context.
///
/// This also allows the user to manually set the halt signal.
fn main() {

    if optional_passive_mode() {
        return;
    };

    let _ = initialize_continue_uma_signal(); // set boolean flag for loops to hault
    let _ = initialize_hard_restart_signal(); // set boolean flag for uma restart

    let mut online_mode: bool;

    loop { // Main loop: let it fail, and try again

        if should_not_hard_restart() { // Check for restart
            debug_log("should_halt_uma(), exiting Uma in main()");
            break;
        }

        debug_log("boot...");
        match initialize_uma_application() {
            Ok(temp_online_val) => {
                online_mode = temp_online_val;
                if online_mode {
                    debug_log!("UMA initialized in online mode.");
                } else {
                    debug_log!("UMA initialized in offline mode.")
                }
            }
            Err(e) => {
                eprintln!("Initialization failed: {}", e);
                debug_log!("Initialization failed: {}", e);
                std::process::exit(1);
                // break;
            }
        }

        debug_log("Start!");

        // Thread 1: Executes the thread1_loop function
        let we_love_projects_loop = thread::spawn(move || {
            let _ = we_love_projects_loop();
        });

        // Thread 2: Executes the thread2_loop function
        if online_mode {
            let you_love_the_sync_team_office = thread::spawn(move || {
                let _ = you_love_the_sync_team_office();
            });
            you_love_the_sync_team_office.join().unwrap(); // Wait for finish
        };

        we_love_projects_loop.join().unwrap(); // Wait for finish
        // if online_mode {
        //     you_love_the_sync_team_office.join().unwrap();
        //     } // Wait for finish
        // End
        println!("All threads completed. The Uma says fare well and strive.");
        debug_log("All threads completed. The Uma says fare well and strive.");
        debug_log(">*< Halt signal received. Exiting The Uma. Closing... main() |o|");
    }
}
