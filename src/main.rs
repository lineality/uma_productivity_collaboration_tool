/*
Uma
2024.09-11
RUST_BACKTRACE=full cargo run

# Uma: Coordination, Productivity, Hygiene
```
4_|
/ \
```
A distributed project graph database MCU (Multipoint Conferencing Unit) with cli TUI, instant messenger, Kanban Task Manager, and other Agile Kahneman-Tversky project, productivity, coordination, collaboration features

Uma Productivity Collaboration Tools for Project-Alignment
~ "Read the old books."
- MIT license
- https://github.com/lineality/uma_productivity_collaboration_tool
- https://github.com/lineality/definition_behavior_studies
- https://github.com/lineality/Online_Voting_Using_One_Time_Pads
- https://github.com/lineality/object_relationship_spaces_ai_ml
In memory of Eleanor Th. Vadala 1923-2023: aviator, astronomer, engineer, pioneer, leader, friend.

cargo.toml ->

[package]
name = "uma"
version = "0.1.0"
edition = "2021"

[dependencies]
walkdir = "2.5.0"
toml = "0.8.19"
serde = { version = "1.0.210", features = ["derive"] }
rand = "0.8.5"
getifaddrs = "0.1.4"

https://docs.rs/getifaddrs/latest/getifaddrs/

// tiny_tui_module.rs

pub mod tiny_tui {
    use std::path::Path;
    use std::time::{
        Duration,
        UNIX_EPOCH
        };
    use crate::{ // Import from the main module
        DEBUG_FLAG,
        debug_log,
        OpenOptions,
        Write,
        };

    pub fn render_list(
        list: &Vec<String>,
        current_path: &Path,
        agenda_process: &str,
        goals_features: &str,
        scope: &str,
        pa2_schedule: &Vec<u64>,
    ) {
        // 1. Get the path components
        let path_components: Vec<_> = current_path.components().collect();

        // 2. Display the path, skipping the first two components
        if path_components.len() > 2 {
            let relevant_path = path_components[2..].iter()
                .map(|c| c.as_os_str().to_string_lossy())
                .collect::<Vec<_>>()
                .join("/");
            println!("Current Path: /{}", relevant_path);
        } else {
            println!("Select a Team-Channel (by number):");
        }

        // 2b. Display added core node fields
        println!("Agenda/Process: {}", agenda_process);
        println!("Goals/Features: {}", goals_features);
        println!("Scope: {}", scope);

        if pa2_schedule.len() == 2 {
            let start_time = pa2_schedule[0];
            let end_time = pa2_schedule[1];
            let duration_days = (end_time - start_time) / (60 * 60 * 24);

            let start_date = format_timestamp_to_date(start_time);
            let end_date = format_timestamp_to_date(end_time);
            println!("Schedule: {} - {} ({} days)", start_date, end_date, duration_days);

        }
        else {
            println!("Schedule: (no schedule)");
        }

        // 3. Display the list items as before
        for (i, item) in list.iter().enumerate() {
            println!("{}. {}", i + 1, item);
        }
    }

    pub fn simple_render_list(list: &Vec<String>, current_path: &Path) {

        // 1. Get the path components
        let path_components: Vec<_> = current_path.components().collect();

        // 2. Display the path, skipping the first two components
        if path_components.len() > 2 {
            let relevant_path = path_components[2..].iter()
                .map(|c| c.as_os_str().to_string_lossy())
                .collect::<Vec<_>>()
                .join("/");
            println!("Current Path: /{}", relevant_path);
        } else {
            println!("Select a Team-Channel (by number):");
        }

        // 3. Display the list items as before
        for (i, item) in list.iter().enumerate() {
            println!("{}. {}", i + 1, item);
        }
    }



/// Converts a Unix timestamp (seconds since 1970-01-01 00:00:00 UTC) to a YYYY-MM-DD formatted date string
///
/// # Arguments
/// * `timestamp` - Unix timestamp in seconds
///
/// # Returns
/// * `String` - Date in "YYYY-MM-DD" format, or "Invalid Date" if the timestamp cannot be converted
///
/// # Examples
/// ```
/// let timestamp = 1672531200; // 2023-01-01 00:00:00 UTC
/// assert_eq!(format_timestamp_to_date(timestamp), "2023-01-01");
/// ```
/// use -> use std::time::{Duration, UNIX_EPOCH};
fn format_timestamp_to_date(timestamp: u64) -> String {
    UNIX_EPOCH
        .checked_add(Duration::from_secs(timestamp))
        .and_then(|datetime| datetime.duration_since(UNIX_EPOCH).ok())
        .map(|duration| {
            let secs = duration.as_secs();
            let year = 1970 + (secs / 31_557_600); // Approximate years (365.25 days)
            let remaining_secs = secs % 31_557_600;
            let month = 1 + (remaining_secs / 2_629_800); // Approximate months (30.44 days)
            let day = 1 + ((remaining_secs % 2_629_800) / 86_400); // Days (24 hours)

            format!("{:04}-{:02}-{:02}", year, month, day)
        })
        .unwrap_or_else(|| "Invalid Date".to_string())
}


    pub fn render_tasks_table(headers: &[String], data: &[Vec<String>], current_path: &Path) {
        debug_log("starting: render_tasks_table");
        // 1. Display Current Path
        print!("\x1B[2J\x1B[1;1H"); // Clear the screen
        println!("Current Path: {}", current_path.display());

        // 2. Display Table (reuse display_table from tiny_tui_module)
        display_table(headers, data);

        // 3. (Optional) Display any other task-specific information or instructions.
        println!("Select a Task (by number):");
    }



    // pub fn render_list(list: &Vec<String>, current_path: &Path) {
    //     println!("Current Path: {}", current_path.display());
    //     for (i, item) in list.iter().enumerate() {
    //         println!("{}. {}", i + 1, item);
    //     }
    // }

    pub fn get_input() -> Result<String, std::io::Error> {
        let mut input = String::new();
        std::io::stdin().read_line(&mut input)?;
        Ok(input.trim().to_string())
    }

    pub fn display_table(headers: &[String], data: &[Vec<String>]) {  // Changed header type
        debug_log("tui module: task-mode: start: display_table()");
        debug_log!(
            "tui module: display_table(): headers -> {:?} data -> {:?}",
            headers,
            data,
        );

        // Print headers
        for header in headers {
            print!("{:<15} ", header);
        }
        println!();

        // Print separator (optional)
        println!("{}", "-".repeat(headers.len() * 15));


        // Print rows:  Handle potentially uneven row lengths
        // Find the maximum number of columns for formatting:
        let max_columns = headers.len();

        for row in data {
            for (i, item) in row.iter().enumerate() {
                if i < max_columns { // Ensure we don't exceed the header count.
                    print!("{:<15} ", item);
                }
            }
            println!();
        }
    }

    // pub fn display_table(headers: &[&str], data: &[Vec<&str>]) {
    //     // Print headers
    //     for header in headers {
    //         print!("{:<15} ", header); // Left-align with padding
    //     }
    //     println!();

    //     // Print separator
    //     println!("{}", "-".repeat(headers.len() * 15));

    //     // Print data rows
    //     for row in data {
    //         for item in row {
    //             print!("{:<15} ", item);
    //         }
    //         println!();
    //     }
    // }
    // // fn main() {
    // //     let headers = vec!["Column 1", "Column 2", "Column 3"];
    // //     let data = vec![
    // //         vec!["Data A", "Data B", "Data C"],
    // //         vec!["Data D", "Data E", "Data F"],
    // //     ];
    // //     display_table(&headers, &data);
    // // }

    // Helper function to transpose the table data
    pub fn transpose_table_data(data: &[Vec<String>]) -> Vec<Vec<String>> {
        debug_log("tui module: task-mode: start: transpose_table_data()");
        if data.is_empty() {
            return Vec::new();
        }

        let num_rows = data.iter().map(|col| col.len()).max().unwrap_or(0);  // Or 0 for an empty table
        let num_cols = data.len();
        let mut transposed_data = vec![vec![String::new(); num_cols]; num_rows];

        for (j, col) in data.iter().enumerate() {
            for (i, item) in col.iter().enumerate() {
                transposed_data[i][j] = item.clone();
            }
        }

        transposed_data
    }

}


# See:
src/manage_absolute_executable_directory_relative_paths.rs
src/read_toml_field.rs
src/read_toml_field.rs

*/

/*

// Get armored public key, using key-id (full fingerprint in)
let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
    Ok(fingerprint) => fingerprint,
    Err(e) => {
        // Since the function returns Result<CoreNode, String>, we need to return a String error
        return Err(format!(
            "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
            e
        ).into());
    }
};

// code from load_core_node...()
// Get the UME temp directory path with proper GpgError conversion
let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
    .map_err(|io_err| GpgError::ValidationError(
        format!("Failed to get UME temp directory path: {}", io_err)
    ))?;

// Using Debug trait for more detailed error information
let node_readcopy_path = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
    &node_toml_path,
    &gpg_full_fingerprint_key_id_string,
    &base_uma_temp_directory_path,
).map_err(|e| format!("Failed to get temporary read copy of TOML file: {:?}", e))?;

or

// Using Debug trait for more detailed error information
let node_readcopy_path = get_pathstring_to_temp_plaintoml_verified_extracted(
    &node_toml_path,
    &gpg_full_fingerprint_key_id_string,
    &base_uma_temp_directory_path,
).map_err(|e| format!("Failed to get temporary read copy of TOML file: {:?}", e))?;

*/

// Set debug flag (future: add time stamp with 24 check)
const DEBUG_FLAG: bool = true;
const MAX_NETWORK_TYPE_LENGTH: usize = 1024; // Example: 1KB limit

const EMPTY_IPV_4: Ipv4Addr = Ipv4Addr::new(127, 0, 0, 1); // == = 127.0.0.1
const EMPTY_IPV_6: Ipv6Addr = Ipv6Addr::UNSPECIFIED; // Correct way to represent an unspecified IPv6 address

use std::env;
use std::hash::{
    Hash,
    DefaultHasher,
    Hasher,
};
use std::io::{
    self,
    Error,
    ErrorKind,
    Write,
    BufRead,
    BufReader,
    Read,
};

// use std::str::FromStr;
use std::process::{
    self,
    Command as StdCommand,
    Stdio,
};
use std::error::Error as StdError;
use walkdir::WalkDir;
use std::path::Path;
use std::path::{
    PathBuf,
};
use std::time::{
    SystemTime,
    UNIX_EPOCH,
    // Instant,
};

use std::fs;
use std::fs::{
    File,
    remove_file,
    create_dir_all,
    OpenOptions,
    read_to_string,
    // write,
    remove_dir_all,
    read_dir,
    // DirEntry,
};
use toml;
use toml::Value;
use serde::{
    Deserialize,
    Serialize,

};

use std::ffi::OsStr;
use std::collections::HashMap;
use std::collections::HashSet;
// use std::process::Command;

// For Sync
use rand::prelude::{
    // SliceRandom,
    // IteratorRandom,
    Rng,
};
use std::thread;
use std::num::ParseIntError;
use std::time::Duration;
use std::net::{
    IpAddr,
    Ipv4Addr,
    Ipv6Addr,
    // TcpListener,
    // TcpStream,
    SocketAddr,
    UdpSocket,
};
// https://docs.rs/getifaddrs/latest/getifaddrs/
use getifaddrs::{getifaddrs, InterfaceFlags};





/*
To eventually replace any 3rd party
toml crates
*/
// For toml and clearsigntoml
mod clearsign_toml_module;
use crate::clearsign_toml_module::{
    GpgError, cleanup_collaborator_temp_file, clearsign_and_encrypt_file_for_recipient, convert_toml_filewithkeyid_into_clearsigntoml_inplace, convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace, decrypt_gpgfile_to_output, extract_verify_store_gpg_encrypted_clearsign_toml, get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml, get_pathstring_to_temp_plaintoml_verified_extracted, get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml, gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck, q_and_a_user_selects_gpg_key_full_fingerprint, read_abstract_collaborator_portassignments_from_clearsigntoml_withoutkeyid, read_abstract_ports_from_clearsigntoml_without_publicgpgkey, read_bool_field_from_toml, read_bool_field_fromtoml_binary, read_bool_from_clearsigntoml_without_publicgpgkey, read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml, read_float_f32_field_from_toml, read_multiline_string_from_clearsigntoml, read_option_bool_from_clearsigntoml_without_publicgpgkey, read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey, read_option_i64_from_clearsigntoml_without_publicgpgkey, read_option_usize_from_clearsigntoml_without_publicgpgkey, read_pathbuf_from_clearsigntoml_without_publicgpgkey, read_single_line_string_field_from_toml, read_singleline_string_from_clearsigntoml, read_singleline_string_from_clearsigntoml_without_publicgpgkey, read_str_array_field_clearsigntoml, read_string_array_field_from_toml, read_stringarray_from_clearsigntoml_without_publicgpgkey, read_teamchannel_collaborator_ports_clearsigntoml_without_keyid, read_u8_array_from_clearsigntoml_without_publicgpgkey, read_u8_field_from_toml, read_u64_array_from_clearsigntoml_without_publicgpgkey, read_u64_field_from_toml, read_u64_from_clearsigntoml_without_publicgpgkey, verify_clearsign, verify_clearsigned_file_and_extract_content_to_output
};


/// for managing file paths
mod manage_absolute_executable_directory_relative_paths;
use manage_absolute_executable_directory_relative_paths::{
    make_input_path_name_abs_executabledirectoryrelative_nocheck,
    make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error,
    make_file_path_abs_executabledirectoryrelative_canonicalized_or_error,
    get_absolute_path_to_executable_parentdirectory,
    abs_executable_directory_relative_exists,
    prepare_file_parent_directories_abs_executabledirectoryrelative,
    make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path,
    // count_subdirectories_executabledirectoryrelative_default_zero,
};

mod padnet_otp_module;
use padnet_otp_module::{
    ValidationLevel,padnet_make_one_pad_set,
    PadIndex, padnet_writer_strict_cleanup_xor_file_to_resultpath, PadnetError, padnet_reader_xor_file
};

// For TUI
#[macro_use]
mod tiny_tui_module;
use tiny_tui_module::tiny_tui;


const FILE_READWRITE_N_RETRIES: u64 = 5;
// const FILE_READWRITE_RETRY_SEC_PAUSE: u64 = 2;
const FILE_READWRITE_RETRY_SEC_PAUSE_MIN: u64 = 1;
const FILE_READWRITE_RETRY_SEC_PAUSE_MAX: u64 = 6;

/*
Path constants will later be converted
to executible-parent-relative-aboslute paths
*/
const UMA_TOML_CONFIGFILE_PATH_STR: &str = "uma.toml";

/// use:
/// "project_graph_data/collaborator_files_address_book/{}__collaborator.toml";
/// "project_graph_data/collaborator_files_address_book/{}__collaborator.gpgtoml";
const COLLABORATOR_ADDRESSBOOK_PATH_STR: &str = "project_graph_data/collaborator_files_address_book";

const TEAM_CHANNELS_HOMEBASE_PATH_STR: &str = "project_graph_data/team_channels/";


/// temp file to clean regularly
const TEMP_DIR_BASE_UMA_PATH_STR: &str = "uma_temp_dir";

const CONTINUE_UMA_PATH_STR: &str = "project_graph_data/session_state_items/continue_uma.txt";
const HARD_RESTART_FLAG_PATH_STR: &str = "project_graph_data/session_state_items/yes_hard_restart_flag.txt";
const SYNC_START_OK_FLAG_PATH_STR: &str = "project_graph_data/session_state_items/ok_to_start_sync_flag.txt";
const INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR: &str = "invites_updates/incoming/key.asc";
const UMA_SESSION_STATE_ITEMS_DIR_PATH_STR: &str = "project_graph_data/session_state_items";

const UMA_CURRENT_NODE_PATH_STR: &str = "project_graph_data/session_state_items/current_node_directory_path.txt";

const WRITER_TO_PADNET_UMA_PATH_STR: &str = "padnet/to";
const READER_FROM_PADNET_UMA_PATH_STR: &str = "padnet/from";

/// Gets the absolute path to temp directory
/// executible-parent-relative-aboslute path
pub fn get_writer_to_padnet_directory_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        WRITER_TO_PADNET_UMA_PATH_STR
    )
}

/// Gets the absolute path to temp directory
/// executible-parent-relative-aboslute path
pub fn get_reader_from_padnet_directory_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        READER_FROM_PADNET_UMA_PATH_STR
    )
}

/*
# Use Example:
```
let absolute_path = match get_team_channels_homebase_directory_path() {
    Ok(path) => path,
    Err(e) => {
        debug_log!("Failed to get absolute path: {}", e);
        return None;
    }
};
```
*/

/// Gets the absolute path to temp directory
/// executible-parent-relative-aboslute path
pub fn get_addressbook_directory_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        COLLABORATOR_ADDRESSBOOK_PATH_STR
    )
}

/// Gets the absolute path to temp directory
/// executible-parent-relative-aboslute path
pub fn get_team_channels_homebase_directory_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        TEAM_CHANNELS_HOMEBASE_PATH_STR
    )
}

/// Gets the absolute path to temp directory
/// executible-parent-relative-aboslute path
pub fn get_base_uma_temp_directory_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        TEMP_DIR_BASE_UMA_PATH_STR
    )
}

/// Gets the absolute path to the hard restart flag file.
/// executible-parent-relative-aboslute path
pub fn get_hard_restart_flag_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        HARD_RESTART_FLAG_PATH_STR
    )
}

/// Gets the absolute path to the sync start OK flag file.
/// executible-parent-relative-aboslute path
pub fn get_sync_start_ok_flag_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        SYNC_START_OK_FLAG_PATH_STR
    )
}

/// Gets the absolute path to the incoming public GPG key file.
/// executible-parent-relative-aboslute path
pub fn get_incoming_publicgpg_keyasc_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR
    )
}

pub fn get_continue_uma_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        CONTINUE_UMA_PATH_STR
    )
}

pub fn get_sessionstateitems_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        UMA_SESSION_STATE_ITEMS_DIR_PATH_STR
    )
}

pub fn get_current_node_path() -> io::Result<PathBuf> {
    make_input_path_name_abs_executabledirectoryrelative_nocheck(
        UMA_CURRENT_NODE_PATH_STR
    )
}


/// Determines if UMA should halt based on the continue_uma.txt file.
///
/// Reads the content of the continue_uma.txt file from its executable-relative
/// absolute path, and checks if the content is "0".
///
/// # Returns
///
/// * `bool` - true if UMA should halt (file contains "0"), false otherwise.
///
/// # Behavior
///
/// - Returns true if the file exists and contains "0"
/// - Returns false if:
///   - The path to the file cannot be resolved
///   - The file does not exist
///   - The file cannot be read
///   - The file contains any value other than "0"
pub fn should_halt_uma() -> bool {
    // 1. Get the absolute path to the continue_uma.txt file
    let file_path = match get_continue_uma_path() {
        Ok(path) => path,
        Err(e) => {
            eprintln!("Error resolving path to continue_uma.txt: {:?}", e);
            return false; // Don't halt if we can't even find the path
        }
    };

    // 2. Read the file content
    let file_content = match fs::read_to_string(&file_path) {
        Ok(content) => content,
        Err(e) => {
            eprintln!("Error reading continue_uma.txt at {:?}: {:?}", file_path, e);

            // Optional: attempt to create the file if it doesn't exist
            if e.kind() == io::ErrorKind::NotFound {
                println!("continue_uma.txt not found, creating with default value '1'");
                if let Some(parent) = file_path.parent() {
                    if let Err(e) = fs::create_dir_all(parent) {
                        eprintln!("Failed to create parent directories: {:?}", e);
                    }
                }

                if let Err(e) = fs::write(&file_path, "1") {
                    eprintln!("Failed to create continue_uma.txt file: {:?}", e);
                }
            }

            return false; // Don't halt on error reading the file
        }
    };

    // 3. Check if the file content is "0"
    file_content.trim() == "0"
}

// use std::fs;
// use std::io::{self, Write};
// use std::path::{Path, PathBuf};
// use crate::manage_absolute_executable_directory_relative_paths::{
//     make_file_path_abs_executabledirectoryrelative_canonicalized_or_error,
//     prepare_file_parent_directories_abs_executabledirectoryrelative,
// };

// /// optional
// /// Gets the absolute path to the continue_uma.txt file, creating it with default content "1"
// /// if it doesn't exist.
// ///
// /// # Returns
// ///
// /// * `io::Result<PathBuf>` - The absolute canonicalized path to the continue_uma.txt file
// ///
// /// # Errors
// ///
// /// This function will return an error if:
// /// * The parent directory cannot be created
// /// * The file cannot be created when it doesn't exist
// /// * Path canonicalization fails for any reason
// fn get_continue_uma_path() -> io::Result<PathBuf> {
//     let relative_path = CONTINUE_UMA_PATH_STR;

//     // First try to get the path if it already exists
//     match make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_path) {
//         Ok(path) => {
//             // File exists, return its canonicalized path
//             println!("Continue UMA file found at: {:?}", path);
//             Ok(path)
//         },
//         Err(_) => {
//             // File doesn't exist or other error - create it with default content "1"
//             println!("Continue UMA file not found, creating it with default value '1'");

//             // Prepare the parent directories
//             let path = prepare_file_parent_directories_abs_executabledirectoryrelative(relative_path)?;

//             // Create the file with default content
//             let mut file = fs::File::create(&path)?;
//             file.write_all(b"1")?;

//             // Return the canonicalized path
//             let canonicalized = path.canonicalize()?;
//             println!("Created continue UMA file at: {:?}", canonicalized);
//             Ok(canonicalized)
//         }
//     }
// }

// /// Reads the content of the continue_uma.txt file, creating it with default value "1"
// /// if it doesn't exist or there's an error reading it.
// ///
// /// # Returns
// ///
// /// * `String` - The content of the continue_uma.txt file ("0" or "1"), defaults to "1" on errors
// fn read_continue_uma_file() -> String {
//     // First get the path, which creates the file if needed
//     let continue_path = match get_continue_uma_path() {
//         Ok(path) => path,
//         Err(e) => {
//             eprintln!("Error ensuring continue_uma.txt path: {}", e);
//             return "1".to_string(); // Default to "continue" on path resolution error
//         }
//     };

//     // Then read the file content
//     match fs::read_to_string(&continue_path) {
//         Ok(content) => {
//             let trimmed = content.trim().to_string();
//             // Validate content - if not "0" or "1", default to "1"
//             if trimmed != "0" && trimmed != "1" {
//                 eprintln!("Invalid content in continue_uma.txt: '{}', defaulting to '1'", trimmed);
//                 // Try to fix the file with correct content
//                 let _ = fs::write(&continue_path, "1");
//                 "1".to_string()
//             } else {
//                 trimmed
//             }
//         },
//         Err(e) => {
//             eprintln!("Error reading continue_uma.txt: {}", e);

//             // Try to recreate the file with default content
//             match fs::write(&continue_path, "1") {
//                 Ok(_) => "1".to_string(),
//                 Err(e2) => {
//                     eprintln!("Error creating continue_uma.txt after read failed: {}", e2);
//                     "1".to_string() // Default to "continue" on write error
//                 }
//             }
//         }
//     }
// }

// ==================
// Uma Error Section
// ==================

pub enum SyncError {
    ConnectionError(std::io::Error),
    ChecksumMismatch,
    Timeout,
    FileReadError(std::io::Error),
    FileWriteError(std::io::Error),
    // ... other potential errors ...
}

// #[derive(Debug, Deserialize, Serialize, Clone)]
// struct CollaboratorPairPorts {
//     collaborator_ports: Vec<ReadTeamchannelCollaboratorPortsToml>,
// }

#[derive(Debug)]
enum MyCustomError {
    /// IO errors from file operations
    IoError(std::io::Error),
    /// TOML parsing and deserialization errors
    TomlDeserializationError(toml::de::Error),
    /// Invalid data format or content errors
    InvalidData(String),
    /// Port collision errors when ports are already in use
    PortCollision(String),
    /// Custom error messages for general purpose errors
    Custom(String),
}


// Implement From<ThisProjectError> for MyCustomError
impl From<ThisProjectError> for MyCustomError {
    fn from(error: ThisProjectError) -> Self {
        match error {
            ThisProjectError::IoError(e) => MyCustomError::IoError(e),
            ThisProjectError::TomlDeserializationError(e) => MyCustomError::TomlDeserializationError(e),
            ThisProjectError::InvalidData(msg) => MyCustomError::InvalidData(msg),
            ThisProjectError::InvalidInput(msg) => MyCustomError::InvalidData(msg),
            ThisProjectError::PortCollision(msg) => MyCustomError::PortCollision(msg),
            // ... add other conversions for your variants ...
            _ => MyCustomError::InvalidData("Unknown error".to_string()), // Default case
        }
    }
}

impl From<String> for MyCustomError {
    /// Converts a String into a MyCustomError::Custom variant
    fn from(error_message: String) -> Self {
        MyCustomError::Custom(error_message)
    }
}

impl From<&str> for MyCustomError {
    /// Converts a &str into a MyCustomError::Custom variant
    fn from(error_message: &str) -> Self {
        MyCustomError::Custom(error_message.to_string())
    }
}

// Optional: implement Display trait for better error messages
impl std::fmt::Display for MyCustomError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            MyCustomError::IoError(e) => write!(f, "IO Error: {}", e),
            MyCustomError::TomlDeserializationError(e) => write!(f, "TOML Error: {}", e),
            MyCustomError::InvalidData(msg) => write!(f, "Invalid Data: {}", msg),
            MyCustomError::PortCollision(msg) => write!(f, "Port Collision: {}", msg),
            MyCustomError::Custom(msg) => write!(f, "Error: {}", msg),
        }
    }
}
// Implement PartialEq manually:
impl PartialEq for MyCustomError {
    fn eq(&self, other: &Self) -> bool {
        match (self, other) {
            // (MyCustomError::IoError(ref e1), MyCustomError::IoError(ref e2)) => {
            (MyCustomError::IoError(e1), MyCustomError::IoError(e2)) => {
                e1.kind() == e2.kind() // Compare the ErrorKind
                // Or you can use:
                // e1.to_string() == e2.to_string()
            },
            (MyCustomError::TomlDeserializationError(e1), MyCustomError::TomlDeserializationError(e2)) => e1 == e2,
            // Add other arms for your variants as needed
            _ => false, // Different variants are never equal
        }
    }
}

// Implement the std::error::Error trait
impl StdError for MyCustomError {
    fn source(&self) -> Option<&(dyn StdError + 'static)> {
        match *self {
            MyCustomError::IoError(ref err) => Some(err),
            MyCustomError::TomlDeserializationError(ref err) => Some(err),
            _ => None, // No underlying source for these variants
        }
    }
}

// impl std::fmt::Display for MyCustomError {
//     fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
//         match self {
//             MyCustomError::IoError(err) => write!(f, "IO Error: {}", err),
//             // MyCustomError::TomlDeserializationError(err) => write!(f, "TOML Error: {}", err),
//             MyCustomError::TomlDeserializationError(err) => write!(f, "TOML Error: {}", err),
//             // &MyCustomError::InvalidData(_) => todo!(),
//             &MyCustomError::InvalidData(_) => todo!(),
//             &MyCustomError::PortCollision(_) => todo!(),
//         }
//     }
// }

// Implement the From trait for easy conversion from io::Error and toml::de::Error:
impl From<io::Error> for MyCustomError {
    fn from(error: io::Error) -> Self {
        MyCustomError::IoError(error)
    }
}

impl From<toml::de::Error> for MyCustomError {
    fn from(error: toml::de::Error) -> Self {
        MyCustomError::TomlDeserializationError(error)
    }
}

#[derive(Debug)]
pub enum ThisProjectError {
    IoError(std::io::Error),
    TomlDeserializationError(toml::de::Error), // May be depricated along with serde-crate
    TomlVanillaDeserialStrError(String), // use without serede crate (good)
    InvalidInput(String),
    InvalidData(String),
    PortCollision(String),
    NetworkError(String),
    WalkDirError(walkdir::Error),
    ParseIntError(ParseIntError),
    GpgError(String),  // GPG-specific error type
    ParseError(std::num::ParseIntError),
    // Add new variant for String errors
    StringError(String),
    // Padnet
    /// File exceeds maximum allowed size for processing
    /// Prevents accidental or malicious processing of oversized files
    FileTooLarge {
        /// Path of the file that was too large
        path: PathBuf,
        /// Actual size in bytes
        size_bytes: usize,
        /// Maximum allowed size in bytes
        max_allowed: usize,
    },

    /// OTP/Padnet operation failed
    /// Wraps errors from the padnet XOR encryption system
    PadnetError(String),

    /// Temporary file cleanup failed (non-fatal, logged only)
    /// Used when temp file deletion fails but operation succeeded
    TempFileCleanupWarning(String),
}

impl From<GpgError> for ThisProjectError {
    fn from(err: GpgError) -> Self {
        ThisProjectError::GpgError(format!("GPG operation failed: {:?}", err))
    }
}

// Implement From<walkdir::Error> for ThisProjectError
impl From<walkdir::Error> for ThisProjectError {
    fn from(err: walkdir::Error) -> Self {
        ThisProjectError::WalkDirError(err)
    }
}

// Implement From<ParseIntError> for ThisProjectError
impl From<ParseIntError> for ThisProjectError {
    fn from(err: ParseIntError) -> Self {
        ThisProjectError::ParseIntError(err)
    }
}

// Implement From<toml::de::Error> for ThisProjectError
impl From<toml::de::Error> for ThisProjectError {
    fn from(err: toml::de::Error) -> Self {
        ThisProjectError::TomlDeserializationError(err)
    }
}

// Implement the std::error::Error trait for ThisProjectError
impl std::error::Error for ThisProjectError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        match *self {
            ThisProjectError::IoError(ref err) => Some(err),
            ThisProjectError::TomlDeserializationError(ref err) => Some(err),
            _ => None,
        }
    }
}

// Implement the Display trait for ThisProjectError for easy printing
impl std::fmt::Display for ThisProjectError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match *self {
            ThisProjectError::IoError(ref err) => write!(f, "IO Error: {}", err),
            ThisProjectError::TomlDeserializationError(ref err) => write!(f, "TOML TomlDeserializationError  Error: {}", err),
            ThisProjectError::TomlVanillaDeserialStrError(ref err) => write!(f, "TomlVanillaDeserialStrError TOML Error: {}", err),
            ThisProjectError::InvalidData(ref msg) => write!(f, "Invalid Data: {}", msg),
            ThisProjectError::InvalidInput(ref msg) => write!(f, "Invalid Input: {}", msg),
            ThisProjectError::PortCollision(ref msg) => write!(f, "Port Collision: {}", msg),
            ThisProjectError::NetworkError(ref msg) => write!(f, "Network Error: {}", msg),
            ThisProjectError::WalkDirError(ref err) => write!(f, "WalkDir Error: {}", err),
            ThisProjectError::ParseIntError(ref err) => write!(f, "ParseInt Error: {}", err),
            ThisProjectError::ParseIntError(ref err) => write!(f, "ParseInt Error: {}", err),
            ThisProjectError::GpgError(ref err) => write!(f, "GPG Error: {}", err),
            ThisProjectError::ParseError(ref err) => write!(f, "Parse Error: {}", err),
            ThisProjectError::StringError(ref msg) => write!(f, "Error: {}", msg),
            // ... add formatting for other error types
            ThisProjectError::FileTooLarge { ref path, size_bytes, max_allowed } => {
                // Security: Only show filename, not full path in production
                let filename = path.file_name()
                    .and_then(|n| n.to_str())
                    .unwrap_or("unknown");
                write!(
                    f,
                    "File too large: {} ({} bytes, max: {} bytes)",
                    filename, size_bytes, max_allowed
                )
            },

            ThisProjectError::PadnetError(ref msg) => {
                write!(f, "OTP Encryption Error: {}", msg)
            },

            ThisProjectError::TempFileCleanupWarning(ref msg) => {
                write!(f, "Temp File Cleanup Warning: {}", msg)
            },
        }
    }
}

// Add conversion from PadnetError if it's a separate type in your project
// If PadnetError is an enum, add this:
impl From<PadnetError> for ThisProjectError {
    fn from(err: PadnetError) -> Self {
        ThisProjectError::PadnetError(format!("{:?}", err))
    }
}

/// Implements conversion from String to ThisProjectError
///
/// This allows using .into() to convert string error messages directly to
/// the project's error type, simplifying error propagation when the error
/// source is a formatted message.
impl From<String> for ThisProjectError {
    fn from(message: String) -> Self {
        // Create a ThisProjectError from a String
        // Assuming ThisProjectError has a variant for string errors
        // Update this to match your actual error type structure
        ThisProjectError::StringError(message)
    }
}

/// Implements conversion from &str to ThisProjectError for convenience
///
/// This allows using string literals as errors without explicit conversion
impl From<&str> for ThisProjectError {
    fn from(message: &str) -> Self {
        // Convert &str to String and then use the String implementation
        ThisProjectError::from(message.to_string())
    }
}



fn remove_duplicates_from_path_array(vec: Vec<PathBuf>) -> Vec<PathBuf> {
    let mut seen = HashSet::new();
    let mut unique_vec = Vec::new();

    for item in vec {
        if seen.insert(item.clone()) {
            unique_vec.push(item);
        }
    }

    unique_vec
}

// Implement the From trait to easily convert from other error types into ThisProjectError
impl From<io::Error> for ThisProjectError {
    fn from(err: io::Error) -> ThisProjectError {
        ThisProjectError::IoError(err)
    }
}


// =====================
// End Uma Error Section
// =====================

/// utility: Gets a list of all IPv4 and IPv6 addresses associated with the current system's network interfaces.
///
/// Returns:
/// - `Ok(Vec<IpAddr>)`: A vector of IP addresses on success.
/// - `Err(io::Error)`: An error if obtaining network interface information fails.
/// From: https://docs.rs/getifaddrs/latest/getifaddrs/
/// use getifaddrs::{getifaddrs, InterfaceFlags};
fn get_local_ip_addresses() -> Result<Vec<IpAddr>, std::io::Error> {
    // https://docs.rs/getifaddrs/latest/getifaddrs/

    // Test Print in Debug Log
    for interface in getifaddrs()? {
        debug_log("fn get_local_ip_addresses() -> std::io::Result<()> {");
        debug_log!("Interface: {}", interface.name);
        debug_log!("  Address: {}", interface.address);
        if let Some(netmask) = interface.netmask {
            debug_log!("  Netmask: {}", netmask);
        }
        debug_log!("  Flags: {:?}", interface.flags);
        if interface.flags.contains(InterfaceFlags::UP) {
            debug_log!("  Status: Up");
        } else {
            debug_log!("  Status: Down");
        }
        debug_log!();
    }

    let mut addresses = Vec::new();

    for interface in getifaddrs()? {
        if interface.flags.contains(InterfaceFlags::UP) && // Interface is up
           !interface.flags.contains(InterfaceFlags::LOOPBACK) { // Not a loopback interface
               match interface.address {
                   IpAddr::V4(addr) => addresses.push(IpAddr::V4(addr)),
                   IpAddr::V6(addr) => addresses.push(IpAddr::V6(addr)),
               }
           }
    }

    Ok(addresses)
}

// /*
// TODO:
// in the nearterm and long term
// there needs to be a way of selecting and coordinating about working ip addresses
// e.g. once an address works, the number of that address in the shared list may be
// transmitted in the ReadySignal to say which ip is being used (e.g. when
//     there are several possible 'campuses' that might be used)

// The primary task is testing what local IP for the local owner user out of the list
// in their file works (and which listen item that is).

// another later task may be using a intranet mode.
// */

/// Get Band: Network config data
/// The function is called during initialization bootstrapping
/// so there are few pre-existing values to put in,
/// this function must bootstrap itself.
/// Note: this is before any team_channel has been entered
///
/// Get Band: Network config data
/// Returns the first valid IP address and its type ("ipv6" or "ipv4") found for the local user,
/// along with its index in the respective list.
///
/// This function is called during initialization bootstrapping to determine a valid network configuration
/// before any team channel is entered. It reads the local user's IP address lists from their collaborator
/// TOML file and attempts to bind a UDP socket to each address to verify its validity.
///
/// Args:
///     uma_local_owner_user: The username of the local UMA user.
///
/// Returns:
///     (String, u8): A tuple containing the network type ("ipv6" or "ipv4") and the index of the valid IP address.
///     Returns ("none", 0) if no valid IP address is found.
fn get_band__find_valid_network_index_and_type(
    uma_local_owner_user: &str,
    full_fingerprint_key_id_string: &str,
) -> (
    bool, // network_found_ok flag
    String, // network_type
    u8, // network_index
    Ipv4Addr,
    Ipv6Addr,
    ) {
    /*
    General Steps
    1. get name of local owner
        paremeter
    2. get local owner file (or fields)
    COLLABORATOR_ADDRESSBOOK_PATH_STR
    "/project_graph_data/collaborator_files_address_book/{}__collaborator.toml", uma_local_owner_user
    3. look for valid ipv6
        find_valid_local_owner_ipv6_address
    4. (if not found) look for valid ivp4
        find_valid_local_owner_ipv4_address
    5. (pending) look for other network band types e.g. CB radio, optical, audio, etc.
    6. return (network_type, network_index) tuple (e.g. ('ipv6', 0)
    */

    // 2. Load IP lists from the collaborator file
    let (ipv4_addresses, ipv6_addresses) = match load_local_ip_lists_to_ipvec(
        uma_local_owner_user,
        &full_fingerprint_key_id_string,
        ) {
        Ok(lists) => lists,
        Err(e) => {
            debug_log!("Error loading IP lists: {}. Returning filler values.", e);
            return (
                false,
                "none".to_string(),
                0,
                EMPTY_IPV_4,  // Filler value
                EMPTY_IPV_6,  // Filler value
            );
        }
    };

    // println!("ipv4_addresses: {:?}", ipv4_addresses);
    // println!("ipv6_addresses: {:?}", ipv6_addresses);


    let (ipv4_addresses_string, ipv6_addresses_string) = match load_local_iplists_as_stringtype(
        uma_local_owner_user,
        &full_fingerprint_key_id_string,
        ) {
        Ok(lists) => lists,
        Err(e) => {
            debug_log!("Error loading IP lists as strings: {}", e);
            // Return "none" with default IP addresses
            return (false, "none".to_string(), 0, Ipv4Addr::UNSPECIFIED, Ipv6Addr::UNSPECIFIED);
        }
    };

    // println!("ipv4_addresses_string: {:?}", ipv4_addresses_string);
    // println!("ipv6_addresses_string: {:?}", ipv6_addresses_string);


    // 3. Try IPv6 addresses first
    if let Some(valid_ipv6) = find_valid_local_owner_ipv6_address(&ipv6_addresses) {
        // Get index
        debug_log!("Found valid ipv6 address: {:?}", valid_ipv6);

        if let Some(index) = get_index_byof_ip(
            &ipv4_addresses_string,
            &ipv6_addresses_string,
            &valid_ipv6.to_string()
        ) {
            return (true, "ipv6".to_string(), index, EMPTY_IPV_4, valid_ipv6);
        } else {
            debug_log!("Valid IPv6 address not found in the list.");
        }
    }

    // 4. If no valid IPv6, then try IPv4
    if let Some(valid_ipv4) = find_valid_local_owner_ipv4_address(&ipv4_addresses) {
        if let Some(index) = get_index_byof_ip(
            &ipv4_addresses_string,
            &ipv6_addresses_string,
            &valid_ipv4.to_string()
        ) {
            return (true, "ipv4".to_string(), index, valid_ipv4, EMPTY_IPV_6);
        } else {
            debug_log!("Valid IPv4 address not found in the list.");
        }
    }

    // 5. No valid IP found
    debug_log!("No valid IPv4 or IPv6 address found.");
    (false, "none".to_string(), 0, EMPTY_IPV_4, EMPTY_IPV_6) // Return a default value
}

/// Attempts to bind a UDP socket to each address in the provided list.
///
/// This function iterates through the `ip_addresses` slice. For each address, it attempts to bind a UDP
/// socket to the address on a designated test port (55555). If successful, the function immediately
/// returns the bindable address. If binding fails for all addresses in the list, the function returns `None`.
///
/// This function is used during initialization to determine a valid local IP address that UMA can use
/// for communication.
///
/// Args:
///     ip_addresses (&[Ipv6Addr]): A slice of IPv6 addresses to test.
///
/// Returns:
///     Option<Ipv6Addr>: The first IPv6 address in the list to which a UDP socket can be successfully bound, or `None` if no address is bindable.
///
fn find_valid_local_owner_ipv6_address(ipv6_addresses: &[Ipv6Addr]) -> Option<Ipv6Addr> {
    for &address in ipv6_addresses {
        if !address.is_loopback() && !address.is_unspecified() { // Use short-circuit &&
            let test_port = 55555;
            let socket_addr = SocketAddr::new(IpAddr::V6(address), test_port);
            if UdpSocket::bind(socket_addr).is_ok() { // Simplified check
                return Some(address);
            } else {
                debug_log!("Could not bind to {:?}. Trying next address...", socket_addr);
            }
        }
    }
    None
}

// Analogous function for IPv4
fn find_valid_local_owner_ipv4_address(ipv4_addresses: &[Ipv4Addr]) -> Option<Ipv4Addr> {
    // ... (Implementation is analogous to the IPv6 version)
    for &address in ipv4_addresses {
        if !address.is_loopback() && !address.is_unspecified() {
            let test_port = 55555;
            let socket_addr = SocketAddr::new(IpAddr::V4(address), test_port);
            if UdpSocket::bind(socket_addr).is_ok() {
                return Some(address);
            } else {
                debug_log!("Could not bind to {:?}. Trying next address...", socket_addr);
            }
        }
    }
    None
}

/// Securely extracts a GPG-encrypted clearsigned TOML file to a temporary location.
///
/// This function decrypts a GPG-encrypted file using the specified key fingerprint and
/// writes the decrypted content to a temporary file with restricted permissions. The
/// temporary file path is returned for further processing.
///
/// # Security
/// - Creates temporary files with restricted permissions (owner-only access)
/// - Uses unique filenames to prevent race conditions
/// - Ensures cross-platform compatibility for file permissions
/// - Caller is responsible for deleting the temporary file
///
/// # Arguments
/// * `gpg_encrypted_path` - Absolute path to the GPG-encrypted file
/// * `full_fingerprint_key_id_string` - Full GPG key fingerprint for decryption
/// * `owner` - Username for generating unique temp filename
///
/// # Returns
/// * `Result<PathBuf, ThisProjectError>` - Path to the temporary decrypted file
fn decrypt_gpgtoml_to_temp_file_secure(
    gpg_encrypted_path: &str,
    full_fingerprint_key_id_string: &str,
    owner: &str,
) -> Result<PathBuf, ThisProjectError> {
    // Verify the encrypted file exists
    if !Path::new(gpg_encrypted_path).exists() {
        return Err(ThisProjectError::IoError(
            io::Error::new(
                io::ErrorKind::NotFound,
                format!("GPG encrypted file not found: {}", gpg_encrypted_path)
            )
        ));
    }

    // Generate a unique temporary filename
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map_err(|e| ThisProjectError::IoError(
            io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e))
        ))?
        .as_nanos();

    let temp_filename = format!("gpg_decrypt_{}_{}.toml", owner, timestamp);
    let temp_dir = std::env::temp_dir();
    let temp_path = temp_dir.join(&temp_filename);

    // Decrypt the GPG file using the gpg command
    let output = std::process::Command::new("gpg")
        .arg("--quiet")
        .arg("--batch")
        .arg("--yes")
        .arg("--local-user")
        .arg(full_fingerprint_key_id_string)
        .arg("--decrypt")
        .arg(gpg_encrypted_path)
        .output()
        .map_err(|e| ThisProjectError::GpgError(
            format!("Failed to execute GPG decrypt command: {}", e)
        ))?;

    if !output.status.success() {
        let stderr = String::from_utf8_lossy(&output.stderr);
        return Err(ThisProjectError::GpgError(
            format!("GPG decryption failed: {}", stderr)
        ));
    }

    // Create the temporary file with restricted permissions
    #[cfg(unix)]
    {
        use std::os::unix::fs::OpenOptionsExt;
        let mut file = std::fs::OpenOptions::new()
            .create(true)
            .write(true)
            .truncate(true)
            .mode(0o600) // Owner read/write only
            .open(&temp_path)
            .map_err(|e| ThisProjectError::IoError(
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("Failed to create secure temp file: {}", e)
                )
            ))?;

        file.write_all(&output.stdout)
            .map_err(|e| ThisProjectError::IoError(
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("Failed to write decrypted content: {}", e)
                )
            ))?;
    }

    #[cfg(not(unix))]
    {
        // On Windows, files in temp directory are typically user-restricted by default
        fs::write(&temp_path, &output.stdout)
            .map_err(|e| ThisProjectError::IoError(
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("Failed to write decrypted content: {}", e)
                )
            ))?;
    }

    Ok(temp_path)
}

/// Attempts to read IP addresses from a GPG-encrypted clearsigned TOML file.
///
/// This function tries to decrypt and read a .gpgtoml file if it exists. It handles
/// the entire process including decryption, reading, and cleanup of temporary files.
///
/// # Security
/// - Decrypts to a temporary file with restricted permissions
/// - Ensures temporary file cleanup even on error
/// - Validates clearsigned content after decryption
///
/// # Arguments
/// * `owner` - Username to locate the collaborator file
/// * `full_fingerprint_key_id_string` - GPG key fingerprint for decryption
///
/// # Returns
/// * `Result<Option<(Vec<String>, Vec<String>)>, ThisProjectError>` - IP addresses if successful,
///   None if .gpgtoml doesn't exist
fn try_read_iplists_from_gpg_encrypted_collaborator_file(
    owner: &str,
    full_fingerprint_key_id_string: &str,
) -> Result<Option<(Vec<String>, Vec<String>)>, ThisProjectError> {
    // Construct path to GPG encrypted file
    let gpg_relative_path = format!(
        "{}/{}__collaborator.gpgtoml",
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        owner,
    );

    // Convert to absolute path
    let gpg_absolute_path = match gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(&gpg_relative_path) {
        Ok(path) => path.to_string_lossy().to_string(),
        Err(_) => return Ok(None), // GPG file doesn't exist, return None
    };

    // Check if GPG encrypted file exists
    if !Path::new(&gpg_absolute_path).exists() {
        return Ok(None); // No GPG file, will fall back to regular clearsign
    }

    // Decrypt to temporary file
    let temp_path = match decrypt_gpgtoml_to_temp_file_secure(
        &gpg_absolute_path,
        full_fingerprint_key_id_string,
        owner
    ) {
        Ok(path) => path,
        Err(e) => {
            // Log the error but return None to allow fallback
            eprintln!("Warning: Failed to decrypt GPG file for {}: {}", owner, e);
            return Ok(None);
        }
    };

    // Ensure cleanup happens regardless of success or failure
    let cleanup_temp_file = |path: &Path| {
        if let Err(e) = fs::remove_file(path) {
            eprintln!("Warning: Failed to remove temporary file {}: {}", path.display(), e);
        }
    };

    // Read from the decrypted clearsigned TOML file
    let temp_path_str = temp_path.to_string_lossy().to_string();

    let ipv4_addresses = match read_str_array_field_clearsigntoml(&temp_path_str, "ipv4_addresses") {
        Ok(addrs) => addrs,
        Err(e) => {
            cleanup_temp_file(&temp_path);
            return Err(ThisProjectError::GpgError(
                format!("Failed to read IPv4 addresses from decrypted file: {}", e)
            ));
        }
    };

    let ipv6_addresses = match read_str_array_field_clearsigntoml(&temp_path_str, "ipv6_addresses") {
        Ok(addrs) => addrs,
        Err(e) => {
            cleanup_temp_file(&temp_path);
            return Err(ThisProjectError::GpgError(
                format!("Failed to read IPv6 addresses from decrypted file: {}", e)
            ));
        }
    };

    // Clean up temporary file
    cleanup_temp_file(&temp_path);

    Ok(Some((ipv4_addresses, ipv6_addresses)))
}

/// Loads the local user's IPv4 and IPv6 addresses from their collaborator TOML file.
///
/// This function reads the collaborator file for the given `owner` and extracts the
/// `ipv4_addresses` and `ipv6_addresses` fields as strings. It ensures security by requiring
/// clearsigned validation of the TOML file.
///
/// # Security
/// - REQUIRES cryptographically verified clearsigned TOML files
/// - Will REJECT files that fail signature verification
/// - Maintains the integrity of configuration data
/// - Attempts to use GPG-encrypted files first for enhanced security
/// - Falls back to regular clearsigned files if GPG version unavailable
///
/// # Process
/// 1. First attempts to read from a GPG-encrypted clearsigned file (.gpgtoml)
/// 2. If .gpgtoml doesn't exist or fails, falls back to regular clearsigned file (.toml)
/// 3. All files must be cryptographically verified (clearsigned)
///
/// # Arguments
/// * `owner` - The username of the local user
/// * `full_fingerprint_key_id_string` - GPG key fingerprint for decrypting .gpgtoml files
///
/// # Returns
/// * `Result<(Vec<String>, Vec<String>), ThisProjectError>` - A tuple containing the IPv4 and IPv6
///   address lists as strings, or a `ThisProjectError` if an error occurs
fn load_local_iplists_as_stringtype(
    owner: &str,
    full_fingerprint_key_id_string: &str,
) -> Result<(Vec<String>, Vec<String>), ThisProjectError> {
    // First, try to read from GPG encrypted file
    match try_read_iplists_from_gpg_encrypted_collaborator_file(owner, full_fingerprint_key_id_string)? {
        Some(ip_lists) => return Ok(ip_lists),
        None => {
            // GPG file doesn't exist or failed, proceed with regular clearsigned file
        }
    }

    // Fall back to regular clearsigned TOML file
    let relative_path = format!(
        "{}/{}__collaborator.toml",
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        owner,
    );

    // Convert to an absolute path based on executable location
    let absolute_path = match gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(&relative_path) {
        Ok(path) => path.to_string_lossy().to_string(),
        Err(e) => {
            return Err(ThisProjectError::IoError(
                std::io::Error::new(
                    std::io::ErrorKind::NotFound,
                    format!("Failed to resolve path for collaborator '{}': {}", owner, e)
                )
            ));
        }
    };

    // Check if the file exists
    if !std::path::Path::new(&absolute_path).exists() {
        return Err(ThisProjectError::IoError(
            std::io::Error::new(
                std::io::ErrorKind::NotFound,
                format!("No collaborator file found for '{}'. Checked both .gpgtoml and .toml", owner)
            )
        ));
    }

    // Read IP addresses as strings from the clearsigned TOML file
    // We use our secure verification function that will fail if verification fails
    let ipv4_addresses = match read_str_array_field_clearsigntoml(&absolute_path, "ipv4_addresses") {
        Ok(strings) => strings,
        Err(e) => {
            return Err(ThisProjectError::GpgError(
                format!("Failed to securely read IPv4 addresses from clearsigned file: {}", e)
            ));
        }
    };

    let ipv6_addresses = match read_str_array_field_clearsigntoml(&absolute_path, "ipv6_addresses") {
        Ok(strings) => strings,
        Err(e) => {
            return Err(ThisProjectError::GpgError(
                format!("Failed to securely read IPv6 addresses from clearsigned file: {}", e)
            ));
        }
    };

    // Return the string representations of the IP addresses directly
    Ok((ipv4_addresses, ipv6_addresses))
}

/// Loads the local user's IPv4 and IPv6 addresses from their collaborator TOML file.
///
/// This function reads the collaborator file for the given `owner` and extracts the
/// `ipv4_addresses` and `ipv6_addresses` fields. It ensures security by requiring
/// clearsigned validation of the TOML file.
///
/// # Security
/// - REQUIRES cryptographically verified clearsigned TOML files
/// - Will REJECT files that fail signature verification
/// - Will NOT fall back to reading unsigned files
/// - Attempts to use GPG-encrypted files first for enhanced security
/// - Falls back to regular clearsigned files if GPG version unavailable
///
/// # Process
/// 1. First attempts to read from a GPG-encrypted clearsigned file (.gpgtoml)
/// 2. If .gpgtoml doesn't exist or fails, falls back to regular clearsigned file (.toml)
/// 3. Parses string IP addresses into strongly-typed Ipv4Addr and Ipv6Addr
/// 4. Invalid IP addresses are logged as warnings but don't fail the operation
///
/// # Arguments
/// * `owner` - The username of the local user
/// * `full_fingerprint_key_id_string` - GPG key fingerprint for decrypting .gpgtoml files
///
/// # Returns
/// * `Result<(Vec<Ipv4Addr>, Vec<Ipv6Addr>), ThisProjectError>` - A tuple containing the IPv4 and IPv6
///   address lists, or a `ThisProjectError` if an error occurs
fn load_local_ip_lists_to_ipvec(
    owner: &str,
    full_fingerprint_key_id_string: &str,
) -> Result<(Vec<Ipv4Addr>, Vec<Ipv6Addr>), ThisProjectError> {
    // Get IP addresses as strings (handles GPG decryption and fallback internally)
    let (ipv4_strings, ipv6_strings) = load_local_iplists_as_stringtype(owner, full_fingerprint_key_id_string)?;

    // Parse the string values into IP address types
    let mut ipv4_addresses = Vec::new();
    for ip_str in ipv4_strings {
        match ip_str.parse::<Ipv4Addr>() {
            Ok(addr) => ipv4_addresses.push(addr),
            Err(e) => {
                println!("Warning: Invalid IPv4 address '{}' for user '{}': {}", ip_str, owner, e);
            }
        }
    }

    let mut ipv6_addresses = Vec::new();
    for ip_str in ipv6_strings {
        match ip_str.parse::<Ipv6Addr>() {
            Ok(addr) => ipv6_addresses.push(addr),
            Err(e) => {
                println!("Warning: Invalid IPv6 address '{}' for user '{}': {}", ip_str, owner, e);
            }
        }
    }

    // Return the collected IP addresses
    Ok((ipv4_addresses, ipv6_addresses))
}

/// This converts between the u8 sent by uma over network and usize that Rust uses for array-indices.
fn get_ip_by_index(
    index: u8,
    ipv4_list: &[Ipv4Addr],
    ipv6_list: &[Ipv6Addr],
) -> Option<(IpAddr, u8)> {
    if index < ipv4_list.len() as u8 {
        Some((IpAddr::V4(ipv4_list[index as usize]), index))
    } else if index < (ipv4_list.len() + ipv6_list.len()) as u8 {
        let ipv6_index = index - ipv4_list.len() as u8;
        Some((IpAddr::V6(ipv6_list[ipv6_index as usize]), index))
    } else {
        None
    }
}

/// Finds the the index in either along, not combined.
/// This converts between the u8 sent by uma over network and usize that Rust uses for array-indices.
///
/// This function searches for the given `ip_address`
/// each list alone.
/// It returns the index found.
///
/// # Arguments
///
/// * `ipv4_list`: The list of IPv4 addresses as strings.
/// * `ipv6_list`: The list of IPv6 addresses as strings.
/// * `ip_address`: The IP address to search for as a string.
///
/// # Returns
///
/// * `Option<u8>`:  The combined index, or `None` if the IP address is not found.
fn get_index_byof_ip(
    ipv4_list: &[String],
    ipv6_list: &[String],
    ip_address: &str,
) -> Option<u8> {
    let ip_addr: IpAddr = ip_address.parse().ok()?;

    debug_log!("get_index_byof_ip ipv4_list{:?}",ipv4_list);
    debug_log!("get_index_byof_ip ipv6_list{:?}",ipv6_list);
    debug_log!("get_index_byof_ip ip_address{:?}",ip_address);
    debug_log!("get_index_byof_ip ip_addr{:?}",ip_addr);

    let result = match ip_addr {
        IpAddr::V4(ipv4) => {
            ipv4_list.iter().position(|ip| ip == &ipv4.to_string()).map(|index| index as u8)
        }
        IpAddr::V6(ipv6) => {
            ipv6_list.iter().position(|ip| ip == &ipv6.to_string()).map(|index| index as u8)
        }
    };

    debug_log!("get_index_byof_ip result {:?}", result);

    result

}

/// Saves the local user's network band config data
/// to sync_data text files
/// As this is done only once during startup, retry is likely not needed
///
fn write_local_band__save_network_band__type_index(
    network_type: String,
    network_index: u8,
    this_ipv4: Ipv4Addr,
    this_ipv6: Ipv6Addr,
) -> Result<(), ThisProjectError> {
    // 1. Construct Path:
    let base_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;

    // 2. Create Directory (if doesn't exist)
    create_dir_all(&base_path)?;

    // 3. Construct Absolute File Paths
    let type_path = base_path.join("network_type.txt");
    let index_path = base_path.join("network_index.txt");
    let ipv4_path = base_path.join("ipv4.txt");
    let ipv6_path = base_path.join("ipv6.txt");

    // 4. Write to Files (handling potential errors):
    let mut type_file = File::create(&type_path)?; // Note the & for borrowing
    writeln!(type_file, "{}", network_type)?;

    let mut index_file = File::create(&index_path)?;
    writeln!(index_file, "{}", network_index)?;

     // 4. Write to Files (handling potential errors):
     // working now?
     // TODO this is not working, it is writing "sync_data/ipv6.txt" as the file text
     // the path to the file should not be the file content...
    let mut ip4_file = File::create(&ipv4_path)?; // Note the & for borrowing
    writeln!(ip4_file, "{}", this_ipv4.to_string())?;  // Write IP string

    let mut ip6_file = File::create(&ipv6_path)?;
    writeln!(ip6_file, "{}", this_ipv6.to_string())?;  // Write IP string

    Ok(())
}

/// Saves the local user's network band config data
/// to sync_data text files
/// as this is done only once during startup, retry is likely not needed
///
fn write_save_rc_bandnetwork_type_index(
    remote_collaborator_name: String,
    team_channel_name: String,
    network_type: String,
    network_index: u8,
    this_ipv4: Ipv4Addr,
    this_ipv6: Ipv6Addr,
) -> Result<(), ThisProjectError> {
    /* ?
    Wait random time in A to B range, N times
    FILE_READWRITE_N_RETRIES
    FILE_READWRITE_RETRY_SEC_PAUSE_MIN
    FILE_READWRITE_RETRY_SEC_PAUSE_max
    */

    debug_log("write_save_rc_bandnetwork_type_index(), starting");

    // 1. Construct Path:
    let mut base_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;
    base_path.push(team_channel_name);
    base_path.push("network_band");
    base_path.push(remote_collaborator_name);

    // Create directory structure if it doesn't exist
    create_dir_all(&base_path)?;

    debug_log!("write_save_rc_bandnetwork_type_index(), base_path {:?}", base_path);

    // 3. Construct Absolute File Paths
    let type_path = base_path.join("network_type.txt");
    let index_path = base_path.join("network_index.txt");
    let ipv4_path = base_path.join("ipv4.txt");
    let ipv6_path = base_path.join("ipv6.txt");

    debug_log!("write_save_rc_bandnetwork_type_index(), type_path {:?}", type_path);
    debug_log!("write_save_rc_bandnetwork_type_index(), index_path {:?}", index_path);
    debug_log!("write_save_rc_bandnetwork_type_index(), ipv4_path {:?}", ipv4_path);
    debug_log!("write_save_rc_bandnetwork_type_index(), ipv6_path {:?}", ipv6_path);

    // 4.1 Write to Files (handling potential errors):
    let mut type_file = File::create(&type_path)?; // Note the & for borrowing
    writeln!(type_file, "{}", network_type)?;

    debug_log!("write_save_rc_bandnetwork_type_index(), type_file {:?}", type_file);

    let mut index_file = File::create(&index_path)?;
    writeln!(index_file, "{}", network_index)?;

    debug_log!("write_save_rc_bandnetwork_type_index(), index_file {:?}", index_file);

    // 4.2 Write to Files (handling potential errors):
    let mut ip4_file = File::create(&ipv4_path)?; // Note the & for borrowing
    writeln!(ip4_file, "{}", this_ipv4.to_string())?;  // Write IP string
    debug_log!("write_save_rc_bandnetwork_type_index(), ip4_file {:?}", ip4_file);

    let mut ip6_file = File::create(&ipv6_path)?;
    writeln!(ip6_file, "{}", this_ipv6.to_string())?;  // Write IP string
    debug_log!("write_save_rc_bandnetwork_type_index(), ip6_file {:?}", ip6_file);

    Ok(())
}

// TODO: maybe use a parameter in team-channel instead of hard-coding ~10 sec
/// hlod_udp_handshake__rc_network_type_rc_ip_addr(): returns (rc_network_type, rc_ip_addr) as (String, String) loop until satisfied:
/// every 10-60 sec: (lite-weight is the goal, not expensive-brute-force)
/// 1. check for hault-uma (if not more often check somehow)
/// 2. check for received ready-signal in /sync_data/ (if so, exit handshake) see below: with this you can get the rc_ip-data read_rc_bandnetwork_type_index()
/// 3. if not the above options: send a ready signal (iterating) to each listed collaborator ip
///   ipv4 and ipv6 (until (step 2) there has been logged a ready-signal from one of them)
///
fn hlod_udp_handshake__rc_network_type_rc_ip_addr(
    local_owner_desk_setup_data: &ForLocalOwnerDeskThread,
    band_local_network_type: &str,
    band_local_user_ipv4_address: &Ipv4Addr,
    band_local_user_ipv6_address: &Ipv6Addr,
    band_local_network_index: u8,
) -> Result<(String, String), ThisProjectError> {
    debug_log("inHLOD: Start hlod_udp_handshake__rc_network_type_rc_ip_addr()");

    // --- 1. Extract Data from Setup Data ---
    let local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip = local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip;


    // --- Select IP Address and Create SocketAddr for Local Listening ---
    let listen_ip_addr = match band_local_network_type {
        "ipv6" => IpAddr::V6(*band_local_user_ipv6_address),
        "ipv4" => IpAddr::V4(*band_local_user_ipv4_address),
        _ => return Err(ThisProjectError::NetworkError(
            "error Invalid network type in hlod_udp_handshake__rc_network_type_rc_ip_addr".into()
            )
        ),
    };

    // TODO
    let local_listen_addr = SocketAddr::new(
        listen_ip_addr,
        local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
    );


    let channel_dir_path_str = read_state_string("current_node_directory_path.txt")?; // read as string first
    debug_log!("hlod_udp_handshake__rc_network_type_rc_ip_addr Channel directory path (from session state): {}", channel_dir_path_str);

    // let team_channel_name = channel_dir_path_str;
    // was  get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl

    let team_channel_name = match get_current_team_channel_name_from_nav_path() {
        Some(name) => name,
        None => {
            debug_log!("Error: Could not get current channel name in get_current_team_channel_name_from_nav_path. Skipping.");
            return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
        },
    };

    // --- Prepare ReadySignal ---
    let timestamp_for_rt = match get_latest_received_from_rc_file_timestamp(
        &team_channel_name,
        &local_owner_desk_setup_data.remote_collaborator_name,
    ) {
        Ok(timestamp) => timestamp,
        Err(e) => {
            debug_log!("error in hlod_udp_handshake__rc_network_type_rc_ip_addr(): Error getting timestamp: {}", e);
            0
        }
    };
    debug_log!(
        "hlod_udp_handshake: .rt, timestamp_for_rt, from get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl -> {:?}",
        timestamp_for_rt,
    );

    // // setup: Get Team Channel Name
    let team_channel_name = match get_current_team_channel_name_from_nav_path() {
        Some(name) => name,
        None => {
            debug_log!("Error: Could not get current channel name in get_current_team_channel_name_from_nav_path. Skipping.");
            return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
        },
    };

    // setup: Construct Path to check for a ready signal received from the rc (remote collaborator)
    // Get the absolute path to the flag file relative to the executable
    let mut got_signal_check_base_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;
    got_signal_check_base_path.push(team_channel_name.clone());
    got_signal_check_base_path.push("network_band");
    got_signal_check_base_path.push(&local_owner_desk_setup_data.remote_collaborator_name);

    loop { // hlod_udp_handshake__rc_network_type_rc_ip_addr() Main loop starts here
        debug_log("hlod_udp_handshake__rc_network_type_rc_ip_addr() main loop (re)starting from the top...");

        // 1. Check for Halt Signal and Team Channel Name (as before)
        if should_halt_uma() { // 1. check for halt-uma
            return Err(ThisProjectError::NetworkError("UMA halt signal received (not an error)".into())); // or log the exit?
        }

        // --- 2. Check for Received Ready Signal ---
        // hlod_udp_handshake__rc_network_type_rc_ip_addr() Main loop starts here
        if got_signal_check_base_path.exists() {
            // The path exists...

            // --- The purpose of this block is to use existing band data if it exists in sync_data
            if let Ok(Some((rc_network_type, _, rc_ip_addr_string))) = read_rc_bandnetwork_type_index(
                &local_owner_desk_setup_data.remote_collaborator_name, // Correct collaborator name
                &team_channel_name, // Use correctly retrieved team channel name
            ) {
                debug_log!(
                    "hlod_udp_handshake__rc_network_type_rc_ip_addr(): Ready signal information found in sync_data for {}. rc_network_type: {}, rc_ip: {:?}",
                    local_owner_desk_setup_data.remote_collaborator_name,
                    rc_network_type,
                    rc_ip_addr_string,
                );

                return Ok((rc_network_type, rc_ip_addr_string)); // Return address, breaking loop
            } else {
                // ... (No ready signal yet, continue sending your own)
                debug_log("hlod_udp_handshake path but no files");
            }
        } else {
                // ... (No ready signal yet, continue sending your own)
                debug_log("hlod_udp_handshake no path yet");
        } // End of if got_signal_check_base_path.exists()

        // --- 3. Send Ready Signal ---
        // ... [Iterate remote IP addresses *only* if no ReadySignal received]

        // Send to each IPv6 address in rc_ipv6_list
        debug_log("hlod_udp_handshake__rc_network_type_rc_ip_addr() Sending Handshake ready signals!");
        for ipv6_addr_string in &local_owner_desk_setup_data.remote_collaborator_ipv6_addr_list {
            send_ready_signal(
                &local_owner_desk_setup_data.local_user_salt_list,
                "ipv6".to_string(),                            // Correct: Always "ipv6" here
                ipv6_addr_string.to_string(),                  //Correct: Use remote IPv6 address
                local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,  // Use provided port
                timestamp_for_rt,                              // Use calculated timestamp
                band_local_network_type,                       // band_local_network_type
                band_local_network_index,                      // Use band index
            )?;
            debug_log!(
                "ReadySignal sent to IPv6: {}:{}",
                ipv6_addr_string,
                local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
            );
        }

        // Send to each IPv4 address in rc_ipv4_list
        for ipv4_addr_string in &local_owner_desk_setup_data.remote_collaborator_ipv4_addr_list {  // Iterate IPv4 list
            send_ready_signal(
                &local_owner_desk_setup_data.local_user_salt_list,
                "ipv4".to_string(),                           // Correct: Always "ipv4" here
                ipv4_addr_string.to_string(),                   // Correct: Use remote IPv4 address
                local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip, // Use port number
                timestamp_for_rt,                           // Use calculated timestamp // Correct: Consistent order
                band_local_network_type,
                band_local_network_index,                           // Use consistent type for band index. // Correct: Consistent order
            )?;
            debug_log!(
                "ReadySignal sent to IPv4: {}:{}",
                ipv4_addr_string,
                local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
            );
        }

        // 1.1 Wait (and check for exit Uma)  this waits and checks N times: for i in 0..N {
        for i in 0..5 {
            // break for loop ?
            if should_halt_uma() {
                debug_log!("hold_udp_handshake: should_halt_uma(), exiting Uma in handle_local_owner_desk()");
                break; // break this for-loop
            }
            thread::sleep(Duration::from_secs(3));
        }
        // Then break out of this function main loop
        if should_halt_uma() {
            debug_log!("hold_udp_handshake: should_halt_uma(). Exiting hlod_upd_handshake()");
            break Ok((Default::default(), Default::default()));
        }

    } // loop end
}


// HEREHERE todo TODO fix this, not checking for likely duely noneexistant files
/// Reads the remote collaborator's band data (network type, index, IP address). -> (network_type, network_index, rc_ip)
///
/// This function reads the remote collaborator's network band information, which was previously
/// saved by the `write_save_rc_bandnetwork_type_index` function. The data is read from files
/// within the following directory structure:
/// sync_data/{team_channel_name}/network_band/{remote_collaborator_name}/
///
/// It returns a tuple containing the remote collaborator's network type (e.g., "ipv4" or "ipv6"),
/// network index (as a u8), and IP address (as an IpAddr).
///
/// # Arguments
///
/// * `remote_collaborator_name`: The remote collaborator's username.
/// * `team_channel_name`: The name of the active team channel.
///
/// # Returns
///
/// * `Result<(String, u8, IpAddr), ThisProjectError>`: A tuple containing the network type,
///   network index, and IP address on success, or a `ThisProjectError` if reading or parsing fails.
///
fn read_rc_bandnetwork_type_index(
    remote_collaborator_name: &str,
    team_channel_name: &str,
) -> Result<Option<(String, u8, String)>, ThisProjectError> { // Returns Option

    let mut base_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;
    base_path.push(team_channel_name);
    base_path.push("network_band");
    base_path.push(remote_collaborator_name);

    // Check if the directory for the collaborator's band data exists
    if !base_path.exists() {
        debug_log!("read_rc_bandnetwork_type_index: Directory for collaborator '{}' not found.  No ready signal received yet.", remote_collaborator_name);
        return Ok(None); // Return None, not an error
    }


    let network_type_path = base_path.join("network_type.txt");
    let network_index_path = base_path.join("network_index.txt");
    let ipv4_path = base_path.join("ipv4.txt");
    let ipv6_path = base_path.join("ipv6.txt");

    // Use a match statement to handle potential file not found errors
    let network_type = match fs::read_to_string(&network_type_path) {
        Ok(content) => content.trim().to_string(),
        Err(e) if e.kind() == ErrorKind::NotFound => {
            debug_log!("read_rc_bandnetwork_type_index: network_type.txt not found for collaborator '{}'.", remote_collaborator_name);
            return Ok(None); // Return None
        }
        Err(e) => return Err(ThisProjectError::IoError(e)), // Return other IO errors
    };

    let network_index: u8 = match fs::read_to_string(&network_index_path) {  //Similar handling
        Ok(content) => content.trim().parse().map_err(ThisProjectError::ParseIntError)?,
        Err(e) if e.kind() == ErrorKind::NotFound => {
             debug_log!("read_rc_bandnetwork_type_index:  network_index.txt not found for collaborator '{}'.", remote_collaborator_name);
            return Ok(None);
        }
        Err(e) => return Err(ThisProjectError::IoError(e)),
    };


    let ip_address_string = match network_type.as_str() { // ... (as before)
        "ipv4" => match fs::read_to_string(&ipv4_path) { //Handle potential file not found error here as well:
                Ok(s) => s.trim().to_string(),
                Err(e) if e.kind() == ErrorKind::NotFound => {
                    debug_log!("read_rc_bandnetwork_type_index: ipv4.txt not found for collaborator '{}'.", remote_collaborator_name);
                    return Ok(None);
                }
                Err(e) => return Err(ThisProjectError::IoError(e)),
            },
        "ipv6" => match fs::read_to_string(&ipv6_path) {  // And here.
                Ok(s) => s.trim().to_string(),
                Err(e) if e.kind() == ErrorKind::NotFound => {
                     debug_log!("read_rc_bandnetwork_type_index: ipv6.txt not found for collaborator '{}'.", remote_collaborator_name);
                    return Ok(None);
                }
                Err(e) => return Err(ThisProjectError::IoError(e)),
            },
        _ => return Err(ThisProjectError::NetworkError("Invalid network type".into())),
    };

    Ok(Some((network_type, network_index, ip_address_string)))  // Wrap the result in Some()
}

/// Reads the local user's network band configuration data from files in the sync_data directory.
/// Uses absolute paths and handles file I/O and parsing errors.
///
/// Returns:
///     Result<(String, u8, Ipv4Addr, Ipv6Addr), ThisProjectError>: A tuple containing the network type, index, IPv4 address, and IPv6 address on success, or a ThisProjectError on failure.
fn read_band__network_config_type_index_specs() -> Result<(String, u8, Ipv4Addr, Ipv6Addr), ThisProjectError> {
    // 1. Construct Absolute Paths (get current absolute working directory)
    let base_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;
    let type_path = base_path.join("network_type.txt");
    let index_path = base_path.join("network_index.txt");
    let ipv4_path = base_path.join("ipv4.txt");
    let ipv6_path = base_path.join("ipv6.txt");

    // 2. Read Values From Files
    let network_type_result = read_to_string(&type_path);
    let network_index_result = read_to_string(&index_path);
    let ipv4_result = read_to_string(&ipv4_path);
    let ipv6_result = read_to_string(&ipv6_path);

    // 3. Handle File Reading Errors: Return early if *any* file read fails
    let network_type = network_type_result?.trim().to_string();
    let network_index_str = network_index_result?.trim().to_string();
    let ipv4_str = ipv4_result?.trim().to_string();
    let ipv6_str = ipv6_result?.trim().to_string();


    // 4. Parse network_index (u8), Handling Errors
    let network_index: u8 = network_index_str
        .parse()
        .map_err(|e| ThisProjectError::InvalidData(format!("Invalid network index: {}", e)))?;


    // 5. Parse IPv4 and IPv6, Handling Errors
    let ipv4: Ipv4Addr = ipv4_str
        .parse()
        .map_err(|e| ThisProjectError::InvalidData(format!("Invalid IPv4 address: {}", e)))?;
    let ipv6: Ipv6Addr = ipv6_str
        .parse()
        .map_err(|e| ThisProjectError::InvalidData(format!("Invalid IPv6 address: {}", e)))?;


    Ok((network_type, network_index, ipv4, ipv6))
}


enum IpAddrKind { V4, V6 }

// impl From<toml::de::Error> for ThisProjectError {
//     fn from(err: toml::de::Error) -> ThisProjectError {
//         ThisProjectError::TomlDeserializationError(err)
//     }
// }


/*
Seri_Deseri Serialize To Start
*/



/// Serialize struct to .toml file
/// Serializes a `CollaboratorTomlData` struct into a TOML-formatted string.
///
/// This function takes a `CollaboratorTomlData` struct and manually constructs
/// a TOML-formatted string representation of the data.
///
/// # No `serde` Crate
///
/// This function implements TOML serialization *without* using the `serde`
/// crate. It manually formats each field of the `CollaboratorTomlData` struct
/// into the TOML syntax.
///
/// This approach is taken to avoid the dependency on the `serde` crate
/// while still providing a way to generate TOML output.
///
/// # TOML Format
///
/// The function generates a TOML string with the following structure:
///
/// ```toml
/// user_name = "value"
/// user_salt_list = [
///     "0xhex_value",
///     "0xhex_value",
///     ...
/// ]
/// ipv4_addresses = [
///     "ip_address",
///     "ip_address",
///     ...
/// ]
/// ipv6_addresses = [
///     "ip_address",
///     "ip_address",
///     ...
/// ]
/// gpg_key_public = "value"
/// sync_interval = value
/// updated_at_timestamp = value
/// ```
///
/// # Helper Function
///
/// The `serialize_ip_addresses` helper function is used to format the
/// `ipv4_addresses` and `ipv6_addresses` fields into TOML array syntax.
///
/// # Parameters
///
/// - `collaborator`: A reference to the `CollaboratorTomlData` struct to be serialized.
///
/// # Returns
///
/// Returns a `Result` containing:
/// - `Ok`: The TOML-formatted string representation of the `CollaboratorTomlData`.
/// - `Err`: A `ThisProjectError` if an error occurs during serialization (although
///           errors are unlikely in this simplified implementation).
///
/// # use with
/// // Serialize the collaborator data to a TOML string
/// match serialize_collaborator_to_toml(&collaborator) {
///     Ok(toml_string) => {
///         println!("Serialized TOML:\n{}", toml_string);
///
///         // Write the TOML string to a file (example file path)
///         match write_toml_to_file("collaborator_data.toml", &toml_string) {
///             Ok(_) => println!("TOML data written to file successfully."),
///             Err(e) => println!("Error writing to file: {}", e),
///         }
///     }
///     Err(e) => println!("Error serializing to TOML: {}", e),
/// }
fn serialize_collaborator_to_toml(collaborator: &CollaboratorTomlData) -> Result<String, ThisProjectError> {
    let mut toml_string = String::new();

    // Add user_name
    toml_string.push_str(&format!("user_name = \"{}\"\n", collaborator.user_name));

    // Add user_salt_list
    toml_string.push_str("user_salt_list = [\n");
    for salt in &collaborator.user_salt_list {
        toml_string.push_str(&format!("    \"0x{:x}\",\n", salt));
    }
    toml_string.push_str("]\n");

    // Add ipv4_addresses
    serialize_ip_addresses(&mut toml_string, "ipv4_addresses", &collaborator.ipv4_addresses)?;

    // Add ipv6_addresses
    serialize_ip_addresses(&mut toml_string, "ipv6_addresses", &collaborator.ipv6_addresses)?;

    // Add gpg_publickey_id
    toml_string.push_str(&format!("gpg_publickey_id = \"{}\"\n", collaborator.gpg_publickey_id));

    // Add gpg_key_public
    toml_string.push_str(&format!("gpg_key_public = \"\"\"{}\"\"\"\n", collaborator.gpg_key_public));

    // Add sync_interval
    toml_string.push_str(&format!("sync_interval = {}\n", collaborator.sync_interval));

    // Add updated_at_timestamp
    toml_string.push_str(&format!("updated_at_timestamp = {}\n", collaborator.updated_at_timestamp));

    Ok(toml_string)
}

// Helper function to serialize IP addresses to TOML array format
fn serialize_ip_addresses<T: std::fmt::Display>(
    toml_string: &mut String,
    key: &str,
    addresses: &Option<Vec<T>>
) -> Result<(), ThisProjectError> {
    if let Some(addr_vec) = addresses {
        toml_string.push_str(&format!("{} = [\n", key));
        for addr in addr_vec {
            toml_string.push_str(&format!("    \"{}\",\n", addr));
        }
        toml_string.push_str("]\n");
    }
    Ok(()) // Return Ok(()) if the addresses field is None
}

// Function to write a TOML string to a file
// Function to write a TOML string to a file
fn write_toml_to_file(file_path: &str, toml_string: &str) -> Result<(), ThisProjectError> {
    /* ?
    Wait random time in A to B range, N times
    FILE_READWRITE_N_RETRIES
    FILE_READWRITE_RETRY_SEC_PAUSE_MIN
    FILE_READWRITE_RETRY_SEC_PAUSE_max
    */

    // Attempt to create the file.
    let mut file = match File::create(file_path) {
        Ok(file) => file,
        Err(e) => return Err(ThisProjectError::IoError(e)),
    };

    // Attempt to write to the file.
    if let Err(e) = file.write_all(toml_string.as_bytes()) {
        return Err(ThisProjectError::IoError(e));
    }

    // Everything successful!
    Ok(())
}
/*
Seri_Deseri Serialize To TOml File End
*/

/*
Seri_Deseri Deserialize From .toml Start
*/

/// TODO: warning - any error should delete the temp file
/// Reads and parses collaborator setup data from a clearsigned TOML file.
///
/// This function securely reads collaborator data from a clearsigned TOML file by:
/// 1. Extracting the GPG public key from the file itself
/// 2. Verifying the clearsign signature to ensure integrity and authenticity
/// 3. If verification succeeds, parsing the TOML data within the clearsigned content
/// 4. Extracting all required fields into a CollaboratorTomlData structure
///
/// # Security Model
/// This function implements a self-verifying approach where each collaborator file
/// contains its own GPG public key and is clearsigned with the corresponding private key.
/// This ensures that:
/// - The data has not been tampered with (integrity)
/// - The data comes from the claimed source (authenticity)
/// - No external key management is required for basic verification
///
/// # File Format Expected
/// The input file should be a clearsigned TOML file with the following structure:
/// ```
/// -----BEGIN PGP SIGNED MESSAGE-----
/// Hash: SHA256
///
/// user_name = "alice"
/// user_salt_list = ["0x11111111111111111111111111111111", "0x11111111111111111111111111111112"]
/// ipv4_addresses = ["192.168.1.1", "10.0.0.1"]
/// ipv6_addresses = ["fe80::1", "::1"]
/// gpg_publickey_id = "3AA5C34371567BD2"
/// gpg_key_public = """-----BEGIN PGP PUBLIC KEY BLOCK-----
/// ...
/// -----END PGP PUBLIC KEY BLOCK-----"""
/// sync_interval = 60
/// updated_at_timestamp = 1728307160
/// -----BEGIN PGP SIGNATURE-----
/// ...
/// -----END PGP SIGNATURE-----
/// ```
///
/// # Arguments
/// * `collaborator_name` - The username/identifier of the collaborator whose data to read
///
/// # Returns
/// * `Ok(CollaboratorTomlData)` - Successfully parsed and verified collaborator data
/// * `Err(ThisProjectError)` - If verification fails, file is missing, or data is malformed
///
/// # Errors
/// This function may return errors for several reasons:
/// * File not found or unreadable
/// * GPG signature verification failure
/// * Missing or invalid GPG public key in the file
/// * Missing required TOML fields
/// * Invalid data formats (e.g., malformed IP addresses, invalid timestamps)
///
/// # Example Usage
/// ```rust
/// match read_one_collaborator_addressbook_toml("alice") {
///     Ok(collaborator_data) => {
///         println!("Successfully loaded data for: {}", collaborator_data.user_name);
///         println!("IP addresses: {:?}", collaborator_data.ipv4_addresses);
///     },
///     Err(e) => {
///         eprintln!("Failed to load collaborator data: {}", e);
///     }
/// }
/// ```
///
/// # Implementation Notes
/// - Uses line-by-line reading instead of loading entire file into memory
/// - Does not use any third-party crates like `serde` or `toml`
/// - Implements manual TOML field extraction for security and control
/// - Performs cryptographic verification before any data extraction
/// - Handles both IPv4 and IPv6 address parsing with proper error handling
///
/// # Related Functions
/// This function uses several helper functions from the clearsign_toml_module:
/// - `read_singleline_string_from_clearsigntoml()` - For single-line string fields
/// - `read_stringarray_field_clearsigntoml()` - For string arrays
/// - `read_u64_field_from_toml()` - For numeric fields (after verification)
/// This function loads collaborator data from either a clearsigned TOML file (.toml)
/// or a GPG-encrypted clearsigned TOML file (.gpgtoml). It ensures data integrity
/// through cryptographic verification and handles both file formats transparently.
///
/// # File Format Support
/// - **Clearsigned TOML (.toml)**: Plain text TOML file with GPG clearsign signature
/// - **GPG Encrypted TOML (.gpgtoml)**: Encrypted version of the clearsigned TOML
///
/// # File Selection Logic
/// 1. Checks for both `{collaborator_name}__collaborator.toml` and `.gpgtoml` files
/// 2. If BOTH exist: prefers the `.toml` file (no decryption needed)
/// 3. If only `.gpgtoml` exists: decrypts it to a temporary file for processing
/// 4. If only `.toml` exists: uses it directly
/// 5. If neither exists: returns an error
///
/// # GPG Decryption Process (for .gpgtoml files)
/// - Uses the specified GPG key from the local keyring for decryption
/// - Creates a secure temporary file with restricted permissions (0600 on Unix)
/// - Decrypts the content to the temporary file
/// - Processes the decrypted clearsigned TOML
/// - Automatically cleans up the temporary file after processing
///
/// # Security Features
/// - All files must be cryptographically clearsigned (signature verification)
/// - Temporary decrypted files have restricted permissions
/// - Temporary files are always cleaned up, even on error paths
/// - Original `.gpgtoml` files are never modified or deleted
///
/// # Error Handling
/// - If GPG decryption fails (wrong key, corrupted file, etc.):
///   - Displays detailed error message to the user
///   - Waits for user to press Enter (for visibility in multi-threaded context)
///   - Returns an error to the caller
/// - This approach ensures users see decryption failures without crashing the application
///
/// # Arguments
/// * `collaborator_name` - The username of the collaborator whose data to read
/// * `full_fingerprint_key_id_string` - The GPG key fingerprint to use for decrypting
///   .gpgtoml files. This must be a private key available in the local keyring.
///
/// # Returns
/// * `Ok(CollaboratorTomlData)` - Successfully parsed collaborator configuration
/// * `Err(ThisProjectError)` - Various errors:
///   - File not found (neither .toml nor .gpgtoml exists)
///   - GPG decryption failure
///   - Clearsign verification failure
///   - TOML parsing errors
///   - IO errors
///
/// # Example
/// ```no_run
/// let collaborator_data = read_one_collaborator_addressbook_toml(
///     "alice",
///     "1234567890ABCDEF1234567890ABCDEF12345678"
/// )?;
/// ```
///
/// # Debug Logging
/// - Logs which file type was selected (.toml vs .gpgtoml)
/// - Logs file paths being processed
/// - Logs GPG operations and any errors encountered
fn read_one_collaborator_addressbook_toml(
    collaborator_name: &str,
    full_fingerprint_key_id_string: &str,
    ) -> Result<CollaboratorTomlData, ThisProjectError> {
    debug_log("Starting ROCST: read_one_collaborator_addressbook_toml()");

    // 1. File Paths
    // Check for both .toml and .gpgtoml files
    let toml_relative = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
        .join(format!("{}__collaborator.toml", collaborator_name));
    let gpgtoml_relative = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
        .join(format!("{}__collaborator.gpgtoml", collaborator_name));

    // Get absolute paths
    let toml_abs = make_input_path_name_abs_executabledirectoryrelative_nocheck(&toml_relative)?;
    let gpgtoml_abs = make_input_path_name_abs_executabledirectoryrelative_nocheck(&gpgtoml_relative)?;

    // Determine which file to use and prepare the path
    let (abs_file_path, temp_file_to_cleanup) = if toml_abs.exists() {
        // Prefer .toml if it exists
        debug_log!("ROCST: Using clearsigned .toml file for collaborator '{}'", collaborator_name);
        (toml_abs, None)
    } else if gpgtoml_abs.exists() {
        // Use .gpgtoml and decrypt it
        debug_log!("ROCST: Using GPG encrypted .gpgtoml file for collaborator '{}'", collaborator_name);

        // Create secure temp file for decrypted content
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| ThisProjectError::IoError(
                std::io::Error::new(std::io::ErrorKind::Other, format!("Time error: {}", e))
            ))?
            .as_nanos();

        let temp_filename = format!("decrypt_collab_{}_{}.toml", collaborator_name, timestamp);
        let temp_path = std::env::temp_dir().join(&temp_filename);

        // Decrypt the .gpgtoml file
        let output = std::process::Command::new("gpg")
            .arg("--quiet")
            .arg("--batch")
            .arg("--yes")
            .arg("--local-user")
            .arg(full_fingerprint_key_id_string)
            .arg("--decrypt")
            .arg("--output")
            .arg(&temp_path)
            .arg(&gpgtoml_abs)
            .output()
            .map_err(|e| {
                let error_msg = format!("Failed to execute GPG decrypt for collaborator '{}': {}", collaborator_name, e);
                eprintln!("\nERROR: {}", error_msg);
                eprintln!("Press Enter to continue...");
                let _ = std::io::stdin().read_line(&mut String::new());
                ThisProjectError::GpgError(error_msg)
            })?;

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            let error_msg = format!("GPG decryption failed for collaborator '{}': {}", collaborator_name, stderr);
            eprintln!("\nERROR: {}", error_msg);
            eprintln!("Press Enter to continue...");
            let _ = std::io::stdin().read_line(&mut String::new());
            return Err(ThisProjectError::GpgError(error_msg));
        }

        // Set restricted permissions on temp file (Unix only)
        #[cfg(unix)]
        {
            use std::os::unix::fs::PermissionsExt;
            std::fs::set_permissions(&temp_path, std::fs::Permissions::from_mode(0o600))
                .map_err(|e| ThisProjectError::IoError(
                    std::io::Error::new(std::io::ErrorKind::Other,
                        format!("Failed to set temp file permissions: {}", e))
                ))?;
        }

        (temp_path.clone(), Some(temp_path))
    } else {
        return Err(ThisProjectError::IoError(
            std::io::Error::new(
                std::io::ErrorKind::NotFound,
                format!("No collaborator file found for '{}' (checked both .toml and .gpgtoml)", collaborator_name)
            )
        ));
    };

    debug_log!("ROCST: read_one_collaborator_addressbook_toml(), abs_file_path -> {:?}", abs_file_path);


    /////


    debug_log!("ROCST: read_one_collaborator_addressbook_toml(), abs_file_path (executable-relative) -> {:?}", abs_file_path);

    // Convert path to string for clearsign functions
    let file_path_str = abs_file_path.to_str()
        .ok_or_else(|| ThisProjectError::TomlVanillaDeserialStrError(
            "Failed to convert file path to string".to_string()
        ))?;

    // 2. Read and verify all fields from the clearsigned TOML file
    // Each read operation includes signature verification
    /*
    pub fn read_singleline_string_from_clearsigntoml(
        path_to_clearsigntoml_with_gpgkey: &str,
        name_of_toml_field_key_to_read: &str,
    ) -> Result<String, String> {
    */

    // Extract user_name
    let user_name = read_singleline_string_from_clearsigntoml(file_path_str, "user_name")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read user_name: {}", e)
        ))?;

    // Extract gpg_publickey_id
    let gpg_publickey_id = read_singleline_string_from_clearsigntoml(file_path_str, "gpg_publickey_id")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read gpg_publickey_id: {}", e)
        ))?;

    // Extract gpg_key_public
    let gpg_key_public = read_multiline_string_from_clearsigntoml(file_path_str, "gpg_key_public")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read gpg_key_public: {}", e)
        ))?;

    // Extract user_salt_list (array of hex strings that need to be converted to u128)
    let salt_strings = read_str_array_field_clearsigntoml(file_path_str, "user_salt_list")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read user_salt_list: {}", e)
        ))?;

    // Convert hex strings to u128 values
    let user_salt_list: Result<Vec<u128>, ThisProjectError> = salt_strings
        .iter()
        .map(|hex_str| {
            // Remove "0x" prefix if present
            let clean_hex = hex_str.trim_start_matches("0x");
            u128::from_str_radix(clean_hex, 16)
                .map_err(|e| ThisProjectError::ParseIntError(e))
        })
        .collect();
    let user_salt_list = user_salt_list?;

    // Extract IPv4 addresses (optional)
    let ipv4_addresses = match read_str_array_field_clearsigntoml(file_path_str, "ipv4_addresses") {
        Ok(addr_strings) => {
            let parsed_addrs: Result<Vec<std::net::Ipv4Addr>, ThisProjectError> = addr_strings
                .iter()
                .map(|addr_str| {
                    addr_str.parse::<std::net::Ipv4Addr>()
                        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
                            format!("Invalid IPv4 address '{}': {}", addr_str, e)
                        ))
                })
                .collect();
            Some(parsed_addrs?)
        },
        Err(_) => None, // Field is optional
    };

    // Extract IPv6 addresses (optional)
    let ipv6_addresses = match read_str_array_field_clearsigntoml(file_path_str, "ipv6_addresses") {
        Ok(addr_strings) => {
            let parsed_addrs: Result<Vec<std::net::Ipv6Addr>, ThisProjectError> = addr_strings
                .iter()
                .map(|addr_str| {
                    addr_str.parse::<std::net::Ipv6Addr>()
                        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
                            format!("Invalid IPv6 address '{}': {}", addr_str, e)
                        ))
                })
                .collect();
            Some(parsed_addrs?)
        },
        Err(_) => None, // Field is optional
    };

    // For numeric fields, we need to read them as strings first (since they're in a clearsigned file)
    // then parse them manually

    // Extract sync_interval
    let sync_interval_str = read_singleline_string_from_clearsigntoml(file_path_str, "sync_interval")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read sync_interval: {}", e)
        ))?;
    let sync_interval = sync_interval_str.parse::<u64>()
        .map_err(|e| ThisProjectError::ParseIntError(e))?;

    // Extract updated_at_timestamp
    let timestamp_str = read_singleline_string_from_clearsigntoml(file_path_str, "updated_at_timestamp")
        .map_err(|e| ThisProjectError::TomlVanillaDeserialStrError(
            format!("Failed to read updated_at_timestamp: {}", e)
        ))?;
    let updated_at_timestamp = timestamp_str.parse::<u64>()
        .map_err(|e| ThisProjectError::ParseIntError(e))?;

    // remove temp file
    // At the very end of the function, clean up temp file if we created one
    if let Some(temp_path) = temp_file_to_cleanup {
        if let Err(e) = std::fs::remove_file(&temp_path) {
            eprintln!("Warning: Failed to remove temporary decrypted file {}: {}", temp_path.display(), e);
        }
    }

    // 3. Construct and return the CollaboratorTomlData structure
    Ok(CollaboratorTomlData {
        user_name,
        user_salt_list,
        ipv4_addresses,
        ipv6_addresses,
        gpg_publickey_id,
        gpg_key_public,
        sync_interval,
        updated_at_timestamp,
    })
}

/// Extracts the `updated_at_timestamp` from TOML data.
///
/// This function takes a byte slice containing TOML data and attempts to extract
/// the `updated_at_timestamp` field as a `u64`.  It handles the cases where
/// the field is missing, has an invalid type, or is out of the valid `u64` range.
///
/// # Arguments
///
/// * `toml_data`: The TOML data as a byte slice.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`: The `updated_at_timestamp` on success, or a
///    `ThisProjectError` if an error occurs.
fn extract_updated_at_timestamp(file_content: &[u8]) -> Result<u64, ThisProjectError> {
    // 1. Convert to String (handle UTF-8 errors).
    let file_str = std::str::from_utf8(file_content).map_err(|_| {
        ThisProjectError::InvalidData("Invalid UTF-8 in file content".into())
    })?;

    // 2. Check for "updated_at_timestamp = " line (TOML-style).
    for line in file_str.lines() {
        if line.starts_with("updated_at_timestamp = ") {
            let value_str = line.trim_start_matches("updated_at_timestamp = ");
            let timestamp = value_str.parse().map_err(|e: ParseIntError| {
                ThisProjectError::InvalidData(format!("Invalid timestamp: {}", e))
            })?;
            return Ok(timestamp);
        }
    }

    // 3. (Optional) If not TOML, try other formats (e.g., JSON).  Add this as needed.
    // ... (Code to handle other formats, checking for similar timestamp fields) ...

    // 4. If no recognized timestamp format is found.
    Err(ThisProjectError::InvalidData("Timestamp field not found in any recognized format".into()))
}

/*
Seri_Deseri Deserialize From End
*/

// /// get unix time
// /// e.g. for use with updated_at_timestamp
// fn get_current_unix_timestamp() -> u64 {
//     SystemTime::now()
//         .duration_since(UNIX_EPOCH)
//         .expect("System time is before the Unix epoch!") // Handle errors appropriately
//         .as_secs()
// }



/*

This demo code is only making one set of unique port assignments, but it should be making a sets of port assignment for each collaborator x other collaborators

Here is a sample of what the code should produce (the demo code does not produce this):
```sample
teamchannel_collaborators_with_access = ["alice", "bob", "charlotte"]
# meeting rooms, collaborator_port_assignments
[abstract_collaborator_port_assignments.alice_bob]
collaborator_ports = [
{ user_name = "alice", ready_port = 50001, intray_port = 50002, gotit_port = 50003 },
{ user_name = "bob", ready_port = 50004, intray_port = 50005, gotit_port = 50006 },
]
[abstract_collaborator_port_assignments.alice_charlotte]
collaborator_ports = [
{ user_name = "alice", ready_port = 50007, intray_port = 50008, gotit_port = 50009 },
{ user_name = "charlotte", ready_port = 50010, intray_port = 50011, gotit_port = 50012 },
]
[abstract_collaborator_port_assignments.bob_charlotte]
collaborator_ports = [
{ user_name = "bob", ready_port = 50013, intray_port = 50014, gotit_port = 50015 },
{ user_name = "charlotte", ready_port = 50016, intray_port = 50017, gotit_port = 50018 },
]
```
demo code:
// Generate collaborator port assignments
let mut abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();
// Add owner to collaborators list
let mut collaborators = Vec::new();
collaborators.push(owner.clone());
debug_log!(
"create_new_team_channel(): owner '{}' added to collaborators",
owner
);
// Generate random ports for the owner
let mut rng = rand::rng();
let ready_port = rng.random_range(40000..60000) as u16;
let tray_port = rng.random_range(40000..60000) as u16;
let gotit_port = rng.random_range(40000..60000) as u16;
let abstract_ports_data = AbstractTeamchannelNodeTomlPortsData {
user_name: owner.clone(),
ready_port,
intray_port: tray_port,
gotit_port,
};
debug_log!(
"create_new_team_channel(): owner's ports assigned - ready:{}, intray:{}, gotit:{}",
ready_port, tray_port, gotit_port
);
// Store in the HashMap with "owner_owner" key
abstract_collaborator_port_assignments.insert(
format!("{}_{}", owner.clone(), owner),
vec![ReadTeamchannelCollaboratorPortsToml { collaborator_ports: vec![abstract_ports_data] }],
);
debug_log!("create_new_team_channel(): owner added to port assignments");
// Retrieve project area data
debug_log!("Retrieving project area data...");
```

the current code is incomplete, or misconfigured, not generating the collaboration pairs:
we need pairs of different collaborators:
"alice_bob" (Alice collaborating with Bob)
"alice_charlotte" (Alice collaborating with Charlotte)
"bob_charlotte" (Bob collaborating with Charlotte)

Design factors:
1. random not sequential ports may be better for security
2. there will be an exclude-list and a range for generating ports (see below)
3. There needs to be a user-interface first step step to add collaborators by string input, and checking that each collaborator is in address book (or sub-folder)
teamchannel_collaborators_with_access = list of collaborators with access (as the name says)
4. the owner needs to be added along with those that the owner invites. the own IS to be added, not optional.

examples steps:
1. "Enter the user-names of collaborators you wish to invite separated by commas"
> user (alice) enters: bob,charlotte,duncan
The program checks that each name exists only once, e.g. make an alphabetical set. (or set and then an alphabetical string array)
The owner is just like any other collaborator in terms of the ports, include the owner alphabetically.
if a string (or more than one) was not in the list, say which it was and ask the user to re-enter the list: "Enter the user-names of collaborators you wish to invite separated by commas"

Checking that users exist works like this (there are a few steps here):
1. there is an exe-parent/COLLABORATOR_ADDRESSBOOK_PATH_STR/
directory.
Code to get directory where addressbook files are:
```rust
let collaborator_files_address_book_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
COLLABORATOR_ADDRESSBOOK_PATH_STR
) {
Ok(directory_path) => {
println!("Team channels directory: {}", directory_path.display());
directory_path
}
Err(io_error) => {
let error_msg = format!(
"Failed to ensure team_channels_dir exists: {}",
io_error
);
eprintln!("ERROR: {}", error_msg);
return Err(ThisProjectError::from(error_msg));
}
};
```
skip sub directories for now:
code showing how to find addressbook files
```rust
// 1. Construct File Path
let relative_file_path = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
.join(format!("{}__collaborator.toml", collaborator_name));
// Get the executable-relative base directory path
let abs_file_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
relative_file_path
) {
Ok(path) => path,
Err(e) => {
debug_log!("ROCST: Failed to resolve collaborator directory path: {}", e);
return Err(ThisProjectError::IoError(e));
}
};
```

maybe using the function
make_input_path_name_abs_executabledirectoryrelative_nocheck()
and then check if that file exists
2. adds the current-owner-user to that list
3. makes version-1 port assignments
4. should check 'globally' for port collisions...
if a file cannot be validated, just print a notice (and debug-log a notice) and skip it, don't crash the program.

We will make a new function to create an exclusion list so no ports collide:
- no ports can collide locally-in-this-team, 100% required.
- ideally no ports should collide globally, should be feasible but is not required.

So a first dev-task may be to make the new version of check_all_ports_in_team_channels_clearsign_validated() maybe
make_exclusionlist_check_ports_in_team_channels_clearsign_validated()
using existing ports as an "exclusion list" when generating new ports, and then double checking to make sure no collisions with self or exclusion list.

the global exclusion list will be made of the ports lists from all team-channels.

The may be a wrapper function
global_ports_exclusion_list_generator()
that uses the 'local'/single exclusion list make to run on all team channels.

e.g.for every team-channel node.toml
get a list of the team_channel directories:
- team_channels
// Ensure the project graph data directory exists relative to the executable
let team_channels_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
"project_graph_data/team_channels"
) {
Ok(directory_path) => {
println!("Team channels directory: {}", directory_path.display());
directory_path
}
Err(io_error) => {
let error_msg = format!(
"Failed to ensure team_channels_dir exists: {}",
io_error
);
eprintln!("ERROR: {}", error_msg);
return Err(ThisProjectError::from(error_msg));
}
};
add .../node.toml to that to get the config files

..
to sum up
1. Collect collaborators interactively: Prompt user to enter comma-separated collaborator names
2. Validate collaborators: Check each collaborator exists in the address book/sub-folder
3. Include owner: Add the current owner to the collaborator list
4. Generate pairwise port assignments: Create port assignments for every collaborator pair (not just one global set)
5. Check global port collisions:
Create a new function return_checked_ports_in_team_channels_clearsign_validated() [based on existing check_all_ports_in_team_channels_clearsign_validated()]
Scan all existing team channel node.toml files for used ports
Ensure new port assignments don't collide with existing ones
ALL ports across ALL pairs must be globally unique across the entire system
Retry on collision: If port assignments collide, regenerate until they're unique
`abstract_collaborator_port_assignments` HashMap should have keys like "alice_bob", "alice_charlotte", "bob_charlotte" with each containing the port data for both collaborators in that pair.
Each pair of collaborators have unique ports for that pair.
there is no redundant bob_alice port set. the name order is always the same as the collaborator list.
Pair Naming Convention: Should the pair names always follow the order they appear in the collaborator list? (e.g., if list is [alice, bob, charlotte], then pairs are alice_bob, alice_charlotte, bob_charlotte)
Total Pairs: For N collaborators, we generate N*(N-1)/2 unique pairs
2 collaborators = 1 pair
3 collaborators = 3 pairs
4 collaborators = 6 pairs
etc.
Port Count: Each pair contains port assignments for both collaborators in that pair, so each pair will have 6 ports total (3 ports  2 collaborators)
...
Generate unique port assignments for every collaborator pair
Ensure ALL ports are globally unique across the entire system
Check against existing team channels to prevent any collisions
since you are using an exclusion-list there should not be a collision. if a collusion happens even though you have an exclusion list show the user a warning and ask if they want to use a list that is locally-in-that-team not-colliding but not-globally-unique (though that can't really happen unless the exclusion list is not functioning)
with 33k possible ports, a small agile team will be able to use locally in that team unique ports.
my understanding is that 49152-65535: IANA designated "Dynamic/Private" ports - safest choice, is a safe port range to use.
of that is full (unlikely) use 32768-65535: Traditional ephemeral range on many Unix systems
"skip subdirectories" ignore any subdirectories in the address book folder entirely (there are none yet, and maybe won't be any)
to recap:
## Scope Confirmation
### 1. Interactive Collaborator Collection
- Prompt user to enter comma-separated collaborator names
- Validate each name exists in `project_graph_data/collaborator_files_address_book/` as `{name}__collaborator.toml`
- Skip subdirectories entirely in address book folder
- If any names don't exist, show which ones and re-prompt for the entire list
- Create alphabetical set (no duplicates)
- Always include the owner in the final collaborator list
### 2. Pairwise Port Assignment Generation
- Generate unique pairs for N collaborators: N*(N-1)/2 pairs
- Pair naming: alphabetical order from collaborator list (e.g., "alice_bob", "alice_charlotte", "bob_charlotte")
- Each pair gets 6 unique ports total (3 ports  2 collaborators)
- Store in `abstract_collaborator_port_assignments` HashMap with pair names as keys
### 3. Global Port Collision Prevention
- Create new function `return_checked_ports_in_team_channels_clearsign_validated()`
- Scan all existing `project_graph_data/team_channels/
*
 /node.toml` files for used ports
- Build exclusion list of all currently used ports across entire system
- Generate new ports from safe range (49152-65535, fallback to 32768-65535)
- ALL ports across ALL pairs must be globally unique system-wide
- If collision occurs despite exclusion list, warn user and offer locally-unique option
### 4. Error Handling
- Gracefully handle missing/invalid collaborator files (log and skip, don't crash)
- Handle file system errors appropriately
- Provide clear user feedback for validation failures
### 5. Port Range Strategy
- Primary: 49152-65535 (IANA Dynamic/Private ports)
- Fallback: 32768-65535 (Traditional ephemeral range)
### 6. Data Structure
The `abstract_collaborator_port_assignments` HashMap structure should look like:
```
"alice_bob" -> Vec<ReadTeamchannelCollaboratorPortsToml> with alice and bob's port data
"alice_charlotte" -> Vec<ReadTeamchannelCollaboratorPortsToml> with alice and charlotte's port data
"bob_charlotte" -> Vec<ReadTeamchannelCollaboratorPortsToml> with bob and charlotte's port data
```
structure:
[abstract_collaborator_port_assignments.alice_bob]
collaborator_ports = [
  { user_name = "alice", ready_port = 50001, intray_port = 50002, gotit_port = 50003 },
  { user_name = "bob", ready_port = 50004, intray_port = 50005, gotit_port = 50006 },
]


If a single team channel's node.toml fails validation in the exclusion list generator, skip it and continue (adding a warning to logs)

Scope of Ports to Include:
The exclusion list includes all ports found (ready, intray, gotit)
the exclusion list only needs the port: if a port is in use, it does not matter who is using it for what, only that it is in use and therefore not available.


## Return Type
**use: `HashSet<u16>`**
- Since you only need port numbers (not types), a `HashSet<u16>` is ideal
- Provides O(1) lookup performance when checking if a port is already in use
- Automatically handles duplicates
- Perfect for an exclusion list use case
## Function Structure
two-function approach:
### 1. Single Team Channel Function
```rust
/// Extracts all ports from a single team channel's node.toml file
/// Returns a HashSet of all ports found (ready, intray, gotit for all collaborators)
pub fn make_exclusionlist_from_single_team_channel(
node_toml_path: &Path,
collaborator_files_dir_relative: &str,
) -> Result<HashSet<u16>, ThisProjectError>
```
### 2. Global Function (No Parameters)
```rust
/// Scans ALL team channels and returns a complete exclusion list of all ports in use
/// Similar to the original function - takes no parameters and scans everything
pub fn global_ports_exclusion_list_generator() -> Result<HashSet<u16>, ThisProjectError>
```
This matches the pattern of the original function:
- No parameters needed
- Automatically determines paths using `make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path()`
- Walks through ALL team channels in `project_graph_data/team_channels`
- Hardcodes the collaborator path as COLLABORATOR_ADDRESSBOOK_PATH_STR
The global function would internally call the single-channel function for each `node.toml` found, aggregating all ports into one master `HashSet<u16>`.
...

*/



/// Checks all ports across all team channels for collisions and usage conflicts.
///
/// # Purpose
/// This function performs a comprehensive audit of all network ports configured across
/// all team channels in the project. It ensures that:
/// 1. No two collaborators are assigned the same port (collision detection)
/// 2. Ports that are supposed to be in use are actually available on the system
/// 3. All team channel configurations are properly clearsigned and validated
///
/// # Process Flow
/// 1. **Directory Setup**: Ensures the team channels directory exists
/// 2. **Channel Discovery**: Walks through all subdirectories looking for `node.toml` files
/// 3. **Security Validation**: Each `node.toml` must be clearsigned and validated
/// 4. **Port Extraction**: Extracts all port assignments from validated files
/// 5. **Collision Detection**: Checks for duplicate port assignments across channels
/// 6. **System Availability**: Verifies if ports marked as "in use" are actually available
///
/// # Security Model
/// - Only processes clearsigned `node.toml` files
/// - Uses owner-based GPG key validation via the collaborator addressbook system
/// - Skips any files that fail signature validation
///
/// # Error Handling
/// The function provides detailed error information and interactive warnings:
/// - Port collisions trigger a warning with user confirmation to continue
/// - Invalid configurations are logged but don't stop the entire scan
/// - Returns a comprehensive error if critical issues are found
///
/// # Returns
/// * `Ok(())` - If all ports are properly configured without collisions
/// * `Err(ThisProjectError)` - If critical errors occur:
///   - Directory access issues
///   - Systematic port collision patterns
///   - Critical configuration errors
///
/// # Example Output
/// ```text
/// === Team Channel Port Audit ===
/// Checking all team channels in: /path/to/project_graph_data/team_channels
///
/// Processing channel: team_alpha
///    Validated signature for owner: alice
///   Found 3 collaborator pairs with 6 port assignments
///
/// Processing channel: team_beta
///    Validated signature for owner: bob
///   Found 2 collaborator pairs with 4 port assignments
///
///   PORT COLLISION DETECTED!
/// Port 50001 is assigned multiple times:
///   - team_alpha: alice (ready_port) in pair alice_bob
///   - team_beta: charlie (ready_port) in pair charlie_dave
///
/// Press Enter to continue scanning or Ctrl+C to abort...
///
/// === Summary ===
/// Total channels scanned: 2
/// Total port assignments: 10
/// Collisions found: 1
/// ```
pub fn check_all_ports_in_team_channels_clearsign_validated() -> Result<(), ThisProjectError> {
    println!("=== Team Channel Port Audit ===");
    debug_log("CAPITCCV starto check_all_ports_in_team_channels_clearsign_validated === Team Channel Port Audit ===");
    // --- Stage 1: Directory Setup ---
    println!("Setting up team channels directory...");
    debug_log!("CAPITCCV Setting up team channels directory...");

    // Ensure the project graph data directory exists relative to the executable
    let team_channels_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        "project_graph_data/team_channels"
    ) {
        Ok(directory_path) => {
            println!("Team channels directory: {}", directory_path.display());
            debug_log!("CAPITCCV Team channels directory: {}", directory_path.display());

            directory_path
        }
        Err(io_error) => {
            let error_msg = format!(
                "CAPITCCV Failed to ensure team_channels_dir exists: {}",
                io_error
            );
            debug_log!("CAPITCCV ERROR: {}", error_msg);
            eprintln!("CAPITCCV ERROR: {}", error_msg);
            return Err(ThisProjectError::from(error_msg));
        }
    };

    // Get collaborator files directory for addressbook lookups
    let collaborator_files_dir_relative = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    /*
    Is this not updated for .gpgclearsign?
    */

    // --- Stage 2: Initialize Tracking Structures ---

    // Why is this making a new struct??
    // Track all port assignments with their context for detailed collision reporting
    #[derive(Debug, Clone)]
    struct PortAssignmentContext {
        channel_name: String,
        pair_name: String,
        user_name: String,
        port_type: String, // "ready", "intray", or "gotit"
    }

    let mut port_registry: HashMap<u16, Vec<PortAssignmentContext>> = HashMap::new();
    let mut channels_processed = 0;
    let mut total_port_assignments = 0;
    let mut validation_failures = 0;
    let mut collision_count = 0;

    println!("\nScanning for team channel configurations...\n");
    debug_log!("\n CAPITCCV Scanning for team channel configurations...for entry in WalkDir::new(&team_channels_dir)\n");


    // --- Stage 3: Walk Through Team Channels ---
    // for entry in WalkDir::new(&team_channels_dir) //  This recursively walks ALL subdirectories!
    //     .into_iter()
    //     .filter_map(|e| e.ok())
    //     .filter(|e| e.file_type().is_dir())
    // {
    // --- Stage 3: Walk Through Team Channels (ONE LEVEL ONLY) ---
    for entry in std::fs::read_dir(&team_channels_dir)
        .map_err(|e| ThisProjectError::from(format!("Failed to read team_channels directory: {}", e)))?
        .filter_map(|e| e.ok())
        .filter(|e| e.file_type().map(|ft| ft.is_dir()).unwrap_or(false))
    {
        /*
        workflow:

        maybe a few small changes just here
        to
        A. use helper functions to use clearsigned or .gpgtoml
        B. make a read-copy and use that path



        */

        // // Check the both!
        // let node_toml_path_a = entry.path().join("node.toml");
        // let node_toml_path_b = entry.path().join("node.gpgtoml");


        // // Skip directories without node.toml
        // if !node_toml_path_a.exists() & !node_toml_path_b.exists(){
        //     continue;
        // }

        // // new code here for gpgtoml

        // // Get armored public key, using key-id (full fingerprint in)
        // let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        //     Ok(fingerprint) => fingerprint,
        //     Err(e) => {
        //         // Since the function returns Result<CoreNode, String>, we need to return a String error
        //         return Err(format!(
        //             "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
        //             e
        //         ).into());
        //     }
        // };

        // // code from load_core_node...()
        // // Get the UME temp directory path with proper GpgError conversion
        // let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        //     .map_err(|io_err| GpgError::ValidationError(
        //         format!("Failed to get UME temp directory path: {}", io_err)
        //     ))?;

        // // Using Debug trait for more detailed error information
        // let node_readcopy_path_string = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        //     &entry.clone().into_path(),
        //     &gpg_full_fingerprint_key_id_string,
        //     &base_uma_temp_directory_path,
        // ).map_err(|e| format!("Failed to get temporary read copy of TOML file: {:?}", e))?;

        // Check for both file types
        let node_toml_path = entry.path().join("node.toml");
        let node_gpgtoml_path = entry.path().join("node.gpgtoml");

        // Determine which file exists and use that path
        let node_file_path = if node_toml_path.exists() {
            node_toml_path
        } else if node_gpgtoml_path.exists() {
            node_gpgtoml_path
        } else {
            // Neither exists, skip this directory
            continue;
        };

        // Get GPG fingerprint (could move this outside the loop if same for all)
        let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => fingerprint,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "CAPITCCV error Failed to read GPG fingerprint for {:?}: {} (skipping)",
                    entry.path(),
                    e
                );
                continue; // Skip this directory, continue with next
            }
        };

        // Get temp directory path (could move this outside the loop if same for all)
        let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
            Ok(path) => path,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "CAPITCCV error Failed to get temp directory path for {:?}: {} (skipping)",
                    entry.path(),
                    e
                );
                continue; // Skip this directory, continue with next
            }
        };

        // Get readable copy
        let node_readcopy_path_string = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
            &node_file_path,
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ) {
            Ok(path) => path,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "CAPITCCV error Failed to get read copy for {:?}: {:?} (skipping)",
                    node_file_path,
                    e
                );
                continue; // Skip this directory, continue with next
            }
        };

        // Extract channel name from directory path
        let channel_name = entry.path()
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("unknown")
            .to_string();

        // Skip the root directory itself
        if entry.path() == team_channels_dir {
            continue;
        }

        debug_log!("CAPITCCV Processing channel: {}", channel_name);
        channels_processed += 1;

        /*
        pub fn read_all_collaborator_port_assignments_clearsigntoml_optimized(
            path_to_clearsigned_toml: &Path,
            // addressbook_files_directory_relative: &str,  // pass in constant here
	       readcopy_path_to_addressbook_file: &Path,
        ) -> Result<HashMap<String, Vec<AbstractTeamchannelNodeTomlPortsData>>, GpgError> {

        */

        // let node_readcopy_path_path = Path::new(&node_readcopy_path_string);

        let absolute_addressbook_directory_pathbuf = match get_addressbook_directory_path() {
            Ok(path) => path,
            Err(e) => {
                debug_log!("CAPITCCV Failed to get absolute path: {}", e);
                return Err(ThisProjectError::from(format!(
                    "CAPITCCV error Failed absolute_addressbook_directory_pathbuf: {}",
                    e
                )));
            }
        };

        // let absolute_addressbook_directory_path = Path::new(&absolute_addressbook_directory_pathbuf);

        // // Get GPG fingerprint
        // let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        //     Ok(fingerprint) => fingerprint,
        //     Err(e) => {
        //         return Err(format!("Failed to read GPG fingerprint from uma.toml: {}", e).into());
        //     }
        // };

        // // Get temp directory path
        // let base_uma_temp_directory_path = get_base_uma_temp_directory_path().map_err(|io_err| {
        //     GpgError::ValidationError(format!("Failed to get UME temp directory path: {}", io_err))
        // })?;

        // --- Stage 4: Read and Validate Clearsigned Configuration ---
        //
        // match read_all_collaborator_port_assignments_clearsigntoml_optimized(
        //     &node_readcopy_path_path,
        //     &absolute_addressbook_directory_path,
        //     &gpg_full_fingerprint_key_id_string,
        //     &base_uma_temp_directory_path,
        // ) {

        // Check for both file types
        let node_toml_path = entry.path().join("node.toml");
        let node_gpgtoml_path = entry.path().join("node.gpgtoml");

        // Determine which file exists and use that path
        let node_file_path = if node_toml_path.exists() {
            node_toml_path
        } else if node_gpgtoml_path.exists() {
            node_gpgtoml_path
        } else {
            // Neither exists, skip this directory
            continue;
        };

        // Get GPG fingerprint (could move this outside the loop if same for all)
        let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => fingerprint,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "CAPITCCV Failed to read GPG fingerprint for {:?}: {} (skipping)",
                    entry.path(),
                    e
                );
                continue; // Skip this directory, continue with next
            }
        };

        // Get temp directory path (could move this outside the loop if same for all)
        let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
            Ok(path) => path,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "CAPITCCV Failed to get temp directory path for {:?}: {} (skipping)",
                    entry.path(),
                    e
                );
                continue; // Skip this directory, continue with next
            }
        };

        // Get readable copy
        let node_readcopy_path_string = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
            &node_file_path,
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ) {
            Ok(path) => path,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "CAPITCCV Failed to get read copy for {:?}: {:?} (skipping)",
                    node_file_path,
                    e
                );
                continue; // Skip this directory, continue with next
            }
        };

        debug_log!("CAPITCCV node_readcopy_path_string->{}", node_readcopy_path_string);

        // addressbook:
        //
        /*
        pub fn read_singleline_string_from_clearsigntoml(
            path_to_clearsigntoml_with_gpgkey: &str,
            name_of_toml_field_key_to_read: &str,
        ) -> Result<String, String> {
        */

        // Read the username from the clearsigned TOML
        // This is the remote collaborator whose addressbook we just received
        let remote_collaborator_username = read_single_line_string_field_from_toml(
            &node_readcopy_path_string,
            "owner"
        ).map_err(|rssfc_e| {
            let error_msg = format!(
                "CAPITCCV Failed read_single_line_string_field_from_toml 'owner' node_readcopy_path_string->{}; rssfc_e->{}; ",
                node_readcopy_path_string,
                rssfc_e,
            );
            debug_log!("CAPITCCV Error: {}", error_msg);
            // debug_log!("CAPITCCV The decrypted file doesn't contain a valid owner field.");
            GpgError::ValidationError(error_msg)
        })?;

        debug_log!("CAPITCCV Extracted remote collaborator's username: {}", remote_collaborator_username);

        // STEP 7.5: Ask user for preferred save format
        debug_log!("CAPITCCV Step 7.5: Prompting user for save format preference");

        // Check for both file types
        let toml_path = absolute_addressbook_directory_pathbuf
            .join(format!("{}__collaborator.toml", remote_collaborator_username));
        let gpgtoml_path = absolute_addressbook_directory_pathbuf
            .join(format!("{}__collaborator.gpgtoml", remote_collaborator_username));

        // Determine which file exists and use that path
        let raw_addressbook_path = if toml_path.exists() {
            // Prefer plain .toml if both exist
            toml_path
        } else if gpgtoml_path.exists() {
            gpgtoml_path
        } else {
            // Neither exists, skip this directory
            #[cfg(debug_assertions)]
            debug_log!(
                "Skipping directory (no node.toml or node.gpgtoml): {:?}",
                &absolute_addressbook_directory_pathbuf
            );
            return Err(ThisProjectError::from(format!(
                "CAPITCCV Err Invalid path encoding for addressbook file: {}",
                absolute_addressbook_directory_pathbuf.display()
            )));
        };

        // Get readable copy
        let specific_readcopy_addressbook_path = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
            &raw_addressbook_path,
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ) {
            Ok(path) => path,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "CAPITCCV Failed to get read copy for {:?}: {:?} (skipping)",
                    node_file_path,
                    e
                );
                continue; // Skip this directory, continue with next
            }
        };

        match read_abstract_collaborator_portassignments_from_clearsigntoml_withoutkeyid(
            &specific_readcopy_addressbook_path, // addressbook_readcopy_path_string
            &node_readcopy_path_string // path_to_clearsigned_toml
        ) {
            Ok(port_assignments) => {
                println!("CAPITCCV   Signature validated successfully");
                println!("CAPITCCV  Found {} collaborator pairs", port_assignments.len());

                // --- Stage 5: Process Port Assignments ---
                for (pair_name, assignments) in port_assignments {
                    for assignment in assignments {
                        // Track each port with its context
                        let port_contexts = [
                            (assignment.ready_port, "ready"),
                            (assignment.intray_port, "intray"),
                            (assignment.gotit_port, "gotit"),
                        ];

                        for (port, port_type) in port_contexts {
                            total_port_assignments += 1;

                            let context = PortAssignmentContext {
                                channel_name: channel_name.clone(),
                                pair_name: pair_name.clone(),
                                user_name: assignment.user_name.clone(),
                                port_type: port_type.to_string(),
                            };

                            // Add to registry
                            port_registry
                                .entry(port)
                                .or_insert_with(Vec::new)
                                .push(context);
                        }
                    }
                }
            }
            Err(e) => {
                validation_failures += 1;
                println!("Validation node_readcopy_path_string: {}", node_readcopy_path_string);
                debug_log!("CAPITCCV Validation node_readcopy_path_string: {}", node_readcopy_path_string);

                eprintln!("   Validation FAILED cuz: {}", e.to_string());
                debug_log!("CAPITCCV Validation FAILED cuz: {}", e.to_string());

                debug_log!("CAPITCCV  Skipping this channel {} due to security validation failure", node_file_path.to_string_lossy());
                eprintln!("  Skipping this channel {} due to security validation failure", node_file_path.to_string_lossy());
                continue;
            }
        }

        println!(); // Empty line between channels
    }

    // --- Stage 6: Analyze Port Collisions ---
    println!("=== Port Collision Analysis ===\n");

    let mut collision_found = false;

    for (port, contexts) in &port_registry {
        if contexts.len() > 1 {
            collision_found = true;
            collision_count += 1;

            // Print collision warning
            println!("  PORT COLLISION DETECTED!");
            println!("Port {} is assigned multiple times:", port);
            debug_log!("  PORT COLLISION DETECTED!");
            debug_log!("Port {} is assigned multiple times:", port);
            for context in contexts {
                println!(
                    "  - Channel '{}': {} ({}_port) in pair {}",
                    context.channel_name,
                    context.user_name,
                    context.port_type,
                    context.pair_name
                );
            }

            println!();

            // Check if the port is actually in use on the system
            if is_port_in_use(*port) {
                println!("   CRITICAL: Port {} is currently IN USE on the system!", port);
                debug_log!("   CRITICAL: Port {} is currently IN USE on the system!", port);

            } else {
                println!("   Port {} is not currently in use on the system", port);
                debug_log!("   CRITICAL: Port {} is currently IN USE on the system!", port);
            }

            // Interactive warning - ask user to continue
            println!("\nPress Enter to continue scanning or Ctrl+C to abort...");
            let mut input = String::new();
            match io::stdin().read_line(&mut input) {
                Ok(_) => {
                    println!("Continuing scan...\n");
                }
                Err(e) => {
                    return Err(ThisProjectError::from(format!(
                        "Failed to read user input: {}",
                        e
                    )));
                }
            }
        }
    }

    if !collision_found {
        println!(" No port collisions detected!");
        debug_log!("No port collisions detected!");

    }

    // --- Stage 7: Summary Report ---
    println!("\n=== Summary ===");
    println!("Total channels scanned: {}", channels_processed);
    println!("Total port assignments: {}", total_port_assignments);
    println!("Unique ports used: {}", port_registry.len());
    println!("Validation failures: {}", validation_failures);
    println!("Port collisions found: {}", collision_count);

    debug_log!("Total channels scanned: {}", channels_processed);
    debug_log!("Total port assignments: {}", total_port_assignments);
    debug_log!("Unique ports used: {}", port_registry.len());
    debug_log!("Validation failures: {}", validation_failures);
    debug_log!("Port collisions found: {}", collision_count);

    // --- Stage 8: Final Status ---
    if collision_found {
        eprintln!("\n Port audit FAILED: {} collision(s) detected", collision_count);
        eprintln!("Please resolve port conflicts before proceeding.");

        debug_log!("\n Port audit FAILED: {} collision(s) detected", collision_count);
        debug_log!("Please resolve port conflicts before proceeding.");
        // Create detailed error message
        let mut collision_details = String::from("Port collisions detected:\n");
        for (port, contexts) in &port_registry {
            if contexts.len() > 1 {
                collision_details.push_str(&format!("  Port {}: {} assignments\n", port, contexts.len()));
            }
        }

        Err(ThisProjectError::PortCollision(collision_details))
    } else if validation_failures > 0 {
        eprintln!("\n  Port audit completed with {} validation failures", validation_failures);
        eprintln!("Some channels could not be verified due to signature issues.");
        debug_log!("\n  Port audit completed with {} validation failures", validation_failures);
        debug_log!("Some channels could not be verified due to signature issues.");
        Ok(())
    } else {
        println!("\n Port audit PASSED: All ports properly configured!");
        debug_log("Done check_all_ports_in_team_channels_clearsign_validated() Port audit PASSED: All ports properly configured!");
        Ok(())
    }
}

/*

*/


/// Extracts all ports from a single team channel's node.toml file.
///
/// # Purpose
/// This function reads a clearsigned `node.toml` file from a team channel and extracts
/// all configured network ports (ready, intray, and gotit ports) for all collaborator
/// pairs. The extracted ports are returned as a HashSet for efficient lookup when
/// checking for port collisions.
///
/// # Parameters
/// * `node_toml_path` - The absolute path to the node.toml file to process
/// * `collaborator_files_dir_relative` - The relative path to the collaborator files
///   directory (typically COLLABORATOR_ADDRESSBOOK_PATH_STR)
///
/// # Security
/// - Only processes clearsigned files that pass GPG validation
/// - Uses the collaborator addressbook system for owner verification
/// - Returns an empty set if validation fails (with appropriate logging)
///
/// # Returns
/// * `Ok(HashSet<u16>)` - A set of all ports found in the file
/// * `Err(ThisProjectError)` - If critical errors occur (not validation failures)
///
/// # Example
/// let ports = make_exclusionlist_from_single_team_channel(
///     Path::new("/path/to/team_channel/node.toml"),
///     COLLABORATOR_ADDRESSBOOK_PATH_STR
/// )?;
/// println!("Found {} unique ports in use", ports.len());
/// node_toml_path
pub fn make_exclusionlist_from_single_team_channel(
    addressbook_readcopy_path_string: &str,
    node_readcopy_path: &Path,  // node_readcopy_path
) -> Result<HashSet<u16>, ThisProjectError> {
    // Initialize the port set
    let mut port_set: HashSet<u16> = HashSet::new();

    // Check if the file exists
    if !node_readcopy_path.exists() {
        debug_log!(
            "make_exclusionlist_from_single_team_channel: File does not exist: {}",
            node_readcopy_path.display()
        );
        // Return empty set for non-existent files
        return Ok(port_set);
    }

    // Extract channel name for logging
    let channel_name = node_readcopy_path
        .parent()
        .and_then(|p| p.file_name())
        .and_then(|n| n.to_str())
        .unwrap_or("unknown");

    debug_log!(
        "make_exclusionlist_from_single_team_channel: Processing channel '{}'",
        channel_name
    );

    // TODO ? instead use read_teamchannel_collaborator_ports_clearsigntoml_without_keyid()

    /*
    addressbook_readcopy_path_string: &str,
    path_to_clearsigned_toml: &str,

    */
    // Read and validate the clearsigned configuration
    // match read_all_collaborator_port_assignments_clearsigntoml_optimized(
    match read_abstract_collaborator_portassignments_from_clearsigntoml_withoutkeyid(
        &addressbook_readcopy_path_string, // addressbook_readcopy_path_string
        &node_readcopy_path.display().to_string(), // path_to_clearsigned_toml
    ) {
        Ok(port_assignments) => {
            debug_log!(
                "make_exclusionlist_from_single_team_channel: Successfully validated channel '{}'",
                channel_name
            );

            // Extract all ports from all collaborator pairs
            for (pair_name, assignments) in port_assignments {
                debug_log!(
                    "make_exclusionlist_from_single_team_channel: Processing pair '{}'",
                    pair_name
                );

                // Process each collaborator in the pair
                for assignment in assignments {
                    // Add all three port types to the set
                    port_set.insert(assignment.ready_port);
                    port_set.insert(assignment.intray_port);
                    port_set.insert(assignment.gotit_port);

                    debug_log!(
                        "make_exclusionlist_from_single_team_channel: Added ports for user '{}': \
                         ready={}, intray={}, gotit={}",
                        assignment.user_name,
                        assignment.ready_port,
                        assignment.intray_port,
                        assignment.gotit_port
                    );
                }
            }

            debug_log!(
                "make_exclusionlist_from_single_team_channel: Channel '{}' total unique ports: {}",
                channel_name,
                port_set.len()
            );
        }
        Err(e) => {
            // Log the validation failure but don't propagate the error
            // Return empty set for files that fail validation
            eprintln!(
                "WARNING: Skipping channel '{}' due to validation failure: {}",
                channel_name,
                e.to_string()
            );
            debug_log!(
                "make_exclusionlist_from_single_team_channel: Validation failed for channel '{}': {}",
                channel_name,
                e.to_string()
            );
        }
    }

    Ok(port_set)
}

// alt
/// Searches for a node configuration file in the given directory.
///
/// This function looks for either `node.toml` or `node.gpgtoml` in the specified directory.
/// It checks for `node.toml` first, and if not found, checks for `node.gpgtoml`.
///
/// # Arguments
///
/// * `input_node_parent_path` - The directory path where to search for the node configuration files
///
/// # Returns
///
/// * `Some(PathBuf)` - The full path to the found configuration file (either node.toml or node.gpgtoml)
/// * `None` - Neither configuration file was found in the directory
///
/// # Example
///
/// ```
/// let parent_path = Path::new("/home/user/project");
/// if let Some(config_path) = find_node_toml_or_gpgtoml_file(parent_path) {
///     println!("Found configuration at: {:?}", config_path);
/// } else {
///     println!("No configuration file found");
/// }
/// ```
fn alt_find_node_toml_or_gpgtoml_file(input_node_parent_path: &Path) -> Option<PathBuf> {
    // First, try to find node.toml in the parent directory
    let node_toml = input_node_parent_path.join("node.toml");

    // Check if node.toml exists and is a regular file (not a directory)
    if node_toml.exists() && node_toml.is_file() {
        // Return the path to node.toml if found
        return Some(node_toml);
    }

    // If node.toml wasn't found, try to find node.gpgtoml
    let node_gpgtoml = input_node_parent_path.join("node.gpgtoml");

    // Check if node.gpgtoml exists and is a regular file (not a directory)
    if node_gpgtoml.exists() && node_gpgtoml.is_file() {
        // Return the path to node.gpgtoml if found
        return Some(node_gpgtoml);
    }

    // Neither file was found in the directory
    None
}
// // Usage example for your specific case:
// let current_full_file_path = PathBuf::from("/your/actual/path");

// // Call the function to find either node.toml or node.gpgtoml
// let node_toml_path = match find_node_toml_or_gpgtoml_file(&current_full_file_path) {
//     Some(path) => {
//         // Successfully found one of the configuration files
//         debug_log!(
//             "nav_graph_look_read_node_toml() node_toml_path -> {:?}",
//             path.clone()
//         );

//         // Add more detailed existence checking
//         debug_log!("Checking if path exists: {:?}", path.exists());
//         debug_log!("Checking if path is file: {:?}", path.is_file());

//         // Return the found path
//         path
//     },
//     None => {
//         // Neither node.toml nor node.gpgtoml was found
//         debug_log!(
//             "nav_graph_look_read_node_toml() no configuration file found in: {:?}",
//             current_full_file_path
//         );

//         // Handle the error case - you need to decide what to do here
//         // Option 1: Return an error from your function
//         return Err("No node configuration file found".to_string());

//         // Option 2: Use a default or panic (not recommended)
//         // panic!("No node configuration file found");
//     }
// };

// // At this point, node_toml_path contains the PathBuf to whichever file was found

/// Searches for a node configuration file in the given directory.
///
/// This function looks for either `node.toml` or `node.gpgtoml` in the specified directory.
/// It checks for `node.toml` first, and if not found, checks for `node.gpgtoml`.
///
/// # Arguments
///
/// * `input_node_parent_path` - The directory path where to search for the node configuration files
///
/// # Returns
///
/// * `Ok(Some(PathBuf))` - The full path to the found configuration file (either node.toml or node.gpgtoml)
/// * `Ok(None)` - Neither configuration file was found in the directory
/// * `Err(String)` - An error occurred while checking the files
///
/// # Example
///
/// ```
/// let parent_path = Path::new("/home/user/project");
/// match find_node_toml_or_gpgtoml_file(parent_path) {
///     Ok(Some(path)) => println!("Found configuration at: {:?}", path),
///     Ok(None) => println!("No configuration file found"),
///     Err(e) => eprintln!("Error: {}", e),
/// }
/// ```
fn find_node_toml_or_gpgtoml_file(input_node_parent_path: &Path) -> Result<Option<PathBuf>, String> {
    // Validate that the input path exists and is a directory
    if !input_node_parent_path.exists() {
        return Err(format!(
            "Parent directory does not exist: {:?}",
            input_node_parent_path
        ));
    }

    if !input_node_parent_path.is_dir() {
        return Err(format!(
            "Path is not a directory: {:?}",
            input_node_parent_path
        ));
    }

    // First check for node.toml
    let node_toml_path = input_node_parent_path.join("node.toml");

    debug_log!(
        "find_node_toml_or_gpgtoml_file() checking for node.toml at: {:?}",
        node_toml_path
    );

    // Check if node.toml exists and is a file
    if node_toml_path.exists() && node_toml_path.is_file() {
        debug_log!(
            "find_node_toml_or_gpgtoml_file() found node.toml at: {:?}",
            node_toml_path
        );
        return Ok(Some(node_toml_path));
    }

    // If node.toml not found, check for node.gpgtoml
    let node_gpgtoml_path = input_node_parent_path.join("node.gpgtoml");

    debug_log!(
        "find_node_toml_or_gpgtoml_file() checking for node.gpgtoml at: {:?}",
        node_gpgtoml_path
    );

    // Check if node.gpgtoml exists and is a file
    if node_gpgtoml_path.exists() && node_gpgtoml_path.is_file() {
        debug_log!(
            "find_node_toml_or_gpgtoml_file() found node.gpgtoml at: {:?}",
            node_gpgtoml_path
        );
        return Ok(Some(node_gpgtoml_path));
    }

    // Neither file was found
    debug_log!(
        "find_node_toml_or_gpgtoml_file() no configuration file found in: {:?}",
        input_node_parent_path
    );

    Ok(None)
}
// // use example
// let current_full_file_path = PathBuf::from("/home/user/project/nodes/example");

// // Find the configuration file (could be either node.toml OR node.gpgtoml)
// let node_toml_path = match find_node_toml_or_gpgtoml_file(&current_full_file_path) {
//     Ok(Some(path)) => {
//         // This is the path to whichever file was found (node.toml OR node.gpgtoml)
//         debug_log!("Found configuration file at: {:?}", path);
//         path  // <-- This could be either file!
//     },
//     Ok(None) => {
//         // No file found - handle the error properly
//         return Err("Neither node.toml nor node.gpgtoml found".to_string());
//     },
//     Err(error_message) => {
//         // Error occurred - handle it properly
//         return Err(error_message);
//     }
// };

// // node_toml_path now contains the path to whichever file was found

/// Scans ALL team channels and returns a complete exclusion list of all ports in use.
///
/// # Purpose
/// This function provides a comprehensive view of all network ports currently allocated
/// across all team channels in the project. It's designed to prevent port collisions
/// when creating new team channels or adding collaborators by maintaining a global
/// registry of used ports.
///
/// # Process
/// 1. Locates the team channels directory
/// 2. Walks through all subdirectories looking for `node.toml` files
/// 3. For each valid team channel found:
///    - Validates the clearsigned configuration
///    - Extracts all port assignments
///    - Adds them to the global exclusion set
/// 4. Returns the complete set of all ports in use
///
/// # Security
/// - Only includes ports from properly clearsigned and validated configurations
/// - Skips any channels that fail validation (logs warnings but continues)
/// - Uses the standard collaborator addressbook for verification
///
/// # Error Handling
/// - Directory access errors are propagated as critical failures
/// - Individual file validation failures are logged but don't stop the scan
/// - Returns partial results if some channels can't be processed
///
/// # Performance
/// - Uses HashSet for O(1) lookup performance
/// - Processes files sequentially to avoid resource contention
/// - Caches nothing - always provides current state
///
/// # Returns
/// * `Ok(HashSet<u16>)` - Set of all ports currently in use across all channels
/// * `Err(ThisProjectError)` - If unable to access the team channels directory
///
/// # Example
///
/// match global_ports_exclusion_list_generator() {
///     Ok(exclusion_list) => {
///         println!("Total ports in use globally: {}", exclusion_list.len());
///         // Check if a specific port is available
///         if !exclusion_list.contains(&50001) {
///             println!("Port 50001 is available");
///         }
///     }
///     Err(e) => eprintln!("Failed to generate exclusion list: {}", e),
/// }
///
pub fn global_ports_exclusion_list_generator() -> Result<HashSet<u16>, ThisProjectError> {
    println!("=== Generating Global Port Exclusion List ===");

    // Initialize the global port set
    let mut global_port_set: HashSet<u16> = HashSet::new();

    // Set up the team channels directory
    let team_channels_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        "project_graph_data/team_channels"
    ) {
        Ok(directory_path) => {
            debug_log!(
                "global_ports_exclusion_list_generator: Team channels directory: {}",
                directory_path.display()
            );
            directory_path
        }
        Err(io_error) => {
            let error_msg = format!(
                "Failed to access team_channels directory: {}",
                io_error
            );
            eprintln!("ERROR: {}", error_msg);
            return Err(ThisProjectError::from(error_msg));
        }
    };

    // Set the collaborator files directory path
    let collaborator_files_dir_relative = COLLABORATOR_ADDRESSBOOK_PATH_STR;

    // Statistics tracking
    let mut channels_processed = 0;
    let mut channels_skipped = 0;
    let mut total_ports_found = 0;

    debug_log!("global_ports_exclusion_list_generator: Starting directory walk...");



    // code from load_core_node...()
    debug_log!(
        "Starting: load_core_node_from_toml_file(), team_channels_dir -> {:?}",
        &team_channels_dir,
    );

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(format!(
                "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            ).into());
        }
    };


    // Walk through all team channel directories
    for entry in WalkDir::new(&team_channels_dir)
        .into_iter()
        .filter_map(|e| e.ok())
        .filter(|e| e.file_type().is_dir())
    {
        // Skip the root directory itself
        if entry.path() == team_channels_dir {
            continue;
        }

        debug_log!("entry.path() {:?}", &entry.path().display());

        // Construct path to node.toml or node.gpgtoml
        // Find the configuration file (could be either node.toml OR node.gpgtoml)
        let node_toml_path = match find_node_toml_or_gpgtoml_file(&entry.path()) {
            Ok(Some(path)) => {
                // This is the path to whichever file was found (node.toml OR node.gpgtoml)
                debug_log!("Found configuration file at: {:?}", path);
                path  // <-- This could be either file!
            },
            Ok(None) => {
                // No file found - handle the error properly
                // return Err("Neither node.toml nor node.gpgtoml found".to_string());
                return Err(ThisProjectError::InvalidInput("Neither node.toml nor node.gpgtoml found".to_string()));
            },
            Err(error_message) => {
                // Error occurred - handle it properly
                // return Err(error_message);
                return Err(ThisProjectError::TomlVanillaDeserialStrError(error_message));
            }
        };

        // Add more detailed existence checking
        debug_log!("Checking if path exists: {:?}", node_toml_path.exists());
        debug_log!("Checking if path is file: {:?}", node_toml_path.is_file());

        // Skip directories without node.toml
        if !node_toml_path.exists() {
            continue;
        }

        //?
        // Extract channel name for logging
        let channel_name = entry.path()
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("unknown")
            .to_string();

        debug_log!(
            "global_ports_exclusion_list_generator: Processing channel '{}'",
            channel_name
        );




        // code from load_core_node...()
        // Get the UME temp directory path with proper GpgError conversion
        let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
            .map_err(|io_err| GpgError::ValidationError(
                format!("Failed to get UME temp directory path: {}", io_err)
            ))?;

        // Using Debug trait for more detailed error information
        let node_readcopy_path = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
            &node_toml_path,
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ).map_err(|e| format!("Failed to get temporary read copy of TOML file: {:?}", e))?;

        ////////////////////////////////
        // Extract Owner for Key Lookup
        ////////////////////////////////
        let owner_name_of_toml_field_key_to_read = "owner";
        debug_log!(
            "Reading file owner from field '{}' for security validation",
            owner_name_of_toml_field_key_to_read
        );

        let file_owner_username = match read_single_line_string_field_from_toml(
            &node_readcopy_path,  // TODO convert to string?
            owner_name_of_toml_field_key_to_read,
        ) {
            Ok(username) => {
                if username.is_empty() {
                    // Convert to String error instead of GpgError
                    return Err(format!(
                        "Field '{}' is empty in TOML file. File owner is required for security validation.",
                        owner_name_of_toml_field_key_to_read
                    ).into());
                }
                username
            }
            Err(e) => {
                // Convert to String error instead of GpgError
                return Err(format!(
                    "Failed to read file owner from field '{}': {}",
                    owner_name_of_toml_field_key_to_read, e
                // ));
                ).into());
            }
        };
        println!("File owner: '{}'", file_owner_username);

        // Get the UME temp directory path with proper GpgError conversion
        let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
            .map_err(|io_err| GpgError::ValidationError(
                format!("Failed to get UME temp directory path: {}", io_err)
            ))?;

        // Extract the addressbook path string with inline error conversion
        let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
            &file_owner_username,
            COLLABORATOR_ADDRESSBOOK_PATH_STR,
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ).map_err(|e| format!(
            "Failed to get addressbook path for user '{}': {:?}",
            file_owner_username,
            e
        ))?;

        // Define cleanup closure
        let cleanup_closure = || {
            let _ = cleanup_collaborator_temp_file(
                &node_readcopy_path,
                &base_uma_temp_directory_path,
                );
            let _ = cleanup_collaborator_temp_file(
                &addressbook_readcopy_path_string,
                &base_uma_temp_directory_path,
                );
        };

        let node_owners_public_gpg_key = read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml(
            &addressbook_readcopy_path_string,
        ).map_err(|e| format!(
            "Failed to get addressbook path for user '{}': {:?}",
            file_owner_username,
            e
        ))?;

        // 2. Paths & Reading-Copies Part 2: addressbook path and read-copy
        // Verify the addressbook file's clearsign signature
        let verify_addressbook_file_result = match verify_clearsign(
            &addressbook_readcopy_path_string,
            &node_owners_public_gpg_key,
        ) {
            Ok(is_valid) => is_valid,
            Err(e) => {
                // Clean up temporary files before returning error
                cleanup_closure();
                return Err(format!(
                    "Failed to verify addressbook clearsign signature for user '{}': {:?}",
                    file_owner_username,
                    e
                ).into());
            }
        };

        // 3. Validate Part 1: validate addressbook file and get node-owner's public gpg
        // (This section would go here if needed)

        // 4. Validation Part 2: validate Node (clearsign validation of .toml)
        // Verify the node file's clearsign signature
        let verify_node_file_result = match verify_clearsign(
            &node_readcopy_path,
            &node_owners_public_gpg_key,
        ) {
            Ok(is_valid) => is_valid,
            Err(e) => {
                // Clean up temporary files before returning error
                cleanup_closure();
                return Err(format!(
                    "Failed to verify node file clearsign signature for user '{}': {:?}",
                    file_owner_username,
                    e
                ).into());
            }
        };

        // Check if both verification results are valid
        // If either verification failed, clean up and return error
        if !verify_addressbook_file_result || !verify_node_file_result {

            debug_log("Whoops, something faileded...");

            // Clean up temporary files
            cleanup_closure();

            // Provide detailed error message about which verification failed
            let mut error_details = Vec::new();
            if !verify_addressbook_file_result {
                error_details.push("addressbook file signature verification failed");
            }
            if !verify_node_file_result {
                error_details.push("node file signature verification failed");
            }

            return Err(format!(
                "Clearsign validation failed for user '{}': {}",
                file_owner_username,
                error_details.join(" and ")
            ).into());
        }

		// make type path
        let node_readcopy_pathtype = Path::new(&node_readcopy_path);

        // Process this channel's ports
        match make_exclusionlist_from_single_team_channel(
            &addressbook_readcopy_path_string,
            &node_readcopy_pathtype,
        ) {
            Ok(channel_ports) => {
                let port_count = channel_ports.len();
                if port_count > 0 {
                    channels_processed += 1;
                    total_ports_found += port_count;

                    // Merge this channel's ports into the global set
                    global_port_set.extend(channel_ports);

                    debug_log!(
                        "global_ports_exclusion_list_generator: Channel '{}' contributed {} ports",
                        channel_name,
                        port_count
                    );
                } else {
                    channels_skipped += 1;
                    debug_log!(
                        "global_ports_exclusion_list_generator: Channel '{}' had no valid ports",
                        channel_name
                    );
                }
            }
            Err(e) => {
                // This shouldn't happen as make_exclusionlist_from_single_team_channel
                // handles errors gracefully, but log it just in case
                channels_skipped += 1;
                eprintln!(
                    "WARNING: Unexpected error processing channel '{}': {}",
                    channel_name,
                    e.to_string()
                );
                debug_log!(
                    "global_ports_exclusion_list_generator: Error processing channel '{}': {}",
                    channel_name,
                    e.to_string()
                );
            }
        }
    }

    // Print summary
    println!("\n=== Exclusion List Generation Summary ===");
    println!("Channels successfully processed: {}", channels_processed);
    println!("Channels skipped (validation failed or empty): {}", channels_skipped);
    println!("Total ports found: {}", total_ports_found);
    println!("Unique ports in exclusion list: {}", global_port_set.len());

    debug_log!(
        "global_ports_exclusion_list_generator: Complete. {} unique ports in exclusion list",
        global_port_set.len()
    );

    Ok(global_port_set)
}

/// WARNING: 'validation' needs to be defined TODO
/// Interactively collects and validates collaborator names from user input.
///
/// # Purpose
/// This function provides an interactive interface for users to specify which
/// collaborators should have access to a new team channel. It ensures all
/// specified collaborators exist in the address book before proceeding.
///
/// # Process
/// 1. Prompts user for comma-separated collaborator names
/// 2. Validates each name exists as a collaborator file
/// 3. Re-prompts if any names are invalid
/// 4. Returns a sorted, deduplicated list of valid collaborators
///
/// # Parameters
/// * `owner` - The owner's name to be included in the final list
///
/// # Returns
/// * `Ok(Vec<String>)` - Alphabetically sorted list of collaborators including owner
/// * `Err(ThisProjectError)` - If critical errors occur
///
/// # Example Interaction
///
/// Enter the user-names of collaborators you wish to invite separated by commas:
/// > bob, charlotte, alice, bob
///
///  Found collaborator: alice
///  Found collaborator: bob
///  Found collaborator: charlotte
///
/// Final collaborator list: ["alice", "bob", "charlotte", "owner"]
///
pub fn collect_and_validate_collaborators(
    owner: &str,
) -> Result<Vec<String>, ThisProjectError> {
    println!("\n=== Collaborator Setup ===");

    // Get the collaborator files directory
    let collaborator_files_dir = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        COLLABORATOR_ADDRESSBOOK_PATH_STR
    ) {
        Ok(directory_path) => {
            debug_log!(
                "collect_and_validate_collaborators: Collaborator directory: {}",
                directory_path.display()
            );
            directory_path
        }
        Err(io_error) => {
            let error_msg = format!(
                "Failed to access collaborator files directory: {}",
                io_error
            );
            eprintln!("ERROR: {}", error_msg);
            return Err(ThisProjectError::from(error_msg));
        }
    };

    loop {
        // Prompt for input
        print!("Enter the user-names of collaborators you wish to invite separated by commas: ");
        io::stdout().flush().map_err(|e| {
            ThisProjectError::from(format!("Failed to flush stdout: {}", e))
        })?;

        // Read user input
        let mut input = String::new();
        io::stdin().read_line(&mut input).map_err(|e| {
            ThisProjectError::from(format!("Failed to read user input: {}", e))
        })?;

        // Parse input into individual names
        let mut collaborator_set: HashSet<String> = input
            .split(',')
            .map(|s| s.trim().to_lowercase())
            .filter(|s| !s.is_empty())
            .collect();

        // Always include the owner
        collaborator_set.insert(owner.to_lowercase());

        // Validate each collaborator
        let mut invalid_names = Vec::new();
        let mut valid_names = Vec::new();

        println!("\nValidating collaborators...");

        for name in &collaborator_set {
            // Skip checking the owner (we trust they exist)
            if name == owner {
                valid_names.push(name.clone());
                continue;
            }

            // // Construct the collaborator file path
            // let collaborator_file = format!("{}__collaborator.toml", name);
            // let file_path = collaborator_files_dir.join(&collaborator_file);

            // // Check if the file exists
            // if file_path.exists() {
            //     println!("   Found collaborator: {}", name);
            //     valid_names.push(name.clone());
            //     debug_log!(
            //         "collect_and_validate_collaborators: Validated collaborator '{}' at {}",
            //         name,
            //         file_path.display()
            //     );
            // } else {
            //     println!("   NOT FOUND: {}", name);
            //     invalid_names.push(name.clone());
            //     debug_log!(
            //         "collect_and_validate_collaborators: Collaborator '{}' not found at {}",
            //         name,
            //         file_path.display()
            //     );
            // }

            // Construct the collaborator file paths for both possible extensions
            let collaborator_gpgtoml = format!("{}__collaborator.gpgtoml", name);
            let collaborator_toml = format!("{}__collaborator.toml", name);

            let gpgtoml_path = collaborator_files_dir.join(&collaborator_gpgtoml);
            let toml_path = collaborator_files_dir.join(&collaborator_toml);

            // Check if either file exists (prefer .gpgtoml for security)
            let file_exists = if gpgtoml_path.exists() {
                debug_log!(
                    "collect_and_validate_collaborators: Found GPG encrypted collaborator file for '{}' at {}",
                    name,
                    gpgtoml_path.display()
                );
                true
            } else if toml_path.exists() {
                debug_log!(
                    "collect_and_validate_collaborators: Found clearsigned collaborator file for '{}' at {}",
                    name,
                    toml_path.display()
                );
                true
            } else {
                false
            };

            // Check if the file exists
            if file_exists {
                println!("   Found collaborator: {}", name);
                valid_names.push(name.clone());
            } else {
                println!("   NOT FOUND: {}", name);
                invalid_names.push(name.clone());
                debug_log!(
                    "collect_and_validate_collaborators: Collaborator '{}' not found (checked both .gpgtoml and .toml)",
                    name
                );
            }


        }

        // Check if all names are valid
        if invalid_names.is_empty() {
            // Sort alphabetically and return
            valid_names.sort();
            println!("\nFinal collaborator list: {:?}", valid_names);
            return Ok(valid_names);
        } else {
            // Show error and re-prompt
            eprintln!("\n The following collaborators were not found in the address book:");
            for name in &invalid_names {
                eprintln!("   - {}", name);
            }
            println!("\nPlease try again with valid collaborator names.\n");
        }
    }
}

fn remove_dir_contents_if_exists<P: AsRef<Path>>(path: P) -> std::io::Result<()> {
    let path = path.as_ref();
    if path.exists() {
        for entry in fs::read_dir(path)? {
            let entry = entry?;
            let path = entry.path();
            if path.is_dir() {
                fs::remove_dir_all(path)?;
            } else {
                fs::remove_file(path)?;
            }
        }
    }
    Ok(())
}

/// Generates a unique port not in the exclusion list.
///
/// # Parameters
/// * `rng` - Random number generator
/// * `exclusion_list` - Set of ports already in use
/// * `local_used_ports` - Set of ports used locally in this generation session
/// * `primary_range` - Primary port range to try first (start, end)
/// * `fallback_range` - Fallback range if primary is exhausted (start, end)
///
/// # Returns
/// * `Ok(u16)` - A unique port number
/// * `Err(ThisProjectError)` - If no available ports found
fn generate_unique_port(
    rng: &mut impl Rng,
    exclusion_list: &HashSet<u16>,
    local_used_ports: &HashSet<u16>,
    primary_range: (u16, u16),
    fallback_range: (u16, u16),
) -> Result<u16, ThisProjectError> {
    // Try primary range first
    let mut attempts = 0;
    const MAX_ATTEMPTS: u32 = 1000;

    while attempts < MAX_ATTEMPTS {
        let port = rng.random_range(primary_range.0..=primary_range.1);
        if !exclusion_list.contains(&port) && !local_used_ports.contains(&port) {
            return Ok(port);
        }
        attempts += 1;
    }

    // Try fallback range
    attempts = 0;
    while attempts < MAX_ATTEMPTS {
        let port = rng.random_range(fallback_range.0..=fallback_range.1);
        if !exclusion_list.contains(&port) && !local_used_ports.contains(&port) {
            debug_log!(
                "generate_unique_port: Using fallback range for port {}",
                port
            );
            return Ok(port);
        }
        attempts += 1;
    }

    Err(ThisProjectError::from(
        "Unable to find available port after maximum attempts"
    ))
}

// /// Generates pairwise port assignments for all collaborators.
// ///
// /// # Purpose
// /// Creates unique port assignments for every pair of collaborators in a team channel.
// /// Each pair gets 6 unique ports (3 for each collaborator) that don't conflict with
// /// any existing ports in the system.
// ///
// /// # Parameters
// /// * `collaborators` - Sorted list of all collaborators (including owner)
// /// * `exclusion_list` - Set of all ports currently in use globally
// ///
// /// # Returns
// /// * `Ok(HashMap)` - Map of pair names to port assignments
// /// * `Err(ThisProjectError)` - If unable to generate unique ports
// ///
// /// # Port Ranges
// /// * Primary: 49152-65535 (IANA Dynamic/Private ports)
// /// * Fallback: 32768-65535 (Traditional ephemeral range)
// pub fn generate_pairwise_port_assignments(
//     collaborators: &[String],
//     exclusion_list: &HashSet<u16>,
// ) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, ThisProjectError> {
//     println!("\n=== Generating Pairwise Port Assignments ===");

//     let mut port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();
//     let mut local_used_ports: HashSet<u16> = HashSet::new();
//     let mut rng = rand::rng();

//     // Define port ranges
//     const PRIMARY_RANGE: (u16, u16) = (49152, 65535);
//     const FALLBACK_RANGE: (u16, u16) = (32768, 65535);

//     // Calculate total number of pairs
//     let n = collaborators.len();
//     let total_pairs = n * (n - 1) / 2;
//     println!("Generating {} collaboration pairs for {} collaborators", total_pairs, n);

//     // Generate pairs
//     for i in 0..n {
//         for j in (i + 1)..n {
//             let collaborator1 = &collaborators[i];
//             let collaborator2 = &collaborators[j];
//             let pair_name = format!("{}_{}", collaborator1, collaborator2);

//             println!("\nGenerating ports for pair: {}", pair_name);

//             // Generate ports for first collaborator
//             let ready_port1 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(ready_port1);

//             let intray_port1 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(intray_port1);

//             let gotit_port1 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(gotit_port1);

//             // Generate ports for second collaborator
//             let ready_port2 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(ready_port2);

//             let intray_port2 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(intray_port2);

//             let gotit_port2 = generate_unique_port(
//                 &mut rng,
//                 exclusion_list,
//                 &local_used_ports,
//                 PRIMARY_RANGE,
//                 FALLBACK_RANGE,
//             )?;
//             local_used_ports.insert(gotit_port2);

//             // Create port assignment structures
//             let ports_data1 = AbstractTeamchannelNodeTomlPortsData {
//                 user_name: collaborator1.clone(),
//                 ready_port: ready_port1,
//                 intray_port: intray_port1,
//                 gotit_port: gotit_port1,
//             };

//             let ports_data2 = AbstractTeamchannelNodeTomlPortsData {
//                 user_name: collaborator2.clone(),
//                 ready_port: ready_port2,
//                 intray_port: intray_port2,
//                 gotit_port: gotit_port2,
//             };

//             // Store in the HashMap
//             port_assignments.insert(
//                 pair_name.clone(),
//                 vec![ReadTeamchannelCollaboratorPortsToml {
//                     collaborator_ports: vec![ports_data1, ports_data2],
//                 }],
//             );

//             println!("  {} ports: ready={}, intray={}, gotit={}",
//                 collaborator1, ready_port1, intray_port1, gotit_port1);
//             println!("  {} ports: ready={}, intray={}, gotit={}",
//                 collaborator2, ready_port2, intray_port2, gotit_port2);

//             debug_log!(
//                 "generate_pairwise_port_assignments: Pair '{}' assigned 6 ports",
//                 pair_name
//             );
//         }
//     }

//     // Final verification - ensure no local collisions
//     if local_used_ports.len() != (total_pairs * 6) as usize {
//         let error_msg = format!(
//             "CRITICAL: Local port collision detected! Expected {} unique ports but got {}",
//             total_pairs * 6,
//             local_used_ports.len()
//         );
//         eprintln!("{}", error_msg);
//         return Err(ThisProjectError::from(error_msg));
//     }

//     println!("\n Successfully generated {} unique ports across {} pairs",
//         local_used_ports.len(), total_pairs);

//     Ok(port_assignments)
// }

/// Generates pairwise port assignments for all collaborators.
///
/// # Purpose
/// Creates unique port assignments for every pair of collaborators in a team channel.
/// Each pair gets 6 unique ports (3 for each collaborator) that don't conflict with
/// any existing ports in the system.
///
/// # Parameters
/// * `collaborators` - Sorted list of all collaborators (including owner)
/// * `exclusion_list` - Set of all ports currently in use globally
///
/// # Returns
/// * `Ok(HashMap)` - Map of pair names to port assignments
/// * `Err(ThisProjectError)` - If unable to generate unique ports
///
/// # Port Ranges
/// * Primary: 49152-65535 (IANA Dynamic/Private ports)
/// * Fallback: 32768-65535 (Traditional ephemeral range)
pub fn generate_pairwise_port_assignments(
    collaborators: &[String],
    exclusion_list: &HashSet<u16>,
) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, ThisProjectError> {

    debug_log("GPPA Staring generate_pairwise_port_assignments");

    println!("\n=== Generating Pairwise Port Assignments ===");

    let mut port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();
    let mut local_used_ports: HashSet<u16> = HashSet::new();
    let mut rng = rand::rng();

    // Define port ranges
    const PRIMARY_RANGE: (u16, u16) = (49152, 65535);
    const FALLBACK_RANGE: (u16, u16) = (32768, 65535);

    // Calculate total number of pairs
    let n = collaborators.len();
    let total_pairs = n * (n - 1) / 2;
    println!("Generating {} collaboration pairs for {} collaborators", total_pairs, n);

    // Generate pairs
    for i in 0..n {
        for j in (i + 1)..n {
            let collaborator1 = &collaborators[i];
            let collaborator2 = &collaborators[j];
            let pair_name = format!("{}_{}", collaborator1, collaborator2);

            println!("\nGenerating ports for pair: {}", pair_name);

            // Generate ports for first collaborator
            let ready_port1 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(ready_port1);

            let intray_port1 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(intray_port1);

            let gotit_port1 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(gotit_port1);

            // Generate ports for second collaborator
            let ready_port2 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(ready_port2);

            let intray_port2 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(intray_port2);

            let gotit_port2 = generate_unique_port(
                &mut rng,
                exclusion_list,
                &local_used_ports,
                PRIMARY_RANGE,
                FALLBACK_RANGE,
            )?;
            local_used_ports.insert(gotit_port2);

            // Create port assignment structures
            let ports_data1 = AbstractTeamchannelNodeTomlPortsData {
                user_name: collaborator1.clone(),
                ready_port: ready_port1,
                intray_port: intray_port1,
                gotit_port: gotit_port1,
            };

            let ports_data2 = AbstractTeamchannelNodeTomlPortsData {
                user_name: collaborator2.clone(),
                ready_port: ready_port2,
                intray_port: intray_port2,
                gotit_port: gotit_port2,
            };

            // Store in the HashMap with Vec wrapper (required by CoreNode)
            port_assignments.insert(
                pair_name.clone(),
                vec![ReadTeamchannelCollaboratorPortsToml {
                    collaborator_ports: vec![ports_data1, ports_data2],
                }],
            );

            println!("  {} ports: ready={}, intray={}, gotit={}",
                collaborator1, ready_port1, intray_port1, gotit_port1);
            println!("  {} ports: ready={}, intray={}, gotit={}",
                collaborator2, ready_port2, intray_port2, gotit_port2);

            debug_log!(
                "GPPA: Pair '{}' assigned 6 ports",
                pair_name
            );
        }
    }

    // Final verification - ensure no local collisions
    if local_used_ports.len() != (total_pairs * 6) as usize {
        let error_msg = format!(
            "GPPA error CRITICAL: Local port collision detected! Expected {} unique ports but got {}",
            total_pairs * 6,
            local_used_ports.len()
        );
        eprintln!("{}", error_msg);
        return Err(ThisProjectError::from(error_msg));
    }

    println!("\n Successfully generated {} unique ports across {} pairs",
        local_used_ports.len(), total_pairs);

    Ok(port_assignments)
}

/// Main function to create team channel port assignments with global collision prevention.
///
/// # Purpose
/// Orchestrates the complete process of creating port assignments for a new team channel:
/// 1. Generates global exclusion list
/// 2. Collects and validates collaborators
/// 3. Generates pairwise port assignments
/// 4. Handles collision scenarios
///
/// # Parameters
/// * `owner` - The owner creating the team channel
///
/// # Returns
/// * `Ok((collaborators, port_assignments))` - The validated collaborators and their port assignments
/// * `Err(ThisProjectError)` - If the process fails
pub fn create_teamchannel_port_assignments(
    owner: &str,
) -> Result<(Vec<String>, HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>), ThisProjectError> {
    println!("\n=== Creating Team Channel Port Assignments ===");
    println!("Owner: {}", owner);

    // Step 1: Generate global exclusion list
    println!("\nStep 1: Checking existing port assignments...");
    let exclusion_list = match global_ports_exclusion_list_generator() {
        Ok(ports) => {
            println!("Found {} ports already in use globally", ports.len());
            ports
        }
        Err(e) => {
            eprintln!("WARNING: Could not generate global exclusion list: {}", e);
            eprintln!("Proceeding with empty exclusion list (may cause collisions)");
            HashSet::new()
        }
    };

    // Step 2: Collect and validate collaborators
    println!("\nStep 2: Setting up collaborators...");
    let collaborators = collect_and_validate_collaborators(owner)?;

    // Step 3: Generate pairwise port assignments
    println!("\nStep 3: Generating port assignments...");
    let port_assignments = match generate_pairwise_port_assignments(&collaborators, &exclusion_list) {
        Ok(assignments) => assignments,
        Err(e) => {
            eprintln!("\n Failed to generate globally unique ports: {}", e);

            // Offer fallback option
            println!("\nWould you like to proceed with locally unique ports?");
            println!("(These may conflict with other team channels)");
            print!("Continue? [y/N]: ");
            io::stdout().flush().map_err(|e| {
                ThisProjectError::from(format!("Failed to flush stdout: {}", e))
            })?;

            let mut input = String::new();
            io::stdin().read_line(&mut input).map_err(|e| {
                ThisProjectError::from(format!("Failed to read user input: {}", e))
            })?;

            if input.trim().to_lowercase() == "y" {
                // Try again with empty exclusion list
                println!("\nGenerating locally unique ports...");
                generate_pairwise_port_assignments(&collaborators, &HashSet::new())?
            } else {
                return Err(ThisProjectError::from("Port assignment cancelled by user"));
            }
        }
    };

    println!("\n Team channel port assignments created successfully!");

    Ok((collaborators, port_assignments))
}


/// Checks if a specific port is currently in use on the system.
///
/// # Purpose
/// This function attempts to bind to a port to determine if it's already in use.
/// It's used during port collision detection to identify which conflicts are
/// most critical (ports already bound vs. just configuration conflicts).
///
/// # Arguments
/// * `port` - The port number to check
///
/// # Returns
/// * `true` - If the port is in use (binding fails)
/// * `false` - If the port is available (binding succeeds)
///
/// # Implementation Note
/// The function attempts to bind to both IPv4 and IPv6 addresses to ensure
/// comprehensive checking across different network configurations.
fn is_port_in_use(port: u16) -> bool {
    use std::net::{TcpListener, SocketAddr, IpAddr, Ipv4Addr, Ipv6Addr};

    // Check IPv4
    let ipv4_addr = SocketAddr::new(IpAddr::V4(Ipv4Addr::LOCALHOST), port);
    let ipv4_in_use = TcpListener::bind(ipv4_addr).is_err();

    // Check IPv6
    let ipv6_addr = SocketAddr::new(IpAddr::V6(Ipv6Addr::LOCALHOST), port);
    let ipv6_in_use = TcpListener::bind(ipv6_addr).is_err();

    // Port is in use if either binding fails
    ipv4_in_use || ipv6_in_use
}

/// Checks if UMA should NOT perform a hard restart.
///
/// Check for a Restart
/// The logic here is easy to get backwards:
/// There are two flags that are checked
/// regarding shut-down.
/// There is the normal ~should_continue flag,
/// which is checked with a should_halt_uma checker.
/// To keep things symetric, there is a parallel
/// system for hard-reboot, working the same way
/// with one exception:
/// If you should restart this also re-reset the 'quit'
/// function (so you are not in an infinite loop of quit-restart).
/// if you check should_not_hard_restart() (this function)
/// and find that you should (quite) not-restart, it works the same way.
/// This function reads the hard restart flag file to determine if UMA should perform a hard restart.
/// The logic works as follows:
///
/// - If file contains "0": Return true (meaning: do NOT restart, normal shutdown)
/// - If file contains "1": Return false (meaning: yes DO restart)
/// - On file read errors: Return false (safer to restart than get stuck)
///
/// When a restart is indicated (function returns false), it also resets the
/// continue_uma flag to "1" to prevent an infinite loop of quit-restart.
///
/// # Returns
///
/// * `bool` - true if UMA should NOT restart (normal shutdown), false if it SHOULD restart
pub fn should_not_hard_restart() -> bool {
    // Get the absolute path to the hard restart flag file
    let file_path = match get_hard_restart_flag_path() {
        Ok(path) => path,
        Err(e) => {
            debug_log!("Error resolving path to hard restart flag: {}", e);
            return false; // Default to restarting if we can't resolve the path
        }
    };

    // Read the file content
    let file_content = match fs::read_to_string(&file_path) {
        Ok(content) => content.trim().to_string(),
        Err(e) => {
            debug_log!("Error reading hard restart flag file: {}", e);
            return false; // Default to restarting if we can't read the file
        }
    };

    // Process the flag value
    let should_not_restart = file_content == "0";

    if should_not_restart {
        debug_log!("Hard restart flag is '0': Normal shutdown (no restart)");
        return true; // Do NOT restart (normal shutdown)
    } else {
        debug_log!("Hard restart flag is '1': Will restart UMA");

        // Reset the continue_uma flag to avoid quit-restart loop
        match initialize_continue_uma_signal() {
            Ok(_) => debug_log!("Reset continue_uma flag to '1' for restart"),
            Err(e) => debug_log!("Warning: Failed to reset continue_uma flag: {}", e)
        }

        return false; // DO restart
    }
}

// TODO not used? use with dubug_assert flag?
/// Prints the status of all control flags for debugging purposes.
///
/// This function reads and displays the values and locations of all flag files
/// used by UMA. This can be helpful for troubleshooting boot and shutdown issues.
pub fn debug_print_flag_status() {
    debug_log!("===== UMA FLAG STATUS =====");

    // Check continue_uma flag
    match get_continue_uma_path() {
        Ok(path) => {
            debug_log!("Continue UMA flag path: {:?}", path);
            match fs::read_to_string(&path) {
                Ok(content) => debug_log!("Continue UMA flag value: '{}'", content.trim()),
                Err(e) => debug_log!("Error reading Continue UMA flag: {}", e)
            }
        },
        Err(e) => debug_log!("Error resolving Continue UMA flag path: {}", e)
    }

    // Check hard restart flag
    match get_hard_restart_flag_path() {
        Ok(path) => {
            debug_log!("Hard restart flag path: {:?}", path);
            match fs::read_to_string(&path) {
                Ok(content) => debug_log!("Hard restart flag value: '{}'", content.trim()),
                Err(e) => debug_log!("Error reading hard restart flag: {}", e)
            }
        },
        Err(e) => debug_log!("Error resolving hard restart flag path: {}", e)
    }

    // Check sync start OK flag
    match get_sync_start_ok_flag_path() {
        Ok(path) => {
            debug_log!("Sync start OK flag path: {:?}", path);
            match fs::read_to_string(&path) {
                Ok(content) => debug_log!("Sync start OK flag value: '{}'", content.trim()),
                Err(e) => debug_log!("Error reading sync start OK flag: {}", e)
            }
        },
        Err(e) => debug_log!("Error resolving sync start OK flag path: {}", e)
    }

    debug_log!("===== END FLAG STATUS =====");
}

// // old relative path version
// fn dir_at_path_is_empty_returns_false(path_to_dir: &Path) -> bool {

//     debug_log!("dir_at_path_is_empty_returns_false()-> Checking if directory is empty: {:?}", path_to_dir);
//     if let Ok(mut entries) = fs::read_dir(path_to_dir) {

//         entries.next().is_some() // Returns false if the directory is empty
//     } else {
//         true // Assume directory is NOT empty if an error occurs reading it
//     }
// }


// use std::fs;
// use std::path::Path;
// use crate::manage_absolute_executable_directory_relative_paths::make_input_path_name_abs_executabledirectoryrelative_nocheck;

/// Checks if a directory is empty and returns the appropriate boolean value.
///
/// This function attempts to check if the directory at the given path is empty.
/// It converts the provided path to an absolute path relative to the executable's
/// location before performing the check.
///
/// # Arguments
///
/// * `path_to_dir` - A reference to a Path that represents the directory to check.
///                   This can be either an absolute path or a path relative to the executable.
///
/// # Returns
///
/// * `bool` - Returns `false` if the directory exists and is empty.
///            Returns `true` if the directory is not empty OR if any error occurs
///            (e.g., the directory doesn't exist, permissions issues, etc.)
///
/// # Note
///
/// The function name indicates its inverse behavior: it returns `false` when
/// a directory is empty, and `true` otherwise. This pattern is maintained for
/// backward compatibility with existing code.
fn dir_at_path_is_empty_returns_false(path_to_dir: &Path) -> bool {
    debug_log!("dir_at_path_is_empty_returns_false()-> Checking if directory is empty: {:?}", path_to_dir);

    // Try to convert the path to an absolute path relative to the executable
    let abs_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(path_to_dir) {
        Ok(path) => path,
        Err(e) => {
            debug_log!("Error resolving absolute path: {}", e);
            return true; // Assume NOT empty (return true) if path conversion fails
        }
    };

    debug_log!("Checking absolute path: {:?}", abs_path);

    // Check if the path exists and is a directory
    if !abs_path.exists() {
        debug_log!("Path does not exist: {:?}", abs_path);
        return true; // Assume NOT empty (return true) if path doesn't exist
    }

    if !abs_path.is_dir() {
        debug_log!("Path exists but is not a directory: {:?}", abs_path);
        return true; // Assume NOT empty (return true) if path is not a directory
    }

    // Attempt to read the directory entries
    match fs::read_dir(&abs_path) {
        Ok(mut entries) => {
            // If there are any entries, the directory is not empty
            let has_entries = entries.next().is_some();

            if has_entries {
                debug_log!("Directory is NOT empty: {:?}", abs_path);
                true // Directory is NOT empty, return true
            } else {
                debug_log!("Directory is empty: {:?}", abs_path);
                false // Directory IS empty, return false
            }
        },
        Err(e) => {
            debug_log!("Error reading directory entries: {}", e);
            true // Assume NOT empty (return true) if an error occurs reading the directory
        }
    }
}

fn get_ipv4_addresses() -> Result<Option<Vec<Ipv4Addr>>, io::Error> {
    let mut addresses = Vec::new();
    loop {
        let mut input = String::new();
        io::stdin().read_line(&mut input)?;
        let input = input.trim();

        if input.to_lowercase() == "done" {
            break;
        } else if input.is_empty() {
            return Ok(None);
        }

        let addr: Ipv4Addr = input.parse()
                               .map_err(|_| io::Error::new(io::ErrorKind::InvalidInput, "Invalid IPv4 address"))?;
        addresses.push(addr);
    }
    Ok(Some(addresses))
}

fn get_ipv6_addresses() -> Result<Option<Vec<Ipv6Addr>>, io::Error> {
    let mut addresses = Vec::new();
    loop {
        let mut input = String::new();
        io::stdin().read_line(&mut input)?;
        let input = input.trim();

        if input.to_lowercase() == "done" {
            break;
        } else if input.is_empty() {
            return Ok(None);
        }

        let addr: Ipv6Addr = input.parse()
                               .map_err(|_| io::Error::new(io::ErrorKind::InvalidInput, "Invalid IPv6 address"))?;
        addresses.push(addr);
    }
    Ok(Some(addresses))
}

// pub fn sign_toml_file(file_path: &Path) -> Result<(), Error> {
//     let output = MainStdCommand::new("gpg")
//         .arg("--clearsign")
//         .arg(file_path)
//         .output()
//         .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to run GPG: {}", e)))?;

//     if output.status.success() {
//         fs::write(file_path, output.stdout)?; // Overwrite with the signed content
//         debug_log!("File {} successfully signed with GPG.", file_path.display());
//         Ok(())
//     } else {
//         debug_log!("GPG signing failed: {}", String::from_utf8_lossy(&output.stderr));
//         Err(Error::new(ErrorKind::Other, "GPG signing failed"))
//     }
// }

pub fn verify_toml_signature(file_path: &Path) -> Result<(), Error> {
    let output = StdCommand::new("gpg")
        .arg("--verify")
        .arg(file_path)
        .output()
        .map_err(|e| Error::new(ErrorKind::Other, format!("Failed to run GPG: {}", e)))?;

    if output.status.success() {
        debug_log!("GPG signature of {} is valid.", file_path.display());
        Ok(())
    } else {
        debug_log!("GPG verification failed: {}", String::from_utf8_lossy(&output.stderr));
        Err(Error::new(ErrorKind::Other, "GPG signature invalid"))
    }
}

// //relative path version
// fn debug_log(message: &str) {
//     if DEBUG_FLAG {
//         let mut file = OpenOptions::new()
//             .append(true)
//             .create(true)
//             .open("uma.log")
//             .expect("Failed to open log file");

//         writeln!(file, "{}", message).expect("Failed to write to log file");
//     }
// }
/// Logs a debug message to a log file located relative to the executable directory.
///
/// This function only writes to the log file if the DEBUG_FLAG is set to true.
/// e.g. const DEBUG_FLAG: bool = true;
/// The log file (uma.log) will be created in the same directory as the executable
/// if it doesn't exist, or appended to if it already exists.
///
/// # Arguments
///
/// * `message` - The debug message to write to the log file
///
/// # Note
///
/// This function handles errors internally and does not propagate them
/// to the caller, to maintain backward compatibility with existing code.
fn debug_log(message: &str) {
    if DEBUG_FLAG {
        // Get the log file path relative to the executable
        let log_file_path_result = make_input_path_name_abs_executabledirectoryrelative_nocheck("uma.log");

        if let Err(path_error) = log_file_path_result {
            // Print error but don't panic
            eprintln!("Failed to determine log file path: {}", path_error);
            return;
        }

        let log_file_path = log_file_path_result.unwrap(); // Safe after check

        // Open the log file
        let file_result = std::fs::OpenOptions::new()
            .append(true)
            .create(true)
            .open(&log_file_path);

        if let Err(file_error) = file_result {
            eprintln!("Failed to open log file at {}: {}", log_file_path.display(), file_error);
            return;
        }

        let mut file = file_result.unwrap(); // Safe after check

        // Write to the log file
        if let Err(write_error) = writeln!(file, "{}", message) {
            eprintln!("Failed to write to log file: {}", write_error);
        }
    }
}

/* TODO
 * A. read-copy
 * B. clearsigned toml
 * C. gpg-option
 * ...is this for... nodes and adressbook or just messages? (maybe messages clerasigned too...)

this is for all files send-able...
maybe
1. check for clearsign
2. validate if clearsign
3. check for .gpgtoml
4. validate if .gpgtoml
5. extract time?
 */
/// TODO this must be replaced
/// read timestamps from .toml files, like you were born to do just that...on Mars!!
///
fn get_toml_file_updated_at_timestamp(file_path: &Path) -> Result<u64, ThisProjectError> {
    debug_log!(
        "Starting get_toml_file_updated_at_timestamp, file_path -> {:?}",
        file_path
    );

    let toml_string = std::fs::read_to_string(file_path)?;

    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = toml::from_str(&toml_string)?;

    let timestamp = toml_value
        .get("updated_at_timestamp") // Access the "updated_at_timestamp" field
        .and_then(Value::as_integer) // Try to convert to an integer
        .and_then(|ts| ts.try_into().ok()) // Try to convert to u64
        .ok_or_else(|| {
            ThisProjectError::InvalidData(format!(
                "Missing or invalid 'updated_at_timestamp' in TOML file: {}",
                file_path.display()
            ))
        })?;

    debug_log!(
        "[Done] get_toml_file_updated_at_timestamp, timestamp -> {:?}",
        timestamp
    );

    Ok(timestamp)
}

/// Macro for logging debug messages to a file located relative to the executable directory.
///
/// This macro formats the input like println! and only executes if DEBUG_FLAG is true.
/// The log file (uma.log) will be created in the same directory as the executable
/// if it doesn't exist, or appended to if it already exists.
///
/// # Examples
///
/// ```
/// debug_log!("Starting application");
/// debug_log!("Value: {}", some_variable);
/// ```
#[macro_export]
macro_rules! debug_log {
    ($($arg:tt)*) => {
        if DEBUG_FLAG {
            // Get the log file path relative to the executable
            let log_file_path_result = crate::manage_absolute_executable_directory_relative_paths::make_input_path_name_abs_executabledirectoryrelative_nocheck("uma.log");

            match log_file_path_result {
                Ok(log_file_path) => {
                    // Open the log file in append mode, creating it if it doesn't exist
                    match std::fs::OpenOptions::new()
                        .append(true)
                        .create(true)
                        .open(&log_file_path)
                    {
                        Ok(mut file) => {
                            // Write the formatted message to the file
                            if let Err(write_err) = writeln!(file, $($arg)*) {
                                eprintln!("Failed to write to log file: {}", write_err);
                            }
                        },
                        Err(open_err) => {
                            eprintln!("Failed to open log file at {}: {}",
                                log_file_path.display(), open_err);
                        }
                    }
                },
                Err(path_err) => {
                    eprintln!("Failed to determine log file path: {}", path_err);
                }
            }
        }
    };
}

// maybe deprecated
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct RemoteCollaboratorPortsData {
    remote_collaborator_name: String,
    remote_ipv6_address: Ipv6Addr,
    remote_collaborator_gpg_publickey_id: String,
    remote_public_gpg: String,
    remote_sync_interval: u64, // depricated? controlled by team-channel?
    remote_ready_port__their_desk_you_listen: u16, // locally: 'you' listen to their port on 'their' desk
    remote_intray_port__their_desk_you_send: u16, // locally: 'you' add files to their port on 'their' desk
    remote_gotit_port__their_desk_you_listen: u16, // locally: 'you' listen to their port on 'their' desk
}

/// struct for reading/extracting raw abstract port assignments
/// from the team_channels/NAME/node.toml
#[derive(Debug, Deserialize, Serialize, Clone, Hash, PartialEq, Eq)] // Add
struct AbstractTeamchannelNodeTomlPortsData {
    user_name: String,
    ready_port: u16,
    intray_port: u16,
    gotit_port: u16, // locally: 'you' listen to their port on 'their' desk
}

/// Represents port assignments for a collaborator in a `CoreNode`.
///
/// This struct holds six different ports used for communication and synchronization
/// between two collaborators.
/// Because Rust does not automatically deal with 'list of dicts' in python terms
/// this struct is a list (array) of 'dictionaries/hashmaps' which are a separate struct
/// so this list is a single list, that is a list of other structs that are dicts/hashmaps
#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct ReadTeamchannelCollaboratorPortsToml {
    /// The port used by the REMOTE collaborator to signal readiness to receive data.
    collaborator_ports: Vec<AbstractTeamchannelNodeTomlPortsData>,
}


/// Instance-Role-Specific Local-Meeting-Room-Struct
/// This is no longer for an abstract set of data
/// that can be used in different ways in different instances,
/// This is now one of those specific instances with local roles
/// and one local way of using those data.
/// The abstract port-assignements will be converted into a
/// disambiguated and clarified specific local instance roles
/// set of port assignments:
/// - local_user_role,
/// - remote_collaborator_role.
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct MeetingRoomSyncDataset {
    local_user_name: String,
    local_user_salt_list: Vec<u128>,
    local_user_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    local_user_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    local_user_gpg_publickey_id: String,
    local_user_public_gpg: String,
    local_user_sync_interval: u64,
    local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen for files sent by the other collaborator
    local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk

    remote_collaborator_name: String,
    remote_collaborator_salt_list: Vec<u128>,
    remote_collaborator_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    remote_collaborator_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    remote_collaborator_gpg_publickey_id: String,
    remote_collaborator_public_gpg: String,
    remote_collaborator_sync_interval: u64,
    remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
    remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' add files to their port on 'their' desk
    remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
    // team_channel_name: String,
    use_padnet: bool,
}

/// ForLocalOwnerDeskThread data from MeetingRoomSyncDataset
/// Get Needed, When Needed
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct ForLocalOwnerDeskThread {
    local_user_name: String,
    remote_collaborator_name: String,
    local_user_salt_list: Vec<u128>,
    remote_collaborator_salt_list: Vec<u128>,
    local_user_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    local_user_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    remote_collaborator_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    remote_collaborator_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    local_user_gpg_publickey_id: String,
    remote_collaborator_gpg_publickey_id: String,
    local_user_public_gpg: String,
    local_user_sync_interval: u64,
    local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen for files sent by the other collaborator
    local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    use_padnet: bool,
}

/// ForRemoteCollaboratorDeskThread data from MeetingRoomSyncDataset
/// Get Needed, When Needed
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct ForRemoteCollaboratorDeskThread {
    remote_collaborator_name: String,
    local_user_name: String,
    remote_collaborator_salt_list: Vec<u128>,
    local_user_salt_list: Vec<u128>,
    remote_collaborator_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    remote_collaborator_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    local_user_ipv6_addr_list: Vec<Ipv6Addr>, // list of ip addresses
    local_user_ipv4_addr_list: Vec<Ipv4Addr>, // list of ip addresses
    remote_collaborator_gpg_publickey_id: String,
    remote_collaborator_public_gpg: String,
    remote_collaborator_sync_interval: u64,
    remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
    remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' add files to their port on 'their' desk
    remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
    use_padnet: bool,
}

/// for translate_port_assignments() to export as
/// Get Needed, When Needed
#[derive(Debug, Clone, Hash, PartialEq, Eq)]
struct RoleBasedLocalPortSet {
    local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen for files sent by the other collaborator
    local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' send a signal through your port on your desk
    remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
    remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: u16, // locally: 'you' add files to their port on 'their' desk
    remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: u16, // locally: 'you' listen to their port on 'their' desk
}

fn translate_port_assignments(
    local_user_name: &str,
    remote_collaborator_name: &str,
    abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
) -> Result<RoleBasedLocalPortSet, MyCustomError> {
    debug_log!("tpa: Entering translate_port_assignments() function");

    // 1. Construct the key for the meeting room based on user names
    let meeting_room_key = get_meeting_room_lookup_fieldkey(local_user_name, remote_collaborator_name);
    debug_log!("tpa 1. Meeting room key: {}", meeting_room_key);

    // 2. Get the port assignment array for this meeting room
    let meeting_room_ports = abstract_collaborator_port_assignments
        .get(&meeting_room_key)
        .ok_or_else(|| MyCustomError::from(io::Error::new(
            io::ErrorKind::NotFound,
            format!("tpa 2. Port assignments not found for meeting room: {}", meeting_room_key),
        )))?;

    // 3. Extract local and remote ports from the vector
    let mut local_ports = None;
    let mut remote_ports = None;

    // Iterate through the ReadTeamchannelCollaboratorPortsToml structs
    for port_data in meeting_room_ports {
        // Iterate through the collaborator_ports vector within each struct
        for port_set in &port_data.collaborator_ports {
            if port_set.user_name == local_user_name {
                local_ports = Some(port_set.clone());
            } else if port_set.user_name == remote_collaborator_name {
                remote_ports = Some(port_set.clone());
            }
        }
    }

    // 4. Ensure both local and remote ports were found
    let local_ports = local_ports.ok_or_else(|| MyCustomError::from(io::Error::new(
        io::ErrorKind::NotFound,
        format!("tpa 4. Local port assignments not found for user: {}", local_user_name),
    )))?;
    let remote_ports = remote_ports.ok_or_else(|| MyCustomError::from(io::Error::new(
        io::ErrorKind::NotFound,
        format!("tpa 4. Remote port assignments not found for user: {}", remote_collaborator_name),
    )))?;

    // 5. Construct and return the RoleBasedLocalPortSet
    Ok(RoleBasedLocalPortSet {
        local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: local_ports.ready_port,
        localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: local_ports.intray_port,
        local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: local_ports.gotit_port,
        remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: remote_ports.ready_port,
        remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: remote_ports.intray_port,
        remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: remote_ports.gotit_port,
    })
}

// // Helper function for translate_port_assignments
// // to construct the meeting room key
// Helper function to construct the meeting room key
fn get_meeting_room_lookup_fieldkey(user1: &str, user2: &str) -> String {
    let mut names = vec![user1, user2];
    names.sort(); // Ensure consistent key regardless of user order
    format!("{}_{}", names[0], names[1])
}

/// Extracts the list of collaborator names from a team channel's `node.toml` file.
///
/// This function reads the `node.toml` file at the specified path, parses the TOML data,
/// and extracts the collaborator names from the `abstract_collaborator_port_assignments` table.
///
/// # Arguments
///
/// * `node_toml_path` - The path to the team channel's `node.toml` file.
///
/// # Returns
///
/// * `Result<Vec<String>, String>` - A `Result` containing a vector of collaborator names
///   on success, or a `String` describing the error on failure.
fn get_collaborator_names_from_node_toml(node_toml_path: &Path) -> Result<Vec<String>, String> {
    debug_log!("GCNRNT 4. Entering get_collaborator_names_from_node_toml() with path: {:?}", node_toml_path);

    // // 1. Read the node.toml file
    // let toml_string = match std::fs::read_to_string(node_toml_path) {
    //     Ok(content) => {
    //         debug_log!("GCNRNT Successfully read node.toml file. Contents:\n{}", content);
    //         content
    //     },
    //     Err(e) => return Err(format!("GCNRNT Error reading node.toml file: {}", e)),
    // };

    // // 2. Parse the TOML data
    // // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    // let toml_value: Value = match toml::from_str(&toml_string) {
    //     Ok(value) => {
    //         debug_log!("GCNRNT Successfully parsed TOML data. Value: {:?}", value);
    //         value
    //     },
    //     Err(e) => return Err(format!("GCNRNT Error parsing node.toml data: {}", e)),
    // };


    let target_path_string = node_toml_path.to_string_lossy();


    ////////////////////////////////
    // Extract Owner for Key Lookup
    ////////////////////////////////
    let owner_name_of_toml_field_key_to_read = "owner";
    debug_log!(
        "LCNFTF: Reading file owner from field '{}' for security validation",
        owner_name_of_toml_field_key_to_read
    );

    // get node_owners_public_gpg_key

    let file_owner_username = match read_single_line_string_field_from_toml(
        &node_toml_path.to_string_lossy(),  // TODO convert to string?
        owner_name_of_toml_field_key_to_read,
    ) {
        Ok(username) => {
            if username.is_empty() {
                // Convert to String error instead of GpgError
                return Err(format!(
                    "LCNFTF: Field '{}' is empty in TOML file. File owner is required for security validation.",
                    owner_name_of_toml_field_key_to_read
                ));
            }
            username
        }
        Err(e) => {
            // Convert to String error instead of GpgError
            return Err(format!(
                "LCNFTF: Failed to read file owner from field '{}': {}",
                owner_name_of_toml_field_key_to_read, e
            ));
        }
    };
    // println!("LCNFTF: File owner: '{}'", file_owner_username);
    debug_log!("LCNFTF: File owner: '{}'", file_owner_username);

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(format!(
                "LCNFTF: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            ));
        }
    };

    // Get the UME temp directory path with explicit String conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| {
            let gpg_error = GpgError::ValidationError(
                format!("LCNFTF: Failed to get UME temp directory path: {}", io_err)
            );
            // Convert GpgError to String for the function's return type
            format!("LCNFTF: {:?}", gpg_error)
        })?;

    // Extract the addressbook path string with inline error conversion
    let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_owner_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| format!(
        "LCNFTF: Failed to get addressbook path for user '{}': {:?}",
        file_owner_username,
        e
    ))?;

    // // Define cleanup closure
    // let cleanup_closure = || {
    //     let _ = cleanup_collaborator_temp_file(
    //         &node_toml_path,
    //         &base_uma_temp_directory_path,
    //         );
    //     let _ = cleanup_collaborator_temp_file(
    //         &addressbook_readcopy_path_string,
    //         &base_uma_temp_directory_path,
    //         );
    // };

    /*
    pub fn read_stringarray_from_clearsigntoml_without_publicgpgkey(
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
        name_of_toml_field_key_to_read: &str,
    ) -> Result<Vec<String>, String> {
    */

    // Example: Read _ from the clearsigned TOML file
    let collaborator_names_array = read_stringarray_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &target_path_string,           // Target clearsigned filepath string
        "teamchannel_collaborators_with_access"                // Field to read
    ).map_err(|e| {
        // cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: description_for_tui sFailed to read description_for_tui: {}", e)
    })?;


    // // 3. Extract collaborator names from abstract_collaborator_port_assignments
    // let mut collaborator_names = Vec::new();
    // debug_log!("GCNRNT Looking for table 'abstract_collaborator_port_assignments'");
    // if let Some(collaborator_assignments_table) = toml_value.get("abstract_collaborator_port_assignments").and_then(Value::as_table) {
    //     debug_log!("GCNRNT Found table 'abstract_collaborator_port_assignments'. Entries: {:?}", collaborator_assignments_table);
    //     for (pair_name, _) in collaborator_assignments_table {
    //         debug_log!("GCNRNT Processing pair: {}", pair_name);
    //         // Split the pair name (e.g., "alice_bob") into individual names
    //         let names: Vec<&str> = pair_name.split('_').collect();
    //         collaborator_names.extend(names.iter().map(|&s| s.to_string()));
    //     }
    // } else {
    //     debug_log!("GCNRNT Table 'abstract_collaborator_port_assignments' not found.");
    // }

    debug_log!("GCNRNT Exiting get_collaborator_names_from_node_toml() with names: {:?}", collaborator_names_array);
    // 4. Return the list of collaborator names
    Ok(collaborator_names_array)
}

/// Calculate the visible message range for pagination
/// Returns (start_index, end_index) for slicing tui_textmessage_list
fn calculate_message_display_range(
    total_messages: usize,
    tui_height: usize,
    messagepost_display_offset: usize,
) -> (usize, usize) {
    // Guard: if messages fit in one screen, show all
    if total_messages <= tui_height {
        return (0, total_messages);
    }

    // Calculate base and effective offsets
    let base_offset = total_messages.saturating_sub(tui_height);
    let effective_offset = base_offset.saturating_sub(messagepost_display_offset);

    // Calculate end (capped at total)
    let end_index = (effective_offset + tui_height).min(total_messages);

    (effective_offset, end_index)
}

/// Extracts the abstract port assignments from a team channel's `node.toml` file.
///
/// This function reads the `node.toml` file, parses the TOML data, and extracts the
/// `collaborator_port_assignments` table, returning it as a HashMap.
///
/// # Arguments
///
/// * `node_toml_path` - The path to the team channel's `node.toml` file.
///
/// # Returns
///
/// * `Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, String>` - A `Result` containing a HashMap of
///   collaborator pair names to their port assignments on success, or a `String` describing the error on failure.
fn get_abstract_port_assignments_from_node_toml(
    node_toml_path: &Path
) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, String> {
    debug_log!("GAPAFNT 5. starting get_abstract_port_assignments_from_node_toml(): 1. Entering function with path: {:?}", node_toml_path);

    // 1. Read the node.toml file
    let toml_string = match std::fs::read_to_string(node_toml_path) {
        Ok(content) => {
            debug_log!("GAPAFNT: 2. Successfully read node.toml file.");
            content
        },
        Err(e) => {
            let error_message = format!("GAPAFNT: Error reading node.toml file: {}", e);
            debug_log!("{}", error_message);
            return Err(error_message);
        }
    };

    // 2. Parse the TOML data
    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = match toml::from_str(&toml_string) {
        Ok(value) => {
            debug_log!("GAPAFNT: 3. Successfully parsed TOML data.");
            value
        },
        Err(e) => {
            let error_message = format!("GAPAFNT: Error parsing node.toml data: {}", e);
            debug_log!("{}", error_message);
            return Err(error_message);
        }
    };

    // 3. Extract the abstract_collaborator_port_assignments table
    let mut abstract_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>> = HashMap::new();
    debug_log!("GAPAFNT: 4. Looking for 'abstract_collaborator_port_assignments' table.");
    if let Some(collaborator_assignments_table) = toml_value.get("abstract_collaborator_port_assignments").and_then(Value::as_table) {
        debug_log!("GAPAFNT: 5. Found 'abstract_collaborator_port_assignments' table.");
        for (pair_name, pair_data) in collaborator_assignments_table {
            debug_log!("GAPAFNT: 6. Processing pair: {}", pair_name);
            if let Some(ports_array) = pair_data.get("collaborator_ports").and_then(Value::as_array) {
                debug_log!("GAPAFNT: 7. Found 'collaborator_ports' array for pair: {}", pair_name);
                let mut ports_for_pair = Vec::new();
                for port_data in ports_array {
                    debug_log!("GAPAFNT: 8. Processing port data: {:?}", port_data);
                    let port_data_str = toml::to_string(&port_data).unwrap();

                    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                    let collaborator_port: AbstractTeamchannelNodeTomlPortsData = toml::from_str(&port_data_str)
                        .map_err(|e| format!("GAPAFNT: Error deserializing collaborator port: {}", e))?;
                    debug_log!("GAPAFNT: 9. Deserialized port data: {:?}", collaborator_port);
                    ports_for_pair.push(ReadTeamchannelCollaboratorPortsToml {
                        collaborator_ports: vec![collaborator_port],
                    });
                }
                debug_log!("GAPAFNT: 10. Inserting ports for pair: {} into HashMap.", pair_name);
                abstract_port_assignments.insert(pair_name.to_string(), ports_for_pair);
            } else {
                debug_log!("GAPAFNT: 11. 'collaborator_ports' array not found for pair: {}", pair_name);
            }
        }
    } else {
        debug_log!("GAPAFNT: 12. 'abstract_collaborator_port_assignments' table not found.");
    }

    debug_log!("GAPAFNT: 13. Exiting function with port assignments: {:?}", abstract_port_assignments);
    // 4. Return the abstract_port_assignments HashMap
    Ok(abstract_port_assignments)
}

// ALPHA VERSION
// Function to read a simple string from a file
pub fn read_state_string(file_name: &str) -> Result<String, std::io::Error> {
    // TODO needs to be exe-relative etc...
    debug_log!("read_state_string (file_name)->{}", file_name);

    let file_path = get_sessionstateitems_path()?.join(file_name);

    debug_log!("read_state_string 1. Channel directory path (file_path)->{:?}", file_path);

    fs::read_to_string(file_path)
}

// ALPHA VERSION
// Function to validate a simple string
/*
Where: Add this to  state_utils.rs module or a similar location.

Purpose: You can define validation rules based on the specific session state item. For example, checking if a string is not empty, if a TOML file has the expected structure, or even performing GPG signature verification.
*/
pub fn validate_state_string(value: &str) -> bool {
    !value.is_empty()
}


// use std::sync::mpmc::Sender;
use std::sync::mpsc::{self, Sender, Receiver, TryRecvError};

/// Thread message types for browser inter-thread communication
///
/// These messages are passed between the input thread, watch thread,
/// and main thread to coordinate actions in the message browser.
enum BrowserThreadMessage {
    KeyInput(char),     // A character was typed
    // Backspace,          // Backspace key pressed
    Enter,              // Enter key pressed
    DirectoryChanged,   // Directory contents changed (new messages)
    Exit,               // Request to exit browser
}

/// Modal message viewing states
///
/// Controls whether the browser updates with new messages
/// or prioritizes uninterrupted user input.
#[derive(PartialEq, Clone, Copy, Debug)]
enum MessageViewMode {
    Refresh, // Allow real-time updates, input may be interrupted
    Insert,  // No updates, focus on uninterrupted input
}

/// Input thread function for message browser
///
/// Continuously reads keyboard input and sends appropriate messages
/// to the main thread through the channel.
fn run_message_browser_input_thread(sender: Sender<BrowserThreadMessage>) {
    let mut stdin = io::stdin();
    let mut buffer = [0; 1];

    loop {
        if stdin.read_exact(&mut buffer).is_ok() {
            let message = match buffer[0] {
                b'\n' | b'\r' => BrowserThreadMessage::Enter,
                // 8 | 127 => BrowserThreadMessage::Backspace,
                b'q' => {
                    debug_log("run_message_browser_input_thread -> q");

                    BrowserThreadMessage::Exit
                },
                c => BrowserThreadMessage::KeyInput(c as char),
                // _ => continue, // or BrowserThreadMessage::Unknown, or log a warning, etc.

            };

            // If send fails, the receiver has been dropped, so exit thread
            if sender.send(message).is_err() {
                break;
            }
        }

        thread::sleep(Duration::from_millis(10));
    }
}

/// Directory watch thread for message browser
///
/// Periodically checks for changes in the message directory
/// and notifies the main thread when changes are detected.
fn run_message_browser_watch_thread(sender: Sender<BrowserThreadMessage>, path: PathBuf) {
    let mut last_hash = 0;

    loop {
        thread::sleep(Duration::from_millis(2000));

        match calculate_message_directory_hash(&path) {
            Ok(current_hash) => {
                if current_hash != last_hash {
                    last_hash = current_hash;

                    // If send fails, the receiver has been dropped, so exit thread
                    if sender.send(BrowserThreadMessage::DirectoryChanged).is_err() {
                        break;
                    }
                }
            },
            Err(_) => {
                // Error calculating hash - directory might be inaccessible
                // Just continue and try again next cycle
            }
        }
    }
}

/// Calculate a hash of the message directory contents
///
/// Used to efficiently detect when directory contents have changed
/// without having to compare all files.
fn calculate_message_directory_hash(path: &Path) -> io::Result<u64> {
    let mut hasher = DefaultHasher::new();

    for entry in fs::read_dir(path)? {
        let entry = entry?;
        let metadata = entry.metadata()?;

        // Hash filename, size, and modification time
        entry.file_name().hash(&mut hasher);
        metadata.len().hash(&mut hasher);
        if let Ok(modified) = metadata.modified() {
            modified.hash(&mut hasher);
        }
    }

    Ok(hasher.finish())
}


// Compression Algorithm Enum
#[derive(Debug, Deserialize, Serialize, Clone, PartialEq)]
enum CompressionAlgorithm {
    Deflate,
    Brotli,
    Zstd,
    None,
}

/// Represents the different input modes of the UMA application's TUI.
///
/// The TUI can be in one of these modes at a time, determining how user input
/// is interpreted and handled.
#[derive(PartialEq, Clone, Debug)]
enum InputMode {
    /// MainCommand Mode:  The default mode. The user can type commands (e.g., "help", "quit", "m")
    /// to navigate the project graph or interact with UMA features.
    MainCommand,
    /// Insert Text Mode:  Used for entering text, such as instant messages. In this mode,
    /// user input is treated as text to be added to the current context.
    InsertText,
    TaskCommand,
}

struct App {
    tui_directory_list: Vec<String>, // For directories in the current path
    tui_file_list: Vec<String>,       // For files in the current path
    tui_focus: usize,                  // Index of the highlighted item in the TUI list
    tui_textmessage_list: Vec<String>, // Content of messages in the current IM conversation
    messagepost_display_offset: usize,    //

    tui_width: usize,               // the number of items to display is dereived from this
    tui_height: usize,

    current_path: PathBuf,              // Current directory being used
    input_mode: InputMode,
    command_input_integer:  Option<usize>,
    current_command_input: Option<String>,
    current_text_input: Option<String>,
    graph_navigation_instance_state: GraphNavigationInstanceState,

    // For Task Display
    next_path_lookup_table: HashMap<usize, PathBuf>,
    ordered_task_column_list: Vec<String>,
    task_display_table: Vec<String>, // ?

}


impl App {
    /*


    */

    // fn new(graph_navigation_instance_state: GraphNavigationInstanceState) -> App {
    //     App {
    //         tui_focus: 0,
    //         current_path: PathBuf::from("project_graph_data/team_channels"),

    /// Creates a new App instance with state initialized from executable-relative paths
    ///
    /// # Arguments
    /// * `graph_navigation_instance_state` - Initial graph navigation state
    ///
    /// # Returns
    /// * `Result<App, io::Error>` - A new App instance or an error if paths cannot be resolved
    fn new(graph_navigation_instance_state: GraphNavigationInstanceState) -> Result<App, io::Error> {
        // Get executable-relative path for project data
        let executable_parent_directory = get_absolute_path_to_executable_parentdirectory()?;
        let target_path = executable_parent_directory.join("project_graph_data/team_channels");

        // Verify the path exists
        if !abs_executable_directory_relative_exists(&target_path)? {
            return Err(io::Error::new(
                io::ErrorKind::NotFound,
                format!("Required directory not found: {:?}", target_path)
            ));
        }

        // Canonicalize the path
        let current_exe_dir_relative_abs_path_canonicalized = target_path.canonicalize()?;

        // Create and return the App instance
        Ok(App {
            tui_focus: 0,
            current_path: current_exe_dir_relative_abs_path_canonicalized,
            input_mode: InputMode::MainCommand,
            tui_file_list: Vec::new(), // Initialize files
            tui_directory_list: Vec::new(), // Initialize files
            tui_textmessage_list: Vec::new(), // Initialize files
            messagepost_display_offset: 0,
            tui_width: 80, // default posix terminal size
            tui_height: 18, // default posix terminal size
            command_input_integer: None,
            current_command_input: None,
            current_text_input: None,
            graph_navigation_instance_state, // Initialize the field

            next_path_lookup_table: HashMap::new(),
            ordered_task_column_list: Vec::new(),
            task_display_table: Vec::new(),
        })
    }
    /*

    ## Task Display

    struct GraphNavigationInstanceState {
        local_owner_user: String, // Store the local user data here
        // local_owner_hash_list: Vec<u8>,
        active_team_channel: String,
        default_im_messages_expiration_days: u64,
        default_task_nodes_expiration_days: u64,
        tui_height: u8,
        tui_width: u8,
        current_full_file_path: PathBuf,
        current_node_teamchannel_collaborators_with_access: Vec<String>,
        current_node_name: String,
        current_node_owner: String,
        current_node_description_for_tui: String,
        current_node_directory_path: PathBuf,
        current_node_unique_id: Vec<u8>,
        current_node_members: Vec<String>,
        home_square_one: bool,

        next_path_lookup_table: HashMap<usize, PathBuf>,
        ordered_task_column_list: Vec<String>, // not needed here?
        task_display_table: Vec<String>, // ?
        }

    impl GraphNavigationInstanceState {
        maybe populate the next_path_lookup_table and task_display_table
        using functions here
    }

    note: columns are (node) directories with a formatted directory name:
    int underscore string: sequence number left to right, underscore, and display name
    to be systematically processed.

    note: the TUI display table should have int space string for the columns and for the tasks

    ### Task Display Parts:
    1. a sequence counter (to mostly increment)
    2. an ordered list of column paths
    3. display table: maybe array of strings (for the TUI to show as a simple table)
    4. path lookup dictionary: a {int:path} path lookup dictionary (for the user-interface to select next path)

    ### Column-item Steps: columns are (node) directories
    1. Preset/Reset the Task Display Parts (see above)
    2. read the "#_str" column names, start the sequence counter after the highest
    3. add column names and numbers (from #_str") to the path lookup dict (these are the column headers)
    4. add column numbers and names to display table (maybe truncate list name depending on display size if name is too long)
    5. add column path to ordered column path list

    ### Task-item Steps: tasks are (node) directories
    1. tasks: iterate through the ordered column path list (in order), for each column:
    2. simple sort the tasks (directories) in the column (directory), alphanumeric
    3. use and increment sequence counter. use the current sequence int and when done increment
    4. add task names and numbers (from #_str") to the path lookup dict: add as rows in the current column
    5. add task number and name to path lookup dictionary


    // example
    let mut graph_state = GraphNavigationInstanceState { /* initialize fields */ };
    graph_state.update_task_display()?;
    graph_state.print_task_display(); // For debugging

    */

    /// Updates the task display components and returns formatted headers and data
    pub fn update_task_display(&mut self) -> std::io::Result<(Vec<String>, Vec<Vec<String>>)> {
        // Reset display components
        self.next_path_lookup_table.clear();
        self.ordered_task_column_list.clear();
        self.task_display_table.clear();

        let mut sequence_counter: usize = 1;
        // Clone the PathBuf to avoid borrowing issues
        // Get absolute path from current directory
        let channel_dir_path = self.current_path.clone();
        debug_log!(
            "update_task_display, channel_dir_path -> {:?}",
            channel_dir_path
        );

        // Initialize vectors for headers and data
        let mut headers: Vec<String> = Vec::new();
        let mut data: Vec<Vec<String>> = Vec::new();

        // Process columns and collect headers
        self.process_columns(&channel_dir_path, &mut sequence_counter, &mut headers)?;

        // Process tasks and collect data
        self.process_tasks(&mut sequence_counter, &headers, &mut data)?;

        Ok((headers, data))
    }

    fn process_columns(
        &mut self,
        current_dir: &Path,
        sequence_counter: &mut usize,
        headers: &mut Vec<String>
    ) -> std::io::Result<()> {
        let mut columns: Vec<(usize, String, PathBuf)> = Vec::new();

        // Collect and parse column directories
        for entry in fs::read_dir(current_dir)? {
            let entry = entry?;
            let path = entry.path();
            if path.is_dir() {
                if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
                    if let Some((seq, display_name)) = parse_directory_name(name) {
                        columns.push((seq, display_name.to_string(), path));
                        *sequence_counter = (*sequence_counter).max(seq + 1);
                    }
                }
            }
        }

        // Sort columns by sequence number
        columns.sort_by_key(|(seq, _, _)| *seq);

        // Process columns
        for (seq, display_name, path) in columns {
            // Add to path lookup
            self.next_path_lookup_table.insert(seq, path.clone());

            // Add to ordered column list
            self.ordered_task_column_list.push(path.to_string_lossy().to_string());

            // Add to headers
            let truncated_name = truncate_string(&display_name, 12);
            headers.push(format!("{:3} {}", seq, truncated_name));
        }

        Ok(())
    }

    fn process_tasks(
        &mut self,
        sequence_counter: &mut usize,
        headers: &[String],
        data: &mut Vec<Vec<String>>
    ) -> std::io::Result<()> {
        let max_rows = self.get_max_tasks_count()?;

        // Initialize data rows
        for _ in 0..max_rows {
            data.push(vec![String::new(); headers.len()]);
        }

        // Process each column
        for (col_idx, column_path_str) in self.ordered_task_column_list.iter().enumerate() {
            let column_path = Path::new(column_path_str);
            let mut tasks: Vec<(String, PathBuf)> = Vec::new();

            // Collect tasks in current column
            for entry in fs::read_dir(column_path)? {
                let entry = entry?;
                let path = entry.path();
                if path.is_dir() {
                    if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
                        tasks.push((name.to_string(), path));
                    }
                }
            }

            // Sort tasks
            tasks.sort_by(|(a, _), (b, _)| a.cmp(b));

            // Process each task
            for (row_idx, (task_name, task_path)) in tasks.iter().enumerate() {
                if row_idx >= data.len() {
                    break;
                }

                // Add to path lookup
                self.next_path_lookup_table.insert(*sequence_counter, task_path.clone());

                // Add to data matrix
                let display_text = format!("{:3} {}",
                    sequence_counter,
                    truncate_string(task_name, 12)
                );

                data[row_idx][col_idx] = display_text;

                *sequence_counter += 1;
            }
        }

        Ok(())
    }


    /// Gets the maximum number of tasks across all columns
    fn get_max_tasks_count(&self) -> std::io::Result<usize> {
        let mut max_count = 0;
        for column_path_str in &self.ordered_task_column_list {
            let count = fs::read_dir(column_path_str)?
                .filter_map(|entry| entry.ok())
                .filter(|entry| entry.path().is_dir())
                .count();
            max_count = max_count.max(count);
        }
        Ok(max_count)
    }

    /// Modal Interactive Message Browser with Dual Refresh/Insert Modes
    ///
    /// # Purpose
    /// Provides a message viewing and composing interface that balances:
    /// - Real-time message updates (in Refresh mode)
    /// - Uninterrupted text input (in Insert mode)
    ///
    /// # Mode System
    /// The function implements a modal interface with two states:
    /// 1. REFRESH MODE: Terminal updates automatically when new messages arrive
    ///    - Pros: Always shows latest messages
    ///    - Cons: May interrupt typing
    ///
    /// 2. INSERT MODE: Terminal freezes updates to allow uninterrupted typing
    ///    - Pros: User can type without interruption
    ///    - Cons: May miss new messages until mode is toggled
    ///
    /// # User Experience
    /// - Toggle between modes: Press ENTER with empty input
    /// - Exit browser: Type 'q', 'quit', 'b', or 'back'
    /// - Send message: Type message and press ENTER in either mode
    ///
    /// # Implementation Details
    /// - Uses three concurrent threads:
    ///   1. Main thread: Manages state and rendering
    ///   2. Input thread: Captures user keystrokes
    ///   3. Watch thread: Monitors directory for changes
    ///
    /// # Parameters
    /// * `channel_path` - Path to the channel containing the message_posts_browser directory
    ///
    /// # Returns
    /// * `io::Result<()>` - Success or IO error
    ///
    /// # Thread Safety
    /// - Uses message passing (mpsc channels) between threads
    /// - No shared mutable state between threads
    /// - Safe shutdown of all threads on exit
    ///
    /// # State Management
    /// - Updates App.current_path to message directory
    /// - Sets App.input_mode appropriately
    /// - Loads messages via App.load_messagepost_messages()
    /// - Restores previous path on exit
    pub fn enter_modal_message_posts_browser(&mut self, channel_path: PathBuf) -> io::Result<()> {
        debug_log("starting enter_modal_message_posts_browser()");

        // Store the original path for restoration on exit
        let original_path = self.current_path.clone();

        // Update the current path to the instant message browser directory
        self.current_path = channel_path.join("message_posts_browser");

        debug_log!(
            "enter_modal_message_posts_browser() app.current_path after joining 'message_posts_browser': {:?}",
            self.current_path
        );

        // Verify directory exists
        if !self.current_path.exists() {
            println!("enter_modal_message_posts_browser Message directory not found!");
            self.current_path = original_path; // Restore original path
            return Ok(());
        }

        // Load initial messages
        self.load_messagepost_messages();

        // Initialize the modal message browser state
        let mut current_message_view_mode = MessageViewMode::Refresh;
        let mut user_input_buffer = String::new();
        let terminal_width = self.graph_navigation_instance_state.tui_width as u16;
        let terminal_height = self.graph_navigation_instance_state.tui_height as u16;

        // Set up channel for thread communication
        let (message_tx, message_rx): (Sender<BrowserThreadMessage>, Receiver<BrowserThreadMessage>) = mpsc::channel();

        // ----- SETUP INPUT THREAD -----
        let input_thread_sender = message_tx.clone();
        let _ = thread::spawn(move || {
            run_message_browser_input_thread(input_thread_sender);
        });

        // ----- SETUP DIRECTORY WATCH THREAD -----
        let watch_thread_sender = message_tx.clone();
        let watch_directory_path = self.current_path.clone();
        let _ = thread::spawn(move || {
            run_message_browser_watch_thread(watch_thread_sender, watch_directory_path);
        });

        // ----- MAIN BROWSER LOOP -----
        let mut needs_display_refresh = true;

        // Initial render
        self.render_message_browser_screen(&current_message_view_mode, &user_input_buffer, terminal_width, terminal_height)?;

        // Process events until exit
        'browser_loop: loop {
            match message_rx.try_recv() {
                Ok(BrowserThreadMessage::KeyInput(c)) => {
                    debug_log("EMMPB KeyInput(c)");
                    if current_message_view_mode == MessageViewMode::Insert || !needs_display_refresh {
                        user_input_buffer.push(c);
                        needs_display_refresh = true;
                    }
                },
                // Ok(BrowserThreadMessage::Backspace) => {
                //     user_input_buffer.pop();
                //     needs_display_refresh = true;
                // },
                Ok(BrowserThreadMessage::Enter) => {
                    if user_input_buffer.is_empty() {
                        debug_log("EMMPB toggle MessageViewMode::Insert/Refresh");

                        // Toggle between Refresh and Insert modes
                        let previous_mode = current_message_view_mode;
                        current_message_view_mode = match current_message_view_mode {
                            MessageViewMode::Refresh => MessageViewMode::Insert,
                            MessageViewMode::Insert => MessageViewMode::Refresh,
                        };

                        // If switching from Insert to Refresh, immediately refresh
                        if previous_mode == MessageViewMode::Insert && current_message_view_mode == MessageViewMode::Refresh {
                            self.load_messagepost_messages();
                        }

                        needs_display_refresh = true;
                    } else {
                        // Process non-empty input (possibly a command or message)
                        // match user_input_buffer.as_str() {
                        //     "q" | "quit" | "b" | "back" => {
                        //         // Exit message browser
                        //         break 'browser_loop;
                        //     },
                        //     _ => {
                        //         // Send message
                        //         self.add_new_message_from_input(&user_input_buffer)?;
                        //         user_input_buffer.clear();
                        //         self.load_messagepost_messages();
                        //         needs_display_refresh = true;
                        //     }
                        // }
                        match user_input_buffer.as_str() {
                            "q" | "quit" | "b" | "back" => {
                            debug_log("EMMPB exit");
                                break 'browser_loop;
                            },
                            "--custom" => {
                                // Launch custom message Q&A
                                user_input_buffer.clear();
                                self.create_custom_message_interactive()?;
                                self.load_messagepost_messages();
                                needs_display_refresh = true;
                            },

                            // Pagination commands
                            "k" | "up" => {
                                // Page up (older messages)
                                let base_offset = self.tui_textmessage_list.len()
                                    .saturating_sub(self.tui_height);
                                if self.messagepost_display_offset < base_offset {
                                    self.messagepost_display_offset += 1;
                                    needs_display_refresh = true;
                                }
                                user_input_buffer.clear();
                            },
                            "j" | "down" => {
                                // Page down (newer messages)
                                if self.messagepost_display_offset > 0 {
                                    self.messagepost_display_offset =
                                        self.messagepost_display_offset.saturating_sub(1);
                                    needs_display_refresh = true;
                                }
                                user_input_buffer.clear();
                            },
                            "tall+" => {
                                self.tui_height += 1;
                                needs_display_refresh = true;
                                user_input_buffer.clear();
                            },
                            "tall-" => {
                                if self.tui_height > 1 {
                                    self.tui_height = self.tui_height.saturating_sub(1);
                                    needs_display_refresh = true;
                                }
                                user_input_buffer.clear();
                            },
                            _ => {
                                // println!("EMMPB calling ANMFI");
                                debug_log("EMMPB calling ANMFI");
                                // Normal message send
                                let input_string = user_input_buffer.to_string();

                                debug_log!("EMMPB input_string->{}", input_string);

                                user_input_buffer.clear();
                                self.add_new_message_from_input(&input_string)?;
                                self.load_messagepost_messages();
                                needs_display_refresh = true;
                            }
                        }
                    }
                },
                Ok(BrowserThreadMessage::DirectoryChanged) => {
                    if current_message_view_mode == MessageViewMode::Refresh {
                        self.load_messagepost_messages();
                        needs_display_refresh = true;
                    }
                },
                Ok(BrowserThreadMessage::Exit) => {
                    // Exit due to quit command
                    break 'browser_loop;
                },
                Err(TryRecvError::Empty) => {
                    // No messages, continue
                },
                Err(TryRecvError::Disconnected) => {
                    // Channel closed, exit
                    break 'browser_loop;
                }
            }

            // Refresh display if needed
            if needs_display_refresh {
                self.render_message_browser_screen(&current_message_view_mode, &user_input_buffer, terminal_width, terminal_height)?;
                needs_display_refresh = false;
            }

            // Small sleep to prevent tight loop
            thread::sleep(Duration::from_millis(10));
        }

        // Clean up and exit
        // No need to join threads as they'll be cleaned up when program exits

        // Restore original path and mode
        self.current_path = original_path;
        self.input_mode = InputMode::MainCommand;

        // Final update before returning to main app
        self.update_directory_list()?;

        // Clear screen for clean transition
        print!("\x1B[2J\x1B[1;1H");
        io::stdout().flush()?;

        debug_log("ending: ender_modal...");
        Ok(())
    }

    /// Create custom message with interactive Q&A prompts
    ///
    /// Prompts user for:
    /// - Recipients (from available collaborators)
    /// - Expiration time (in minutes)
    /// - Encryption setting (unless required by policy)
    /// - Message text
    ///
    /// # Returns
    ///
    /// * `Ok(())` - Message created successfully or user cancelled
    /// * `Err(io::Error)` - If message creation fails
    fn create_custom_message_interactive(&mut self) -> io::Result<()> {
        // Clear screen for clean Q&A interface
        print!("\x1B[2J\x1B[1;1H");

        // // 5. Preview and Confirm
        // Clear stdin buffer by prompting for explicit Enter
        // This consumes any leftover input from previous operations
        println!("\nPress ENTER (maybe twice) to continue...");
        let mut _buffer_clear = String::new();
        io::stdin().read_line(&mut _buffer_clear)?;

        io::stdout().flush()?;

        println!("=== Custom Message Creation ===\n");

        // 1. Get Recipients with retry loop
        let recipients = loop {
            println!("Available collaborators:");
            for (i, collab) in self.graph_navigation_instance_state
                .current_node_teamchannel_collaborators_with_access
                .iter()
                .enumerate()
            {
                println!("  {}. {}", i + 1, collab);
            }
            println!("\nRecipients (enter comma-separated names, or Enter for ALL):");

            let mut recipients_input = String::new();
            io::stdin().read_line(&mut recipients_input)?;
            let recipients_input = recipients_input.trim();

            // if empty (empty enter) use all collaborators
            if recipients_input.is_empty() {
                break self.graph_navigation_instance_state
                    .current_node_teamchannel_collaborators_with_access
                    .clone();  // Return the full list
            }

            // Validate recipients
            let mut validated = Vec::new();
            let mut all_valid = true;

            for name in recipients_input.split(',') {
                let trimmed = name.trim();
                if self.graph_navigation_instance_state
                    .current_node_teamchannel_collaborators_with_access
                    .contains(&trimmed.to_string())
                {
                    validated.push(trimmed.to_string());
                } else {
                    println!(" Error: '{}' not in collaborator list", trimmed);
                    all_valid = false;
                }
            }

            if all_valid && !validated.is_empty() {
                break validated;
            }

            if !all_valid {
                println!("\nPlease try again with valid names.\n");
            }
        };

        // ping - send to the attention of (voluntary look for ping by them)

        // 1. Get Recipients with retry loop
        let ping_list = loop {
            println!("Available collaborators:");
            for (i, collab) in self.graph_navigation_instance_state
                .current_node_teamchannel_collaborators_with_access
                .iter()
                .enumerate()
            {
                println!("  {}. {}", i + 1, collab);
            }
            println!("\nPing (send to the attention of), list comma-separated names, or Enter for NONE:");

            let mut ping_input = String::new();
            io::stdin().read_line(&mut ping_input)?;
            let ping_input = ping_input.trim();

            if ping_input.is_empty() {
                // Empty = all recipients
                break Vec::new();
            }

            // Validate recipients
            let mut validated = Vec::new();
            let mut all_valid = true;

            for name in ping_input.split(',') {
                let trimmed = name.trim();
                if self.graph_navigation_instance_state
                    .current_node_teamchannel_collaborators_with_access
                    .contains(&trimmed.to_string())
                {
                    validated.push(trimmed.to_string());
                } else {
                    println!(" Error: '{}' not in collaborator list", trimmed);
                    all_valid = false;
                }
            }

            if all_valid && !validated.is_empty() {
                break validated;
            }

            if !all_valid {
                println!("\nPlease try again with valid names.\n");
            }
        };

        // 3. Get Expiration (absolute timestamp in seconds)
        let expires_at_timestamp = loop {
            println!("\nExpiration time (in minutes from now, or ENTER for default +999 years):");

            let mut input = String::new();
            io::stdin().read_line(&mut input)?;
            let input = input.trim();

            let now = get_current_unix_timestamp();

            if input.is_empty() {
                // Default: +999 years from now
                let years_999_in_seconds: u64 = 999 * 365 * 24 * 60 * 60; // ~31.5 billion seconds
                break now + years_999_in_seconds;
            }

            match input.parse::<u64>() {
                Ok(minutes) if minutes > 0 => {
                    // Convert minutes to seconds, add to current time
                    let duration_seconds = minutes * 60;
                    break now + duration_seconds;
                }
                _ => {
                    println!(" Invalid input. Please enter a positive number or press ENTER for default.");
                }
            }
        };

        // // 2. Get Expiration (in minutes, convert to seconds)
        // let expires_duration_seconds = loop {
        //     println!("\nExpiration time (in minutes from now, or ENTER for default 30 days):");

        //     let mut input = String::new();
        //     io::stdin().read_line(&mut input)?;
        //     let input = input.trim();

        //     if input.is_empty() {
        //         // Default: 30 days in SECONDS
        //         break Some(30 * 24 * 60 * 60);  // 30 days = 2,592,000 seconds
        //     }

        //     match input.parse::<u64>() {
        //         Ok(minutes) if minutes > 0 => {
        //             // Convert minutes to seconds
        //             break Some(minutes * 60);
        //         }
        //         _ => {
        //             println!(" Invalid input. Please enter a positive number or press ENTER for default.");
        //         }
        //     }
        // };


        // // 2. Get Expiration (in minutes)
        // let expires_minutes = loop {
        //     println!("\nExpiration time (in minutes from now, or ENTER for default 30 days):");

        //     let mut input = String::new();
        //     io::stdin().read_line(&mut input)?;
        //     let input = input.trim();

        //     if input.is_empty() {
        //         // Default: 30 days
        //         break 30 * 24 * 60;
        //     }

        //     match input.parse::<u64>() {
        //         Ok(minutes) if minutes > 0 => break minutes,
        //         _ => {
        //             println!(" Invalid input. Please enter a positive number or press ENTER for default.");
        //         }
        //     }
        // };

        // 3. Get Encryption Setting (with override check)
        let use_encryption = if self.graph_navigation_instance_state.message_post_gpgtoml_required == Some(true) {
            println!("\nEncryption: REQUIRED by channel policy (gpgtoml will be used)");
            true
        } else {
            loop {
                println!("\nUse encryption? (y/n, default: n):");

                let mut input = String::new();
                io::stdin().read_line(&mut input)?;

                match input.trim().to_lowercase().as_str() {
                    "y" | "yes" => break true,
                    "n" | "no" | "" => break false,
                    _ => {
                        println!(" Invalid input. Please enter 'y' or 'n'.");
                    }
                }
            }
        };

        // 4. Get Message Text (single line only)
        let text_message = loop {
            println!("\nPress ENTER (maybe twice) to continue...");
            let mut _buffer_clear = String::new();
            io::stdin().read_line(&mut _buffer_clear)?;
            // io::stdout().flush()?;

            println!("\nMessage text:");

            let mut input = String::new();
            io::stdin().read_line(&mut input)?;
            let text = input.trim();

            // ToDo remove these loops!!
            if text.is_empty() {
                println!("Try again:");
            } else {
                break text.to_string();
            }
        };

        println!("\n--- Message Preview ---");

        let recipients_display = if recipients.is_empty() {
            "All".to_string()
        } else {
            recipients.join(", ")
        };

        println!("To: {}", recipients_display);
        println!("Ping: {:?}", ping_list);
        println!("Expires: {:?} expires_at_timestamp", expires_at_timestamp);
        println!("Encrypted: {}", use_encryption);
        println!("Text: {}", text_message);

        loop {
            println!("\nCreate this message? (y/n):");

            let mut input = String::new();
            io::stdin().read_line(&mut input)?;

            // testing
            println!("input: {}", input);

            match input.trim().to_lowercase().as_str() {
                "y" | "yes" => {
                    // Create and send message
                    self.send_custom_message(
                        recipients,
                        ping_list,
                        use_encryption,
                        text_message,
                        expires_at_timestamp,
                    )?;

                    println!("\n Message was created.");
                    break;
                }
                "n" | "no" => {
                    println!("\n Message cancelled");
                    break;
                }
                _ => {
                    println!(" Invalid input. Please enter 'y' or 'n'.");
                }
            }
        }

        // Pause before returning to browser
        println!("\nPress ENTER to continue...");
        let mut _dummy = String::new();
        io::stdin().read_line(&mut _dummy)?;

        Ok(())
    }

    /// Send custom message with specified settings
    ///
    /// Helper function that handles the message creation and saving.
    fn send_custom_message(
        &mut self,
        recipients: Vec<String>,
        ping_list: Vec<String>,
        use_encryption: bool,
        text_message: String,
        expires_at: u64,
    ) -> io::Result<()> {
        debug_log("SCM Starting send_custom_message");

        // Read metadata to get node info
        let metadata_path = self.current_path.join("0.toml");
        let metadata_path_string = metadata_path.to_string_lossy();

        debug_log!("SCM metadata_path_string {}", metadata_path_string);

        // Step 4: Read the requested field from the verified file
        let node_name = read_single_line_string_field_from_toml(
            &metadata_path_string,
            "node_name",
        )
        .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("SCM: node_name read_single_line_string_field_from_toml error: {}", e)))?;

        // Step 4: Read the requested field from the verified file
        let path_in_node = read_single_line_string_field_from_toml(
            &metadata_path_string,
            "path_in_node",
        )
        .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("SCM: path_in_node read_single_line_string_field_from_toml error: {}", e)))?;

        // Get next sequential file path
        let file_path = get_next_message_file_path(
            &self.current_path,
            &self.graph_navigation_instance_state.local_owner_user
        );

        debug_log!("SCM: Creating message at: {:?}", file_path);

        /*
        impl MessagePostFile {
            fn new(
                graph_navigation_instance_state: &GraphNavigationInstanceState,
                owner: &str, // owner
                node_name: &str, // node_name
                filepath_in_node: &str, //filepath_in_node
                text_message: &str, // text_message
                recipients_list: Vec<String>, // teamchannel_collaborators_with_access
                ping: //
                messagepost_gpgtoml: bool,
                expires_at: Option<u64>,  // NEW: Custom expiration, or None for default
            ) -> MessagePostFile {
        */

        // Create message with custom settings
        let message = MessagePostFile::new(
            // &self.graph_navigation_instance_state,
            &self.graph_navigation_instance_state.local_owner_user,
            &node_name,
            &path_in_node,
            &text_message,
            if recipients.is_empty() {
                self.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access.clone()
            } else {
                recipients.clone()
            },
            ping_list,
            use_encryption,
            Some(expires_at),
        );
        debug_log("SCM Starting serialize_messagepost_toml");

        let toml_data = match serialize_messagepost_toml(&message) {
            Ok(toml_string) => {
                debug_log!("SCM: TOML serialization successful, {} bytes", toml_string.len());
                toml_string
            }
            Err(e) => {
                debug_log!("SCM: serialization failed");
                return Err(io::Error::new(
                    io::ErrorKind::InvalidInput,
                    format!("SCM: error serialize_messagepost_toml {}", e)
                ));
            }
        };

        // Save based on encryption setting
        if use_encryption {
            let base_path = file_path.with_extension("");
            save_message_as_gpgtoml(&base_path, &toml_data)?;
        } else {
            save_message_as_clearsigned_toml(&file_path, &toml_data)?;
        }

        // Write sync flags
        let final_recipients = if recipients.is_empty() {
            &self.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access
        } else {
            &recipients
        };

        let _ = write_newfile_sendq_flag(final_recipients, &file_path);

        debug_log!("SCM: Message created successfully");

        Ok(())
    }

    /// Helper function to render the message browser screen
    ///
    /// Displays:
    /// 1. Message list from tui_textmessage_list
    /// 2. Mode indicator (Refresh/Insert)
    /// 3. Input prompt with current buffer
    fn render_message_browser_screen(
        &self,
        message_view_mode: &MessageViewMode,
        input_buffer: &str,
        terminal_width: u16,
        terminal_height: u16
    ) -> io::Result<()> {
        // Clear screen
        print!("\x1B[2J\x1B[1;1H");

        // Header/Legend
        let _ = write_formatted_messagepost_legend_to_tui();

        // 1. Display messages using existing function
        // tiny_tui::simple_render_list(&self.tui_textmessage_list, &self.current_path);
        // Calculate visible range
        let (start_idx, end_idx) = calculate_message_display_range(
            self.tui_textmessage_list.len(),
            self.tui_height,
            self.messagepost_display_offset,
        );

        // Create slice and convert to Vec for simple_render_list
        let visible_messages: Vec<String> = self.tui_textmessage_list[start_idx..end_idx]
            .to_vec();

        // Display with pagination info in path/header
        tiny_tui::simple_render_list(&visible_messages, &self.current_path);


        // 2. Fill remaining space to position info bar correctly
        let path_lines = 6; // Header line showing path
        let message_count = self.tui_textmessage_list.len();
        let info_bar_position = (terminal_height) as usize;

        for _ in 0..info_bar_position.saturating_sub(path_lines + message_count) {
            println!();
        }

        // 3. Display mode info bar with clear instructions
        match message_view_mode {
            MessageViewMode::Refresh => print!("\\|/  Refresh Mode "),
            MessageViewMode::Insert => print!(">_  Insert Mode "),
        }

        // 4. Display input prompt with current buffer
        // print!("{}", input_buffer);
        // println!("Showing {}-{} of {} | k j | :{} >",             start_idx + 1, end_idx, self.tui_textmessage_list.len(), self.tui_height);

        print!("Showing {}-{} of {} | k j > ",
            start_idx + 1, end_idx, self.tui_textmessage_list.len());
        io::stdout().flush()
    }

    /// Add a new message from user input
    ///
    /// Creates a new message file with the user's input as content.
    /// Extracts message-post configuration from navigation state and passes
    /// to the helper function for processing.
    ///
    /// # Process Flow
    ///
    /// 1. Extract all message-post config from navigation state
    /// 2. Generate next message file path
    /// 3. Pass config and input to helper function for validation and creation
    ///
    /// # Configuration Parameters
    ///
    /// The following are extracted from `self.graph_navigation_instance_state`:
    /// - Time window constraints (start/end dates)
    /// - Structured format ranges (integer, integer-string)
    /// - Max string length limit
    /// - Public/private setting
    /// - User confirmation requirement
    /// - GPG encryption requirement
    ///
    /// # Returns
    ///
    /// * `Ok(())` - Message created successfully OR skipped due to validation
    /// * `Err(io::Error)` - System error during message creation
    ///
    fn add_new_message_from_input(&mut self, input: &str) -> io::Result<()> {

        debug_log("ANMFI: starting add_new_message_from_input");

        // =================================================
        // Extract Configuration from Navigation State
        // =================================================

        let local_owner_user = &self.graph_navigation_instance_state.local_owner_user;
        debug_log!("ANMFI: local_owner_user->{:?}", local_owner_user);

        let current_node_owner = &self.graph_navigation_instance_state.current_node_owner;
        debug_log!("ANMFI: current_node_owner->{:?}", current_node_owner);

        // Time window configuration
        let start_date_utc_posix = self.graph_navigation_instance_state.message_post_start_date_utc_posix;
        let end_date_utc_posix = self.graph_navigation_instance_state.message_post_end_date_utc_posix;
        debug_log!("ANMFI: time window start: {:?}, end: {:?}", start_date_utc_posix, end_date_utc_posix);

        // Structured format configuration
        let integer_ranges = self.graph_navigation_instance_state
            .message_post_data_format_specs_integer_ranges_from_to_tuple_array
            .clone();
        let integer_string_ranges = self.graph_navigation_instance_state
            .message_post_data_format_specs_int_string_ranges_from_to_tuple_array
            .clone();
        debug_log!("ANMFI: integer_ranges: {:?}", integer_ranges);
        debug_log!("ANMFI: integer_string_ranges: {:?}", integer_string_ranges);

        // Other configuration
        let max_string_length = self.graph_navigation_instance_state.message_post_max_string_length_int;
        let is_public = self.graph_navigation_instance_state.message_post_is_public_bool;
        let user_confirms = self.graph_navigation_instance_state.message_post_user_confirms_bool;
        let gpgtoml_required = self.graph_navigation_instance_state.message_post_gpgtoml_required;

        debug_log!("ANMFI: max_string_length: {:?}", max_string_length);
        debug_log!("ANMFI: is_public: {:?}", is_public);
        debug_log!("ANMFI: user_confirms: {:?}", user_confirms);
        debug_log!("ANMFI: gpgtoml_required: {:?}", gpgtoml_required);

        // =================================================
        // Generate Message File Path
        // =================================================

        let message_path = get_next_message_file_path(&self.current_path, local_owner_user);
        debug_log!("ANMFI: message_path->{:?}", message_path);

        // =================================================
        // Call Helper Function with All Configuration
        // =================================================

       let input_string = input.to_string();
       // input.clear();

        add_new_messagepost_message(
            &message_path,
            local_owner_user,
            input_string.trim(),
            &self.graph_navigation_instance_state,
        ).map_err(|e| io::Error::new(
            io::ErrorKind::Other,
            format!("Failed to add message: {}", e)
        ))
    }

    /// Load instant messages from current directory
    ///
    /// # Purpose
    ///
    /// Loads all instant message files from the current directory, handling both
    /// clearsigned (.toml) and encrypted (.gpgtoml) formats. Displays messages
    /// in the TUI message list.
    ///
    /// # Process Flow
    ///
    /// 1. Clear existing message list
    /// 2. Check if directory contains messages (excluding 0.toml metadata)
    /// 3. If empty, prompt user to create first message
    /// 4. For each message file:
    ///    - Get readable temp copy (decrypt if .gpgtoml, verify if clearsigned)
    ///    - Read owner and text fields
    ///    - Add to display list
    ///    - Clean up temp copy
    ///
    /// # Message File Formats
    ///
    /// - `.toml` files: Clearsigned TOML (authenticated but readable)
    /// - `.gpgtoml` files: Encrypted TOML (requires decryption)
    /// - `0.toml`: Metadata file (excluded from message list)
    ///
    /// # Error Handling
    ///
    /// Errors are logged but don't halt loading - allows partial message display
    /// if some files fail to load. First message creation errors are fatal.
    ///
    /// # Side Effects
    ///
    /// - Clears `self.tui_textmessage_list`
    /// - Populates `self.tui_textmessage_list` with loaded messages
    /// - May prompt user for input if channel is empty
    /// - Creates temp files for reading (cleaned up after use)
    fn load_messagepost_messages(&mut self) {
        debug_log!("LIM: Starting load_messagepost_messages");
        debug_log!("LIM: Current path: {:?}", self.current_path);

        self.tui_textmessage_list.clear();

        // Verify current path is a directory
        if !self.current_path.is_dir() {
            debug_log!("LIM: Current path is not a directory");
            return;
        }

        debug_log!("LIM: Scanning directory for message files");

        // // Collect all entries in directory (max depth 1)
        // let entries: Vec<_> = WalkDir::new(&self.current_path)
        //     .max_depth(1)
        //     .into_iter()
        //     .filter_map(|entry| entry.ok())
        //     .filter(|entry| entry.path().is_file())
        //     .collect();

        // Collect all entries in directory (max depth 1)
        let mut entries: Vec<_> = WalkDir::new(&self.current_path)
            .max_depth(1)
            .into_iter()
            .filter_map(|entry| entry.ok())
            .filter(|entry| entry.path().is_file())
            .collect();

        // Sort entries by numeric prefix in filename (1__, 2__, 3__, etc.)
        entries.sort_by_key(|entry| {
            entry.path()
                .file_name()
                .and_then(|n| n.to_str())
                .and_then(|s| s.split("__").next())  // Get part before "__"
                .and_then(|num_str| num_str.parse::<u64>().ok())  // Parse as number
                .unwrap_or(u64::MAX)  // Put unparseable names at end
        });

        debug_log!("LIM: Entries sorted by filename prefix");

        // Debug: Log all found files
        debug_log!("LIM: === Files found in directory ===");
        for entry in &entries {
            debug_log!("LIM:   {:?}", entry.path());
        }
        debug_log!("LIM: === End of file list ===");

        // Check if directory is empty or only contains 0.toml
        let has_messages = entries.iter().any(|entry| {
            if let Some(file_name) = entry.path().file_name() {
                file_name != OsStr::new("0.toml")
            } else {
                false
            }
        });

        if !has_messages {
            // Channel is empty - prompt for first message
            debug_log!("LIM: Channel is empty, prompting for first message");
            println!("This channel is empty. Write a welcoming message:");

            let mut first_message = String::new();
            if let Err(e) = io::stdin().read_line(&mut first_message) {
                debug_log!("LIM: Failed to read user input: {}", e);
                return;
            }

            debug_log!("LIM: first_message: {}", first_message);


            let local_owner_user = self.graph_navigation_instance_state.local_owner_user.clone();
            let this_file_name = format!("1__{}.toml", local_owner_user);

            debug_log!("LIM: Creating first message file: {}", this_file_name);

            /*
            fn  add_new_messagepost_message(
                incoming_file_path: &Path,
                owner: &str,
                text: &str,
                signature: Option<String>,
                graph_navigation_instance_state: &GraphNavigationInstanceState,
            ) -> Result<(), io::Error> {
            */

            // Add the first message
            match add_new_messagepost_message(
                &self.current_path.join(this_file_name),
                &local_owner_user,
                first_message.trim(),
                &self.graph_navigation_instance_state,
            ) {
                Ok(()) => {
                    debug_log!("LIM: First message created successfully");
                    // Recursively reload messages
                    self.load_messagepost_messages();
                    return;
                }
                Err(e) => {
                    debug_log!("LIM: Failed to add first message: {}", e);
                    println!("Error creating first message: {}", e);
                    return;
                }
            }
        }

        // Get GPG fingerprint for decryption/verification
        debug_log!("LIM: Getting GPG fingerprint from uma.toml");
        let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => {
                debug_log!("LIM: GPG fingerprint retrieved: {}", fingerprint);
                fingerprint
            }
            Err(e) => {
                debug_log!("LIM: Failed to read GPG fingerprint from uma.toml: {}", e);
                println!("Error: Cannot load messages without GPG fingerprint");
                return;
            }
        };

        // Get temp directory for read copies
        let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
            Ok(path) => path,
            Err(e) => {
                debug_log!("LIM: Failed to get temp directory path: {}", e);
                println!("Error: Cannot create temp directory for message reading");
                return;
            }
        };

        // Load messages (excluding 0.toml)
        debug_log!("LIM: Loading message files");
        let mut loaded_count = 0;
        let mut error_count = 0;

        for entry in entries {
            if !entry.path().is_file() {
                continue;
            }

            // Get filename
            let file_name = match entry.path().file_name() {
                Some(name) => name.to_string_lossy().to_string(),
                None => {
                    debug_log!("LIM: Entry has no filename: {:?}", entry.path());
                    continue;
                }
            };

            // Skip metadata file
            if file_name == "0.toml" {
                debug_log!("LIM: Skipping metadata file: {}", file_name);
                continue;
            }

            debug_log!("LIM: Processing message file: {}", file_name);

            // Get readable temp copy (handles both .toml and .gpgtoml)
            let message_readcopy_path = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
                entry.path(),
                &gpg_full_fingerprint_key_id_string,
                &base_uma_temp_directory_path,
            ) {
                Ok(path) => {
                    debug_log!("LIM: Got temp read copy at: {}", path);
                    path
                }
                Err(e) => {
                    debug_log!("LIM: Failed to get readable copy of {}: {:?}", file_name, e);
                    error_count += 1;
                    continue;
                }
            };

            // check if expired
            // if so
            // move to uma_archive/...same path after team_channel/...
            // Read owner field
            let expires_at_value = match read_u64_field_from_toml(
                &message_readcopy_path,
                "expires_at",
            ) {
                Ok(expires_at_value) => {
                    expires_at_value
                }
                Err(e) => {
                    debug_log!("LIM: expires_at to read owner from {}: {}", file_name, e);
                    error_count += 1;
                    continue;
                }
            };

            // After reading expires_at_value, check if expired
            let now = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs();

            if expires_at_value < now {
                debug_log!("LMM ARCHIVING!! MessagePostFile: expires_at_value < now");

                /*
                fn move_expired_message_to_archive(
                source_path: &str, file_name: &str)
                -> Result<(), String> {
                 */
                 let _ = move_expired_message_to_archive(&entry.path());
                 continue; // Skip further processing of this message
            }


            // Read owner field
            let owner = match read_single_line_string_field_from_toml(
                &message_readcopy_path,
                "owner",
            ) {
                Ok(owner_value) => {
                    if owner_value.is_empty() {
                        debug_log!("LIM: Owner field is empty in {}", file_name);
                        error_count += 1;
                        continue;
                    }
                    owner_value
                }
                Err(e) => {
                    debug_log!("LIM: Failed to read owner from {}: {}", file_name, e);
                    error_count += 1;
                    continue;
                }
            };

            // Read text_message field
            let text_message = match read_single_line_string_field_from_toml(
                &message_readcopy_path,
                "text_message",
            ) {
                Ok(text) => {
                    if text.is_empty() {
                        debug_log!("LIM: text_message field is empty in {}", file_name);
                        error_count += 1;
                        continue;
                    }
                    text
                }
                Err(e) => {
                    debug_log!("LIM: Failed to read text_message from {}: {}", file_name, e);
                    error_count += 1;
                    continue;
                }
            };

            debug_log!("LIM: Successfully loaded message from {}: {} chars", owner, text_message.len());

            // Add to display list
            self.tui_textmessage_list.push(format!("{}: {}", owner, text_message));
            loaded_count += 1;

            // Cleansup Time!
            let _ = cleanup_collaborator_temp_file(
                &message_readcopy_path,
                &base_uma_temp_directory_path,
                );
        }

        debug_log!("LIM: Finished loading messages: {} messages loaded, {} problems", loaded_count, error_count);

        if loaded_count == 0 && error_count > 0 {
            println!("Warning: Failed to load any messages from this channel");
        }
    }

    fn enter_task_browser(&mut self) {
        debug_log!("task-mode: starting: enter_task_browser");
        if self.current_path.exists() {
            self.load_tasks();
            self.input_mode = InputMode::TaskCommand;
        } else {
            debug_log!("'task_browser' directory not found in current node.");

        }
    }


    fn is_at_task_browser_root(&self) -> bool {
        self.current_path.ends_with("task_browser") && self.tui_file_list.is_empty()
    }

    // What? selection? ...????
    fn handle_task_action(&mut self, input: &str) -> bool { // Return true to exit task mode
        // TODO handle 'b' back

        if input == "q" || input == "quit" || input == "b" || input == "back" {
            self.input_mode = InputMode::MainCommand; //Switch back to MainCommand mode
            self.current_path.pop(); // Go back to parent directory ("task_browser")
            self.load_tasks();        //Refresh task view at the previous parent level.
            return false;             // Stay in the main loop (don't exit Uma)

        } else if let Ok(_) = input.parse::<usize>() {
            // ... (Logic for task number handling - See detailed code below)
        } else {
            debug_log!("Invalid task command.");
            // (Optional) Display error message in TUI
        }
        false // Don't exit task mode by default for other commands
    }

    /// headers/columns = directories with names starting with int and underscore such as 1_plan 2_started 3_done
    /// the number and underscore should be removed
    /// the number should be used as the header/column number
    /// for MVP each directory-name in side each column-directory becomes a row-item in that column
    /// e.g. if 1_plan contains a directory called "report" then given report a sequential number
    /// and list it under the header "plan"
    /// results sent to display_table() as function or as method
    fn load_tasks(&mut self) {
        debug_log!("task-mode: starting: tasks app: load_tasks");
        self.tui_directory_list.clear(); // Clear directories
        self.tui_file_list.clear();  // Clear files

        let task_browser_dir = &self.current_path;

        if self.is_at_task_browser_root() {

            // Version 2: More detailed error handling
            match self.update_task_display() {
                Ok((headers, data)) => {
                    if headers.is_empty() {
                        debug_log("Warning: No headers found in task display");
                        tiny_tui::render_tasks_table(
                            &["No Tasks".to_string()],
                            &Vec::new(),
                            &self.current_path,
                        );
                    } else {
                        // pub fn render_tasks_table(headers: &[String], data: &[Vec<String>], current_path: &Path) {
                        tiny_tui::render_tasks_table(
                            &headers,
                            &data,
                            &self.current_path,
                        );


                    }
                },
                Err(e) => {
                    debug_log(&format!("Error updating task display: {}", e));
                    // Show error message in table format
                    tiny_tui::render_tasks_table(
                        &["Error".to_string()],
                        &vec![vec![format!("Failed to load tasks: {}", e)]],
                        &self.current_path
                    );
                }
            }

        } else { // Inside a column
             // ... (task display within a column remains the same)
            let mut file_list = Vec::new();

            //Iterate through tasks and add to file_list (no column header)
            if let Ok(entries) = read_dir(task_browser_dir) {
                for (i, entry) in entries.flatten().enumerate() {
                    if entry.file_type().unwrap().is_dir() {  // Check for directories
                        file_list.push(format!("{}. {}", i + 1, entry.file_name().to_string_lossy().to_string())); //Corrected type here
                    }
                }
            } else {
                // ... handle errors
            }

            // Render the list using the correct parameters:
            tiny_tui::render_list(
                &file_list,      // Pass the file list
                &self.current_path, //Pass the current path
                &self.graph_navigation_instance_state.pa1_process,
                &self.graph_navigation_instance_state.pa2_schedule,
                &self.graph_navigation_instance_state.pa3_users,
                &self.graph_navigation_instance_state.pa4_features,
                &self.graph_navigation_instance_state.pa5_mvp,
                &self.graph_navigation_instance_state.pa6_feedback,
            );
        }
    }

    // What is wrong with the brain of the person who invented this function?
    fn is_in_team_channel_list(&self) -> bool {
        let is_in_team_channel_list_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(
            "project_graph_data/team_channels"
        ).ok();
        match is_in_team_channel_list_dir {
            Some(dir) => self.current_path == dir,
            None => false,
        }
        // let is_in_team_channel_list_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        //     "project_graph_data/team_channels"
        // )?;

        // self.current_path == is_in_team_channel_list_dir
        // PathBuf::from("project_graph_data/team_channels")
    }

    fn is_in_message_posts_browser_directory(&self) -> bool {
        self.current_path.ends_with("message_posts_browser")
    }

    fn update_directory_list(&mut self) -> io::Result<()> {
        self.tui_directory_list.clear();

        for entry in fs::read_dir(&self.current_path)? {
            let entry = entry?;
            let path = entry.path();
            if path.is_dir() { // Only add directories to the list
                let file_name = path.file_name().unwrap().to_string_lossy().to_string();
                self.tui_directory_list.push(file_name);
            }
        }

        Ok(())
    }

}
// end impl App {

/// Represents local user configuration for Uma collaboration tools.
/// This struct holds all user-specific settings including identity,
/// GPG key information, and UI preferences.
#[derive(Debug, Clone)]
struct LocalUserUma {
    /// The username/nickname for this Uma instance owner
    uma_local_owner_user: String,
    /// Full GPG key fingerprint for encryption/signing
    gpg_full_fingerprint_key_id_string: String,
    /// Number of days before IM messages expire (default: 28)
    uma_default_im_messages_expiration_days: u64,
    /// Number of days before task nodes expire (default: 90)
    uma_default_task_nodes_expiration_days: u64,
    /// Terminal UI height in rows (default: 24)
    tui_height: u8,
    /// Terminal UI width in columns (default: 80)
    tui_width: u8,
    /// Refresh rate in seconds for log mode display (default: 1.5)
    log_mode_refresh: f32,
}
/*
Sample:

// Get armored public key, using key-id (full fingerprint in)
let full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
    Ok(fingerprint) => fingerprint,
    Err(e) => {
        eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
        return Err(ThisProjectError::from(format!(
            "Failed to read GPG fingerprint from uma.toml: {}", e
        )));
    }
};

// Read individual fields when you don't need the whole struct
let uma_local_owner_user = match LocalUserUma::read_owner_from_file(&uma_toml_path) {
    Ok(owner) => owner,
    Err(e) => {
        eprintln!("Failed to read owner from uma.toml: {}", e);
        return Ok(false);
    }
};

let gpg_fingerprint = match LocalUserUma::read_gpg_fingerprint_from_file(&uma_toml_path) {
    Ok(fingerprint) => fingerprint,
    Err(e) => {
        eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
        return Ok(false);
    }
};

debug_log!("Loaded user: {} with GPG key: {}", uma_local_owner_user, gpg_fingerprint);
*/

impl LocalUserUma {

    /// Creates a new LocalUserUma instance with the specified owner and GPG fingerprint.
    /// Other fields are initialized with sensible defaults.
    ///
    /// # Arguments
    /// * `uma_local_owner_user` - The username for this Uma instance
    /// * `gpg_full_fingerprint_key_id_string` - The full GPG key fingerprint
    ///
    /// # Returns
    /// A new LocalUserUma instance with default values for non-specified fields
    fn new(
        uma_local_owner_user: String,
        gpg_full_fingerprint_key_id_string: String,
    ) -> LocalUserUma {
        LocalUserUma {
            uma_local_owner_user,
            gpg_full_fingerprint_key_id_string,
            uma_default_im_messages_expiration_days: 28,  // Default to 28 days
            uma_default_task_nodes_expiration_days: 90,  // Default to 90 days
            tui_height: 24,
            tui_width: 80,
            log_mode_refresh: 1.5,  // Refresh every 1.5 seconds
        }
    }

    /// Saves the entire LocalUserUma configuration to a file in plain text format.
    /// Each field is written as a key-value pair on its own line.
    ///
    /// # Arguments
    /// * `path` - The absolute path where the configuration file should be written
    ///
    /// # Returns
    /// * `Ok(())` if the file was written successfully
    /// * `Err(io::Error)` if there was an I/O error
    fn save_to_uma_toml_file(&self, path: &Path) -> Result<(), io::Error> {
        // Build the configuration string with all fields
        let config_content = format!(
            r#"uma_local_owner_user = "{}"
gpg_full_fingerprint_key_id_string = "{}"
uma_default_im_messages_expiration_days = {}
uma_default_task_nodes_expiration_days = {}
tui_height = {}
tui_width = {}
log_mode_refresh = {}"#,
            self.uma_local_owner_user,
            self.gpg_full_fingerprint_key_id_string,
            self.uma_default_im_messages_expiration_days,
            self.uma_default_task_nodes_expiration_days,
            self.tui_height,
            self.tui_width,
            self.log_mode_refresh
        );

        // Write the content to the file
        fs::write(path, config_content)?;
        Ok(())
    }

    /// Reads only the uma_local_owner_user field from a configuration file.
    ///
    /// # Arguments
    /// * `path` - The absolute path to the configuration file
    ///
    /// # Returns
    /// * `Ok(String)` containing the owner username if found
    /// * `Err(io::Error)` if the file couldn't be read or the field wasn't found
    fn read_owner_from_file() -> Result<String, io::Error> {
        // Get the absolute path to the flag file relative to the executable
        let uma_toml_path_exerel_abs = make_input_path_name_abs_executabledirectoryrelative_nocheck(
            "uma.toml"
        )?;

        let file = fs::File::open(uma_toml_path_exerel_abs)?;
        let reader = BufReader::new(file);

        for line in reader.lines() {
            let line = line?;
            let trimmed = line.trim();

            if trimmed.starts_with("uma_local_owner_user") {
                if let Some(equals_pos) = trimmed.find('=') {
                    let value = trimmed[equals_pos + 1..].trim();
                    return Self::parse_string_value(value);
                }
            }
        }

        Err(io::Error::new(
            io::ErrorKind::InvalidData,
            "uma_local_owner_user not found in configuration file",
        ))
    }

    // TODO: this should use clearsign verification
    /// Reads only the gpg_full_fingerprint_key_id_string field from a configuration file.
    ///
    /// # Arguments
    /// * `path` - The absolute path to the configuration file
    ///
    /// # Returns
    /// * `Ok(String)` containing the GPG fingerprint if found
    /// * `Err(io::Error)` if the file couldn't be read or the field wasn't found
    ///
    /// sample
    ///     // Get armored public key, using key-id (full fingerprint in)
    /// let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
    ///     Ok(fingerprint) => fingerprint,
    ///     Err(e) => {
    ///         return Err(io::Error::new(
    ///             io::ErrorKind::Other,
    ///             format!("implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}", e)
    ///         ));
    ///     }
    /// };
    ///
    fn read_gpg_fingerprint_from_file() -> Result<String, io::Error> {

        // Get the absolute path to the flag file relative to the executable
        let uma_toml_path_exerel_abs = make_input_path_name_abs_executabledirectoryrelative_nocheck(
            "uma.toml"
        )?;

        let file = fs::File::open(uma_toml_path_exerel_abs)?;
        let reader = BufReader::new(file);

        for line in reader.lines() {
            let line = line?;
            let trimmed = line.trim();

            if trimmed.starts_with("gpg_full_fingerprint_key_id_string") {
                if let Some(equals_pos) = trimmed.find('=') {
                    let value = trimmed[equals_pos + 1..].trim();
                    return Self::parse_string_value(value);
                }
            }
        }

        Err(io::Error::new(
            io::ErrorKind::InvalidData,
            "gpg_full_fingerprint_key_id_string not found in configuration file",
        ))
    }

    /// Helper function to parse a string value from the configuration format.
    /// Handles quoted strings and removes the quotes.
    ///
    /// # Arguments
    /// * `value` - The raw value string from the configuration file
    ///
    /// # Returns
    /// * `Ok(String)` with quotes removed if present
    /// * `Err(io::Error)` if the value format is invalid
    fn parse_string_value(value: &str) -> Result<String, io::Error> {
        let trimmed = value.trim();

        // Remove quotes if present
        if trimmed.starts_with('"') && trimmed.ends_with('"') && trimmed.len() >= 2 {
            Ok(trimmed[1..trimmed.len() - 1].to_string())
        } else {
            // Accept unquoted strings as well
            Ok(trimmed.to_string())
        }
    }

}


#[derive(Debug, Deserialize, serde::Serialize, Clone)]
struct CollaboratorTomlData {
    user_name: String,
    user_salt_list: Vec<u128>,
    ipv4_addresses: Option<Vec<Ipv4Addr>>,
    ipv6_addresses: Option<Vec<Ipv6Addr>>,
    gpg_publickey_id: String,
    gpg_key_public: String,
    sync_interval: u64,
    updated_at_timestamp: u64,
}

impl CollaboratorTomlData {
    fn new(
        user_name: String,
        user_salt_list: Vec<u128>, // Take ownership of user_salt_list
        ipv4_addresses: Option<Vec<Ipv4Addr>>,
        ipv6_addresses: Option<Vec<Ipv6Addr>>,
        gpg_publickey_id: String,
        gpg_key_public: String,
        sync_interval: u64,
        updated_at_timestamp: u64,
    ) -> CollaboratorTomlData {
        debug_log!("CollaboratorTomlData.new: user_salt_list {:?}", user_salt_list);
        CollaboratorTomlData {
            user_name,
            user_salt_list,
            ipv4_addresses,
            ipv6_addresses,
            gpg_publickey_id,
            gpg_key_public,
            sync_interval,
            updated_at_timestamp,
        }
    }
}


/*
addressbook creation with gpg encryption
*/

/// Prompts the user to choose between clearsigned TOML or GPG encrypted clearsigned TOML format.
///
/// This function presents a choice to the user for how to save the collaborator configuration:
/// - Clearsigned TOML (.toml) - Type "yes" (case-insensitive)
/// - GPG encrypted clearsigned TOML (.gpgtoml) - Any other input (default)
///
/// The function validates user input and returns their choice.
///
/// # Returns
/// * `true` - User chose clearsigned TOML only
/// * `false` - User chose GPG encrypted clearsigned TOML (default)
fn prompt_user_for_collaborator_file_format() -> bool {
    use std::io::{self, Write};

    println!("\n=== Collaborator File Format Selection ===");
    println!("Do you want to save this as a read-able clearsigned .toml, not encrypted .gpgtoml (also clearsigned)?");
    println!("The default (recommended) is GPG protected (.gpgtoml).");
    println!("Type 'clearsign' to choose clearsign only, anything else (or empty enter) for default (recommended) GPG encrypted.");
    print!("\nEnter your choice: ");

    // Ensure the prompt is displayed immediately
    let _ = io::stdout().flush();

    // Read user input
    let mut input = String::new();
    match io::stdin().read_line(&mut input) {
        Ok(_) => {
            // Trim whitespace and convert to lowercase for case-insensitive comparison
            let cleaned_input = input.trim().to_lowercase();
            // Return true only if user explicitly typed "yes"
            cleaned_input == "clearsign"
        }
        Err(e) => {
            eprintln!("Error reading input: {}. Defaulting to GPG encrypted format.", e);
            false // Default to encrypted on error
        }
    }
}

/// Encrypts a clearsigned TOML file using a provided GPG public key.
///
/// This function takes a clearsigned TOML file and encrypts it using the provided
/// public key content directly, without any keyring operations. The encrypted
/// content is saved to a new file with the .gpgtoml extension.
///
/// # Security
/// - Uses the public key content directly without keyring operations
/// - Creates temporary files with restricted permissions
/// - Ensures cleanup of all temporary files
/// - Does not modify or access the GPG keyring
///
/// # Arguments
/// * `clearsigned_toml_path` - Path to the clearsigned TOML file to encrypt
/// * `gpg_key_public` - The GPG public key content to use for encryption
/// * `output_gpgtoml_path` - Path where the encrypted file should be saved
///
/// # Returns
/// * `Result<(), std::io::Error>` - Ok(()) on success, or an error
fn encrypt_clearsigned_toml_with_public_key_content(
    clearsigned_toml_path: &Path,
    gpg_key_public: &str,
    output_gpgtoml_path: &Path,
) -> Result<(), std::io::Error> {
    use std::fs;
    use std::process::Command;

    debug_log!("Starting GPG encryption of clearsigned TOML");
    debug_log!("Input file: {}", clearsigned_toml_path.display());
    debug_log!("Output file: {}", output_gpgtoml_path.display());

    // Create a temporary file for the public key
    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map_err(|e| std::io::Error::new(
            std::io::ErrorKind::Other,
            format!("Time error: {}", e)
        ))?
        .as_nanos();

    let temp_pubkey_filename = format!("temp_pubkey_{}.asc", timestamp);
    let temp_dir = std::env::temp_dir();
    let temp_pubkey_path = temp_dir.join(&temp_pubkey_filename);

    // Write the public key to temporary file
    debug_log!("Writing public key to temporary file: {}", temp_pubkey_path.display());
    fs::write(&temp_pubkey_path, gpg_key_public)?;

    // Ensure cleanup happens regardless of success or failure
    let cleanup_result = (|| -> Result<(), std::io::Error> {
        // Read the clearsigned content
        let clearsigned_content = fs::read_to_string(clearsigned_toml_path)?;

        // Use GPG to encrypt with the public key directly (no keyring operations)
        let output = Command::new("gpg")
            .arg("--batch")
            .arg("--yes")
            .arg("--trust-model")
            .arg("always") // Trust the key without keyring
            .arg("--armor")
            .arg("--encrypt")
            .arg("--recipient-file")
            .arg(&temp_pubkey_path) // Use the public key file directly
            .arg("--output")
            .arg(output_gpgtoml_path)
            .arg(clearsigned_toml_path)
            .output()?;

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("GPG encryption failed: {}", stderr)
            ));
        }

        debug_log!("Successfully encrypted file to: {}", output_gpgtoml_path.display());
        Ok(())
    })();

    // Always clean up the temporary public key file
    if let Err(e) = fs::remove_file(&temp_pubkey_path) {
        eprintln!("Warning: Failed to remove temporary public key file {}: {}",
                  temp_pubkey_path.display(), e);
    }

    cleanup_result
}


// TODO, maybe add to buffy
/// Writes a single hotkey command with color highlighting directly to terminal
///
/// ## Memory: ZERO HEAP
/// Writes hotkey (RED) + description (YELLOW) using buffy_print
///
/// ## Parameters
/// - hotkey: The command character(s) to highlight in RED
/// - description: The rest of the text in YELLOW
///
/// ## Example
/// ```rust
/// write_red_hotkey("q", "uit ")?;  // Outputs: RED"q" + YELLOW"uit "
/// ```
fn write_red_hotkey(hotkey: &str, description: &str) -> io::Result<()> {
    buffy_print(
        "{}{}{}{}",
        &[
            BuffyFormatArg::Str(RED),
            BuffyFormatArg::Str(hotkey),
            BuffyFormatArg::Str(YELLOW),
            BuffyFormatArg::Str(description),
        ],
    )
}

const BOLD: &str = "\x1b[1m";
const GREEN: &str = "\x1b[32m";
// const BLUE: &str = "\x1b[34m";
// const BOLD: &str = "\x1b[1m";
// const ITALIC: &str = "\x1b[3m";
// const UNDERLINE: &str = "\x1b[4m";
const RED: &str = "\x1b[31m";
const YELLOW: &str = "\x1b[33m";
const BG_WHITE: &str = "\x1b[47m";
const BG_CYAN: &str = "\x1b[46m";
const RESET: &str = "\x1b[0m";
mod buffy_format_write_module;
use buffy_format_write_module::{BuffyFormatArg, buffy_print, buffy_println};

// TODO, maybe add to buffy
/// Writes a two-part hotkey command with color highlighting directly to terminal
///
/// ## Memory: ZERO HEAP
/// Writes hotkey_1 (RED) + hotkey_2 (GREEN) + description (YELLOW) using buffy_print
///
/// ## Parameters
/// - hotkey_1: First part of command to highlight in RED
/// - hotkey_2: Second part of command to highlight in GREEN
/// - description: The rest of the text in YELLOW
///
/// ## Example
/// ```rust
/// write_red_green_hotkey("s", "a", "v ")?;  // Outputs: RED"s" + GREEN"a" + YELLOW"v "
/// write_red_green_hotkey("/", "/", "/cmnt ")?;  // Outputs: RED"/" + GREEN"/" + YELLOW"/cmnt "
/// ```
fn write_red_green_hotkey(hotkey_1: &str, hotkey_2: &str, description: &str) -> io::Result<()> {
    buffy_print(
        "{}{}{}{}{}{}",
        &[
            BuffyFormatArg::Str(RED),
            BuffyFormatArg::Str(hotkey_1),
            BuffyFormatArg::Str(GREEN),
            BuffyFormatArg::Str(hotkey_2),
            BuffyFormatArg::Str(YELLOW),
            BuffyFormatArg::Str(description),
        ],
    )
}

/// Writes the complete navigation legend directly to terminal
///
/// ## Project Context
/// Displays all available keyboard commands for file navigation with
/// color-coded hotkeys. Each command section written independently for
/// maintainability - adding/removing commands requires no argument counting.
///
/// ## Memory: ZERO HEAP
/// All output written directly to terminal using buffy functions.
/// No intermediate String building, no heap allocation.
///
/// ## Operation
/// Writes legend in modular sections:
/// - Each command written separately via write_red_hotkey()
/// - Colors applied per-command (RED hotkey, YELLOW description)
/// - RESET applied at end
/// - Modular: Add/remove commands without affecting others
///
/// ## Safety & Error Handling
/// - Returns io::Result for write failures
/// - Each command write is independent
/// - Failure in one command doesn't affect others structurally
///
/// ## Legend Commands
/// - q: quit application
/// - sav: save current state (red and green and yellow)
/// - re: reload/refresh
/// - undo: undo last operation
/// - del: delete item
/// - nrm: normal mode
/// - ins: insert mode
/// - vis: visual mode
/// - hex: hex editor mode
/// - raw: raw view
/// - pasty: paste operation
/// - cvy: copy operation
/// - wrd,b,end: word navigation
/// - ///cmnt: comment operations (red and green and yellow)
/// - []idnt: indent operations
/// - hjkl: vim-style navigation
///
/// ## Example
/// ```rust
/// // In main display loop:
/// write_formatted_messagepost_legend_to_tui()?;
/// ```
fn write_formatted_messagepost_legend_to_tui() -> Result<(),Error> {
    // File operations group
        write_red_hotkey("Q", "uit ")?;

    // // Mode operations group
    write_red_hotkey("B", "ack|" )?;
    // write_red_hotkey("T", "ask ")?;
    // // Three Colour
    // write_red_green_hotkey("s", "a", "v ")?;
    // // Red only
    // write_red_hotkey("M", "essage|")?;

    // write_red_hotkey("A", "dd Node|")?;
    write_red_hotkey("Enter", " toggle Refesh/Insert|")?;
    write_red_hotkey("--custom", "|")?;
    // write_red_hotkey("hex", " ")?;

    // // View operations group
    write_red_hotkey("tall-", " ")?;
    write_red_hotkey("tall+", "|")?;
    // write_red_hotkey("cvy", "|")?;

    // // Navigation group
    write_red_hotkey("k", "/")?;
    write_red_hotkey("up", " ")?;
    write_red_hotkey("j", "/")?;
    write_red_hotkey("down", "|")?;

    // write_red_hotkey("e", "nd ")?;

    // // Comment/indent group
    // // Three Colour
    // write_red_green_hotkey("/", "/", "/cmnt ")?;
    // // Red only
    // write_red_hotkey("[]", "idnt ")?;

    // // Movement group
    // write_red_hotkey("hjkl", "")?;

    // Clear formatting: ANSI color codes are stateful
    // Make sure NEXT prints
    // are not also formatted.
    buffy_print("{}", &[BuffyFormatArg::Str(RESET)])?;

    // Complete the line with newline \n
    buffy_println("", &[])?;

    // Done
    Ok(())
}


/// Writes the complete navigation legend directly to terminal
///
/// ## Project Context
/// Displays all available keyboard commands for file navigation with
/// color-coded hotkeys. Each command section written independently for
/// maintainability - adding/removing commands requires no argument counting.
///
/// ## Memory: ZERO HEAP
/// All output written directly to terminal using buffy functions.
/// No intermediate String building, no heap allocation.
///
/// ## Operation
/// Writes legend in modular sections:
/// - Each command written separately via write_red_hotkey()
/// - Colors applied per-command (RED hotkey, YELLOW description)
/// - RESET applied at end
/// - Modular: Add/remove commands without affecting others
///
/// ## Safety & Error Handling
/// - Returns io::Result for write failures
/// - Each command write is independent
/// - Failure in one command doesn't affect others structurally
///
/// ## Legend Commands
/// - q: quit application
/// - sav: save current state (red and green and yellow)
/// - re: reload/refresh
/// - undo: undo last operation
/// - del: delete item
/// - nrm: normal mode
/// - ins: insert mode
/// - vis: visual mode
/// - hex: hex editor mode
/// - raw: raw view
/// - pasty: paste operation
/// - cvy: copy operation
/// - wrd,b,end: word navigation
/// - ///cmnt: comment operations (red and green and yellow)
/// - []idnt: indent operations
/// - hjkl: vim-style navigation
///
/// ## Example
/// ```rust
/// // In main display loop:
/// write_formatted_navigation_legend_to_tui()?;
/// ```
fn write_formatted_navigation_legend_to_tui() -> Result<(),Error> {
    // File operations group
    write_red_hotkey("q", "uit ")?;
    write_red_hotkey("home ", "")?;

    // // Mode operations group
    write_red_hotkey("b", "ack|" )?;
    write_red_hotkey("t", "ask ")?;
    // // Three Colour
    // write_red_green_hotkey("s", "a", "v ")?;
    // // Red only
    write_red_hotkey("m", "essage|")?;

    write_red_hotkey("add", " node|")?;
    // write_red_hotkey("hex", " ")?;

    // // View operations group

    write_red_green_hotkey("pt", "v", "/")?;

    write_red_green_hotkey("pm", "v", " ")?;

    // chagne name to refresh view?
    // write_red_hotkey("", "passive ")?;

    write_red_green_hotkey("", "tmux split", "")?;

    write_red_hotkey("", " refresh|")?;

    write_red_hotkey("invite", "")?;
    // write_red_hotkey("cvy", "|")?;

    // // Navigation group
    // write_red_hotkey("w", "rd,")?;
    // write_red_hotkey("b", ",")?;
    // write_red_hotkey("e", "nd ")?;

    // // Comment/indent group
    // // Three Colour
    // write_red_green_hotkey("/", "/", "/cmnt ")?;
    // // Red only
    // write_red_hotkey("[]", "idnt ")?;

    // // Movement group
    // write_red_hotkey("hjkl", "")?;

    // Clear formatting: ANSI color codes are stateful
    // Make sure NEXT prints
    // are not also formatted.
    buffy_print("{}", &[BuffyFormatArg::Str(RESET)])?;

    // Complete the line with newline \n
    buffy_println("", &[])?;

    // Done
    Ok(())
}


/// Writes the complete navigation legend directly to terminal
///
/// ## Project Context
/// Displays all available keyboard commands for file navigation with
/// color-coded hotkeys. Each command section written independently for
/// maintainability - adding/removing commands requires no argument counting.
///
/// ## Memory: ZERO HEAP
/// All output written directly to terminal using buffy functions.
/// No intermediate String building, no heap allocation.
///
/// ## Operation
/// Writes legend in modular sections:
/// - Each command written separately via write_red_hotkey()
/// - Colors applied per-command (RED hotkey, YELLOW description)
/// - RESET applied at end
/// - Modular: Add/remove commands without affecting others
///
/// ## Safety & Error Handling
/// - Returns io::Result for write failures
/// - Each command write is independent
/// - Failure in one command doesn't affect others structurally
///
/// ## Legend Commands
/// - q: quit application
/// - sav: save current state (red and green and yellow)
/// - re: reload/refresh
/// - undo: undo last operation
/// - del: delete item
/// - nrm: normal mode
/// - ins: insert mode
/// - vis: visual mode
/// - hex: hex editor mode
/// - raw: raw view
/// - pasty: paste operation
/// - cvy: copy operation
/// - wrd,b,end: word navigation
/// - ///cmnt: comment operations (red and green and yellow)
/// - []idnt: indent operations
/// - hjkl: vim-style navigation
///
/// ## Example
/// ```rust
/// // In main display loop:
/// write_formatted_navigation_legend_to_tui()?;
/// ```
fn write_formatted_taskbored_legend_to_tui() -> Result<(),Error> {
    // File operations group
        write_red_hotkey("q", "uit ")?;

    // // Mode operations group
    write_red_hotkey("b", "ack|" )?;
    // write_red_hotkey("t", "ask ")?;
    // // Three Colour
    // write_red_green_hotkey("s", "a", "v ")?;
    // // // Red only
    // write_red_hotkey("m", "essage|")?;

    write_red_hotkey("a", "dd task/node|")?;
    write_red_hotkey("int", " go to task-node")?;

    // // View operations group

    // write_red_green_hotkey("pt", "v", "/")?;

    // write_red_green_hotkey("pm", "v", " ")?;

    // write_red_hotkey("", " passive ")?;

    // write_red_green_hotkey("", "tmux split", "")?;

    // write_red_hotkey("", " refresh|")?;

    // write_red_hotkey("p", "asty ")?;
    // write_red_hotkey("cvy", "|")?;

    // // Navigation group
    // write_red_hotkey("w", "rd,")?;
    // write_red_hotkey("b", ",")?;
    // write_red_hotkey("e", "nd ")?;

    // // Comment/indent group
    // // Three Colour
    // write_red_green_hotkey("/", "/", "/cmnt ")?;
    // // Red only
    // write_red_hotkey("[]", "idnt ")?;

    // // Movement group
    // write_red_hotkey("hjkl", "")?;

    // Clear formatting: ANSI color codes are stateful
    // Make sure NEXT prints
    // are not also formatted.
    buffy_print("{}", &[BuffyFormatArg::Str(RESET)])?;

    // Complete the line with newline \n
    buffy_println("", &[])?;

    // Done
    Ok(())
}

/// Adds a new collaborator by creating a TOML configuration file in the executable-relative
/// collaborator directory.
///
/// This function creates a `CollaboratorTomlData` instance from the provided parameters,
/// serializes it to TOML format, and saves it to a file in the collaborator directory.
/// The file path is determined relative to the executable location rather than the current
/// working directory to ensure consistent path resolution regardless of where the program
/// is executed from.
///
/// The user is prompted to choose between:
/// - Clearsigned TOML file (.toml) - for compatibility
/// - GPG encrypted clearsigned TOML file (.gpgtoml) - for enhanced security (default)
///
/// # Security
/// - Files are always clearsigned for integrity verification
/// - Optional GPG encryption provides confidentiality
/// - The collaborator's public key is used for encryption
/// - No keyring operations are performed
///
/// # Arguments
///
/// * `user_name` - The collaborator's username
/// * `user_salt_list` - List of salt values used for this collaborator
/// * `ipv4_addresses` - Optional list of IPv4 addresses associated with the collaborator
/// * `ipv6_addresses` - Optional list of IPv6 addresses associated with the collaborator
/// * `gpg_publickey_id` - The GPG public key ID for the collaborator
/// * `gpg_key_public` - The GPG public key content for the collaborator
/// * `sync_interval` - The synchronization interval in seconds
/// * `updated_at_timestamp` - Unix timestamp of when this collaborator data was last updated
///
/// # Returns
///
/// * `Result<(), std::io::Error>` - Ok(()) if the operation succeeded, or an error if any step failed
///
/// # Errors
///
/// This function can return errors in the following cases:
/// * If creating the collaborator directory fails
/// * If serializing the collaborator data to TOML fails
/// * If creating or writing to the file fails
/// * If GPG operations fail (clearsigning or encryption)
pub fn make_new_collaborator_addressbook_toml_file(
    user_name: String,
    user_salt_list: Vec<u128>,
    ipv4_addresses: Option<Vec<Ipv4Addr>>,
    ipv6_addresses: Option<Vec<Ipv6Addr>>,
    gpg_publickey_id: String,
    gpg_key_public: String,
    sync_interval: u64,
    updated_at_timestamp: u64,
) -> Result<(), std::io::Error> {
    /*
    use std::fs::File;
    use std::io::Write;
    use std::net::{Ipv4Addr, Ipv6Addr};
    use std::path::Path;

    // Import the path management module
    use crate::manage_absolute_executable_directory_relative_paths::make_input_path_name_abs_executabledirectoryrelative_nocheck;
    use crate::manage_absolute_executable_directory_relative_paths::prepare_file_parent_directories_abs_executabledirectoryrelative;
    */
    debug_log("Starting: fn make_new_collaborator_addressbook_toml_file");

    // Log function parameters for debugging
    debug_log!("user_name {:?}", user_name);
    debug_log!("user_salt_list {:?}", &user_salt_list);
    debug_log!("ipv4_addresses {:?}", ipv4_addresses);
    debug_log!("ipv6_addresses {:?}", ipv6_addresses);
    debug_log!("gpg_publickey_id {:?}", &gpg_publickey_id);
    debug_log!("gpg_key_public {:?}", &gpg_key_public);
    debug_log!("sync_interval {:?}", sync_interval);
    debug_log!("updated_at_timestamp {:?}", updated_at_timestamp);

    // Create the CollaboratorTomlData instance
    let collaborator = CollaboratorTomlData::new(
        user_name,
        user_salt_list,
        ipv4_addresses,
        ipv6_addresses,
        gpg_publickey_id,
        gpg_key_public,
        sync_interval,
        updated_at_timestamp,
    );

    debug_log!("collaborator {:?}", collaborator);

    // Serialize the collaborator to TOML format
    // TODO this may need to be done inhouse
    let toml_string = match serialize_collaborator_to_toml(&collaborator) {
        Ok(content) => {
            debug_log!("Successfully serialized collaborator to TOML");
            content
        },
        Err(e) => {
            debug_log!("Error serializing to TOML: {}", e);
            return Err(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("TOML serialization error: {}", e),
            ));
        }
    };

    // Loop until we successfully create a collaborator file
    // This ensures the system can proceed, as it cannot function without this file
    loop {
        // Prompt user for file format choice
        let use_clearsign_only = prompt_user_for_collaborator_file_format();

        // Determine the file extension based on user choice
        let file_extension = if use_clearsign_only {
            "toml"
        } else {
            "gpgtoml"
        };

        debug_log!("User selected file format: .{}", file_extension);

        // Construct the relative path to the collaborator file
        // For .gpgtoml, we'll create a temporary .toml first
        let relative_path = format!(
            "{}/{}__collaborator.{}",
            COLLABORATOR_ADDRESSBOOK_PATH_STR,
            collaborator.user_name,
            if use_clearsign_only { "toml" } else { "toml" } // Always start with .toml
        );

        // TODO is it correct that this is not used??
        // Convert the relative path to an absolute path based on the executable's directory
        let file_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
            &relative_path
        ) {
            Ok(path) => path,
            Err(e) => {
                eprintln!("Error creating absolute path: {}. Trying again...", e);
                continue; // Try again
            }
        };

        // Ensure parent directories exist
        let prepared_path = match prepare_file_parent_directories_abs_executabledirectoryrelative(
            &relative_path
        ) {
            Ok(path) => path,
            Err(e) => {
                eprintln!("Error preparing parent directories: {}. Trying again...", e);
                continue; // Try again
            }
        };

        // Log the constructed file path
        debug_log!("Attempting to write collaborator file to: {:?}", prepared_path.display());

        // --- Block for file writing ---
        // This ensures `file` is dropped and the file is closed before the GPG operation.
        {
            let mut file = match File::create(&prepared_path) {
                Ok(f) => f,
                Err(e) => {
                    // Corrected debug_log! usage:
                    eprintln!("Error creating file '{}': {}. Trying again...", prepared_path.display(), e);
                    continue; // Try again
                }
            };

            // Write the serialized TOML to the file
            match file.write_all(toml_string.as_bytes()) {
                Ok(_) => {
                    // Corrected debug_log! usage:
                    debug_log!("Successfully wrote initial TOML data to collaborator file: {}", prepared_path.display());
                    // Do NOT return Ok(()) here yet. Proceed to the next step.
                },
                Err(e) => {
                    // Corrected debug_log! usage:
                    eprintln!("Error writing TOML data to file '{}': {}. Trying again...", prepared_path.display(), e);
                    continue; // Try again
                }
            }
        } // `file` is dropped here, so it's closed.

        // Now that the TOML file is written and closed, proceed to clearsign it in-place.
        // Corrected debug_log! usage:
        debug_log!("Attempting to clearsign the TOML file '{}' in-place.", prepared_path.display());

        // Call the in-place clearsigning function.
        // Note: `prepared_path` is a `PathBuf`. `&prepared_path` correctly provides a `&Path`.
        match convert_toml_filewithkeyid_into_clearsigntoml_inplace(&prepared_path) {
            Ok(()) => {
                // Clearsigning was successful.
                // Corrected debug_log! usage:
                debug_log!("Successfully converted '{}' to clearsigned TOML in-place.", prepared_path.display());

                // Now decide whether to encrypt or leave as clearsigned
                if use_clearsign_only {
                    // User chose clearsigned only, we're done
                    return Ok(());
                } else {
                    // User chose GPG encrypted, proceed with encryption
                    let gpgtoml_relative_path = format!(
                        "{}/{}__collaborator.gpgtoml",
                        COLLABORATOR_ADDRESSBOOK_PATH_STR,
                        collaborator.user_name,
                    );

                    let gpgtoml_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(&gpgtoml_relative_path) {
                        Ok(path) => path,
                        Err(e) => {
                            eprintln!("Error creating GPG output path: {}. Trying again...", e);
                            // Clean up the temporary .toml file
                            let _ = std::fs::remove_file(&prepared_path);
                            continue; // Try again
                        }
                    };

                    // Encrypt the clearsigned TOML file
                    match encrypt_clearsigned_toml_with_public_key_content(
                        &prepared_path,
                        &collaborator.gpg_key_public,
                        &gpgtoml_path
                    ) {
                        Ok(()) => {
                            // Encryption successful, remove the temporary .toml file
                            debug_log!("Successfully created encrypted file: {}", gpgtoml_path.display());

                            // Delete the temporary clearsigned .toml file
                            if let Err(e) = std::fs::remove_file(&prepared_path) {
                                eprintln!("Warning: Failed to remove temporary file {}: {}",
                                          prepared_path.display(), e);
                            }

                            return Ok(());
                        }
                        Err(e) => {
                            eprintln!("GPG encryption failed: {}. Please choose again.", e);
                            // Clean up the temporary .toml file
                            let _ = std::fs::remove_file(&prepared_path);
                            continue; // Try again with new user choice
                        }
                    }
                }
            }
            Err(gpg_error) => {
                // Clearsigning failed.
                eprintln!("Failed to clearsign file: {}. Trying again...", gpg_error);
                // Clean up the failed file
                let _ = std::fs::remove_file(&prepared_path);
                continue; // Try again
            }
        }
    } // End of retry loop
}

fn add_collaborator_qa(
    // graph_navigation_instance_state: &GraphNavigationInstanceState
) -> Result<(), io::Error> {

    println!("Name: Enter collaborator user name:");
    let mut new_username = String::new();
    io::stdin().read_line(&mut new_username)?;
    let new_username = new_username.trim().to_string();

    // Salt List!
    println!("Salt List: Press Enter for random, or type 'manual' for manual input");
    let mut new_usersalt_list_input = String::new();
    io::stdin().read_line(&mut new_usersalt_list_input)?;
    let new_usersalt_list_input = new_usersalt_list_input.trim().to_string();

    let new_usersalt_list: Vec<u128> = if new_usersalt_list_input == "manual" {
        let mut salts = Vec::new();
        for i in 1..=4 {
            println!("Enter salt {} (u128):", i);
            let mut salt_input = String::new();
            io::stdin().read_line(&mut salt_input)?;
            let salt: u128 = salt_input.trim().parse().expect("Invalid input, so using u128 input for salt");
            salts.push(salt);
        }
        salts
    } else {
        // Generate 4 random u128 salts
        (0..4)
            .map(|_| rand::rng().random())
            .collect()
    };

    println!("Using salts: {:?}", new_usersalt_list);


    // choice...
    // Get IP address input method
    // TODO for auto-detect don't use local-only ports... duh!!
    println!("Do you want to auto-detect IPv6 and IPv4? ('yes' or 'no' for manual input)");
    let mut pick_ip_find_method = String::new();
    io::stdin().read_line(&mut pick_ip_find_method)?;
    let pick_ip_find_method = pick_ip_find_method.trim().to_string();

    let (ipv4_addresses, ipv6_addresses) = if pick_ip_find_method == "yes" {
        // Auto-detect IP addresses
        let detected_addresses = get_local_ip_addresses()?;
        let mut ipv4_addresses: Option<Vec<Ipv4Addr>> = None;
        let mut ipv6_addresses: Option<Vec<Ipv6Addr>> = None;

        for addr in detected_addresses {
            match addr {
                IpAddr::V4(v4) => {
                    if ipv4_addresses.is_none() {
                        ipv4_addresses = Some(Vec::new());
                    }
                    ipv4_addresses.as_mut().unwrap().push(v4);
                }
                IpAddr::V6(v6) => {
                    if ipv6_addresses.is_none() {
                        ipv6_addresses = Some(Vec::new());
                    }
                    ipv6_addresses.as_mut().unwrap().push(v6);
                }
            }
        }
        (ipv4_addresses, ipv6_addresses) // Return the detected addresses
    } else {
        // Manual IP address input
        println!("Enter IPv4 address (or 'done' if finished, leave blank to skip):");
        let ipv4_addresses = get_ipv4_addresses()?;

        println!("Enter IPv6 address (or 'done' if finished, leave blank to skip):");
        let ipv6_addresses = get_ipv6_addresses()?;
        (ipv4_addresses, ipv6_addresses) // Return the manually entered addresses
    };

    println!("Enter the collaborator's public GPG key ID (public, NOT PRIVATE!!):");
    let mut gpg_publickey_id = String::new();
    io::stdin().read_line(&mut gpg_publickey_id)?;
    let gpg_publickey_id = gpg_publickey_id.trim().to_string();

    println!("Enter the collaborator's public GPG key is ascii armored lines (public, NOT PRIVATE!!):");
    let mut gpg_key_public = String::new();
    io::stdin().read_line(&mut gpg_key_public)?;
    let gpg_key_public = gpg_key_public.trim().to_string();

    println!("Enter the collaborator's sync interval in seconds (default: 60):");
    let mut sync_interval_input = String::new();
    io::stdin().read_line(&mut sync_interval_input)?;
    let sync_interval: u64 = sync_interval_input.trim().parse().unwrap_or(60);

    // Error Handling (You'll want to add more robust error handling here)
    if new_username.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "Username cannot be empty",
        ));
    }

    // Create the CollaboratorTomlData struct
    let new_collaborator = CollaboratorTomlData::new(
        new_username, // for: user_name
        new_usersalt_list, // for: user_salt
        ipv4_addresses,
        ipv6_addresses,
        gpg_publickey_id,
        gpg_key_public,
        sync_interval,
        get_current_unix_timestamp(), // for: updated_at_timestamp
    );

    // Load existing collaborators from files
    // let existing_collaborators = read_a_collaborator_setup_toml().unwrap_or_default();
    // let (existing_collaborators, errors) = read_one_collaborator_addressbook_toml().unwrap_or_default();

    // Persist the new collaborator
    make_new_collaborator_addressbook_toml_file(
        new_collaborator.user_name.clone(),
        new_collaborator.user_salt_list.clone(),
        new_collaborator.ipv4_addresses,
        new_collaborator.ipv6_addresses,
        new_collaborator.gpg_publickey_id,
        new_collaborator.gpg_key_public,
        new_collaborator.sync_interval,
        new_collaborator.updated_at_timestamp,
    )?;

    println!("CollaboratorTomlData '{}' added!", new_collaborator.user_name);
    Ok(())
}

/// Represents the current state of a user's navigation within the UMA project graph.
///
/// This struct holds information about the currently active team channel, the current node,
/// and other session-related data. It is used to manage user navigation and track the context
/// of user interactions.
///
/// In UMA, the file path of the `node.toml` file within the `project_graph_data/team_channels`
/// directory uniquely identifies a team channel. This method reads data from the `node.toml`
/// file at the current path to determine the active team channel and load relevant information.
#[derive(Debug, Deserialize, Serialize, Clone)]
struct GraphNavigationInstanceState {
    local_owner_user: String, // Store the local user data here
    // local_owner_hash_list: Vec<u8>,
    active_team_channel: String,
    default_im_messages_expiration_days: u64,
    default_task_nodes_expiration_days: u64,
    tui_height: u8,
    tui_width: u8,
    current_full_file_path: PathBuf,
    current_node_teamchannel_collaborators_with_access: Vec<String>,
    current_node_name: String,
    current_node_owner: String,
    current_node_description_for_tui: String,
    current_node_directory_path: PathBuf,
    current_node_unique_id: Vec<u8>,
    current_node_members: Vec<String>,
    home_square_one: bool,
    // from task fields:
    // project module items as task-ish thing
    pa1_process: String,
    pa2_schedule: Vec<u64>, // Vec<u64>,?
    pa3_users: String,
    // goals_features_subfeatures_tools_targets: String,
    pa4_features: String,
    pa5_mvp: String,
    pa6_feedback: String,
    /*
    pa1_process
    pa2_schedule
    pa3_users
    pa4_features
    pa5_mvp
    pa6_feedback

    The project areas
        pa1_process - Process: Values, Agenda, Methods, Coordinated Decisions (Data/System)Ecology: Collapse & Productivity
        pa2_schedule - Schedule: (?; whole; this iteration)
        pa3_users - Users: Stakeholders & Needs & Goals Evaluation (of users)
        pa4_features - Features: User-Features & Subfeatures (or hidden features)
        pa5_mvp - MVP: 'MVP's (Minimum Viable Products); Tools & 'Tool Stack / Tech Stack'
        pa6_feedback - Feedback: Tests, Ecological Effects, Communication, Documentation & Iteration (~agile)
    */

    /// message_post_gpgtoml_required
    message_post_gpgtoml_required:  Option<bool>,

    /// Integer validation ranges as tuples (min, max) - inclusive bounds
    /// e.g. option 1-3 (inclusive) are integers
    message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Integer-string validation ranges as tuples (min, max) for the integer part
    /// e.g. options 3-5 (inclusive) are write-in options
    message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Maximum string length
    message_post_max_string_length_int: Option<usize>,

    /// Whether posts are public or private
    message_post_is_public_bool: Option<bool>,

    /// Whether user confirmation is required before posting
    message_post_user_confirms_bool: Option<bool>,

    /// Start time for accepting posts (UTC POSIX timestamp)
    message_post_start_date_utc_posix: Option<i64>,

    /// End time for accepting posts (UTC POSIX timestamp)
    message_post_end_date_utc_posix: Option<i64>,

	// // limit of how many posts (or per time duration)
    //    max_posts: Option<i64>,
    //    duration_for_maxposts: MaxPostsDurationUnitsEnum, // hours, days, weeks
    //    n_durations_for_maxposts: Option<i64>,

    /// Padnet Network Layer
    use_padnet: bool,
}

impl GraphNavigationInstanceState {

    /// To read a node toml: See if you want to use load_core_node_from_toml_file() instead.
    ///
    /// This is the routine check to see, as you navigate around
    /// if you are not entering a new node (do nothing becuase
    /// there is no node.toml), if you are entering a new normal node,
    /// or if you are entering the special-case of a team-channel node.
    ///
    /// Loads and updates the `GraphNavigationInstanceState` based on the `current_full_file_path`.
    ///
    /// This method is called whenever the user navigates to a new directory within the
    /// UMA project graph. It determines the type of node (team-channel, project,
    ///  messages, tasks, etc., etc.)
    /// based on the `current_full_file_path` and loads relevant information from the
    /// `node.toml` file, updating the internal state accordingly.
    ///
    /// ## Team Channel Nodes
    ///
    /// If the `current_full_file_path` indicates a team-channel node (a directory within
    /// `project_graph_data/team_channels`), this method performs the following:
    ///
    /// 1. Sets the `active_team_channel` to the name of the team-channel.
    /// 2. Loads collaborator port assignments from the `node.toml` file.
    /// 3. Populates the `collaborator_ports` field with a `HashMap` mapping collaborator
    ///    usernames to their respective `CollaboratorPorts` struct.
    ///
    /// ## Other Node Types
    ///
    /// For project nodes and task nodes, this method will load relevant data from
    /// the `node.toml` file but will NOT load active_team_channel, as this is
    ///  only relevant at the team-channel level.
    ///
    /// ## Error Handling
    ///
    /// If the `node.toml` file is not found or cannot be parsed, the method logs an error
    /// message and returns without updating the state.
    ///
    /// This function specifically loads Port assignments if the `current_full_file_path`
    /// corresponds to a team-channel node, as indicated by the path being within the
    /// `project_graph_data/team_channels` directory.
    ///
    /// Not all information has the same owner-author and privacy requirements and so cannot be obtained from any mythical singularity. Port-assignments are made by the owner of the team-channel so as to be guaranteed not to collide and adding a new user/collaborator will not disrupt existing processes/collaborators/users/workers/participants/network-connections.
    /// A user's ip addresses and gpg keys and screen-name can only come from, and be owned by, that user/collaborator.
    ///
    /// Likewise, the list of possible collaborators is set by the team-channel-owner. But whether another collaborator has actually shared their private connection data with you is and must be 100% their choice done by them and owned by them GPG signed by them and GPG encrypted for only 'you' (the current user) to use.
    ///
    /// The 'collaborators' for your session are then an intersection between these two categories of sources of truth: the collaborators who have connected with you (their choice, their owned documents), and the collaborators invited to the team-channel by the team-channel-owner (their choice, their owned document).
    /// Note: Your no-context set of all-collaborators is everyone in every channel, a general no-context address-book.
    /// By analogy: Tom is organizing a flower show and says Alice Bob and you are invited, and he asks you to call them.
    /// Bob is the one who chooses who to invite.
    /// You have an address book that includes Alice and Bob and everyone else in your address book.
    ///
    /// To make these call-connections you need to find the intersection between these two sets:
    /// 1. Who did the team-owner (Tom) invite to the flower show?
    /// 2. Who is in your address book?
    ///
    /// You cannot call everyone in your address book, because Tom didn't invite everyone in your address book.
    /// And Tom can't tell you Bob's phone number and call availability information, because only Bob can tell you his own private information.
    ///
    /// This means there are at least two sources or two different categories of truths that must be used when loading "state" for a session in a team-channel in Uma.
    ///
    /// Note: it is crutial that he source of truth for whether a node is a team-channel node be the file-structure itself
    /// and that code to extract team-channel connection data (such as port-assignments) is never attempted used in other
    /// nodes such as non-team-channel nodes within that team-channel (nearly ~everything is a node, only a few are team-channels)
    fn nav_graph_look_read_node_toml(&mut self) {
        debug_log!(
            "NGLRNT! starting nav_graph_look_read_node_toml() self.current_full_file_path -> {:?}, self.active_team_channel.clone() -> {:?}",

            self.current_full_file_path.clone(),
            self.active_team_channel.clone(),
        );

        // TODO check for node.toml or .gpgtoml

        // Construct path to node.toml or node.gpgtoml
        // Find the configuration file (could be either node.toml OR node.gpgtoml)
        let node_toml_path = match find_node_toml_or_gpgtoml_file(
            &self.current_full_file_path,
            ) {
            Ok(Some(path)) => {
                // This is the path to whichever file was found (node.toml OR node.gpgtoml)
                debug_log!("FNGLRNT ound configuration file at: {:?}", path);
                path  // <-- This could be either file!
            },
            Ok(None) => {
                // No file found - handle the error properly
                debug_log("NGLRNT Neither node.toml nor node.gpgtoml found");
                return;
            },
            Err(e) => {
                // Error occurred - handle it properly
                debug_log!("NGLRNT Neither node.toml nor node.gpgtoml found >> {}", e);
                return;
            }
        };

        // Now you have node_toml_path available for use
        debug_log!(
            "NGLRNT nav_graph_look_read_node_toml() node_toml_path -> {:?}",
            node_toml_path.clone()
        );

        // Add more detailed existence checking
        debug_log!("NGLRNT Checking if path exists: {:?}", node_toml_path.exists());
        debug_log!("NGLRNT Checking if path is file: {:?}", node_toml_path.is_file());

        debug_log!(
            "NGLRNT nav_graph_look_read_node_toml() node_toml_path -> {:?}",
            node_toml_path.clone()
        );

        debug_log!(
            "NGLRNT nav_graph_look_read_node_toml() node_toml_path -> {:?}",
            node_toml_path.clone()
        );

        // Add more detailed existence checking
        debug_log!("NGLRNT Checking if path exists: {:?}", node_toml_path.exists());
        debug_log!("NGLRNT Checking if path is file: {:?}", node_toml_path.is_file());

        // if no file exists, return immediately!
        if !node_toml_path.exists() {
            debug_log!("NGLRNT No node.toml at {:?} - this directory is not a node", node_toml_path);
            return;
        }

        // // Try to read the file metadata
        // match fs::metadata(&node_toml_path) {
        //     Ok(metadata) => {
        //         debug_log!("File metadata found: is_file={}, size={}", metadata.is_file(), metadata.len());
        //     },
        //     Err(e) => {
        //         debug_log!("\n\n nav_graph_look_read_node_toml() Error reading file metadata: {}", e);
        //     }
        // }

        debug_log("NGLRNT In nav_graph_look_read_node_toml(), next calling: load_core_node_from_toml_file(file_path: &Path) -> Result<CoreNode");
        // Try to open and read the file
        // match fs::read_to_string(&node_toml_path) {
        //     Ok(contents) => {
        //         debug_log!("Successfully read file, content length: {}", contents.len());



        // // A. Check for either node.toml or node.gpgtoml
        // let node_toml_path = channel_dir_path.join("node.toml");
        // let node_gpgtoml_path = channel_dir_path.join("node.gpgtoml");

        // let raw_channelnodetoml_path = if node_toml_path.exists() {
        //     debug_log!("TCS: Found node.toml");
        //     node_toml_path
        // } else if node_gpgtoml_path.exists() {
        //     debug_log!("TCS: Found node.gpgtoml");
        //     node_gpgtoml_path
        // } else {
        //     return Err(MyCustomError::from(
        //         "TCS: Neither node.toml nor node.gpgtoml found in team channel directory".to_string()
        //     ));
        // };

        // // Get GPG fingerprint (could move this outside the loop if same for all)
        // let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        //     Ok(fingerprint) => fingerprint,
        //     Err(e) => {
        //         #[cfg(debug_assertions)]
        //         debug_log!(
        //             "NGLRNT error Failed to read GPG fingerprint for {:?}:  (skipping)",
        //             e
        //         );
        //         // continue; // Skip this directory, continue with next
        //         return
        //     }
        // };

        // // Get temp directory path (could move this outside the loop if same for all)
        // let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
        //     Ok(path) => path,
        //     Err(e) => {
        //         #[cfg(debug_assertions)]
        //         debug_log!(
        //             "NGLRNT error Failed to get temp directory path for {:?}: (skipping)",
        //             e
        //         );
        //         // continue; // Skip this directory, continue with next
        //         return
        //     }
        // };

        // // Get readable copy
        // // Get readable copy
        // let node_readcopy_path_string = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        //     &node_toml_path,
        //     &gpg_full_fingerprint_key_id_string,
        //     &base_uma_temp_directory_path,
        // ) {
        //     Ok(path) => path,
        //     Err(e) => {
        //         #[cfg(debug_assertions)]
        //         debug_log!(
        //             "NGLRNT error Failed to get read copy for {:?}: {:?} (skipping)",
        //             node_toml_path,
        //             e
        //         );
        //         // continue; // Skip this directory, continue with next
        //         return
        //     }
        // };

        // debug_log!("NGLRNT: channel_node_tomlpath_string
        //     : {}", node_readcopy_path_string
        // );

        // let path_node_readcopy_path = Path::new(&node_readcopy_path_string);

        // debug_log!("NGLRNT: path_node_readcopy_path
        //     : {:?}", path_node_readcopy_path
        // );

        // Load and parse the node.toml file
        let this_node = match load_core_node_from_toml_file(&node_toml_path) {
            Ok(node) => node,
            Err(e) => {
                debug_log!("NGLRNT ERROR: nav_graph_look_read_node_toml(), load_core_node_from_toml_file(), Failed to load node.toml: {}", e);
                return;
            }
        };

        debug_log!("NGLRNT nav_graph_look_read_node_toml(), this_node -> {:?}", this_node);

        // // Check if this is a Team Channel Node using path components
        // let is_team_channel = self.current_full_file_path
        //     .components()
        //     .any(|component| component.as_os_str() == "team_channels");
        debug_log(&format!("NGLRNT self.current_full_file_path {:?}", self.current_full_file_path));


        let is_team_channel: bool;
        // Get the last three components as an iterator
        let last_three: Vec<_> = self.current_full_file_path.iter().rev().take(3).collect();
        // Reverse back to original order
        let last_three: Vec<_> = last_three.into_iter().rev().collect();
        // Take the first two of these three
        let first_two_of_last_three = &last_three[..2];
        // Convert to strings for comparison
        let first_two_strs: Vec<String> = first_two_of_last_three
            .into_iter()
            .filter_map(|c| c.to_str())
            .map(|s| s.to_string())
            .collect();
        // Join with "/" for comparison
        let first_two_joined = first_two_strs.join("/");
        if first_two_joined == "project_graph_data/team_channels" {
            debug_log!("NGLRNT in: project_graph_data/team_channels");
            is_team_channel = true;
        } else {
            // println!("HCMM Path does not match.");
            debug_log!("NGLRNT not in: project_graph_data/team_channels");
            is_team_channel = false;
        }



        if is_team_channel {
            debug_log!("nav_graph_look_read_node_toml(), IS team channel node");
            // Update state for team channel node
            self.active_team_channel = this_node.node_name.clone();
            self.current_node_teamchannel_collaborators_with_access = this_node.teamchannel_collaborators_with_access.clone();
            self.current_node_name = this_node.node_name.clone();
            self.current_node_owner = this_node.owner.clone();
            self.current_node_description_for_tui = this_node.description_for_tui.clone();
            self.current_node_directory_path = this_node.directory_path.clone();
            self.current_node_unique_id = this_node.node_unique_id;
            self.home_square_one = false;

            // Project Areas
            self.pa1_process = this_node.pa1_process;
            self.pa2_schedule = this_node.pa2_schedule;
            self.pa3_users = this_node.pa3_users;
            self.pa4_features = this_node.pa4_features;
            self.pa5_mvp = this_node.pa5_mvp;
            self.pa6_feedback = this_node.pa6_feedback;

            // Message posting configuration fields (if present in CoreNode)
            self.message_post_gpgtoml_required = None;
            self.message_post_data_format_specs_integer_ranges_from_to_tuple_array = None;
            self.message_post_data_format_specs_int_string_ranges_from_to_tuple_array = None;
            self.message_post_max_string_length_int = None;
            self.message_post_is_public_bool = None;
            self.message_post_user_confirms_bool = None;
            self.message_post_start_date_utc_posix = None;
            self.message_post_end_date_utc_posix = None;

        } else {
            debug_log!("nav_graph_look_read_node_toml(), not a team channel node");
            /*
            this should be loading... node items...
            */

            // Update state for non-team-channel nodes
            // These fields should be updated for ANY node type
            self.current_node_teamchannel_collaborators_with_access = this_node.teamchannel_collaborators_with_access.clone();
            self.current_node_name = this_node.node_name.clone();
            self.current_node_owner = this_node.owner.clone();
            self.current_node_description_for_tui = this_node.description_for_tui.clone();
            self.current_node_directory_path = this_node.directory_path.clone();
            self.current_node_unique_id = this_node.node_unique_id;
            // self.current_node_members = this_node.members.clone();
            self.home_square_one = false;

            // Project Areas - these should be available for any node
            self.pa1_process = this_node.pa1_process;
            self.pa2_schedule = this_node.pa2_schedule;
            self.pa3_users = this_node.pa3_users;
            self.pa4_features = this_node.pa4_features;
            self.pa5_mvp = this_node.pa5_mvp;
            self.pa6_feedback = this_node.pa6_feedback;

            // Message posting configuration fields (if present in CoreNode)
            self.message_post_gpgtoml_required = this_node.message_post_gpgtoml_required;
            self.message_post_data_format_specs_integer_ranges_from_to_tuple_array = this_node.message_post_data_format_specs_integer_ranges_from_to_tuple_array;
            self.message_post_data_format_specs_int_string_ranges_from_to_tuple_array = this_node.message_post_data_format_specs_int_string_ranges_from_to_tuple_array;
            self.message_post_max_string_length_int = this_node.message_post_max_string_length_int;
            self.message_post_is_public_bool = this_node.message_post_is_public_bool;
            self.message_post_user_confirms_bool = this_node.message_post_user_confirms_bool;
            self.message_post_start_date_utc_posix = this_node.message_post_start_date_utc_posix;
            self.message_post_end_date_utc_posix = this_node.message_post_end_date_utc_posix;

            // Note: We do NOT update active_team_channel
            // because these are only relevant for team-channel nodes


        }
            // },
            // Err(e) => {
            //     // the error would be an error in reading node.toml
            //     // it is not an error to not need to try to read
            //     // a file that is not there.
            //     debug_log!("NGLRNT Error reading file: {}", e);
            //     debug_log!("NGLRNTThis directory is not a node. nav_graph_look_read_node_toml() node.toml not found at {:?}. ", node_toml_path);
            //     return;
            // }
        // }

        // // create team channel...path state
        // // set file-state team-channel's current_node_directory_path
        // let file_path = get_sessionstateitems_path()?.join("current_node_directory_path.txt");
        // if let Some(path_str) = self.current_node_directory_path.to_str() {
        //     fs::write(file_path, path_str)?;
        // }

        // create team channel...path state
        // set file-state team-channel's current_node_directory_path
        if let Ok(session_path) = get_sessionstateitems_path() {
            let file_path = session_path.join("current_node_directory_path.txt");
            if let Some(path_str) = self.current_node_directory_path.to_str() {
                if let Err(e) = fs::write(file_path, path_str) {
                    debug_log!("NGLRNT Failed to write file: {}", e);
                    // Optionally log the error or handle it in another way
                }
            }
        } else {
            debug_log!("NGLRNT Failed to get session state items path");
            // Optionally log the error or handle it in another way
        }

        debug_log!("NGLRNT Done: ending: nav_graph_look_read_node_toml()");
    }
}  // end of impl GraphNav...

/// Helper function to parse directory name in format "number_name"
fn parse_directory_name(name: &str) -> Option<(usize, &str)> {
    let parts: Vec<&str> = name.splitn(2, '_').collect();
    if parts.len() == 2 {
        if let Ok(num) = parts[0].parse::<usize>() {
            return Some((num, parts[1]));
        }
    }
    None
}

/// Helper function to truncate string to specified length
fn truncate_string(s: &str, max_len: usize) -> String {
    if s.len() <= max_len {
        s.to_string()
    } else {
        format!("{}...", &s[..max_len.saturating_sub(3)])
    }
}

//e.g.
// // Load active_team_channel:
// self.active_team_channel = fs::read_to_string(session_items_path.join("active_team_channel.txt"))?;

#[derive(Debug, Deserialize, Serialize, Clone)]
enum NodePriority {
    High,
    Medium,
    Low,
}

/*
the .toml files and the overall Uma~browser must be able to know their location in the overall project_graph_data/file-system

1. command 'make node' needs to be filled in to make a node in the 'current'
graph-dungeon location.
2. produce a .toml file in the node when node is made
3. load from the .toml file node is navigated into
4. node_name needs to be integrated, and accessed when the node is navigated into
*/

/// Represents a core node in the UMA project graph.
///
/// This struct holds information about a node, including its name, description, collaborators,
/// port assignments for collaborators, and other metadata. It is used to save and load node
/// data to and from `node.toml` files.
///
/// # Collaborator Ports
///
/// Collaborator port assignments are stored in the `abstract_collaborator_port_assignments` field, which is a
/// `HashMap`. The keys of the `HashMap` are the usernames of the collaborators (strings),
/// and the values are instances of the `CollaboratorPorts` struct.
///
/// The `CollaboratorPorts` struct contains six `u16` fields representing the different ports
/// assigned to each collaborator for synchronization purposes:
///  - `ready_port`: The port used by a collaborator to signal they are ready to receive data.
///  - `tray_port`: The port used to send files to a collaborator (their "in-tray").
///  - `gotit_port`: The port used by a collaborator to confirm receipt of a file.
///  - `self_ready_port`: The port this node listens on for ready signals from the collaborator.
///  - `self_tray_port`: The port this node listens on for incoming files from the collaborator.
///  - `self_gotit_port`: The port this node uses to confirm file receipt to the collaborator.
///
/// ## Serialization and Deserialization
///
/// When saving a `CoreNode` to a `node.toml` file (using the `save_node_to_clearsigned_file` function),
/// the `abstract_collaborator_port_assignments` field is serialized as a TOML table where the keys are the
/// collaborator usernames and the values are tables containing the six port assignments.
///
/// When loading a `CoreNode` from a `node.toml` file (using the `load_node_from_file` function),
/// the TOML table representing collaborator ports is deserialized into the
/// `abstract_collaborator_port_assignments` field.
///
/// ## Example `node.toml` Section
///
/// ```toml
/// [abstract_collaborator_port_assignments]
/// alice = { ready_port = 50001, tray_port = 50002, gotit_port = 50003, self_ready_port = 50004, self_tray_port = 50005, self_gotit_port = 50006 }
/// bob = { ready_port = 50011, tray_port = 50012, gotit_port = 50013, self_ready_port = 50014, self_tray_port = 50015, self_gotit_port = 50016 }
/// ```
///
/// there is a design and security debate over how to define a team-channel node
/// I think it is safer to define it as a physical directory basal location, in the team_channels direcorry
/// rather than give it ia declarative-definiiton where anyone could invent or uninvent a team-channel
/// and all the port use that goes along with that
#[derive(Debug, Deserialize, Serialize, Clone)]
struct CoreNode {
    /// The name of the node. This is used for display and identification.
    node_name: String,
    /// Is node.toml file gpg encrypted
    corenode_gpgtoml: bool,
    /// A description of the node, intended for display in the TUI.
    description_for_tui: String,
    /// A unique identifier for the node, generated using pearson hashes of the other fields
    node_unique_id: Vec<u8>,
    /// The path to the directory on the file system where the node's data is stored.
    directory_path: PathBuf,
    /// The username of the owner of the node.
    owner: String,
    /// The Unix timestamp representing when the node was last updated.
    updated_at_timestamp: u64,
    /// The Unix timestamp representing when the node will expire.
    expires_at: u64,
    /// An ordered vector of collaborator usernames associated with this node.
    teamchannel_collaborators_with_access: Vec<String>,
    /// A map containing port assignments for each collaborator associated with the node.
    abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,

    /// project areas: project module items as task-ish thing
    pa1_process: String,
    pa2_schedule: Vec<u64>,
    pa3_users: String,
    pa4_features: String,
    pa5_mvp: String,
    pa6_feedback: String,

    /////////////////
    // message_posts
    /////////////////

    /// maybe: gpg encrypted messages (new clearsign standard?)
    pub message_post_gpgtoml_required: Option<bool>,

    /// Integer validation ranges as tuples (min, max) - inclusive bounds
    pub message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Integer-string validation ranges as tuples (min, max) for the integer part
    pub message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Maximum string length
    pub message_post_max_string_length_int: Option<usize>,

    /// Whether posts are public or private
    pub message_post_is_public_bool: Option<bool>,

    /// Whether user confirmation is required before posting
    pub message_post_user_confirms_bool: Option<bool>,

    /// Start time for accepting posts (UTC POSIX timestamp)
    pub message_post_start_date_utc_posix: Option<i64>,

    /// End time for accepting posts (UTC POSIX timestamp)
    pub message_post_end_date_utc_posix: Option<i64>,

	// limit of how many posts (or per time duration)
    // pub max_posts: Option<i64>,
    // pub duration_for_maxposts: MaxPostsDurationUnitsEnum, // hours, days, weeks
    // pub n_durations_for_maxposts: Option<i64>,

    // Padnet
    pub use_padnet: Option<bool>,
}

/// Creates a new `CoreNode` instance.
///
/// # Arguments
///
/// * `node_name` - The name of the node.
/// * `description_for_tui` - A description for display in the TUI.
/// * `directory_path` - The path to the node's directory.
/// * `order_number` - The order number for the node.
/// * `priority` - The priority of the node.
/// * `owner` - The username of the node's owner.
/// * `collaborators` - An ordered vector of collaborator usernames.
/// * `abstract_collaborator_port_assignments` - A map of collaborator port assignments.
///
/// # Returns
///
/// * A new `CoreNode` instance with the given attributes.
///
/// The name of the node. This is used for display and identification.
/// node_name: String,
/// A description of the node, intended for display in the TUI.
/// description_for_tui: String,
/// A unique identifier for the node, generated using a timestamp at node creation.
/// node_unique_id: u64,
/// The path to the directory on the file system where the node's data is stored.
/// directory_path: PathBuf,
/// An order number used to define the node's position within a list or hierarchy.
/// order_number: u32,
/// The priority of the node, which can be High, Medium, or Low.
/// priority: NodePriority,
/// The username of the owner of the node.
/// owner: String,
/// The Unix timestamp representing when the node was last updated.
/// updated_at_timestamp: u64,
/// The Unix timestamp representing when the node will expire.
/// expires_at: u64,
/// A vector of `CoreNode` structs representing the child nodes of this node.
/// children: Vec<CoreNode>,
/// An ordered vector of collaborator usernames associated with this node.
/// teamchannel_collaborators_with_access: Vec<String>,
/// A map containing port assignments for each collaborator associated with the node.
/// abstract_collaborator_port_assignments: HashMap<String, CollaboratorPorts>,
///
/// # Arguments
///
/// * `node_name` - The name of the node
/// * `description_for_tui` - Description to display in the TUI
/// * `directory_path` - Absolute path to the node's directory
/// * `owner` - Username of the node owner
/// * `teamchannel_collaborators_with_access` - List of collaborators with access
/// * `abstract_collaborator_port_assignments` - Port assignments for collaborators
/// * `pa1_process` - Project area 1: process description
/// * `pa2_schedule` - Project area 2: schedule timestamps
/// * `pa3_users` - Project area 3: users description
/// * `pa4_features` - Project area 4: features description
/// * `pa5_mvp` - Project area 5: MVP description
/// * `pa6_feedback` - Project area 6: feedback description
/// message_post_gpgtoml_required
/// * `message_post_data_format_specs_integer_ranges_from_to_tuple_array` - Integer validation ranges
/// * `message_post_data_format_specs_int_string_ranges_from_to_tuple_array` - Integer-string validation ranges
/// * `message_post_max_string_length_int` - Max string length for int-string pairs
/// * `message_post_is_public_bool` - Whether posts are public
/// * `message_post_user_confirms_bool` - Whether user confirmation is required
/// * `message_post_start_date_utc_posix` - Start date for accepting posts
/// * `message_post_end_date_utc_posix` - End date for accepting posts
impl CoreNode {
    fn new(
        node_name: String,
        corenode_gpgtoml: bool,
        description_for_tui: String,
        directory_path: PathBuf,
        owner: String,
        teamchannel_collaborators_with_access: Vec<String>,
        abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
        // Project Areas
        pa1_process: String,
        pa2_schedule: Vec<u64>, // Vec<u64>
        pa3_users: String,
        pa4_features: String,
        pa5_mvp: String,
        pa6_feedback: String,
        // Message Post Configuration
        message_post_gpgtoml_required: Option<bool>,
        message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,
        message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,
        message_post_max_string_length_int: Option<usize>,
        message_post_is_public_bool: Option<bool>,
        message_post_user_confirms_bool: Option<bool>,
        message_post_start_date_utc_posix: Option<i64>,
        message_post_end_date_utc_posix: Option<i64>,
        use_padnet: Option<bool>,
    ) -> Result<CoreNode, ThisProjectError> {

        debug_log!("Starting CoreNode:new");
        debug_log!("implCoreNode-new: Directory path received: {:?}", directory_path);
        debug_log!("implCoreNode-new: Checking if directory exists: {}", directory_path.exists());
        debug_log!("implCoreNode-new: Absolute path: {:?}", directory_path.canonicalize().unwrap_or(directory_path.clone()));

        debug_log!("implCoreNode-new: About to get current timestamp");
        let expires_at = get_current_unix_timestamp() + 11111111111;
        let updated_at_timestamp = get_current_unix_timestamp();
        debug_log!("implCoreNode-new: Got timestamps");

        // Get armored public key, using key-id (full fingerprint in)
        let full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => fingerprint,
            Err(e) => {
                eprintln!("implCoreNode-new: Failed to read GPG fingerprint from uma.toml: {}", e);
                return Err(ThisProjectError::from(format!(
                    "implCoreNode-new: Failed to read GPG fingerprint from uma.toml: {}", e
                )));
            }
        };

        // 1. Get the salt list using the correct function
        debug_log!("implCoreNode-new: About to get address book data for owner: {}", owner);
        let owner_data = match get_addressbook_file_by_username(
            &owner,
            &full_fingerprint_key_id_string,
            ) {
            Ok(data) => {
                debug_log!("implCoreNode-new: Successfully got address book data");
                data
            },
            Err(e) => {
                debug_log!("implCoreNode-new: impl corenode new() Error getting address book data: {:?}", e);
                return Err(e);
            }
        };
        let salt_list = owner_data.user_salt_list;

        debug_log!("implCoreNode-new: About to calculate node_unique_id");
        // 2. Calculate the hash
        // TODO add new fields to hash
        let node_unique_id = match calculate_corenode_hashes(
            &node_name,
            &description_for_tui,
            updated_at_timestamp,
            &salt_list,
        ) {
            Ok(id) => {
                debug_log!("implCoreNode-new: Successfully calculated node_unique_id");
                id
            },
            Err(e) => {
                debug_log!("implCoreNode-new: Error calculating node_unique_id: {:?}", e);
                return Err(e);
            }
        };

        debug_log!("implCoreNode-new: About to create CoreNode instance");
        // 3. Create the CoreNode instance
        let node = CoreNode {
            node_name,
            corenode_gpgtoml,
            description_for_tui,
            node_unique_id,
            directory_path,
            owner,
            updated_at_timestamp,
            expires_at,
            teamchannel_collaborators_with_access,
            abstract_collaborator_port_assignments,
            // Project Areas
            pa1_process,
            pa2_schedule, // Vec<u64>
            pa3_users,
            pa4_features,
            pa5_mvp,
            pa6_feedback,
            // Message Post Configuration
            message_post_gpgtoml_required,
            message_post_data_format_specs_integer_ranges_from_to_tuple_array,
            message_post_data_format_specs_int_string_ranges_from_to_tuple_array,
            message_post_max_string_length_int,
            message_post_is_public_bool,
            message_post_user_confirms_bool,
            message_post_start_date_utc_posix,
            message_post_end_date_utc_posix,
            use_padnet,
        };
        debug_log!("Successfully created CoreNode instance");

        Ok(node)
    }

    /// Saves the `CoreNode` data to a `node.toml` file.
    ///
    /// This function serializes the `CoreNode` struct into TOML format and writes
    /// it to a file at the path specified by the `directory_path` field, creating
    /// the directory if it doesn't exist.
    ///
    /// # Error Handling
    ///
    /// Returns a `Result<(), io::Error>` to handle potential errors during:
    ///  - TOML serialization
    ///  - Directory creation
    ///  - File writing
    fn save_node_to_clearsigned_file(&self) -> Result<(), io::Error> {
        // Debug logging for initial state
        debug_log!("in imple CoreNode: SNCTF -> Starting save_node_to_clearsigned_file!");
        debug_log!("SNCTF: Current working directory: {:?}", std::env::current_dir()?);
        debug_log!("SNCTF: Target directory path: {:?}", self.directory_path);

        // 1. Verify and create directory structure
        if !self.directory_path.exists() {
            debug_log!("SNCTF: Directory doesn't exist, creating it");
            fs::create_dir_all(&self.directory_path)?;
        }
        debug_log!("SNCTF: Directory now exists: {}", self.directory_path.exists());

        // 2. Verify directory is actually a directory
        if !self.directory_path.is_dir() {
            debug_log!("SNCTF: Path exists but is not a directory!");
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNCTF: Path exists but is not a directory"
            ));
        }

        // 3. Serialize the CoreNode struct to a TOML string
        let toml_string = toml::to_string(&self).map_err(|e| {
            debug_log!("SNCTF: TOML serialization error: {}", e);
            io::Error::new(
                io::ErrorKind::Other,
                format!("SNCTF: TOML serialization error: {}", e),
            )
        })?;
        debug_log!("SNCTF: Successfully serialized CoreNode to TOML");

        // 4. Construct and verify the file path
        let file_path = self.directory_path.join("node.toml");
        debug_log!("SNCTF: Full file path for node.toml: {:?}", file_path);

        // 5. Verify parent directory one more time
        if let Some(parent) = file_path.parent() {
            if !parent.exists() {
                debug_log!("SNCTF: Parent directory missing, creating: {:?}", parent);
                fs::create_dir_all(parent)?;
            }
        }

        // 6. Write the TOML data to the file
        debug_log!("SNCTF: Writing TOML data to file...");
        fs::write(&file_path, &toml_string)?;

        // 7. Verify the file was created
        if file_path.exists() {
            debug_log!("SNCTF: Successfully created node.toml at: {:?}", file_path);
        } else {
            debug_log!("SNCTF: Warning: File write succeeded but file doesn't exist!");
        }

        /*

        this will include an extra lookup step:
                1. get file_owner name from the clearsign-toml file
                2. look up user addressbook file by user-name
                3. get key-id from file-owner's addressbook file
                4. clearsign with key-id so that reader can varify clearsign with public-key
                from addressbook file.
                convert_toml_filewithkeyid_into_clearsigntoml_inplace?
                maybe new function with extra lookup step...

        the new function will be:
        fn convert_tomlfile_without_keyid_into_clearsigntoml_inplace(
            path_to_toml_file: &Path,
        ) -> Result<(), GpgError> {

        these may be the needed steps:

            // Read username from the configuration file, mapping any reading errors to our error type
            let file_owner_username = read_single_line_string_field_from_toml(config_path_str, "owner")
                .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
                    format!("Failed to read file_owner_username from config: {}", error_message)
                ))?;

            debug_log!("file_owner_username {}", file_owner_username);

            // Convert the collaborator files directory to an absolute path based on the executable's location
            // AND verify that the directory exists (returns error if not found or not a directory)
            let addressbook_files_directory_relative = COLLABORATOR_ADDRESSBOOK_PATH_STR;
            let addressbook_files_directory_absolute = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(
                addressbook_files_directory_relative
            ).map_err(|io_error| ThisProjectError::IoError(io_error))?;

            // Construct the path to the user's collaborator file, which contains their GPG key ID
            let collaborator_filename = format!("{}__collaborator.toml", file_owner_username);
            let user_config_path = addressbook_files_directory_absolute.join(collaborator_filename);

            debug_log!("user_config_path {}", user_config_path.display());

            // Convert the collaborator file path to string for TOML reading
            let user_config_path_str = user_config_path.to_str()
                .ok_or_else(|| ThisProjectError::InvalidInput("Cannot convert collaborator file path to string".to_string()))?;

            debug_log!("user_config_path {}", user_config_path.display());
            println!("user_config_path {}", user_config_path.display());

            // Extract the GPG key ID from the collaborator file
            let gpg_key_id = read_singleline_string_from_clearsigntoml(user_config_path_str, "gpg_publickey_id")
                .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
                    format!("export_public_gpg_key_converts_to_abs_path() Failed read_singleline_string_from_clearsigntoml() to read GPG key ID from clearsigntoml collaborator file: {}", error_message)
                ))?;


                notes:
                File Types Being Handled:

        The Target TOML File (the one we want to clearsign):

        Initially: Plain TOML file (NOT clearsigned)
        Contains: An owner field with the username
        Read with: read_single_line_string_field_from_toml()
        End state: Will become clearsigned after our function runs


        The Collaborator Addressbook File ({username}__collaborator.toml):

        Already clearsigned TOML
        Contains: The gpg_publickey_id field
        Read with: read_singleline_string_from_clearsigntoml()
        Remains unchanged by our function

        scope summary:
                Scope Confirmation
        Purpose
        Create a function that clearsigns a plain TOML file in-place, but unlike the existing function, this one does not expect the gpg_publickey_id to be present in the target TOML file. Instead, it performs a multi-step lookup process to determine which GPG key to use for signing.
        Key Differences from Existing Function

        Target TOML file: Does NOT contain gpg_publickey_id field
        Target TOML file: MUST contain an owner field with the file owner's username
        Additional lookup: Uses the owner's username to find their collaborator addressbook file
        GPG key source: Extracts the gpg_publickey_id from the owner's addressbook file (not from the target file)

        Process Flow

        Read owner username from the target TOML file (plain TOML)

        Field name: "owner"
        Use: read_single_line_string_field_from_toml()


        Construct addressbook file path

        Base directory: COLLABORATOR_ADDRESSBOOK_PATH_STR (relative to executable)
        Convert to absolute path using: make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error()
        Filename pattern: {owner_username}__collaborator.toml


        Read GPG key ID from the addressbook file

        The addressbook file is already clearsigned
        Field name: "gpg_publickey_id"
        Use: read_singleline_string_from_clearsigntoml()


        Clearsign the target file

        Use the extracted GPG key ID to sign the original target TOML file
        Replace the original file in-place with its clearsigned version



        File States

        Target TOML file: Starts as plain TOML  Ends as clearsigned TOML
        Addressbook file: Already clearsigned  Remains unchanged (read-only operation)

        */
        debug_log!("SNCTF: Starting convert_tomlfile_without_keyid_into_clearsigntoml_inplace()");

        // Get armored public key, using key-id (full fingerprint in)
        let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => fingerprint,
            Err(e) => {
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}", e)
                ));
            }
        };

        convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
            &file_path,
            COLLABORATOR_ADDRESSBOOK_PATH_STR,
            &gpg_full_fingerprint_key_id_string,
        )
        .map_err(|gpg_err| {
            // Convert GpgError to std::io::Error
            std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("SNCTF: GPG into_clearsign operation failed: {:?}", gpg_err),
            )
        })?;

        Ok(())
    }

    // fn update_updated_at_timestamp(&mut self) {
    //     self.updated_at_timestamp = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
    // }

    /// Saves the `CoreNode` data to a `node.gpgtoml` file.
    ///
    /// This function serializes the `CoreNode` struct into TOML format,
    /// clearsigns it with the local user's GPG key, then encrypts it
    /// with their public key, and writes it as a GPG encrypted clearsigned file
    /// at the path specified by the `directory_path` field, creating
    /// the directory if it doesn't exist.
    ///
    /// # Process Flow
    ///
    /// 1. Serialize CoreNode to TOML
    /// 2. Write to temporary file in project temp directory
    /// 3. Clearsign the temp file in-place using user's secret key
    /// 4. Extract user's public key from GPG keyring
    /// 5. Encrypt the clearsigned file with public key
    /// 6. Save as node.gpgtoml in target directory
    /// 7. Clean up all temporary files
    ///
    /// # Error Handling
    ///
    /// Returns a `Result<(), io::Error>` to handle potential errors during:
    ///  - TOML serialization
    ///  - Directory creation
    ///  - File writing
    ///  - GPG operations (clearsigning and encryption)
    ///  - Temp file cleanup (ensures no files left in production)
    fn save_node_as_gpgtoml(&self) -> Result<(), io::Error> {
        // Debug logging for initial state
        debug_log!("in impl CoreNode: SNAGTF -> Starting save_node_as_gpgtoml!");
        debug_log!("SNAGTF: Current working directory: {:?}", std::env::current_dir()?);
        debug_log!("SNAGTF: Target directory path: {:?}", self.directory_path);

        // 1. Verify and create target directory structure
        if !self.directory_path.exists() {
            debug_log!("SNAGTF: Directory doesn't exist, creating it");
            fs::create_dir_all(&self.directory_path)?;
        }
        debug_log!("SNAGTF: Directory now exists: {}", self.directory_path.exists());

        // 2. Verify directory is actually a directory
        if !self.directory_path.is_dir() {
            debug_log!("SNAGTF: Path exists but is not a directory!");
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNAGTF: Path exists but is not a directory"
            ));
        }

        // 3. Serialize the CoreNode struct to a TOML string
        let toml_string = toml::to_string(&self).map_err(|e| {
            debug_log!("SNAGTF: TOML serialization error: {}", e);
            io::Error::new(
                io::ErrorKind::Other,
                format!("SNAGTF: TOML serialization error: {}", e),
            )
        })?;
        debug_log!("SNAGTF: Successfully serialized CoreNode to TOML");

        // 4. Get temp directory and create unique temp file path
        let temp_dir = get_base_uma_temp_directory_path()?;
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
            .as_secs();
        let temp_file_name = format!("node_{}.toml", timestamp);
        let temp_file_path = temp_dir.join(temp_file_name);
        debug_log!("SNAGTF: Temp file path: {:?}", temp_file_path);

        // 5. Write TOML data to temp file
        debug_log!("SNAGTF: Writing TOML data to temp file...");
        fs::write(&temp_file_path, &toml_string)?;

        // Verify temp file was created
        if !temp_file_path.exists() {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNAGTF: Failed to create temp file"
            ));
        }
        debug_log!("SNAGTF: Successfully created temp file at: {:?}", temp_file_path);

        // 6. Get GPG fingerprint for the local user
        let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => {
                debug_log!("SNAGTF: Retrieved GPG fingerprint: {}", fingerprint);
                fingerprint
            },
            Err(e) => {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("impl CoreNode save_node_as_gpgtoml: Failed to read GPG fingerprint from uma.toml: {}", e)
                ));
            }
        };

        // 7. Clearsign the temp file in-place
        debug_log!("SNAGTF: Starting clearsign operation on temp file");
        match convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
            &temp_file_path,
            COLLABORATOR_ADDRESSBOOK_PATH_STR,
            &gpg_full_fingerprint_key_id_string,
        ) {
            Ok(()) => {
                debug_log!("SNAGTF: Successfully clearsigned temp file");
            },
            Err(gpg_err) => {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("SNAGTF: GPG clearsign operation failed: {:?}", gpg_err),
                ));
            }
        }

        // 8. Extract public key from GPG keyring using fingerprint
        debug_log!("SNAGTF: Extracting public key from GPG for fingerprint: {}", gpg_full_fingerprint_key_id_string);
        let public_key_output = std::process::Command::new("gpg")
            .arg("--armor")
            .arg("--export")
            .arg(&gpg_full_fingerprint_key_id_string)
            .output()
            .map_err(|e| {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("SNAGTF: Failed to execute GPG export command: {}", e)
                )
            })?;

        // Check if GPG command succeeded
        if !public_key_output.status.success() {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            let stderr = String::from_utf8_lossy(&public_key_output.stderr);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SNAGTF: GPG export failed: {}", stderr)
            ));
        }

        // Convert public key bytes to string
        let public_key_string = String::from_utf8(public_key_output.stdout)
            .map_err(|e| {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                io::Error::new(
                    io::ErrorKind::Other,
                    format!("SNAGTF: Failed to convert public key to UTF-8: {}", e)
                )
            })?;

        // Verify we got a valid public key
        if public_key_string.trim().is_empty() {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNAGTF: GPG export returned empty public key"
            ));
        }
        debug_log!("SNAGTF: Successfully extracted public key from GPG");

        // 9. Construct final output path for encrypted file
        let final_file_path = self.directory_path.join("node.gpgtoml");
        debug_log!("SNAGTF: Final encrypted file path: {:?}", final_file_path);

        // 10. Encrypt the clearsigned temp file with the public key
        debug_log!("SNAGTF: Starting encryption of clearsigned file");
        match encrypt_clearsigned_toml_with_public_key_content(
            &temp_file_path,
            &public_key_string,
            &final_file_path
        ) {
            Ok(()) => {
                debug_log!("SNAGTF: Successfully created encrypted file at: {:?}", final_file_path);
            },
            Err(e) => {
                // Clean up temp file before returning error
                let _ = fs::remove_file(&temp_file_path);
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("SNAGTF: Encryption failed: {:?}", e)
                ));
            }
        }

        // 11. Clean up temp file (critical for production)
        debug_log!("SNAGTF: Cleaning up temp file");
        if let Err(e) = fs::remove_file(&temp_file_path) {
            // Log warning but don't fail the operation since the main task succeeded
            debug_log!("SNAGTF: Warning: Failed to remove temp file: {}", e);
        }

        // 12. Verify final file exists
        if final_file_path.exists() {
            debug_log!("SNAGTF: Success! node.gpgtoml created at: {:?}", final_file_path);
        } else {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                "SNAGTF: Final file creation appeared successful but file doesn't exist"
            ));
        }

        debug_log!("SNAGTF: save_node_as_gpgtoml completed successfully");
        Ok(())
    }

}

/// Calculates Pearson hashes for the provided CoreNode fields and salts.
/// This function is now external to CoreNode, taking individual fields as arguments.
///
/// Args:
///     node_name: The node's name.
///     description: The node's description.
///     timestamp: The node's timestamp.
///     salt_list: The list of salts for hashing.
///
/// Returns:
///     Result<Vec<u8>, ThisProjectError>: A vector of calculated hashes, or an error.
fn calculate_corenode_hashes(
    node_name: &str,
    description: &str,
    updated_at_timestamp: u64,
    salt_list: &[u128],
) -> Result<Vec<u8>, ThisProjectError> {
    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(node_name.as_bytes());
    data_to_hash.extend_from_slice(description.as_bytes());
    data_to_hash.extend_from_slice(&updated_at_timestamp.to_be_bytes());

    let mut hash_list = Vec::new();
    for salt in salt_list {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());
        match pearson_hash_base(&salted_data) {
            Ok(hash) => hash_list.push(hash),
            Err(e) => return Err(e.into()),  // Return the error.
        }
    }
    Ok(hash_list)
}

/*
let node_unique_id_str_result = extract_string_from_toml_bytes(received_file_bytes, "node_unique_id");

// Then handle the result...
match node_unique_id_str_result {
    Ok(node_unique_id_str) => {
        // Use the node_unique_id_str
    }
    Err(e) => {
        // Handle error
    }
}
*/
/// Extracts a string value associated with a given key from a TOML-formatted byte slice.
///
/// This function manually parses the byte slice, looking for a line that matches the
/// format `key = "value"`.  It handles cases where the key is not found or the value is
/// not enclosed in double quotes. It does NOT handle TOML arrays or tables.
/// It does NOT depend on the serde or toml crate.
///
/// # Arguments
///
/// * `toml_bytes`: The TOML data as a byte slice.
/// * `key`: The key to search for.
///
/// # Returns
///
/// * `Result<String, ThisProjectError>`: The extracted value or an error.
fn extract_string_from_toml_bytes(toml_bytes: &[u8], key: &str) -> Result<String, ThisProjectError> {
    let toml_str = std::str::from_utf8(toml_bytes).map_err(|_| ThisProjectError::InvalidData("Invalid UTF-8".into()))?;

    for line in toml_str.lines() {
        let line = line.trim();
        if line.starts_with(key) && line.contains('=') {
            let parts: Vec<&str> = line.split('=').map(|s| s.trim()).collect();
            if parts.len() == 2 {
                let value = parts[1];
                if value.starts_with('"') && value.ends_with('"') {
                    return Ok(value[1..value.len() - 1].to_string());
                } else {
                    return Err(ThisProjectError::InvalidData("Value not in quotes".into()));
                }
            }
        }
    }
    Err(ThisProjectError::InvalidData(format!("Key '{}' not found", key).into()))
}

/*
Under Construction!
should not use any 3rd party crates
- pending:
-- clearsign validate: new functions in clearsign module
-- add new fields for message-post

- only extract values from validated files
AGAIN: ONLY EXTRACT VALUES FROM VALIDATED FILES!
AGAIN: ONLY EXTRACT VALUES FROM VALIDATED FILES!!
NO BACK DOORS
AGAIN: ONLY EXTRACT VALUES FROM VALIDATED FILES!!!
NO VALIDATION = NO EXTRACTED VALUE
NO BACK DOORS!!!!!!!
NO EXCEPTIONS

use functions from clearsign module

    Get the current-local-user's gpg in this function with something like this:
            // Get GPG key fingerprint
            let full_fingerprint_key_id_string = match q_and_a_user_selects_gpg_key_full_fingerprint() {
                Ok(fingerprint) => {
                    println!("Selected key id (full fingerprint): {}", fingerprint);
                    fingerprint
                }
                Err(e) => {
                    eprintln!("Error selecting GPG key fingerprint: {}", e);
                    return Ok(false);
                }
            };

# Workflow for reading Nodes (CoreNodes) including team-channels

load_core_node_from_toml_file(
        path,
    )

get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_path,
        &gpg_full_fingerprint_key_id_string,
    )


The top level summary is more simplified than the actual steps which are more intertwined. Overall the workflow is: get path -> validate/verify file -> extract field. But you cannot validate/verify the node.toml file until you have both validated and extracted data from the addressbook file.

1. Paths & Reading-Copies Part 1: node.toml path and read-copy
2. Paths & Reading-Copies Part 2: addressbook path and read-copy
3. Verification/Validation Part 1: validate/verify addressbook file and get node-owner's public gpg
4. Extraction Part 1: Addressbook field extraction.
5. Verification/Validation Part 2: validate/verify Node (clearsign validation of .toml)
6. Extraction Part 2: Node.toml Field Extraction
7. Cleanup
8. Return Node Struct (CoreNode)


Step 1: Paths & Reading-Copies Part 1: node.toml path and read-copy
There are several reasons for separate paths and reading-copies.
While it is somewhat an undesirable swiss-army-knife: a file-to-be-read may be .toml or a .gpgtoml. A simple clearsign-toml is simpler than a .gpgtoml, but the workflow for a .gpgtoml introduces at least two useful robustness steps.

Reading from a reading-copy rather than from an original file: While collisions are likely to be rare, it is probably a good standard best practice (in general, not without exceptions) for Uma to do all file-reading from reading-copies of files. This should be better in a distributed-graph-database of files where any file owner can move or update a file at any time. Also, the modus-operandi of Uma is that individual files are always small modules, with any larger structure being made of small modular parts, so there should be no issues of copying a large file when there are no large files.

Another benefit of .gpgtoml files is the implicit 'login/signin' step that prevents any hardware-operator (physical or remote) who does not control the local-owner-user's gpg keys from using Uma ('Anti Evil-Maid').

That said, there is a balance between .gpgtoml advantages and the original Aim of Uma being "These are files and folders on your computer." Uma is a narrowly purpose-specific file(system)-sharing system (a distributed graph-database), not a file-hiding system. The whole point of Uma is using and sharing files so that you and chosen collaborators can look at the files you create. The main outlier may be the addressbook files which, while not containing any secrets, are not 'useful project files' and it does add to security-hardening (and 'login') to .gpg encrypt those. Team-channel files are likely an ongoing grey area: some people may prefer to .gpg encrypt these too, but in many cases being able to read and modify these files as files is likely useful. A compromise may be having a minimal team-channel file that is .gpg encrypted and using other nodes for more details.
It likely makes sense to leave this up to the team, and to "Nudge" (see book title and association with Kahneman/Tversky) people towards default-more-security that they can opt out of: so addressbook files are definitely .gpgtoml by default, and team-channel files...probably .gpgtoml by default.

Nodes (node.toml files) like addressbook files can be either clearsign-toml .toml files or gpg encrypted .gpgtoml encrypted clearsigned .toml files
(encryption is done with the local owner's public key (so the local owner decrypts with their private key using that key's key-id), clearsigning is with the file-owner's private key: so the clearsign is validated/verified using the file-owner's shared public gpg-key (which is in their addressbook file, looked up by the user's name (or 'handle')))

If failing to make a read copy, e.g. due to file collisions with that file being updated or moved at the exact time of read-copy, the procedure should be to wait and try again twice before considering this to be an error/failure. Collisions in uses of files are expected to be rare but are expected.

Every error-section of the function after this point must delete the read-copies as a first step of the error handling process.


Step 2. Paths & Reading-Copies Part 2: addressbook path and read-copy
The owner of the addressbook file cannot be found until the node.toml file is readable and read.

- use node.toml owner name
- get Addressbook directory path simplified
- get real path to read-copy with:
pub fn get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
    collaborator_name: &str,
    addressbook_files_directory_relative: &str,
    gpg_full_fingerprint_key_id_string: &str,
) -> Result<(PathBuf, PathBuf), GpgError>


Step 3. Verification/Validation Part 1: validate addressbook file and get node-owner's public gpg key

node_owners_public_gpg_key = read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml()


Step 4. Extraction Part 1: Addressbook field extraction.

In order to validate/verify the node.toml files we need to
get the file-owner's public-gpg-key from file-owner's addressbook:
read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml()


Step 5. Verification/Validation Part 2: validate Node file (clearsign validation of .toml)
- validate and proceed or delete read-copies and return-error

While some would probably argue for punting on (skipping) gpg-clearsign-validation of the node.toml file on the grounds that later other functions to load data from the unverified file probably include some kind of implicit validation steps, that procrastination/excuse is not good-process and invites potential risks. First see if the file can be clearsign-validated. If the file cannot be clearsign-validated, do not attempt to load any data from a known to be bad and possibly tampered-with file.

The terminology or semantics might be confusing but the workflow should be clear.
There is no path to export an extracted field value bypassing the validated-extraction process. We have to 'read' the name of the file owner from the file, but that is not stored in a variable capable of returning that as an extracted-output.

The return-extracted-verified/validated-value process must be used for all 'extracted-to-output' fields. On the one hand this is redundantly reading the field a second time, on the other hand it is applying a uniform process and not skimping on due diligence for the sake of creating a liability and irregular workflows.

    // // 5. Validation Part 2: validate Node (clearsign validation of .toml)
    let verify_node_file_result = verify_clearsign(
    	&node_readcopy_path,
    	&node_owners_public_gpg_key,
    );


Step 6. Extraction Part 2: Node.toml Field Extraction
Fields should be individually extracted using a standardized individual validation/verification process.

There need to be individual functions for reading clearsign_toml fields,
from clearsing-toml files that do not contain the public gpg-key, based on:
A. the datatype of the 'value' (as in key (field name) and value (data), as in key
B. if the struct field is 'option' (possibly None)

likely the input parameters will be the same for all such functions:
(
    pathstr_to_config_file_that_contains_gpg_key: &str,
    pathstr_to_target_clearsigned_file: &str,
    name_of_toml_field_key_to_read: &str,
)

Nodes and 'Get-Needed-When-Need' (Get something that is needed when it is needed; not get everything when you do not need it.):
By default Uma operates on a "Get (what is) needed when (it is) needed." basis, but in this case you actually do need to load all node fields when entering that node.
However, the reading of each field is not exempt: reading every struct item from a toml file does NOT mean greedily, lazily, slopily, and dangerously, pulling the entire file into memory. Uma operates by strictly dealing only with specific approved structs and enum structures, period. People will try to put malicious executable code into a 'file to share,' but Uma does not deal with random files or random data: Rust structs within Rust enums are shared with Uma, externatized in the form of (clearsigned and gpg encrypted) .toml files, with strict size and other parameters. Uma is not a random filesharing system.

This will probably evolve over time but to date the datatypes needed are:

Data Types (including 'Option'):
    string
    vec<u8>
    PathBuf
    u64
    vec<String>
    HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
    Option<Vec<(i32, i32)>>,
    Option<usize>,
    Option<bool>,
    Option<i64>,

Functions:
    string -> read_singleline_string_from_clearsigntoml_without_publicgpgkey()
    vec<u8> -> read_u8_array_from_clearsigntoml_without_publicgpgkey()
    PathBuf -> read_pathbuf_from_clearsigntoml_without_publicgpgkey()
    u64 -> read_u64_from_clearsigntoml_without_publicgpgkey()
    vec<String> -> read_stringarray_from_clearsigntoml_without_publicgpgkey()

   HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
-> read_hashmap_corenode_ports_from_clearsigntoml_without_publicgpgkey()

Option<Vec<(i32, i32)>> -> read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey()
    Option<usize> -> read_option_usize_from_clearsigntoml_without_publicgpgkey()
    Option<bool> -> read_option_bool_from_clearsigntoml_without_publicgpgkey()
    Option<i64> -> read_option_i64_from_clearsigntoml_without_publicgpgkey()


For reference, this is the CoreNode struct showing the struct fields that have said datatypes:
struct CoreNode {
    /// The name of the node. This is used for display and identification.
    node_name: String,

    /// A description of the node, intended for display in the TUI.
    description_for_tui: String,

    /// A unique identifier for the node, generated using pearson hashes of the other fields
    node_unique_id: Vec<u8>,

    /// The path to the directory on the file system where the node's data is stored.
    directory_path: PathBuf,

    /// An order number used to define the node's position within a list or hierarchy.
    // order_number: u32,
    /// The priority of the node, which can be High, Medium, or Low.
    // priority: NodePriority,
    /// The username of the owner of the node.
    owner: String,

    /// The Unix timestamp representing when the node was last updated.
    updated_at_timestamp: u64,

    /// The Unix timestamp representing when the node will expire.
    expires_at: u64,

    /// A vector of `CoreNode` structs representing the child nodes of this node.
    // children: Vec<CoreNode>,
    /// An ordered vector of collaborator usernames associated with this node.
    teamchannel_collaborators_with_access: Vec<String>,

    /// A map containing port assignments for each collaborator associated with the node.
    abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,

    // project areas: project module items as task-ish thing
    pa1_process: String,
    pa2_schedule: Vec<u64>,
    pa3_users: String,
    pa4_features: String,
    pa5_mvp: String,
    pa6_feedback: String,


    /////////////////
    // message_posts
    /////////////////

    /// Integer validation ranges as tuples (min, max) - inclusive bounds
    pub message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Integer-string validation ranges as tuples (min, max) for the integer part
    pub message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Maximum string length
    pub message_post_max_string_length_int: Option<usize>,

    /// Whether posts are public or private
    pub message_post_is_public_bool: Option<bool>,

    /// Whether user confirmation is required before posting
    pub message_post_user_confirms_bool: Option<bool>,

    /// Start time for accepting posts (UTC POSIX timestamp)
    pub message_post_start_date_utc_posix: Option<i64>,

    /// End time for accepting posts (UTC POSIX timestamp)
    pub message_post_end_date_utc_posix: Option<i64>,

	// limit of how many posts (or per time duration)
    // pub max_posts: Option<i64>,
    // pub duration_for_maxposts: MaxPostsDurationUnitsEnum, // hours, days, weeks
    // pub n_durations_for_maxposts: Option<i64>,
}


Step 7. Cleanup
If the process gets this far, hopefully it usually does, the temporary read-files are deleted.
```
   fn cleanup_collaborator_temp_file(temp_file_path: &Path) -> Result<(), GpgError> {
```

Step 8. Return Node Struct (struct CoreNode)
return the struct (after deleting the read-files), or an error (after deleting the read-files).

*/
/// Loads a `CoreNode` from a TOML file, handling potential errors.
///
/// # Arguments
///
/// * `file_path` - The path to the TOML file containing the node data.
///
/// # Returns
///
/// * `Result<CoreNode, String>` - `Ok(CoreNode)` if the node is successfully loaded,
///    `Err(String)` containing an error message if an error occurs.
///
///
fn load_core_node_from_toml_file(
    file_path: &Path,
) -> Result<CoreNode, String> {

    /*
    1. Paths & Reading-Copies Part 1: node.toml path and read-copy
    2. Paths & Reading-Copies Part 2: addressbook path and read-copy
    3. Validate Part 1: validate addressbook file and get node-owner's public gpg
    4. Validation Part 2: validate Node (clearsign validation of .toml)
    5. Field Extraction
    6. Cleanup
    7. Return Node Struct (CoreNode)



    1. updating Nodes: Plan A
    -> fn load_core_node_from_toml_file

    - add feature to look first for and optionally read .gpgtoml for addressbook files
    - add identification of local owner user addressbook file
    - select key for self-decrypt for local owner user .gpgtoml
    - maybe need to add that to app/navigation state?
    - feature to enable headless OS enter passphrase for local owner user .gpgtoml
    - add feature to save .gpgtoml format of addressbook file (e.g. in invite/update)

    - functions to read each field of clearsigned node
    - adding new 'modular message-post' fields to navigation state

    workflow, steps:
    validation: clearsign validation of the node.toml file,
       which is a file without the gpg-public-key to validate,
       so use the owner field to get the owners public gpg key
       from their addressbook file (which will also need to be
           clearsign validated...after it is .gpg decrypted,
           using the current-user's gpg-key-id from
           the uma.toml config file)

    1.1 get path to addressbook file
    get_path_to_temp_copy_of_addressbook_toml_or_decrypted_gpgtoml(
    collaborator_name: &str,
    addressbook_files_directory_relative: &str,
    gpg_full_fingerprint_key_id_string: &str,

    2 validate and get public gpg key from file...
    clearsign multiilne string?

    3. extract data from node.toml fields

    4. remove temp file

    5. return struct

    note: once decrypted temp file is made, any error should delete that file

    last (and with any error) remove temp file:
    fn cleanup_collaborator_temp_file(temp_file_path: &Path) -> Result<(), GpgError> {
    */


    debug_log!(
        "LCNFTF: Starting: load_core_node_from_toml_file(), file_path -> {:?}",
        file_path,
    );

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(format!(
                "LCNFTF: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            ));
        }
    };

    // // 1. Paths & Reading-Copies Part 1: node.toml path and read-copy

    // Get the UME temp directory path with explicit String conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| {
            let gpg_error = GpgError::ValidationError(
                format!("LCNFTF: Failed to get UME temp directory path: {}", io_err)
            );
            // Convert GpgError to String for the function's return type
            format!("LCNFTF: {:?}", gpg_error)
        })?;

    // Using Debug trait for more detailed error information
    let node_readcopy_path = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_path,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| format!("LCNFTF: Failed to get temporary read copy of TOML file: {:?}", e))?;

    // //    // simple read string to get owner name
    // //    // not for extraction and return, just part of validation


    ////////////////////////////////
    // Extract Owner for Key Lookup
    ////////////////////////////////
    let owner_name_of_toml_field_key_to_read = "owner";
    debug_log!(
        "LCNFTF: Reading file owner from field '{}' for security validation",
        owner_name_of_toml_field_key_to_read
    );

    // get node_owners_public_gpg_key

    let file_owner_username = match read_single_line_string_field_from_toml(
        &node_readcopy_path,  // TODO convert to string?
        owner_name_of_toml_field_key_to_read,
    ) {
        Ok(username) => {
            if username.is_empty() {
                // Convert to String error instead of GpgError
                return Err(format!(
                    "LCNFTF: Field '{}' is empty in TOML file. File owner is required for security validation.",
                    owner_name_of_toml_field_key_to_read
                ));
            }
            username
        }
        Err(e) => {
            // Convert to String error instead of GpgError
            return Err(format!(
                "LCNFTF: Failed to read file owner from field '{}': {}",
                owner_name_of_toml_field_key_to_read, e
            ));
        }
    };
    // println!("LCNFTF: File owner: '{}'", file_owner_username);
    debug_log!("LCNFTF: File owner: '{}'", file_owner_username);

    // TODO returns full response not just string
    // because the filepath needs to be constructed
    // this is a separate function
	// let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
    //        &file_owner_username,
    //        COLLABORATOR_ADDRESSBOOK_PATH_STR,
    //        &gpg_full_fingerprint_key_id_string,
    //    );

    // Get the UME temp directory path with error handling
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| format!(
            "LCNFTF: Failed to get UME temp directory path: {:?}",
            io_err
        ))?;

    // Extract the addressbook path string with inline error conversion
    let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_owner_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| format!(
        "LCNFTF: Failed to get addressbook path for user '{}': {:?}",
        file_owner_username,
        e
    ))?;

    // Define cleanup closure
    let cleanup_closure = || {
        let _ = cleanup_collaborator_temp_file(
            &node_readcopy_path,
            &base_uma_temp_directory_path,
            );
        let _ = cleanup_collaborator_temp_file(
            &addressbook_readcopy_path_string,
            &base_uma_temp_directory_path,
            );
    };

    // use function for general .toml or .gpgtoml readcopy
    // let node_owners_public_gpg_key = read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml(
    //     &addressbook_readcopy_path_string,
    // );

    let node_owners_public_gpg_key = read_clearsignvalidated_gpg_key_public_multiline_string_from_clearsigntoml(
        &addressbook_readcopy_path_string,
    ).map_err(|e| format!(
        "LCNFTF: Failed to get addressbook path for user '{}': {:?}",
        file_owner_username,
        e
    ))?;

    // 2. Paths & Reading-Copies Part 2: addressbook path and read-copy
    // Verify the addressbook file's clearsign signature
    let verify_addressbook_file_result = match verify_clearsign(
        &addressbook_readcopy_path_string,
        &node_owners_public_gpg_key,
    ) {
        Ok(is_valid) => is_valid,
        Err(e) => {
            // Clean up temporary files before returning error
            cleanup_closure();
            return Err(format!(
                "LCNFTF: Failed to verify addressbook clearsign signature for user '{}': {:?}",
                file_owner_username,
                e
            ));
        }
    };

    // 3. Validate Part 1: validate addressbook file and get node-owner's public gpg
    // (This section would go here if needed)

    // 4. Validation Part 2: validate Node (clearsign validation of .toml)
    // Verify the node file's clearsign signature
    let verify_node_file_result = match verify_clearsign(
        &node_readcopy_path,
        &node_owners_public_gpg_key,
    ) {
        Ok(is_valid) => is_valid,
        Err(e) => {
            // Clean up temporary files before returning error
            cleanup_closure();
            return Err(format!(
                "Failed to verify node file clearsign signature for user '{}': {:?}",
                file_owner_username,
                e
            ));
        }
    };

    // Check if both verification results are valid
    // If either verification failed, clean up and return error
    if !verify_addressbook_file_result || !verify_node_file_result {

        debug_log("LCNFTF: Whoops, something faileded...");

        // Clean up temporary files
        cleanup_closure();

        // Provide detailed error message about which verification failed
        let mut error_details = Vec::new();
        if !verify_addressbook_file_result {
            error_details.push("LCNFTF: addressbook file signature verification failed");
        }
        if !verify_node_file_result {
            error_details.push("LCNFTF: node file signature verification failed");
        }

        return Err(format!(
            "LCNFTF: Clearsign validation failed for user '{}': {}",
            file_owner_username,
            error_details.join(" and ")
        ));
    }


    // // 5. Field Extraction

    /*
    This will probably evolve over time but to date the datatypes needed are:
    string
    vec<u8>
    PathBuf
    u64
    vec<String>

   	HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,

    Option<Vec<(i32, i32)>>,
    Option<usize>,
    Option<bool>,
    Option<i64>,

    Functions:

    all use these parameters:
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
        name_of_toml_field_key_to_read: &str,


        string -> read_singleline_string_from_clearsigntoml_without_publicgpgkey()
        vec<u8> -> read_u8_array_from_clearsigntoml_without_publicgpgkey()
        PathBuf -> read_pathbuf_from_clearsigntoml_without_publicgpgkey()
        u64 -> read_u64_from_clearsigntoml_without_publicgpgkey()
        vec<String> -> read_stringarray_from_clearsigntoml_without_publicgpgkey()

    HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,
    -> read_hashmap_corenode_ports_from_clearsigntoml_without_publicgpgkey()

    Option<Vec<(i32, i32)>> -> read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey()
        Option<usize> -> read_option_usize_from_clearsigntoml_without_publicgpgkey()
        Option<bool> -> read_option_bool_from_clearsigntoml_without_publicgpgkey()
        Option<i64> -> read_option_i64_from_clearsigntoml_without_publicgpgkey()

    struct CoreNode {
        /// The name of the node. This is used for display and identification.
        node_name: String,
        /// A description of the node, intended for display in the TUI.
        description_for_tui: String,
        /// A unique identifier for the node, generated using pearson hashes of the other fields
        node_unique_id: Vec<u8>,
        /// The path to the directory on the file system where the node's data is stored.
        directory_path: PathBuf,
        /// An order number used to define the node's position within a list or hierarchy.
        // order_number: u32,
        /// The priority of the node, which can be High, Medium, or Low.
        // priority: NodePriority,
        /// The username of the owner of the node.
        owner: String,
        /// The Unix timestamp representing when the node was last updated.
        updated_at_timestamp: u64,
        /// The Unix timestamp representing when the node will expire.
        expires_at: u64,
        /// A vector of `CoreNode` structs representing the child nodes of this node.
        // children: Vec<CoreNode>,
        /// An ordered vector of collaborator usernames associated with this node.
        teamchannel_collaborators_with_access: Vec<String>,
        /// A map containing port assignments for each collaborator associated with the node.
        abstract_collaborator_port_assignments: HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>,

        // project areas: project module items as task-ish thing
        pa1_process: String,
        pa2_schedule: Vec<u64>,
        pa3_users: String,
        pa4_features: String,
        pa5_mvp: String,
        pa6_feedback: String,

        /////////////////
        // message_posts
        /////////////////

        /// Integer validation ranges as tuples (min, max) - inclusive bounds
        pub message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

        /// Integer-string validation ranges as tuples (min, max) for the integer part
        pub message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

        /// Maximum string length
        pub message_post_max_string_length_int: Option<usize>,

        /// Whether posts are public or private
        pub message_post_is_public_bool: Option<bool>,

        /// Whether user confirmation is required before posting
        pub message_post_user_confirms_bool: Option<bool>,

        /// Start time for accepting posts (UTC POSIX timestamp)
        pub message_post_start_date_utc_posix: Option<i64>,

        /// End time for accepting posts (UTC POSIX timestamp)
        pub message_post_end_date_utc_posix: Option<i64>,

    	// limit of how many posts (or per time duration)
        // pub max_posts: Option<i64>,
        // pub duration_for_maxposts: MaxPostsDurationUnitsEnum, // hours, days, weeks
        // pub n_durations_for_maxposts: Option<i64>,
        }
        */


    // 1. Read File Contents
    /*
    /// match read_singleline_string_from_clearsigntoml_without_publicgpgkey(
    ///     config_path,
    ///     target_path,
    ///     "api_endpoint"
    /// ) {
    ///     Ok(value) => println!("API Endpoint: {}", value),
    ///     Err(e) => eprintln!("Error: {}", e)
    /// }
    /// ```
    ///
    pub fn read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
        name_of_toml_field_key_to_read: &str,
    ) -> Result<String, String> {

    */

    /*
    // Define cleanup closure
    let cleanup = || {
        cleanup_collaborator_temp_file(node_readcopy_path);
        cleanup_collaborator_temp_file(addressbook_readcopy_path_string);
    };

    // Use the function to read a value - convert Path to &str
    let file_path_str = file_path.to_str()
        .ok_or_else(|| {
            cleanup_closure();
            "Invalid file path encoding".to_string()
        })?;

    // Example: Read node_id from the clearsigned TOML file
    let node_id = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        "config/security.toml",  // Config file containing GPG key
        file_path_str,           // Target clearsigned file
        "node_id"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("Failed to read node_id: {}", e)
    })?;
    */

    // Example: Read _ from the clearsigned TOML file
    let node_name = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "node_name"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: node_name Failed to read node_name: {}", e)
    })?;

    // TODO...should be bool not option bool
    // Example: Read _ from the clearsigned TOML file
    let corenode_gpgtoml = read_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,                // Target clearsigned file
        "corenode_gpgtoml"                  // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: node_name Failed to read corenode_gpgtoml: {}", e)
    })?;

    // Example: Read _ from the clearsigned TOML file
    let description_for_tui = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "description_for_tui"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: description_for_tui sFailed to read description_for_tui: {}", e)
    })?;

    // Example: Read _ from the clearsigned TOML file
    let node_unique_id = read_u8_array_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "node_unique_id"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: node_unique_id Failed to read node_unique_id: {}", e)
    })?;

    // Example: Read _ from the clearsigned TOML file
    let directory_path = read_pathbuf_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "directory_path"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: directory_path Failed to read directory_pathe_id: {}", e)
    })?;



    // Example: Read _ from the clearsigned TOML file
    let owner = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "owner"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: owner Failed to read owner: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let updated_at_timestamp = read_u64_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "updated_at_timestamp"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: updated_at_timestamp Failed to read updated_at_timestamp: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let expires_at = read_u64_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "expires_at"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: expires_at Failed to read expires_at: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let teamchannel_collaborators_with_access = read_stringarray_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "teamchannel_collaborators_with_access"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: teamchannel_collaborators_with_access Failed to read teamchannel_collaborators_with_access: {}", e)
    })?;


    debug_log("LCNFTF: starting read_teamchannel_collaborator_ports_clearsigntoml_without_keyid...");

    /*
    pub fn read_hashmap_corenode_ports_from_clearsigntoml_without_publicgpgkey(
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
    ) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, String> {
    */

    // Example: Read _ from the clearsigned TOML file
    // let abstract_collaborator_port_assignments = read_teamchannel_collaborator_ports_clearsigntoml_without_keyid(
    //     &addressbook_readcopy_path_string,     // Config file containing GPG key
    //     &node_readcopy_path,                   // Target clearsigned file
    // ).map_err(|e| {
    //     cleanup_closure(); // Run cleanup on error
    //     format!("LCNFTF: read_abstract_collaborator_port_assignments Failed to read abstract_collaborator_port_assignments: {}", e)
    // })?;

    // let abstract_collaborator_port_assignments =
    //     read_teamchannel_collaborator_ports_clearsigntoml_without_keyid(
    //         &addressbook_readcopy_path_string,
    //         &node_readcopy_path,
    //     )
    //     .or_else(|e| {
    //         eprintln!("LCNFTF: read_abstract_collaborator_port_assignments Failed to read abstract_collaborator_port_assignments: {}", e);
    //         Ok(HashMap::new())
    //     })?;

    let abstract_collaborator_port_assignments =
        read_teamchannel_collaborator_ports_clearsigntoml_without_keyid(
            &addressbook_readcopy_path_string,
            &node_readcopy_path,
        )
        .unwrap_or_else(|e| {
            debug_log!("LCNFTF read_teamchannel_collaborator_ports_clearsigntoml_without_keyid file_path {:?}", file_path);
            debug_log!("LCNFTF: No existing abstract_collaborator_port_assignments found (this should happen for non-team-channels): {}", e);
            HashMap::new()
        });

	////?////////////
	// Project Areas
	/////////////////

    // Example: Read _ from the clearsigned TOML file
    let pa1_process = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa1_process"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: pa1_process Failed to read pa1_process: {}", e)
    })?;



    // Example: Read _ from the clearsigned TOML file
    let pa2_schedule = read_u64_array_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa2_schedule"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: pa2_schedule Failed to read pa2_schedule: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let pa3_users = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa3_users"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error:  pa3_users Failed to read pa3_users: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let pa4_features = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa4_features"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: pa4_features Failed to read pa4_features: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let pa5_mvp = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa5_mvp"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: pa5_mvp Failed to read pa5_mvp: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let pa6_feedback = read_singleline_string_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "pa6_feedback"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: pa6_feedback Failed to read pa6_feedback: {}", e)
    })?;

	////////////////
	// Message-Post
	////////////////

	// Example: Read _ from the clearsigned TOML file
    let message_post_gpgtoml_required = read_option_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_gpgtoml_required"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_gpgtoml_required Failed to read message_post_gpgtoml_required: {}", e)
    })?;

    // Example: Read _ from the clearsigned TOML file
    let message_post_data_format_specs_integer_ranges_from_to_tuple_array = read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_data_format_specs_integer_ranges_from_to_tuple_array"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_data_format_specs_integer_ranges_from_to_tuple_array Failed to read message_post_data_format_specs_integer_ranges_from_to_tuple_array: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_data_format_specs_int_string_ranges_from_to_tuple_array = read_option_i32_tuple_array_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_data_format_specs_int_string_ranges_from_to_tuple_array"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_data_format_specs_int_string_ranges_from_to_tuple_array Failed to read message_post_data_format_specs_int_string_ranges_from_to_tuple_array: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_max_string_length_int = read_option_usize_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_max_string_length_int"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_max_string_length_int Failed to read message_post_max_string_length_int: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_is_public_bool = read_option_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_is_public_bool"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_is_public_bool Failed to read node_imessage_post_is_public_boold: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_user_confirms_bool = read_option_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_user_confirms_bool"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_user_confirms_bool Failed to read message_post_user_confirms_bool: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_start_date_utc_posix = read_option_i64_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_start_date_utc_posix"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_start_date_utc_posix Failed to read message_post_start_date_utc_posix: {}", e)
    })?;


    // Example: Read _ from the clearsigned TOML file
    let message_post_end_date_utc_posix = read_option_i64_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,           // Target clearsigned file
        "message_post_end_date_utc_posix"                // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF error: message_post_end_date_utc_posix Failed to read message_post_end_date_utc_posix: {}", e)
    })?;

    /*
    TODO
    error[E0425]: cannot find value `message_post_max_string_length_int` in this scope
        --> src/main.rs:11420:9
        |
    11420 |         message_post_max_string_length_int,
        |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not found in this scope

    */

    // Example: Read _ from the clearsigned TOML file
    let use_padnet = read_option_bool_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,  // Config file containing GPG key
        &node_readcopy_path,                // Target clearsigned file
        "use_padnet"                  // Field to read
    ).map_err(|e| {
        cleanup_closure(); // Run cleanup on error
        format!("LCNFTF: node_name Failed to read corenode_gpgtoml: {}", e)
    })?;

    // 6. Deserialize into CoreNode Struct (Manually)
    let core_node = CoreNode {
        // node_name: toml_value.get("node_name").and_then(Value::as_str).unwrap_or("").to_string(),
        // description_for_tui: toml_value.get("description_for_tui").and_then(Value::as_str).unwrap_or("").to_string(),
        // node_unique_id: node_unique_id,
        // directory_path: PathBuf::from(toml_value.get("directory_path").and_then(Value::as_str).unwrap_or("")),
        // owner: toml_value.get("owner").and_then(Value::as_str).unwrap_or("").to_string(),
        // updated_at_timestamp: toml_value.get("updated_at_timestamp").and_then(Value::as_integer).unwrap_or(0) as u64,
        // expires_at: toml_value.get("expires_at").and_then(Value::as_integer).unwrap_or(0) as u64,
        // teamchannel_collaborators_with_access: toml_value.get("teamchannel_collaborators_with_access").and_then(Value::as_array).map(|arr| arr.iter().filter_map(Value::as_str).map(String::from).collect()).unwrap_or_default(),

        node_name: node_name,
        corenode_gpgtoml: corenode_gpgtoml,
        description_for_tui: description_for_tui,
        node_unique_id: node_unique_id,
        directory_path: directory_path,
        owner: owner,
        updated_at_timestamp: updated_at_timestamp,
        expires_at: expires_at,
        teamchannel_collaborators_with_access: teamchannel_collaborators_with_access,

        abstract_collaborator_port_assignments: abstract_collaborator_port_assignments,

        // Project Areas
        pa1_process: pa1_process,
        pa2_schedule: pa2_schedule,
        pa3_users: pa3_users,
        pa4_features: pa4_features,
        pa5_mvp: pa5_mvp,
        pa6_feedback: pa6_feedback,

        // Message Post Configuration
        message_post_gpgtoml_required,
        message_post_data_format_specs_integer_ranges_from_to_tuple_array,
        message_post_data_format_specs_int_string_ranges_from_to_tuple_array,
        message_post_max_string_length_int,
        message_post_is_public_bool,
        message_post_user_confirms_bool,
        message_post_start_date_utc_posix,
        message_post_end_date_utc_posix,

        // padnet
        use_padnet,
    };

    // TODO
    // // 7. Handle collaborator port assignments
    // if let Some(collaborator_assignments_table) = toml_value.get("collaborator_port_assignments").and_then(Value::as_table) {
    //     for (pair_name, pair_data) in collaborator_assignments_table {
    //         debug_log("Looking for 'collaborator_ports' load_core...");
    //         if let Some(ports_list) = pair_data.get("collaborator_ports").and_then(Value::as_array) {
    //             // Create a vector to hold ReadTeamchannelCollaboratorPortsToml instances for this pair
    //             let mut ports_for_pair = Vec::new();

    //             for port_data in ports_list {
    //                 // Deserialize each AbstractTeamchannelNodeTomlPortsData from the array
    //                 let port_data_str = toml::to_string(&port_data).unwrap(); // Convert Value to String
    //                 let collaborator_port: AbstractTeamchannelNodeTomlPortsData = toml::from_str(&port_data_str).map_err(|e| format!("Error deserializing collaborator port: {}", e))?;

    //                 // Create ReadTeamchannelCollaboratorPortsToml and add it to the vector
    //                 let read_teamchannel_collaborator_ports_toml = ReadTeamchannelCollaboratorPortsToml {
    //                     collaborator_ports: vec![collaborator_port], // Wrap in a vector
    //                 };
    //                 ports_for_pair.push(read_teamchannel_collaborator_ports_toml);
    //             }

    //             // Insert the vector of ReadTeamchannelCollaboratorPortsToml into the HashMap
    //             core_node.abstract_collaborator_port_assignments.insert(pair_name.clone(), ports_for_pair);
    //         }
    //     }
    // }


    // // 6. Cleanup
    //
    debug_log("Proper cleansup");
    let _ = cleanup_collaborator_temp_file(
        &node_readcopy_path,
        &base_uma_temp_directory_path,
        );
    let _ = cleanup_collaborator_temp_file(
        &addressbook_readcopy_path_string,
        &base_uma_temp_directory_path,
        );

    // // 7. Return Node Struct (CoreNode)
    debug_log!("LCNFTF: core_node {:?}", core_node);

    debug_log("LCNFTF DONE: Ending load_core_node_from_toml_file");
    Ok(core_node)
}


// NO!!!!!! NOT TOML CRATE!!!!!!!!!!!!
// Generic function to save any serializable data to a TOML file
pub fn save_toml_to_file<T: Serialize>(data: &T, file_path: &Path) -> Result<(), Error> {
    let toml_string = toml::to_string(data).map_err(|e| {
        Error::new(
            std::io::ErrorKind::Other,
            format!("TOML serialization error: {}", e),
        )
    })?;
    fs::write(file_path, toml_string)?;
    Ok(())
}

// ====================
// Message Post Section
// ====================

/// Creates a tuple of (directory_path, final_filename) for message post files.
///
/// # Purpose
///
/// This function handles the path and filename logic for instant message files,
/// determining the correct file extension based on encryption settings:
/// - `.toml` for clearsigned TOML files (unencrypted but signed)
/// - `.gpgtoml` for GPG encrypted TOML files
///
/// # Project Context
///
/// Instant messages in the system can be stored in two formats:
/// 1. Clearsigned TOML: Human-readable, cryptographically signed
/// 2. GPG Encrypted TOML: Encrypted + signed, only readable by key holder
///
/// The choice affects both file extension and subsequent processing pipeline.
/// This function ensures consistent naming across the message storage system.
///
/// # Arguments
///
/// * `incoming_path` - The full path including base filename (may include .toml extension)
/// * `use_encryption` - If `true`, use `.gpgtoml` extension; if `false`, use `.toml`
///
/// # Returns
///
/// * `Ok((directory, filename))` - Tuple of parent directory and final filename with correct extension
/// * `Err(io::Error)` - If path validation fails or path has no parent directory
///
/// # Error Cases
///
/// - Path has no filename component
/// - Path has no parent directory (e.g., root path or relative path with no parent)
/// - Path contains invalid UTF-8 (though this is handled gracefully)
///
/// # Examples
///
/// ```rust
/// use std::path::Path;
///
/// // Clearsigned format (unencrypted)
/// let input = Path::new("sync_data/team/messages/1234567890.toml");
/// let (dir, file) = create_messagepost_file_namepath_extension_tuple(input, false)?;
/// // dir: "sync_data/team/messages"
/// // file: "1234567890.toml"
///
/// // GPG encrypted format
/// let input = Path::new("sync_data/team/messages/1234567890.toml");
/// let (dir, file) = create_messagepost_file_namepath_extension_tuple(input, true)?;
/// // dir: "sync_data/team/messages"
/// // file: "1234567890.gpgtoml"
///
/// // Also works without extension in input
/// let input = Path::new("sync_data/team/messages/1234567890");
/// let (dir, file) = create_messagepost_file_namepath_extension_tuple(input, false)?;
/// // dir: "sync_data/team/messages"
/// // file: "1234567890.toml"
/// ```
fn create_messagepost_file_namepath_extension_tuple(
    incoming_path: &Path,
    use_encryption: bool,
) -> Result<(PathBuf, PathBuf), io::Error> {

    // Debug logging for inputs
    debug_log!("CMFNPET: Starting create_messagepost_file_namepath_extension_tuple");
    debug_log!("CMFNPET: incoming_path: {:?}", incoming_path);
    debug_log!("CMFNPET: use_encryption: {}", use_encryption);

    // Debug-Assert: Path must have a filename component
    // ONLY runs in debug builds, NOT in tests or release
    // #[cfg(not(test))]
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        incoming_path.file_name().is_some(),
        "CMFNPET: Path must contain a filename component"
    );

    // Production-Catch: Handle missing filename
    // This ALWAYS runs and returns Err instead of panicking
    let filename_os = incoming_path.file_name()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "CMFNPET: Path must contain a filename component"
        ))?;

    debug_log!("CMFNPET: Original filename: {:?}", filename_os);

    // Extract parent directory
    // Debug-Assert: Path must have a parent directory
    // ONLY runs in debug builds, NOT in tests or release
    // #[cfg(not(test))]
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        incoming_path.parent().is_some(),
        "CMFNPET: Path must have a parent directory"
    );

    // Production-Catch: Handle missing parent directory
    // This ALWAYS runs and returns Err instead of panicking
    let directory_path = incoming_path.parent()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "CMFNPET: Path must have a parent directory"
        ))?
        .to_path_buf();

    debug_log!("CMFNPET: Parent directory: {:?}", directory_path);

    // Strip any existing extension to get base filename
    // Use file_stem() to get filename without extension
    let base_filename = incoming_path.file_stem()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "CMFNPET: Cannot extract base filename"
        ))?;

    debug_log!("CMFNPET: Base filename (no extension): {:?}", base_filename);

    // Construct final filename with appropriate extension
    let final_filename = if use_encryption {
        // GPG encrypted format: use .gpgtoml extension
        let mut filename = base_filename.to_os_string();
        filename.push(".gpgtoml");
        PathBuf::from(filename)
    } else {
        // Clearsigned format: use .toml extension
        let mut filename = base_filename.to_os_string();
        filename.push(".toml");
        PathBuf::from(filename)
    };

    debug_log!("CMFNPET: Final filename with extension: {:?}", final_filename);

    // Debug-Assert: Final filename must have an extension
    // ONLY runs in debug builds, NOT in tests or release
    debug_assert!(
        final_filename.extension().is_some(),
        "CMFNPET: Final filename must have an extension"
    );

    // Production-Catch: Verify extension exists
    // This ALWAYS runs and returns Err instead of panicking
    if final_filename.extension().is_none() {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "CMFNPET: Failed to create filename with extension"
        ));
    }

    // Verify correct extension was applied
    let expected_extension = if use_encryption { "gpgtoml" } else { "toml" };

    // Debug-Assert: Extension must match encryption setting
    // ONLY runs in debug builds, NOT in tests or release
    debug_assert!(
        final_filename.extension()
            .and_then(|ext| ext.to_str())
            .map(|ext| ext == expected_extension)
            .unwrap_or(false),
        "CMFNPET: Extension must match encryption setting"
    );

    // Production-Catch: Verify correct extension
    // This ALWAYS runs and returns Err instead of panicking
    let actual_extension = final_filename.extension()
        .and_then(|ext| ext.to_str())
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::Other,
            "CMFNPET: Cannot read final extension"
        ))?;

    if actual_extension != expected_extension {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            format!(
                "CMFNPET: Extension mismatch: expected '{}', got '{}'",
                expected_extension,
                actual_extension
            )
        ));
    }

    debug_log!("CMFNPET: Successfully created tuple");
    debug_log!("CMFNPET: Directory: {:?}", directory_path);
    debug_log!("CMFNPET: Filename: {:?}", final_filename);

    Ok((directory_path, final_filename))
}

#[cfg(test)]
mod message_post_names_tests {
    use super::*;
    use std::path::Path;

    /// Test: Basic clearsigned TOML path handling with .toml input
    ///
    /// Verifies that when given a path with .toml extension and encryption disabled,
    /// the function correctly extracts directory and preserves .toml extension.
    #[test]
    fn test_clearsigned_with_toml_extension() {
        let input = Path::new("sync_data/team/messages/1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must succeed with valid path
        assert!(result.is_ok(), "Function should succeed with valid path");

        let (dir, file) = result.unwrap();

        // Test-Assert: Directory path must match expected
        assert_eq!(
            dir,
            PathBuf::from("sync_data/team/messages"),
            "Directory path should be extracted correctly"
        );

        // Test-Assert: Filename must match expected
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Filename should have .toml extension"
        );

        // Test-Assert: Extension must be 'toml'
        assert_eq!(
            file.extension().and_then(|e| e.to_str()),
            Some("toml"),
            "Extension should be 'toml'"
        );
    }

    /// Test: GPG encrypted path handling with .toml input
    ///
    /// Verifies that when given a path with .toml extension and encryption enabled,
    /// the function replaces the extension with .gpgtoml.
    #[test]
    fn test_encrypted_replaces_toml_extension() {
        let input = Path::new("sync_data/team/messages/1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, true);

        // Test-Assert: Function must succeed with valid path
        assert!(result.is_ok(), "Function should succeed with valid path");

        let (dir, file) = result.unwrap();

        // Test-Assert: Directory path must match expected
        assert_eq!(
            dir,
            PathBuf::from("sync_data/team/messages"),
            "Directory path should be extracted correctly"
        );

        // Test-Assert: Filename must have .gpgtoml extension
        assert_eq!(
            file,
            PathBuf::from("1234567890.gpgtoml"),
            "Filename should have .gpgtoml extension"
        );

        // Test-Assert: Extension must be 'gpgtoml'
        assert_eq!(
            file.extension().and_then(|e| e.to_str()),
            Some("gpgtoml"),
            "Extension should be 'gpgtoml'"
        );
    }

    /// Test: Path without extension, clearsigned format
    ///
    /// Verifies that the function adds .toml extension when input has no extension.
    #[test]
    fn test_no_extension_clearsigned() {
        let input = Path::new("sync_data/team/messages/1234567890");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must succeed with extensionless path
        assert!(result.is_ok(), "Function should succeed with extensionless path");

        let (dir, file) = result.unwrap();

        // Test-Assert: Directory must match expected
        assert_eq!(
            dir,
            PathBuf::from("sync_data/team/messages"),
            "Directory path should be extracted correctly"
        );

        // Test-Assert: Extension must be added
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should add .toml extension"
        );
    }

    /// Test: Path without extension, encrypted format
    ///
    /// Verifies that the function adds .gpgtoml extension when input has no extension.
    #[test]
    fn test_no_extension_encrypted() {
        let input = Path::new("sync_data/team/messages/1234567890");
        let result = create_messagepost_file_namepath_extension_tuple(input, true);

        // Test-Assert: Function must succeed with extensionless path
        assert!(result.is_ok(), "Function should succeed with extensionless path");

        let (dir, file) = result.unwrap();

        // Test-Assert: Directory must match expected
        assert_eq!(
            dir,
            PathBuf::from("sync_data/team/messages"),
            "Directory path should be extracted correctly"
        );

        // Test-Assert: Extension must be added
        assert_eq!(
            file,
            PathBuf::from("1234567890.gpgtoml"),
            "Should add .gpgtoml extension"
        );
    }

    /// Test: Different extension gets replaced (clearsigned)
    ///
    /// Verifies that non-.toml extensions are replaced with .toml for clearsigned.
    #[test]
    fn test_different_extension_replaced_clearsigned() {
        let input = Path::new("sync_data/team/messages/1234567890.txt");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must succeed
        assert!(result.is_ok(), "Function should succeed");

        let (_, file) = result.unwrap();

        // Test-Assert: Extension must be replaced
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should replace .txt with .toml"
        );
    }

    /// Test: Different extension gets replaced (encrypted)
    ///
    /// Verifies that non-.gpgtoml extensions are replaced with .gpgtoml for encrypted.
    #[test]
    fn test_different_extension_replaced_encrypted() {
        let input = Path::new("sync_data/team/messages/1234567890.txt");
        let result = create_messagepost_file_namepath_extension_tuple(input, true);

        // Test-Assert: Function must succeed
        assert!(result.is_ok(), "Function should succeed");

        let (_, file) = result.unwrap();

        // Test-Assert: Extension must be replaced
        assert_eq!(
            file,
            PathBuf::from("1234567890.gpgtoml"),
            "Should replace .txt with .gpgtoml"
        );
    }

    /// Test: Nested directory structure
    ///
    /// Verifies function works with deeply nested paths.
    #[test]
    fn test_nested_directory_structure() {
        let input = Path::new("a/b/c/d/e/message.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle nested paths
        assert!(result.is_ok(), "Function should handle nested paths");

        let (dir, file) = result.unwrap();

        // Test-Assert: Full nested path must be extracted
        assert_eq!(
            dir,
            PathBuf::from("a/b/c/d/e"),
            "Should extract full nested directory path"
        );

        // Test-Assert: Filename must be correct
        assert_eq!(
            file,
            PathBuf::from("message.toml"),
            "Should extract filename correctly"
        );
    }

    /// Test: Single directory level
    ///
    /// Verifies function works with minimal directory depth.
    #[test]
    fn test_single_directory_level() {
        let input = Path::new("messages/1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle single directory level
        assert!(result.is_ok(), "Function should handle single directory level");

        let (dir, file) = result.unwrap();

        // Test-Assert: Single directory must be extracted
        assert_eq!(
            dir,
            PathBuf::from("messages"),
            "Should extract single directory correctly"
        );

        // Test-Assert: Filename must be correct
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should extract filename correctly"
        );
    }
    /// Test: Error case - no filename
        ///
        /// Verifies function returns error when path has no filename component.
        #[test]
        fn test_error_no_filename() {
            // Use root path which has no filename
            let input = Path::new("/");
            let result = create_messagepost_file_namepath_extension_tuple(input, false);

            assert!(
                result.is_err(),
                "Function should return error for path without filename"
            );

            if let Err(e) = result {
                let error_msg = format!("{}", e);
                assert!(
                    error_msg.contains("filename component"),
                    "Error message should mention missing filename component, got: {}",
                    error_msg
                );
            }
        }

        /// Test: Error case - no parent directory
        ///
        /// Verifies function returns error when path has no parent.
        #[test]
        fn test_error_no_parent() {
            // Use root path which has no parent
            let input = Path::new("/");
            let result = create_messagepost_file_namepath_extension_tuple(input, false);

            assert!(
                result.is_err(),
                "Function should return error for path without parent directory"
            );

            if let Err(e) = result {
                let error_msg = format!("{}", e);
                assert!(
                    error_msg.contains("parent directory") || error_msg.contains("filename component"),
                    "Error message should mention missing parent directory, got: {}",
                    error_msg
                );
            }
        }

    /// Test: Complex filename with multiple dots
    ///
    /// Verifies that only the final extension is replaced, not intermediate dots.
    #[test]
    fn test_filename_with_multiple_dots() {
        let input = Path::new("messages/my.message.file.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, true);

        // Test-Assert: Function must handle multiple dots
        assert!(result.is_ok(), "Function should handle multiple dots");

        let (_, file) = result.unwrap();

        // Test-Assert: Dots in stem must be preserved
        assert_eq!(
            file,
            PathBuf::from("my.message.file.gpgtoml"),
            "Should preserve dots in filename stem and replace extension"
        );
    }

    /// Test: Filename with spaces
    ///
    /// Verifies function handles filenames containing spaces correctly.
    #[test]
    fn test_filename_with_spaces() {
        let input = Path::new("messages/my message file.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle spaces in filename
        assert!(result.is_ok(), "Function should handle spaces in filename");

        let (_, file) = result.unwrap();

        // Test-Assert: Spaces must be preserved
        assert_eq!(
            file,
            PathBuf::from("my message file.toml"),
            "Should preserve spaces in filename"
        );
    }

    /// Test: Absolute path (Unix-style)
    ///
    /// Verifies function works with absolute paths.
    #[test]
    #[cfg(unix)]
    fn test_absolute_path_unix() {
        let input = Path::new("/home/user/sync_data/messages/1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle absolute paths
        assert!(result.is_ok(), "Function should handle absolute paths");

        let (dir, file) = result.unwrap();

        // Test-Assert: Absolute directory path must be correct
        assert_eq!(
            dir,
            PathBuf::from("/home/user/sync_data/messages"),
            "Should extract absolute directory path correctly"
        );

        // Test-Assert: Filename must be correct
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should extract filename correctly from absolute path"
        );
    }

    /// Test: Absolute path (Windows-style)
    ///
    /// Verifies function works with Windows absolute paths.
    #[test]
    #[cfg(windows)]
    fn test_absolute_path_windows() {
        let input = Path::new("C:\\Users\\user\\sync_data\\messages\\1234567890.toml");
        let result = create_messagepost_file_namepath_extension_tuple(input, false);

        // Test-Assert: Function must handle Windows absolute paths
        assert!(result.is_ok(), "Function should handle Windows absolute paths");

        let (dir, file) = result.unwrap();

        // Test-Assert: Windows absolute directory path must be correct
        assert_eq!(
            dir,
            PathBuf::from("C:\\Users\\user\\sync_data\\messages"),
            "Should extract Windows absolute directory path correctly"
        );

        // Test-Assert: Filename must be correct
        assert_eq!(
            file,
            PathBuf::from("1234567890.toml"),
            "Should extract filename correctly from Windows path"
        );
    }

    /// Test: Extension consistency - clearsigned always gives .toml
    ///
    /// Verifies that use_encryption=false always results in .toml extension.
    #[test]
    fn test_extension_consistency_clearsigned() {
        let test_cases = vec![
            "dir/file.toml",
            "dir/file.gpgtoml",
            "dir/file.txt",
            "dir/file.md",
            "dir/file",
        ];

        for input_str in test_cases {
            let input = Path::new(input_str);
            let result = create_messagepost_file_namepath_extension_tuple(input, false);

            // Test-Assert: Function must succeed for all test cases
            assert!(
                result.is_ok(),
                "Should succeed for input: {}",
                input_str
            );

            let (_, file) = result.unwrap();

            // Test-Assert: Extension must always be 'toml' for clearsigned
            assert_eq!(
                file.extension().and_then(|e| e.to_str()),
                Some("toml"),
                "Extension should always be 'toml' for clearsigned, input was: {}",
                input_str
            );
        }
    }

    /// Test: Extension consistency - encrypted always gives .gpgtoml
    ///
    /// Verifies that use_encryption=true always results in .gpgtoml extension.
    #[test]
    fn test_extension_consistency_encrypted() {
        let test_cases = vec![
            "dir/file.toml",
            "dir/file.gpgtoml",
            "dir/file.txt",
            "dir/file.md",
            "dir/file",
        ];

        for input_str in test_cases {
            let input = Path::new(input_str);
            let result = create_messagepost_file_namepath_extension_tuple(input, true);

            // Test-Assert: Function must succeed for all test cases
            assert!(
                result.is_ok(),
                "Should succeed for input: {}",
                input_str
            );

            let (_, file) = result.unwrap();

            // Test-Assert: Extension must always be 'gpgtoml' for encrypted
            assert_eq!(
                file.extension().and_then(|e| e.to_str()),
                Some("gpgtoml"),
                "Extension should always be 'gpgtoml' for encrypted, input was: {}",
                input_str
            );
        }
    }
}

/// Saves message content as a clearsigned TOML file.
///
/// # Purpose
///
/// Creates a cryptographically signed TOML file for instant messages
/// by writing the TOML content and then clearsigning it in-place.
///
/// # Process Flow (Mirrors save_node_to_clearsigned_file)
///
/// 1. Validate target directory and create if needed
/// 2. Write plain TOML content to target file
/// 3. Get local user's GPG fingerprint from uma.toml
/// 4. Clearsign the file in-place
///
/// # Arguments
///
/// * `target_file_path` - Full path where clearsigned file should be saved
/// * `toml_content` - Pre-serialized TOML string to be clearsigned
///
/// # Returns
///
/// * `Ok(())` - File successfully created and clearsigned
/// * `Err(io::Error)` - If any step fails
fn save_message_as_clearsigned_toml(
    target_file_path: &Path,
    toml_content: &str,
) -> Result<(), io::Error> {

    debug_log!("SMACT: Starting save_message_as_clearsigned_toml");
    debug_log!("SMACT: target_file_path: {:?}", target_file_path);
    debug_log!("SMACT: toml_content length: {} bytes", toml_content.len());

    // Debug-Assert: TOML content must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !toml_content.is_empty(),
        "SMACT: TOML content must not be empty"
    );

    // Production-Catch: Handle empty TOML content
    if toml_content.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "SMACT: TOML content must not be empty"
        ));
    }

    // 1. Get target directory and verify/create it
    let target_dir = target_file_path.parent()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "SMACT: Target path must have a parent directory"
        ))?;

    if !target_dir.exists() {
        debug_log!("SMACT: Target directory doesn't exist, creating it");
        fs::create_dir_all(target_dir)?;
    }
    debug_log!("SMACT: Directory now exists: {}", target_dir.exists());

    // 2. Verify directory is actually a directory
    if !target_dir.is_dir() {
        debug_log!("SMACT: Path exists but is not a directory!");
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMACT: Target parent path exists but is not a directory"
        ));
    }

    // 3. Write the TOML data to the file
    debug_log!("SMACT: Writing TOML data to file...");
    fs::write(target_file_path, toml_content)?;

    // 4. Verify the file was created
    if target_file_path.exists() {
        debug_log!("SMACT: Successfully created file at: {:?}", target_file_path);
    } else {
        debug_log!("SMACT: Warning: File write succeeded but file doesn't exist!");
    }

    // 5. Get local user's GPG fingerprint from uma.toml
    debug_log!("SMACT: Getting GPG fingerprint from uma.toml");
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => {
            debug_log!("SMACT: Retrieved GPG fingerprint: {}", fingerprint);
            fingerprint
        },
        Err(e) => {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMACT: Failed to read GPG fingerprint from uma.toml: {}", e)
            ));
        }
    };

    // 6. Clearsign the file in-place
    debug_log!("SMACT: Starting clearsign operation");
    convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
        target_file_path,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
    )
    .map_err(|gpg_err| {
        std::io::Error::new(
            std::io::ErrorKind::Other,
            format!("SMACT: GPG clearsign operation failed: {:?}", gpg_err),
        )
    })?;

    debug_log!("SMACT: Successfully created clearsigned message file at: {:?}", target_file_path);
    debug_log!("SMACT: save_message_as_clearsigned_toml completed successfully");

    Ok(())
}

#[cfg(test)]
mod tests_clearsigned_v2 {
    use super::*;
    use std::path::{Path, PathBuf};
    use std::fs;

    /// Helper function to create test temp directory
    fn create_test_temp_dir() -> Result<PathBuf, io::Error> {
        let temp_base = std::env::temp_dir();
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
            .as_secs();
        let test_dir = temp_base.join(format!("test_clearsign_v2_{}", timestamp));
        fs::create_dir_all(&test_dir)?;
        Ok(test_dir)
    }

    /// Helper function to cleanup test directory
    fn cleanup_test_dir(dir: &Path) {
        let _ = fs::remove_dir_all(dir);
    }

    /// Test: Error case - empty TOML content
    ///
    /// Verifies that the function returns an error when given empty TOML content.
    #[test]
    fn test_error_empty_toml_content() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let target_file = test_dir.join("test_message.toml");

        let result = save_message_as_clearsigned_toml(
            &target_file,
            "", // Empty content
        );

        assert!(result.is_err(), "Function should return error for empty TOML content");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("TOML content must not be empty"),
                "Error message should mention empty TOML content, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }

    // For save_message_as_clearsigned_toml test:
    #[test]
    fn test_error_no_parent_directory() {
        let result = save_message_as_clearsigned_toml(
            Path::new("message.toml"),
            "owner = \"test\"\ntext = \"message\"",
        );

        assert!(result.is_err(), "Function should return error for path without proper parent");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("parent directory") ||
                error_msg.contains("empty path") ||
                error_msg.contains("not a directory"),  // ADD THIS
                "Error message should mention parent directory issue, got: {}",
                error_msg
            );
        }
    }

    /// Test: Directory creation when target directory doesn't exist
    ///
    /// Verifies that the function creates necessary directories.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_creates_target_directory() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let nested_dir = test_dir.join("level1/level2/level3");
        let target_file = nested_dir.join("test_message.toml");

        // Directory shouldn't exist yet
        assert!(!nested_dir.exists(), "Nested directory should not exist yet");

        let _result = save_message_as_clearsigned_toml(
            &target_file,
            "owner = \"test\"\ntext = \"message\"",
        );

        // Would verify directory was created if GPG setup available

        cleanup_test_dir(&test_dir);
    }

    /// Test: TOML content with special characters
    ///
    /// Verifies that the function handles TOML with quotes, newlines, etc.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_toml_with_special_characters() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let target_file = test_dir.join("test_message.toml");

        let toml_content = r#"owner = "testuser"
text = "Message with \"quotes\" and\nnewlines"
timestamp = 1234567890"#;

        let result = save_message_as_clearsigned_toml(
            &target_file,
            toml_content,
        );

        // With GPG setup, this should succeed
        // Without GPG, validates that content validation passes
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("TOML content must not be empty"),
                "Should not fail on content validation with valid special chars"
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Large TOML content
    ///
    /// Verifies that the function can handle large message content.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_large_toml_content() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let target_file = test_dir.join("test_message.toml");

        // Create large content (10KB)
        let large_text = "x".repeat(10000);
        let toml_content = format!("owner = \"testuser\"\ntext = \"{}\"", large_text);

        let result = save_message_as_clearsigned_toml(
            &target_file,
            &toml_content,
        );

        // With GPG setup, should handle large content
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("TOML content must not be empty"),
                "Should not fail on content validation with large content"
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Basic functionality with valid inputs
    ///
    /// This test requires GPG setup to run fully.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_basic_clearsign_success() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");

        let target_file = test_dir.join("test_message.toml");
        let toml_content = "owner = \"testuser\"\ntext = \"Test message\"";

        let result = save_message_as_clearsigned_toml(
            &target_file,
            toml_content,
        );

        // With proper GPG setup, this should succeed
        // assert!(result.is_ok(), "Function should succeed with valid inputs");
        // assert!(target_file.exists(), "Target file should exist");

        cleanup_test_dir(&test_dir);
    }
}

/// Saves message content as a GPG encrypted TOML file.
///
/// # Purpose
///
/// Creates a cryptographically signed AND encrypted TOML file.
///
/// # Process Flow (Mirrors save_node_as_gpgtoml)
///
/// 1. Verify target directory and create if needed
/// 2. Create temp file in project temp directory
/// 3. Write plain TOML to temp file
/// 4. Get local user's GPG fingerprint from uma.toml
/// 5. Clearsign temp file in-place
/// 6. Extract public key from GPG keyring
/// 7. Encrypt clearsigned file with public key
/// 8. Save to final .gpgtoml file
/// 9. Clean up temp file
///
/// # Arguments
///
/// * `base_file_path` - Path WITHOUT extension (function adds .gpgtoml)
/// * `toml_content` - Pre-serialized TOML string to be encrypted
///
/// # Returns
///
/// * `Ok(())` - File successfully created, clearsigned, and encrypted
/// * `Err(io::Error)` - If any step fails
fn save_message_as_gpgtoml(
    base_file_path: &Path,
    toml_content: &str,
) -> Result<(), io::Error> {

    debug_log!("SMAGF: Starting save_message_as_gpgtoml");
    debug_log!("SMAGF: base_file_path: {:?}", base_file_path);
    debug_log!("SMAGF: toml_content length: {} bytes", toml_content.len());

    // Debug-Assert: TOML content must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !toml_content.is_empty(),
        "SMAGF: TOML content must not be empty"
    );

    // Production-Catch: Handle empty TOML content
    if toml_content.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "SMAGF: TOML content must not be empty"
        ));
    }

    // 1. Construct final file path with .gpgtoml extension
    let final_file_path = base_file_path.with_extension("gpgtoml");
    debug_log!("SMAGF: Final file path: {:?}", final_file_path);

    // 2. Verify and create target directory structure if needed
    let target_dir = final_file_path.parent()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "SMAGF: Target path must have a parent directory"
        ))?;

    if !target_dir.exists() {
        debug_log!("SMAGF: Target directory doesn't exist, creating it");
        fs::create_dir_all(target_dir)?;
    }
    debug_log!("SMAGF: Directory now exists: {}", target_dir.exists());

    // Verify directory is actually a directory
    if !target_dir.is_dir() {
        debug_log!("SMAGF: Path exists but is not a directory!");
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMAGF: Target parent path exists but is not a directory"
        ));
    }

    // 3. Get temp directory and create unique temp file path
    let temp_dir = get_base_uma_temp_directory_path()?;

    let timestamp = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map_err(|e| io::Error::new(
            io::ErrorKind::Other,
            format!("SMAGF: Time error: {}", e)
        ))?
        .as_secs();

    let temp_file_name = format!("message_gpgtoml_{}.toml", timestamp);
    let temp_file_path = temp_dir.join(temp_file_name);

    debug_log!("SMAGF: Temp file path: {:?}", temp_file_path);

    // 4. Write plain TOML content to temp file
    debug_log!("SMAGF: Writing TOML content to temp file");

    if let Err(e) = fs::write(&temp_file_path, toml_content) {
        debug_log!("SMAGF: Failed to write temp file: {}", e);
        return Err(e);
    }

    // Verify temp file was created
    if !temp_file_path.exists() {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMAGF: Failed to create temp file"
        ));
    }

    debug_log!("SMAGF: Successfully wrote temp file");

    // 5. Get local user's GPG fingerprint from uma.toml
    debug_log!("SMAGF: Getting GPG fingerprint from uma.toml");

    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => {
            debug_log!("SMAGF: Retrieved GPG fingerprint: {}", fingerprint);
            fingerprint
        },
        Err(e) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Failed to read GPG fingerprint from uma.toml: {}", e)
            ));
        }
    };

    // 6. Clearsign the temp file in-place
    debug_log!("SMAGF: Starting clearsign operation on temp file");

    match convert_tomlfile_without_keyid_using_gpgtomlkeyid_into_clearsigntoml_inplace(
        &temp_file_path,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
    ) {
        Ok(()) => {
            debug_log!("SMAGF: Successfully clearsigned temp file");
        },
        Err(gpg_err) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: GPG clearsign operation failed: {:?}", gpg_err),
            ));
        }
    }

    // 7. Extract public key from GPG keyring using fingerprint
    debug_log!("SMAGF: Extracting public key from GPG for fingerprint: {}", gpg_full_fingerprint_key_id_string);

    let public_key_output = match std::process::Command::new("gpg")
        .arg("--armor")
        .arg("--export")
        .arg(&gpg_full_fingerprint_key_id_string)
        .output()
    {
        Ok(output) => output,
        Err(e) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Failed to execute GPG export command: {}", e)
            ));
        }
    };

    // Check if GPG command succeeded
    if !public_key_output.status.success() {
        // Clean up temp file before returning error
        let _ = fs::remove_file(&temp_file_path);
        let stderr = String::from_utf8_lossy(&public_key_output.stderr);
        return Err(io::Error::new(
            io::ErrorKind::Other,
            format!("SMAGF: GPG export failed: {}", stderr)
        ));
    }

    // Convert public key bytes to string
    let public_key_string = match String::from_utf8(public_key_output.stdout) {
        Ok(key_str) => key_str,
        Err(e) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Failed to convert public key to UTF-8: {}", e)
            ));
        }
    };

    // Verify we got a valid public key
    if public_key_string.trim().is_empty() {
        // Clean up temp file before returning error
        let _ = fs::remove_file(&temp_file_path);
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMAGF: GPG export returned empty public key"
        ));
    }

    debug_log!("SMAGF: Successfully extracted public key from GPG");

    // 8. Encrypt the clearsigned temp file with the public key
    debug_log!("SMAGF: Starting encryption of clearsigned file");

    match encrypt_clearsigned_toml_with_public_key_content(
        &temp_file_path,
        &public_key_string,
        &final_file_path
    ) {
        Ok(()) => {
            debug_log!("SMAGF: Successfully created encrypted file at: {:?}", final_file_path);
        },
        Err(e) => {
            // Clean up temp file before returning error
            let _ = fs::remove_file(&temp_file_path);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Encryption failed: {:?}", e)
            ));
        }
    }

    // 9. Clean up temp file (critical for production)
    debug_log!("SMAGF: Cleaning up temp file");

    if let Err(e) = fs::remove_file(&temp_file_path) {
        // Log warning but don't fail the operation since main task succeeded
        debug_log!("SMAGF: Warning: Failed to remove temp file: {}", e);
    }

    // 10. Verify final file exists and is non-empty
    if !final_file_path.exists() {
        return Err(io::Error::new(
            io::ErrorKind::Other,
            "SMAGF: Final file creation appeared successful but file doesn't exist"
        ));
    }

    // Check file size
    match fs::metadata(&final_file_path) {
        Ok(metadata) => {
            let file_size = metadata.len();
            debug_log!("SMAGF: Final file size: {} bytes", file_size);

            if file_size == 0 {
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    "SMAGF: Final file was created but is empty"
                ));
            }
        },
        Err(e) => {
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("SMAGF: Cannot read final file metadata: {}", e)
            ));
        }
    }

    debug_log!("SMAGF: Successfully created encrypted message file at: {:?}", final_file_path);
    debug_log!("SMAGF: save_message_as_gpgtoml completed successfully");

    Ok(())
}

#[cfg(test)]
mod tests_gpgtoml_v2 {
    use super::*;
    use std::path::{Path, PathBuf};
    use std::fs;

    /// Helper function to create test temp directory
    fn create_test_temp_dir() -> Result<PathBuf, io::Error> {
        let temp_base = std::env::temp_dir();
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("Time error: {}", e)))?
            .as_secs();
        let test_dir = temp_base.join(format!("test_gpgtoml_v2_{}", timestamp));
        fs::create_dir_all(&test_dir)?;
        Ok(test_dir)
    }

    /// Helper function to cleanup test directory
    fn cleanup_test_dir(dir: &Path) {
        let _ = fs::remove_dir_all(dir);
    }

    /// Test: Error case - empty TOML content
    ///
    /// Verifies that the function returns an error when given empty TOML content.
    #[test]
    fn test_error_empty_toml_content() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message");

        let result = save_message_as_gpgtoml(
            &base_file,
            "", // Empty content
        );

        assert!(result.is_err(), "Function should return error for empty TOML content");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                error_msg.contains("TOML content must not be empty"),
                "Error message should mention empty TOML content, got: {}",
                error_msg
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Error case - base path with no parent directory
    ///
    /// Verifies that the function returns an error when base path has no parent.
    #[test]
    fn test_error_no_parent_directory() {
        let result = save_message_as_gpgtoml(
            Path::new("message"), // Path with empty parent ("")
            "owner = \"test\"\ntext = \"message\"",
        );

        assert!(result.is_err(), "Function should return error for path without proper parent");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            // The error could be about parent directory or that empty path is not a directory
            assert!(
                error_msg.contains("parent directory") ||
                error_msg.contains("empty path") ||
                error_msg.contains("not a directory"),
                "Error message should mention parent directory issue, got: {}",
                error_msg
            );
        }
    }

    /// Test: Extension handling - gpgtoml extension is added
    ///
    /// Verifies that .gpgtoml extension is correctly added to base path.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_extension_added_correctly() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message");

        let result = save_message_as_gpgtoml(
            &base_file,
            "owner = \"test\"\ntext = \"message\"",
        );

        // With GPG setup, should create file with .gpgtoml extension
        // Without GPG, validates that path construction doesn't fail

        cleanup_test_dir(&test_dir);
    }

    /// Test: Extension handling - existing extension is replaced
    ///
    /// Verifies that if base path has an extension, it's replaced with .gpgtoml.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_existing_extension_replaced() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message.toml");

        let _ = save_message_as_gpgtoml(
            &base_file,
            "owner = \"test\"\ntext = \"message\"",
        );

        // Should create .gpgtoml file, replacing .toml extension

        cleanup_test_dir(&test_dir);
    }

    /// Test: TOML content with special characters
    ///
    /// Verifies that the function handles TOML with quotes, newlines, etc.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_toml_with_special_characters() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message");

        let toml_content = r#"owner = "testuser"
text = "Message with \"quotes\" and\nnewlines"
timestamp = 1234567890"#;

        let result = save_message_as_gpgtoml(
            &base_file,
            toml_content,
        );

        // With GPG setup, should handle special characters
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("TOML content must not be empty"),
                "Should not fail on content validation with valid special chars"
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Large TOML content
    ///
    /// Verifies that the function can handle large message content.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_large_toml_content() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");
        let base_file = test_dir.join("test_message");

        // Create large content (10KB)
        let large_text = "x".repeat(10000);
        let toml_content = format!("owner = \"testuser\"\ntext = \"{}\"", large_text);

        let result = save_message_as_gpgtoml(
            &base_file,
            &toml_content,
        );

        // With GPG setup, should handle large content
        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(
                !error_msg.contains("TOML content must not be empty"),
                "Should not fail on content validation with large content"
            );
        }

        cleanup_test_dir(&test_dir);
    }

    /// Test: Basic functionality with valid inputs
    ///
    /// This test requires GPG setup to run fully.
    #[test]
    #[ignore] // Requires GPG setup
    fn test_basic_gpgtoml_success() {
        let test_dir = create_test_temp_dir().expect("Failed to create test directory");

        let base_file = test_dir.join("test_message");
        let toml_content = "owner = \"testuser\"\ntext = \"Test message\"";

        let result = save_message_as_gpgtoml(
            &base_file,
            toml_content,
        );

        // With proper GPG setup, should create .gpgtoml file
        // assert!(result.is_ok(), "Function should succeed with valid inputs");
        // let expected_file = test_dir.join("test_message.gpgtoml");
        // assert!(expected_file.exists(), "Target file should exist with .gpgtoml extension");

        cleanup_test_dir(&test_dir);
    }
}

/// Check if current time is within allowed message posting window
///
/// # Purpose
///
/// Validates whether the current UTC time falls within configured time boundaries
/// for message posting. This is the earliest validation point in the message creation
/// pipeline - if the time window check fails, no message creation occurs.
///
/// # Project Context
///
/// The Message Post Suite supports time-bounded posting periods for various use cases:
/// - Limited-duration surveys/polls
/// - Event-specific feedback windows
/// - Time-sensitive announcements
/// - Scheduled messaging periods
///
/// Time windows can have:
/// - Both start and end bounds (fixed window)
/// - Only start bound (open-ended after start)
/// - Only end bound (open-ended until end)
/// - No bounds (always open)
///
/// When a message post attempt occurs outside the configured window, this function
/// prints an informative message and returns false, allowing the caller to exit
/// gracefully without creating any message file.
///
/// # Time Window Logic
///
/// Window is OPEN (return true) when:
/// - No start AND no end specified (no constraints)
/// - Current time >= start (if start exists) AND current time <= end (if end exists)
///
/// Window is CLOSED (return false) when:
/// - Current time < start (too early)
/// - Current time > end (too late)
///
/// # Arguments
///
/// * `start_utc_posix` - Optional Unix timestamp (seconds since epoch) for window start
/// * `end_utc_posix` - Optional Unix timestamp (seconds since epoch) for window end
///
/// # Returns
///
/// * `Ok(true)` - Current time is within window OR no window configured
/// * `Ok(false)` - Current time is outside window (message printed to user)
/// * `Err(io::Error)` - System time retrieval failed (extremely rare, indicates system issue)
///
/// # Error Handling
///
/// System time errors are propagated as io::Error since they indicate serious
/// system-level problems (corrupted system clock, time before Unix epoch, etc.).
/// The caller should handle these as system failures.
///
/// # Examples
///
/// ```rust
/// // No window constraints - always open
/// let result = check_time_window(None, None)?;
/// assert_eq!(result, true);
///
/// // Window with only end time
/// let one_hour_from_now = current_time + 3600;
/// let result = check_time_window(None, Some(one_hour_from_now))?;
/// // Returns true if current time < one_hour_from_now
///
/// // Fixed window (start and end)
/// let start = 1704067200; // Jan 1, 2024 00:00:00 UTC
/// let end = 1735689600;   // Jan 1, 2025 00:00:00 UTC
/// let result = check_time_window(Some(start), Some(end))?;
/// // Returns true only if current time is between start and end
/// ```
///
/// # Security Notes
///
/// - Uses system UTC time (not local time) for consistency across time zones
/// - Inclusive bounds: time exactly at start or end is considered valid
/// - Does not expose internal timestamp values in user-facing messages
///
fn check_time_window(
    start_utc_posix: Option<i64>,
    end_utc_posix: Option<i64>,
) -> io::Result<bool> {

    // =================================================
    // Debug-Assert (debug builds only, NOT tests)
    // =================================================

    // Validate that if both bounds exist, start <= end
    #[cfg(all(debug_assertions, not(test)))]
    {
        if let (Some(start), Some(end)) = (start_utc_posix, end_utc_posix) {
            debug_assert!(
                start <= end,
                "CTW: Time window start must not be after end (start: {}, end: {})",
                start,
                end
            );
        }
    }

    // =================================================
    // Production-Catch: Validate time window consistency
    // =================================================

    // Handle invalid configuration where start > end
    if let (Some(start), Some(end)) = (start_utc_posix, end_utc_posix) {
        if start > end {
            // Invalid configuration - treat as closed window
            println!("\n Message posting window configuration error (start after end)");
            println!("Please contact administrator.\n");
            return Ok(false);
        }
    }

    // =================================================
    // Get Current Time
    // =================================================

    // Get current UTC time as seconds since Unix epoch
    let current_time_secs = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map_err(|e| io::Error::new(
            io::ErrorKind::Other,
            format!("CTW: System time error: {}", e)
        ))?
        .as_secs() as i64; // Convert u64 to i64 for comparison

    // =================================================
    // Check Time Window Bounds
    // =================================================

    // Check start bound (if exists)
    if let Some(start) = start_utc_posix {
        if current_time_secs < start {
            // Before window opens
            println!("\n Message posting window has not opened yet.");
            println!("Please try again when the posting period begins.\n");
            return Ok(false);
        }
    }

    // Check end bound (if exists)
    if let Some(end) = end_utc_posix {
        if current_time_secs > end {
            // After window closes
            println!("\n Message posting window has closed.");
            println!("The posting period has ended.\n");
            return Ok(false);
        }
    }

    // =================================================
    // Window is Open
    // =================================================

    // Either no bounds exist, or current time is within bounds
    Ok(true)
}

#[cfg(test)]
mod tests_check_time_window {
    use super::*;

    /// Test: No time constraints - window always open
    ///
    /// When both start and end are None, the window should always be open
    /// regardless of current time.
    #[test]
    fn test_no_constraints_always_open() {
        let result = check_time_window(None, None);
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), true, "Window with no constraints should be open");
    }

    /// Test: Only start constraint - current time is after start
    ///
    /// When only start is specified and current time is after start,
    /// window should be open.
    #[test]
    fn test_only_start_after_start_time() {
        // Use a timestamp from the past (Jan 1, 2020)
        let past_start = 1577836800_i64;

        let result = check_time_window(Some(past_start), None);
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), true, "Window should be open when current time > start");
    }

    /// Test: Only start constraint - current time is before start
    ///
    /// When only start is specified and current time is before start,
    /// window should be closed.
    #[test]
    fn test_only_start_before_start_time() {
        // Use a timestamp far in the future (Jan 1, 2030)
        let future_start = 1893456000_i64;

        let result = check_time_window(Some(future_start), None);
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), false, "Window should be closed when current time < start");
    }

    /// Test: Only end constraint - current time is before end
    ///
    /// When only end is specified and current time is before end,
    /// window should be open.
    #[test]
    fn test_only_end_before_end_time() {
        // Use a timestamp far in the future (Jan 1, 2030)
        let future_end = 1893456000_i64;

        let result = check_time_window(None, Some(future_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), true, "Window should be open when current time < end");
    }

    /// Test: Only end constraint - current time is after end
    ///
    /// When only end is specified and current time is after end,
    /// window should be closed.
    #[test]
    fn test_only_end_after_end_time() {
        // Use a timestamp from the past (Jan 1, 2020)
        let past_end = 1577836800_i64;

        let result = check_time_window(None, Some(past_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), false, "Window should be closed when current time > end");
    }

    /// Test: Both constraints - current time is before window
    ///
    /// When both start and end are specified and current time is before start,
    /// window should be closed.
    #[test]
    fn test_both_constraints_before_window() {
        // Both timestamps in the future
        let future_start = 1893456000_i64; // Jan 1, 2030
        let future_end = 1925078400_i64;   // Jan 1, 2031

        let result = check_time_window(Some(future_start), Some(future_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), false, "Window should be closed before start time");
    }

    /// Test: Both constraints - current time is within window
    ///
    /// When both start and end are specified and current time is between them,
    /// window should be open.
    #[test]
    fn test_both_constraints_within_window() {
        // Start in the past, end in the future
        let past_start = 1577836800_i64;   // Jan 1, 2020
        let future_end = 1893456000_i64;   // Jan 1, 2030

        let result = check_time_window(Some(past_start), Some(future_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), true, "Window should be open when current time is within bounds");
    }

    /// Test: Both constraints - current time is after window
    ///
    /// When both start and end are specified and current time is after end,
    /// window should be closed.
    #[test]
    fn test_both_constraints_after_window() {
        // Both timestamps in the past
        let past_start = 1546300800_i64;   // Jan 1, 2019
        let past_end = 1577836800_i64;     // Jan 1, 2020

        let result = check_time_window(Some(past_start), Some(past_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), false, "Window should be closed after end time");
    }

    /// Test: Invalid configuration - start after end
    ///
    /// When start > end (invalid configuration), function should handle gracefully
    /// and return false (closed window).
    #[test]
    fn test_invalid_config_start_after_end() {
        // Start is after end - invalid configuration
        let invalid_start = 1577836800_i64; // Jan 1, 2020
        let invalid_end = 1546300800_i64;   // Jan 1, 2019

        let result = check_time_window(Some(invalid_start), Some(invalid_end));
        assert!(result.is_ok(), "Function should return Ok even with invalid config");
        assert_eq!(result.unwrap(), false, "Invalid configuration should result in closed window");
    }

    /// Test: Edge case - current time exactly at start
    ///
    /// Tests inclusive lower bound: time exactly at start should be valid.
    /// Uses a narrow window to test boundary condition.
    #[test]
    fn test_edge_case_at_start_boundary() {
        // Create a window that will be in the past but close together
        let past_start = 1577836800_i64;   // Jan 1, 2020 00:00:00
        let past_end = 1577836860_i64;     // Jan 1, 2020 00:01:00 (60 seconds later)

        // Current time will be after both (in 2025+), so this tests the logic
        // but doesn't test the exact boundary. For exact boundary testing,
        // we would need dependency injection or a time-mocking framework.

        let result = check_time_window(Some(past_start), Some(past_end));
        assert!(result.is_ok(), "Function should return Ok");
        // Result will be false since we're after the window, but the test
        // validates the comparison logic works correctly
    }

    /// Test: Edge case - current time exactly at end
    ///
    /// Tests inclusive upper bound: time exactly at end should be valid.
    #[test]
    fn test_edge_case_at_end_boundary() {
        // Start in past, end in future
        let past_start = 1577836800_i64;   // Jan 1, 2020
        let future_end = 1893456000_i64;   // Jan 1, 2030

        let result = check_time_window(Some(past_start), Some(future_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), true, "Current time within window should return true");
    }

    /// Test: Zero timestamps (Unix epoch)
    ///
    /// Tests that the function handles timestamp 0 (Jan 1, 1970) correctly.
    #[test]
    fn test_zero_timestamp_epoch() {
        let epoch_start = 0_i64;
        let future_end = 1893456000_i64;   // Jan 1, 2030

        let result = check_time_window(Some(epoch_start), Some(future_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), true, "Window from epoch to future should be open");
    }

    /// Test: Negative timestamps (before Unix epoch)
    ///
    /// Tests that the function handles negative timestamps correctly
    /// (times before Jan 1, 1970).
    #[test]
    fn test_negative_timestamp_before_epoch() {
        let before_epoch_start = -86400_i64; // Dec 31, 1969
        let past_end = 1577836800_i64;       // Jan 1, 2020

        let result = check_time_window(Some(before_epoch_start), Some(past_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), false, "Window entirely in past should be closed");
    }

    /// Test: Very large timestamps (far future)
    ///
    /// Tests that the function handles very large timestamps without overflow.
    #[test]
    fn test_very_large_timestamp_far_future() {
        let far_future_start = 253402300800_i64; // Year 9999
        let far_future_end = 253402387200_i64;   // Year 9999 + 1 day

        let result = check_time_window(Some(far_future_start), Some(far_future_end));
        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), false, "Window entirely in far future should be closed");
    }

    /// Test: Same start and end (instant window)
    ///
    /// Tests edge case where start equals end (window is a single instant).
    #[test]
    fn test_same_start_and_end_instant_window() {
        let same_time = 1577836800_i64; // Jan 1, 2020

        let result = check_time_window(Some(same_time), Some(same_time));
        assert!(result.is_ok(), "Function should return Ok");
        // Current time is after this instant, so window is closed
        assert_eq!(result.unwrap(), false, "Instant window in past should be closed");
    }
}

/// Truncate message text to maximum allowed length with warning
///
/// # Purpose
///
/// Enforces maximum string length constraints on message post content.
/// When a maximum length is configured and the input exceeds it, this function
/// truncates the text and notifies the user. The truncated message is still
/// posted - the user can retry with a shorter message if desired.
///
/// # Project Context
///
/// The Message Post Suite supports configurable message length limits for:
/// - Survey/poll responses with character limits
/// - Standardized form fields with fixed-width constraints
/// - Micro-blogging with tweet-like length restrictions
/// - SMS-style text messaging with length caps
/// - Database field size constraints
///
/// Length limits apply to the user input string itself (not including any
/// formatting added by structured message processing like "#comment: " prefix
/// or "3. " integer selection prefix).
///
/// # Truncation Policy
///
/// - Truncation occurs at the character (not byte) boundary
/// - Warning is printed to inform user of truncation
/// - Truncated message is still created (non-blocking)
/// - User can retry with shorter input if they choose
/// - No loops: function runs once and returns result
///
/// # Arguments
///
/// * `input` - The message text to check and potentially truncate
/// * `max_length` - Optional maximum character length constraint
///
/// # Returns
///
/// * `Ok(String)` - Original string if within limit, or truncated string if exceeded
/// * `Err(io::Error)` - Only on catastrophic failure (should be extremely rare)
///
/// # Behavior
///
/// - If `max_length` is None: Returns original string unchanged
/// - If input length <= max_length: Returns original string unchanged
/// - If input length > max_length: Truncates to max_length, prints warning, returns truncated
///
/// # Examples
///
/// ```rust
/// // No length limit - returns original
/// let result = truncate_message_to_max_length("Hello world", None)?;
/// assert_eq!(result, "Hello world");
///
/// // Within limit - returns original
/// let result = truncate_message_to_max_length("Hello", Some(10))?;
/// assert_eq!(result, "Hello");
///
/// // Exceeds limit - returns truncated with warning printed
/// let result = truncate_message_to_max_length("Hello world", Some(5))?;
/// assert_eq!(result, "Hello");
/// // Prints: " Message exceeded maximum length (11 > 5) - truncated to 5 characters"
/// ```
///
/// # Character vs Byte Length
///
/// This function operates on character count (Unicode scalar values), not byte count.
/// A multi-byte character like "" counts as 1 character, not 4 bytes.
///
/// # Security Notes
///
/// - Does not expose full original message content in warning
/// - Length information is safe to display (not sensitive)
/// - Truncation prevents resource exhaustion from oversized messages
///
fn truncate_message_to_max_length(
    input: &str,
    max_length: Option<usize>,
) -> io::Result<String> {

    // =================================================
    // Debug-Assert (debug builds only, NOT tests)
    // =================================================

    // Validate input is not empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !input.is_empty(),
        "TMTML: Input message should not be empty"
    );

    // Validate max_length is not zero if Some
    #[cfg(all(debug_assertions, not(test)))]
    {
        if let Some(max) = max_length {
            debug_assert!(
                max > 0,
                "TMTML: Max length must be greater than zero if specified"
            );
        }
    }

    // =================================================
    // Production-Catch: Validate inputs
    // =================================================

    // Handle empty input
    if input.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "TMTML: Input message cannot be empty"
        ));
    }

    // Handle zero max_length (invalid configuration)
    if let Some(0) = max_length {
        // Zero max length is invalid - treat as no limit
        println!("\n Warning: Maximum length configured as 0 (invalid) - no limit applied\n");
        return Ok(input.to_string());
    }

    // =================================================
    // Check Length Constraint
    // =================================================

    // If no max_length specified, return original string
    let max = match max_length {
        None => return Ok(input.to_string()),
        Some(m) => m,
    };

    // Get character count (not byte count)
    let char_count = input.chars().count();

    // If within limit, return original string
    if char_count <= max {
        return Ok(input.to_string());
    }

    // =================================================
    // Truncate and Warn
    // =================================================

    // Truncate to max characters
    let truncated: String = input.chars().take(max).collect();

    // Print warning to user
    println!("\n Message exceeded maximum length ({} > {}) - truncated to {} characters",
        char_count,
        max,
        max
    );
    println!("   Truncated message will be posted. You may retry with a shorter message if desired.\n");

    // Return truncated string
    Ok(truncated)
}

#[cfg(test)]
mod tests_truncate_message_to_max_length {
    use super::*;

    /// Test: No max length constraint - returns original string
    ///
    /// When max_length is None, the original string should be returned unchanged
    /// regardless of its length.
    #[test]
    fn test_no_max_length_returns_original() {
        let input = "Hello, world!";
        let result = truncate_message_to_max_length(input, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), input, "Should return original string when no limit set");
    }

    /// Test: Input within limit - returns original string
    ///
    /// When the input string is shorter than the max_length,
    /// it should be returned unchanged.
    #[test]
    fn test_within_limit_returns_original() {
        let input = "Short";
        let max_length = Some(10);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), input, "Should return original string when within limit");
    }

    /// Test: Input exceeds limit - returns truncated string
    ///
    /// When the input string is longer than the max_length,
    /// it should be truncated to exactly max_length characters.
    #[test]
    fn test_exceeds_limit_returns_truncated() {
        let input = "This is a very long message";
        let max_length = Some(10);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated, "This is a ", "Should truncate to exactly max_length");
        assert_eq!(truncated.chars().count(), 10, "Truncated length should be exactly 10");
    }

    /// Test: Input exactly at limit - returns original string
    ///
    /// Boundary test: when input length equals max_length exactly,
    /// the original string should be returned.
    #[test]
    fn test_exactly_at_limit_returns_original() {
        let input = "12345";
        let max_length = Some(5);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), input, "Should return original when exactly at limit");
    }

    /// Test: Empty string input - returns error
    ///
    /// Empty strings are invalid message content and should return an error.
    #[test]
    fn test_empty_string_returns_error() {
        let input = "";
        let max_length = Some(10);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_err(), "Empty string should return error");
    }

    /// Test: Zero max length - treats as no limit
    ///
    /// Invalid configuration where max_length is 0 should be handled
    /// gracefully by treating it as no limit.
    #[test]
    fn test_zero_max_length_treats_as_no_limit() {
        let input = "Hello, world!";
        let max_length = Some(0);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Should handle zero max_length gracefully");
        assert_eq!(result.unwrap(), input, "Zero max_length should act as no limit");
    }

    /// Test: Single character with limit 1
    ///
    /// Edge case: single character message with limit of 1
    /// should return the single character.
    #[test]
    fn test_single_character_with_limit_one() {
        let input = "A";
        let max_length = Some(1);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), "A", "Single character should be preserved");
    }

    /// Test: Multiple characters truncated to limit 1
    ///
    /// When input has multiple characters but limit is 1,
    /// should truncate to first character only.
    #[test]
    fn test_multiple_chars_truncated_to_one() {
        let input = "ABC";
        let max_length = Some(1);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), "A", "Should truncate to first character");
    }

    /// Test: Unicode multi-byte characters - character count vs byte count
    ///
    /// Ensures truncation works on character boundaries, not byte boundaries.
    /// Emoji and other multi-byte characters should count as single characters.
    #[test]
    fn test_unicode_multibyte_characters() {
        let input = "HelloWorld"; // Contains 2 emoji (4 bytes each)
        let max_length = Some(8);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated, "HelloWo", "Should truncate at character boundary");
        assert_eq!(truncated.chars().count(), 8, "Should count characters, not bytes");
    }

    /// Test: Unicode emoji only - character counting
    ///
    /// Tests that emoji are correctly counted as single characters.
    #[test]
    fn test_unicode_emoji_only() {
        let input = ""; // 5 emoji characters
        let max_length = Some(3);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated, "", "Should truncate emoji correctly");
        assert_eq!(truncated.chars().count(), 3, "Should have exactly 3 emoji characters");
    }

    /// Test: Asian characters (CJK) - multi-byte character handling
    ///
    /// Tests that Chinese/Japanese/Korean characters are counted correctly.
    #[test]
    fn test_asian_characters_multibyte() {
        let input = ""; // 6 Chinese characters
        let max_length = Some(4);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated, "", "Should truncate CJK characters correctly");
        assert_eq!(truncated.chars().count(), 4, "Should have exactly 4 characters");
    }

    /// Test: Very long string truncation
    ///
    /// Tests performance with a long string and small limit.
    #[test]
    fn test_very_long_string_truncation() {
        let input = "a".repeat(10000); // 10,000 character string
        let max_length = Some(100);
        let result = truncate_message_to_max_length(&input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated.chars().count(), 100, "Should truncate to exactly 100 characters");
        assert_eq!(truncated, "a".repeat(100), "Should contain first 100 characters");
    }

    /// Test: Whitespace at boundary
    ///
    /// Tests that truncation doesn't have special behavior for whitespace.
    /// Truncation occurs at character count, not word boundaries.
    #[test]
    fn test_whitespace_at_boundary() {
        let input = "Hello world this is a test";
        let max_length = Some(11); // Cuts in middle of "world"
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated, "Hello world", "Should truncate at character boundary, not word boundary");
    }

    /// Test: Newlines and special characters
    ///
    /// Tests that newlines, tabs, and other special characters are counted correctly.
    #[test]
    fn test_newlines_and_special_chars() {
        let input = "Line1\nLine2\tTab";
        let max_length = Some(10);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated.chars().count(), 10, "Should count newlines and tabs as characters");
        assert_eq!(truncated, "Line1\nLine", "Should preserve special characters in truncation");
    }

    /// Test: String with only spaces
    ///
    /// Tests that a string of only whitespace is handled correctly.
    #[test]
    fn test_string_only_spaces() {
        let input = "     "; // 5 spaces
        let max_length = Some(3);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated, "   ", "Should truncate spaces correctly");
        assert_eq!(truncated.chars().count(), 3, "Should have exactly 3 space characters");
    }

    /// Test: Mixed ASCII and Unicode
    ///
    /// Tests truncation with a mix of ASCII and multi-byte Unicode characters.
    #[test]
    fn test_mixed_ascii_and_unicode() {
        let input = "HelloWorld"; // Mix of ASCII, emoji, and CJK
        let max_length = Some(9);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated, "HelloWor", "Should handle mixed character sets");
        assert_eq!(truncated.chars().count(), 9, "Should count all character types correctly");
    }

    /// Test: Max length of 1 with long string
    ///
    /// Edge case: aggressive truncation to just 1 character.
    #[test]
    fn test_max_length_one_with_long_string() {
        let input = "This is a very long message that will be severely truncated";
        let max_length = Some(1);
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_ok(), "Function should return Ok");
        let truncated = result.unwrap();
        assert_eq!(truncated, "T", "Should truncate to single first character");
        assert_eq!(truncated.chars().count(), 1, "Should have exactly 1 character");
    }

    /// Test: Empty string with no limit
    ///
    /// Even with no limit, empty string should still return error.
    #[test]
    fn test_empty_string_no_limit() {
        let input = "";
        let max_length = None;
        let result = truncate_message_to_max_length(input, max_length);

        assert!(result.is_err(), "Empty string should return error even with no limit");
    }
}

/// Result of validating user input against structured format ranges
///
/// This enum represents the outcome of parsing and validating user input
/// for structured message posts with integer-based selection options.
#[derive(Debug, PartialEq, Eq)]
enum IntegerValidationResult {
    /// Input is not a valid integer
    NotAnInteger,

    /// Input is a valid integer but not in any configured range
    /// Contains the parsed integer value
    NotInAnyRange(i32),

    /// Input is a valid integer in an integer-only range
    /// Contains the parsed integer value
    InIntegerOnlyRange(i32),

    /// Input is a valid integer in an integer-string range (write-in option)
    /// Contains the parsed integer value
    InIntegerStringRange(i32),
}

/// Validate user input against structured message format integer ranges
///
/// # Purpose
///
/// Parses user input and validates it against configured integer selection ranges
/// for structured message posts. This is the foundation of the Q&A system that
/// guides users through multiple-choice, write-in, and mixed-format responses.
///
/// # Project Context
///
/// The Message Post Suite supports structured formats for:
/// - Multiple choice questions (integer-only ranges)
/// - Write-in options (integer-string ranges)
/// - Mixed formats (some choices are fixed, some allow write-in)
/// - Surveys, polls, elections, questionnaires, forms
///
/// Integer ranges define which selections are valid. For example:
/// - Options 1-3: Multiple choice (integer-only)
/// - Options 4-5: Write-in answers (integer-string)
///
/// # Range Priority
///
/// When ranges overlap, **integer-string ranges have priority** over integer-only ranges.
/// This allows configurations where some options are write-in and some are not,
/// even if the numbers overlap.
///
/// Example:
/// - Integer-only: (1, 3) and (6, 8)
/// - Integer-string: (3, 5)
/// - Input "3"  InIntegerStringRange (priority)
/// - Input "1"  InIntegerOnlyRange
/// - Input "4"  InIntegerStringRange
/// - Input "9"  NotInAnyRange
///
/// # Structured Format Activation
///
/// Structured format is considered **active** when:
/// - Some(vec![...]) with at least one tuple exists in either range parameter
///
/// Structured format is **not active** when:
/// - Both parameters are None
/// - Both parameters are Some(vec![]) (empty vectors)
///
/// # Range Format
///
/// Ranges are tuples (min, max) with **inclusive bounds**:
/// - (1, 3) includes: 1, 2, 3
/// - (5, 5) includes: 5 only
/// - Ranges can be non-continuous: vec![(1,3), (7,9)] includes 1,2,3,7,8,9 (not 4,5,6)
///
/// # Arguments
///
/// * `input` - User input string to parse and validate
/// * `integer_ranges` - Integer-only selection ranges (e.g., multiple choice)
/// * `integer_string_ranges` - Integer-string selection ranges (e.g., write-in options)
///
/// # Returns
///
/// * `Ok(IntegerValidationResult)` - Validation result with appropriate variant
/// * `Err(io::Error)` - Only on catastrophic failure
///
/// # Examples
///
/// ```rust
/// // No ranges configured - not structured format
/// let result = validate_integer_in_ranges("5", None, None)?;
/// // Returns NotAnInteger (structured format not active)
///
/// // Integer-only range
/// let int_ranges = Some(vec![(1, 3)]);
/// let result = validate_integer_in_ranges("2", int_ranges, None)?;
/// // Returns InIntegerOnlyRange(2)
///
/// // Integer-string range
/// let int_str_ranges = Some(vec![(4, 6)]);
/// let result = validate_integer_in_ranges("5", None, int_str_ranges)?;
/// // Returns InIntegerStringRange(5)
///
/// // Overlapping ranges - int-string has priority
/// let int_ranges = Some(vec![(1, 5)]);
/// let int_str_ranges = Some(vec![(3, 7)]);
/// let result = validate_integer_in_ranges("3", int_ranges, int_str_ranges)?;
/// // Returns InIntegerStringRange(3) - priority to int-string
///
/// // Not in any range
/// let int_ranges = Some(vec![(1, 3)]);
/// let result = validate_integer_in_ranges("10", int_ranges, None)?;
/// // Returns NotInAnyRange(10)
///
/// // Not a valid integer
/// let int_ranges = Some(vec![(1, 3)]);
/// let result = validate_integer_in_ranges("hello", int_ranges, None)?;
/// // Returns NotAnInteger
/// ```
///
/// # Security Notes
///
/// - Input parsing is safe against malformed integers
/// - No heap allocation in hot path
/// - Range checking is O(n) where n is number of range tuples
///
fn validate_integer_in_ranges(
    input: &str,
    integer_ranges: Option<Vec<(i32, i32)>>,
    integer_string_ranges: Option<Vec<(i32, i32)>>,
) -> io::Result<IntegerValidationResult> {

    // =================================================
    // Debug-Assert (debug builds only, NOT tests)
    // =================================================

    // Validate input is not empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !input.is_empty(),
        "VIIR: Input should not be empty"
    );

    // Validate range tuples have min <= max
    #[cfg(all(debug_assertions, not(test)))]
    {
        if let Some(ref ranges) = integer_ranges {
            for (min, max) in ranges {
                debug_assert!(
                    min <= max,
                    "VIIR: Integer range min must be <= max (got min:{}, max:{})",
                    min, max
                );
            }
        }
        if let Some(ref ranges) = integer_string_ranges {
            for (min, max) in ranges {
                debug_assert!(
                    min <= max,
                    "VIIR: Integer-string range min must be <= max (got min:{}, max:{})",
                    min, max
                );
            }
        }
    }

    // =================================================
    // Production-Catch: Validate inputs
    // =================================================

    // Handle empty input
    if input.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "VIIR: Input cannot be empty"
        ));
    }

    // =================================================
    // Parse Input as Integer
    // =================================================

    // Try to parse input as i32
    let parsed_value = match input.trim().parse::<i32>() {
        Ok(val) => val,
        Err(_) => {
            // Not a valid integer
            return Ok(IntegerValidationResult::NotAnInteger);
        }
    };

    // =================================================
    // Check Integer-String Ranges FIRST (Priority)
    // =================================================

    // Check if in integer-string range (write-in options)
    if let Some(ref ranges) = integer_string_ranges {
        for (min, max) in ranges {
            // Validate range (production catch for invalid config)
            if min > max {
                // Invalid range - skip it
                continue;
            }

            // Check if value is in this range (inclusive)
            if parsed_value >= *min && parsed_value <= *max {
                return Ok(IntegerValidationResult::InIntegerStringRange(parsed_value));
            }
        }
    }

    // =================================================
    // Check Integer-Only Ranges SECOND
    // =================================================

    // Check if in integer-only range (multiple choice)
    if let Some(ref ranges) = integer_ranges {
        for (min, max) in ranges {
            // Validate range (production catch for invalid config)
            if min > max {
                // Invalid range - skip it
                continue;
            }

            // Check if value is in this range (inclusive)
            if parsed_value >= *min && parsed_value <= *max {
                return Ok(IntegerValidationResult::InIntegerOnlyRange(parsed_value));
            }
        }
    }

    // =================================================
    // Not in Any Range
    // =================================================

    // Parsed successfully but not in any configured range
    Ok(IntegerValidationResult::NotInAnyRange(parsed_value))
}

#[cfg(test)]
mod tests_validate_integer_in_ranges {
    use super::*;

    /// Test: Input is not a valid integer
    ///
    /// When input cannot be parsed as an integer, should return NotAnInteger.
    #[test]
    fn test_not_an_integer() {
        let int_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("hello", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::NotAnInteger);
    }

    /// Test: Empty input returns error
    ///
    /// Empty strings are invalid and should return an error.
    #[test]
    fn test_empty_input_returns_error() {
        let int_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("", int_ranges, None);

        assert!(result.is_err(), "Empty input should return error");
    }

    /// Test: Valid integer in integer-only range
    ///
    /// When input is a valid integer within an integer-only range,
    /// should return InIntegerOnlyRange with the value.
    #[test]
    fn test_valid_integer_in_int_only_range() {
        let int_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("3", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(3));
    }

    /// Test: Valid integer in integer-string range
    ///
    /// When input is a valid integer within an integer-string range,
    /// should return InIntegerStringRange with the value.
    #[test]
    fn test_valid_integer_in_int_string_range() {
        let int_str_ranges = Some(vec![(4, 6)]);
        let result = validate_integer_in_ranges("5", None, int_str_ranges);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerStringRange(5));
    }

    /// Test: Integer not in any range
    ///
    /// When input is a valid integer but not in any configured range,
    /// should return NotInAnyRange with the value.
    #[test]
    fn test_integer_not_in_any_range() {
        let int_ranges = Some(vec![(1, 3)]);
        let int_str_ranges = Some(vec![(7, 9)]);
        let result = validate_integer_in_ranges("5", int_ranges, int_str_ranges);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(5));
    }

    /// Test: Priority - int-string range over int-only when overlapping
    ///
    /// When ranges overlap, integer-string range should have priority.
    #[test]
    fn test_priority_int_string_over_int_only() {
        let int_ranges = Some(vec![(1, 5)]);
        let int_str_ranges = Some(vec![(3, 7)]);
        let result = validate_integer_in_ranges("3", int_ranges, int_str_ranges);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(
            result.unwrap(),
            IntegerValidationResult::InIntegerStringRange(3),
            "Int-string range should have priority over int-only"
        );
    }

    /// Test: Priority - complete overlap
    ///
    /// When int-string range completely overlaps int-only range,
    /// int-string should always win.
    #[test]
    fn test_priority_complete_overlap() {
        let int_ranges = Some(vec![(1, 10)]);
        let int_str_ranges = Some(vec![(1, 10)]);
        let result = validate_integer_in_ranges("5", int_ranges, int_str_ranges);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(
            result.unwrap(),
            IntegerValidationResult::InIntegerStringRange(5),
            "Int-string range should have priority even with complete overlap"
        );
    }

    /// Test: Boundary - minimum value in range
    ///
    /// Tests inclusive lower bound: minimum value should be valid.
    #[test]
    fn test_boundary_minimum_value() {
        let int_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("1", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(1));
    }

    /// Test: Boundary - maximum value in range
    ///
    /// Tests inclusive upper bound: maximum value should be valid.
    #[test]
    fn test_boundary_maximum_value() {
        let int_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("5", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(5));
    }

    /// Test: Boundary - just below minimum
    ///
    /// Value just below minimum should not be in range.
    #[test]
    fn test_boundary_below_minimum() {
        let int_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("0", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(0));
    }

    /// Test: Boundary - just above maximum
    ///
    /// Value just above maximum should not be in range.
    #[test]
    fn test_boundary_above_maximum() {
        let int_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("6", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(6));
    }

    /// Test: Single value range
    ///
    /// Range where min equals max should work (single valid value).
    #[test]
    fn test_single_value_range() {
        let int_ranges = Some(vec![(5, 5)]);
        let result = validate_integer_in_ranges("5", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(5));
    }

    /// Test: Single value range - value not matching
    ///
    /// With single value range, other values should not be in range.
    #[test]
    fn test_single_value_range_not_matching() {
        let int_ranges = Some(vec![(5, 5)]);
        let result = validate_integer_in_ranges("4", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(4));
    }

    /// Test: Multiple non-continuous ranges in int-only
    ///
    /// Should support multiple separate ranges in a single vector.
    #[test]
    fn test_multiple_noncontinuous_int_ranges() {
        let int_ranges = Some(vec![(1, 3), (7, 9)]);

        // In first range
        let result = validate_integer_in_ranges("2", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(2));

        // In second range
        let result = validate_integer_in_ranges("8", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(8));

        // Between ranges (not in any)
        let result = validate_integer_in_ranges("5", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(5));
    }

    /// Test: Multiple non-continuous ranges in int-string
    ///
    /// Should support multiple separate ranges in integer-string vector.
    #[test]
    fn test_multiple_noncontinuous_int_string_ranges() {
        let int_str_ranges = Some(vec![(1, 3), (7, 9)]);

        // In first range
        let result = validate_integer_in_ranges("2", None, int_str_ranges.clone());
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerStringRange(2));

        // In second range
        let result = validate_integer_in_ranges("8", None, int_str_ranges.clone());
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerStringRange(8));

        // Between ranges (not in any)
        let result = validate_integer_in_ranges("5", None, int_str_ranges.clone());
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(5));
    }

    /// Test: Negative integers in range
    ///
    /// Should handle negative integers correctly.
    #[test]
    fn test_negative_integers_in_range() {
        let int_ranges = Some(vec![(-5, -1)]);
        let result = validate_integer_in_ranges("-3", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(-3));
    }

    /// Test: Negative to positive range
    ///
    /// Range spanning negative and positive values.
    #[test]
    fn test_negative_to_positive_range() {
        let int_ranges = Some(vec![(-3, 3)]);

        // Negative in range
        let result = validate_integer_in_ranges("-2", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(-2));

        // Zero in range
        let result = validate_integer_in_ranges("0", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(0));

        // Positive in range
        let result = validate_integer_in_ranges("2", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(2));
    }

    /// Test: Zero as valid input
    ///
    /// Zero should be handled like any other integer.
    #[test]
    fn test_zero_as_valid_input() {
        let int_ranges = Some(vec![(0, 5)]);
        let result = validate_integer_in_ranges("0", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(0));
    }

    /// Test: Very large integers
    ///
    /// Should handle large i32 values correctly.
    #[test]
    fn test_very_large_integers() {
        let int_ranges = Some(vec![(1000000, 2000000)]);
        let result = validate_integer_in_ranges("1500000", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(1500000));
    }

    /// Test: Invalid range configuration (min > max) - should skip
    ///
    /// When a range has min > max, it should be skipped gracefully.
    #[test]
    fn test_invalid_range_min_greater_than_max() {
        let int_ranges = Some(vec![(5, 1)]); // Invalid: min > max
        let result = validate_integer_in_ranges("3", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        // Should not match the invalid range
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(3));
    }

    /// Test: Mixed valid and invalid ranges
    ///
    /// Should skip invalid ranges but use valid ones.
    #[test]
    fn test_mixed_valid_and_invalid_ranges1() {
        let int_ranges = Some(vec![(10, 5), (1, 3), (8, 6)]); // First and third invalid

        // Should match the valid range (1, 3)
        let result = validate_integer_in_ranges("2", int_ranges, None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(2));

    }

    /// Test: Mixed valid and invalid ranges
    ///
    /// Should skip invalid ranges but use valid ones.
    #[test]
    fn test_mixed_valid_and_invalid_ranges2() {
        let int_ranges = Some(vec![(10, 5), (1, 3), (8, 6)]); // First and third invalid


        // Should not match invalid ranges
        let result = validate_integer_in_ranges("7", int_ranges, None);
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(7));
    }

    /// Test: Input with whitespace
    ///
    /// Should trim whitespace before parsing.
    #[test]
    fn test_input_with_whitespace() {
        let int_ranges = Some(vec![(1, 5)]);

        // Leading whitespace
        let result = validate_integer_in_ranges("  3", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(3));

        // Trailing whitespace
        let result = validate_integer_in_ranges("3  ", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(3));

        // Both
        let result = validate_integer_in_ranges("  3  ", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(3));
    }

    /// Test: Input with plus sign
    ///
    /// Positive integers can be prefixed with + in Rust parsing.
    #[test]
    fn test_input_with_plus_sign() {
        let int_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("+3", int_ranges, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(3));
    }

    /// Test: Invalid integer formats
    ///
    /// Various invalid formats should return NotAnInteger.
    #[test]
    fn test_invalid_integer_formats() {
        let int_ranges = Some(vec![(1, 5)]);

        // Decimal number
        let result = validate_integer_in_ranges("3.5", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::NotAnInteger);

        // Mixed alphanumeric
        let result = validate_integer_in_ranges("3a", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::NotAnInteger);

        // Just letters
        let result = validate_integer_in_ranges("abc", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::NotAnInteger);

        // Special characters
        let result = validate_integer_in_ranges("@#$", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::NotAnInteger);
    }

    /// Test: Integer overflow (beyond i32 range)
    ///
    /// Values beyond i32 range should be treated as NotAnInteger.
    #[test]
    fn test_integer_overflow_beyond_i32() {
        let int_ranges = Some(vec![(1, 5)]);

        // Beyond i32::MAX
        let result = validate_integer_in_ranges("9999999999999", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::NotAnInteger);

        // Beyond i32::MIN
        let result = validate_integer_in_ranges("-9999999999999", int_ranges.clone(), None);
        assert_eq!(result.unwrap(), IntegerValidationResult::NotAnInteger);
    }

    /// Test: No ranges configured (None, None)
    ///
    /// When no ranges are configured, any valid integer should be NotInAnyRange.
    #[test]
    fn test_no_ranges_configured() {
        let result = validate_integer_in_ranges("5", None, None);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(5));
    }

    /// Test: Empty range vectors (Some(vec![]), Some(vec![]))
    ///
    /// Empty vectors should behave like no ranges configured.
    #[test]
    fn test_empty_range_vectors() {
        let result = validate_integer_in_ranges("5", Some(vec![]), Some(vec![]));

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(5));
    }

    /// Test: Only int-string ranges configured
    ///
    /// Should work with only int-string ranges (no int-only).
    #[test]
    fn test_only_int_string_ranges() {
        let int_str_ranges = Some(vec![(1, 5)]);
        let result = validate_integer_in_ranges("3", None, int_str_ranges);

        assert!(result.is_ok(), "Function should return Ok");
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerStringRange(3));
    }

    /// Test: Complex multi-range scenario with priority
    ///
    /// Tests realistic scenario with multiple ranges of both types.
    #[test]
    fn test_complex_multi_range_priority() {
        let int_ranges = Some(vec![(1, 3), (10, 15)]);
        let int_str_ranges = Some(vec![(4, 6), (12, 14)]);

        // In int-only range only
        let result = validate_integer_in_ranges("2", int_ranges.clone(), int_str_ranges.clone());
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerOnlyRange(2));

        // In int-string range only
        let result = validate_integer_in_ranges("5", int_ranges.clone(), int_str_ranges.clone());
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerStringRange(5));

        // In both (overlap) - int-string priority
        let result = validate_integer_in_ranges("13", int_ranges.clone(), int_str_ranges.clone());
        assert_eq!(result.unwrap(), IntegerValidationResult::InIntegerStringRange(13));

        // Not in any range
        let result = validate_integer_in_ranges("8", int_ranges.clone(), int_str_ranges.clone());
        assert_eq!(result.unwrap(), IntegerValidationResult::NotInAnyRange(8));
    }
}

/// Perform interactive Q&A for structured message format
///
/// # Purpose
///
/// Guides user through creating a structured message post response via interactive
/// Q&A prompts. Handles both comment and answer-response flows, including:
/// - Validating integer selections against configured ranges
/// - Collecting write-in text for integer-string options
/// - Formatting the final message according to structured format rules
///
/// # Project Context
///
/// The Message Post Suite's structured format enables:
/// - Surveys and polls with multiple choice + write-in options
/// - Standardized questionnaires with validated responses
/// - Elections/votes with numbered ballot options
/// - Forms with specific field formats
///
/// Structured messages differentiate between:
/// - **Comments**: Free-form text tagged with "#comment: " prefix
/// - **Answers**: Validated responses to structured questions
///   - Integer-only: Multiple choice selections (e.g., "3")
///   - Integer-string: Write-in options (e.g., "3. Chocolate")
///
/// # Q&A Flow
///
/// **Step 1: Validate Initial Input**
/// - Parse user_input as integer
/// - Validate against configured ranges
/// - If invalid, will prompt for new selection
///
/// **Step 2: Comment or Answer?**
/// - Ask user: "Are you commenting or answering-responding?"
/// - Comment path: Format as "#comment: {user_input}" and return
/// - Answer path: Continue to validation
///
/// **Step 3: Selection Validation (if answering)**
/// - If initial input invalid/out of range: Prompt for valid selection (ONE attempt)
/// - If still invalid: Skip message creation (return Ok(None))
///
/// **Step 4: Write-in Collection (if int-string range)**
/// - If selection is in integer-string range: Prompt for write-in text
/// - Apply max_string_length to write-in text
/// - Format as "{integer}. {text}"
///
/// **Step 5: Return Formatted Message**
/// - Integer-only: "{integer}"
/// - Integer-string: "{integer}. {text}"
/// - Comment: "#comment: {user_input}"
///
/// # No Loops Policy
///
/// This function runs **once** with **one Q&A session**:
/// - User gets ONE chance to correct invalid input
/// - User gets ONE chance to provide write-in text
/// - If user makes mistake, they can retry by calling function again
/// - This prevents infinite loops and respects single-pass design
///
/// # Arguments
///
/// * `user_input` - Initial input string from user (may be integer or text)
/// * `integer_ranges` - Integer-only selection ranges (multiple choice)
/// * `integer_string_ranges` - Integer-string selection ranges (write-in options)
/// * `max_string_length` - Maximum length for write-in text (NOT for formatted result)
///
/// # Returns
///
/// * `Ok(Some(String))` - Successfully formatted message ready to post
/// * `Ok(None)` - Skip message creation (invalid input, user error, etc.)
/// * `Err(io::Error)` - System I/O error (stdin/stdout failure)
///
/// # Examples
///
/// ```rust
/// // User comments on the question
/// let result = structured_format_qa_interactive(
///     "I disagree with this poll",
///     Some(vec![(1, 3)]),
///     Some(vec![(4, 5)]),
///     Some(100)
/// )?;
/// // Returns Ok(Some("#comment: I disagree with this poll"))
///
/// // User selects integer-only option
/// let result = structured_format_qa_interactive(
///     "2",
///     Some(vec![(1, 3)]),
///     None,
///     None
/// )?;
/// // Returns Ok(Some("2"))
///
/// // User selects write-in option
/// let result = structured_format_qa_interactive(
///     "4",
///     Some(vec![(1, 3)]),
///     Some(vec![(4, 5)]),
///     Some(100)
/// )?;
/// // Prompts: "Your write-in answer: "
/// // User enters: "Chocolate"
/// // Returns Ok(Some("4. Chocolate"))
///
/// // User provides invalid initial input
/// let result = structured_format_qa_interactive(
///     "999",
///     Some(vec![(1, 3)]),
///     None,
///     None
/// )?;
/// // Prompts: "Enter your selection (1-3): "
/// // If valid: Returns Ok(Some("{selection}"))
/// // If invalid again: Returns Ok(None) - skip message
/// ```
///
/// # Security Notes
///
/// - Input validation prevents injection attacks
/// - Max length enforcement prevents resource exhaustion
/// - No sensitive data in error messages
///
fn structured_format_qa_interactive(
    user_input: &str,
    integer_ranges: Option<Vec<(i32, i32)>>,
    integer_string_ranges: Option<Vec<(i32, i32)>>,
    max_string_length: Option<usize>,
) -> io::Result<Option<String>> {

    // =================================================
    // Debug-Assert (debug builds only, NOT tests)
    // =================================================

    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !user_input.is_empty(),
        "SFQAI: User input should not be empty"
    );

    // =================================================
    // Production-Catch: Validate inputs
    // =================================================

    if user_input.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "SFQAI: User input cannot be empty"
        ));
    }

    // =================================================
    // Step 1: Validate Initial Input Against Ranges
    // =================================================

    let initial_validation = validate_integer_in_ranges(
        user_input,
        integer_ranges.clone(),
        integer_string_ranges.clone(),
    )?;

    // =================================================
    // Step 2: Q&A - Comment or Answer?
    // =================================================

    println!("\n--- Structured Message Response ---");
    println!("Are you commenting or answering-responding?");
    println!("  'c' = Comment (free-form text)");
    println!("  'a' = Answer (validated response)");
    print!("Your choice (c/a): ");
    io::stdout().flush()?;

    let mut choice = String::new();
    io::stdin().read_line(&mut choice)?;
    let choice = choice.trim().to_lowercase();

    // =================================================
    // Handle Comment Path
    // =================================================

    if choice == "c" || choice == "comment" {
        // Format as comment
        let comment_message = format!("#comment: {}", user_input);
        println!("\nComment formatted: {}", comment_message);
        return Ok(Some(comment_message));
    }

    // =================================================
    // Handle Answer Path - Validate Selection
    // =================================================

    if choice != "a" && choice != "answer" {
        println!("\n Invalid choice. Message creation cancelled.");
        return Ok(None);
    }

    // User chose "answer" - validate their selection
    let mut final_selection = initial_validation;

    // If initial input was invalid or not in range, prompt for valid selection
    match final_selection {
        IntegerValidationResult::NotAnInteger | IntegerValidationResult::NotInAnyRange(_) => {
            println!("\n Your input is not a valid selection.");

            // Build range description for user
            let mut range_desc = String::new();
            if let Some(ref int_ranges) = integer_ranges {
                for (min, max) in int_ranges {
                    if !range_desc.is_empty() {
                        range_desc.push_str(", ");
                    }
                    if min == max {
                        range_desc.push_str(&format!("{}", min));
                    } else {
                        range_desc.push_str(&format!("{}-{}", min, max));
                    }
                }
            }
            if let Some(ref int_str_ranges) = integer_string_ranges {
                for (min, max) in int_str_ranges {
                    if !range_desc.is_empty() {
                        range_desc.push_str(", ");
                    }
                    if min == max {
                        range_desc.push_str(&format!("{}", min));
                    } else {
                        range_desc.push_str(&format!("{}-{}", min, max));
                    }
                }
            }

            println!("Valid options: {}", range_desc);
            print!("Enter your selection: ");
            io::stdout().flush()?;

            let mut new_selection = String::new();
            io::stdin().read_line(&mut new_selection)?;
            let new_selection = new_selection.trim();

            // Validate new selection (ONE attempt only)
            final_selection = validate_integer_in_ranges(
                new_selection,
                integer_ranges.clone(),
                integer_string_ranges.clone(),
            )?;

            // Check if new selection is valid
            match final_selection {
                IntegerValidationResult::NotAnInteger | IntegerValidationResult::NotInAnyRange(_) => {
                    println!("\n Invalid selection. Message creation cancelled.");
                    println!("You may retry if you wish.\n");
                    return Ok(None);
                }
                _ => {
                    // Valid selection - continue
                }
            }
        }
        _ => {
            // Initial input was valid - continue
        }
    }

    // =================================================
    // Step 3: Format Result Based on Range Type
    // =================================================

    match final_selection {
        IntegerValidationResult::InIntegerOnlyRange(value) => {
            // Integer-only selection - return just the number
            let result = format!("{}", value);
            println!("\nSelection: {}", result);
            Ok(Some(result))
        }

        IntegerValidationResult::InIntegerStringRange(value) => {
            // Integer-string selection - need write-in text
            println!("\nYou selected option {} (write-in).", value);

            // Show max length if configured
            if let Some(max_len) = max_string_length {
                print!("Your write-in answer (max {} characters): ", max_len);
            } else {
                print!("Your write-in answer: ");
            }
            io::stdout().flush()?;

            let mut write_in = String::new();
            io::stdin().read_line(&mut write_in)?;
            let write_in = write_in.trim();

            // Validate write-in is not empty
            if write_in.is_empty() {
                println!("\n Write-in text cannot be empty. Message creation cancelled.");
                return Ok(None);
            }

            // Apply max length truncation to write-in text
            let write_in_final = truncate_message_to_max_length(write_in, max_string_length)?;

            // Format as "integer. text"
            let result = format!("{}. {}", value, write_in_final);
            println!("\nFormatted answer: {}", result);
            Ok(Some(result))
        }

        IntegerValidationResult::NotAnInteger | IntegerValidationResult::NotInAnyRange(_) => {
            // Should not reach here (handled above), but safety catch
            println!("\n Invalid selection. Message creation cancelled.");
            Ok(None)
        }
    }
}
/*
```
Input  Validate  Comment/Answer?
                       
            Comment  "#comment: {text}"
                       
                    Answer  Valid?
                              
                         No  Prompt once  Valid?
                                              
                                          No  Skip
                                            
                            Yes   Yes
                              
                     Int-only or Int-string?
                                     
                   Int-only      Int-string
                                     
                    Return "{n}"  Ask write-in
                                      
                                 Return "{n}. {text}"
```
*/


#[cfg(test)]
mod tests_structured_format_qa_interactive {
    use super::*;

    /// Test: Empty input handling
    ///
    /// Validates that empty input is rejected with appropriate error.
    /// This test doesn't require stdin interaction.
    #[test]
    fn test_empty_input_rejected() {
        let result = structured_format_qa_interactive(
            "",
            Some(vec![(1, 3)]),
            None,
            None,
        );

        assert!(result.is_err(), "Empty input should return error");
        let err = result.unwrap_err();
        assert!(
            err.to_string().contains("SFQAI"),
            "Error should have function prefix"
        );
    }

    /// Test: Valid initial integer parsing (partial path)
    ///
    /// Tests that valid integer input is parsed correctly by the validation step.
    /// Note: Full flow requires interactive stdin which is not tested here.
    #[test]
    fn test_valid_integer_input_parsed() {
        // This validates the initial validation logic path
        // The actual Q&A prompts would require stdin mocking

        let validation_result = validate_integer_in_ranges(
            "2",
            Some(vec![(1, 3)]),
            None,
        );

        assert!(validation_result.is_ok(), "Validation should succeed");
        match validation_result.unwrap() {
            IntegerValidationResult::InIntegerOnlyRange(val) => {
                assert_eq!(val, 2, "Should parse to integer 2");
            }
            _ => panic!("Should be in integer-only range"),
        }

        // Note: Full structured_format_qa_interactive test would require
        // stdin simulation for "comment or answer" prompt
    }
}

// =================================================
// Integration Test Note
// =================================================
//
// Full testing of interactive Q&A flows requires:
// 1. Stdin simulation/mocking (not available without external crates)
// 2. Integration tests with scripted input
// 3. Manual testing procedures
//
// For production validation, consider:
// - Manual test scripts with predefined inputs
// - Integration test suite with expect-style testing
// - Refactoring to dependency injection for testability (if needed)
//
// Current minimal tests validate:
// - Function compiles with correct signature
// - Basic error handling (empty input)
// - Initial validation logic path
//
// =================================================

/// Add New Message File with Configuration-Based Validation
///
/// # Purpose
///
/// Creates and saves a message post file with full validation pipeline:
/// - Time window validation (earliest exit)
/// - Structured format Q&A (if configured)
/// - Length truncation (if configured)
/// - Privacy mode handling (if configured)
/// - User confirmation (if configured)
/// - GPG encryption override (if configured)
///
/// # Project Context
///
/// This function is the main entry point for creating message posts in the
/// team collaboration system with the Message Post Suite's modular configuration.
/// It supports various use cases:
/// - Time-bounded surveys/polls
/// - Structured questionnaires with validated responses
/// - Private or public messaging
/// - Length-restricted micro-blogging
/// - User-confirmed submissions
///
/// # Process Flow
///
/// 1. **Time Window Check** (earliest exit point)
///    - Validate current time against start/end constraints
///    - If outside window: print message, return Ok(())
///
/// 2. **Structured Format Q&A** (if configured)
///    - Check if integer ranges are configured
///    - If yes: Run interactive Q&A to format response
///    - If no: Use original input text
///    - If Q&A cancelled: return Ok(())
///
/// 3. **Max Length Truncation** (if configured)
///    - Apply length limit to message text
///    - Print warning if truncated
///
/// 4. **Recipient List Determination**
///    - Parse {to:username} syntax from text
///    - If is_public == Some(false): Override to [local_owner, node_owner]
///    - Otherwise: Use team channel collaborators or {to:} recipient
///
/// 5. **User Confirmation** (if configured)
///    - Display message preview with all fields
///    - Ask user to confirm
///    - If not confirmed: return Ok(())
///
/// 6. **Message File Creation**
///    - Read metadata from 0.toml
///    - Create MessagePostFile struct
///    - Apply gpgtoml_required override
///    - Serialize to TOML
///    - Save as clearsigned or encrypted file
///    - Write sync flags for recipients
///
/// # Arguments
///
/// * `incoming_file_path` - Full path where message file should be saved
/// * `owner` - Username of message author/sender
/// * `text` - Message text content (initial input from user)
/// * `graph_navigation_instance_state` - Navigation state with collaborator info
/// * `start_date_utc_posix` - Optional start time for posting window
/// * `end_date_utc_posix` - Optional end time for posting window
/// * `gpgtoml_required` - Whether GPG encryption is required
/// * `max_string_length` - Optional maximum message length
/// * `is_public` - Whether message is public or private
/// * `user_confirms` - Whether user confirmation is required
/// * `integer_ranges` - Integer-only selection ranges for structured format
/// * `integer_string_ranges` - Integer-string selection ranges for structured format
/// * `current_node_owner` - Username of current node owner (for private mode)
///
/// # Returns
///
/// * `Ok(())` - Message created successfully OR skipped (time window, user cancel, etc.)
/// * `Err(io::Error)` - System error during message creation
///
/// # Examples
///
/// ```rust
/// // Simple message with no special config
/// add_new_messagepost_message(
///     Path::new("messages/123.toml"),
///     "alice",
///     "Hello team!",
///     &state,
///     None, None, None, None, None, None, None, None,
///     "bob"
/// )?;
///
/// // Time-bounded structured survey response
/// add_new_messagepost_message(
///     Path::new("messages/124.toml"),
///     "alice",
///     "2",
///     &state,
///     Some(start_time),
///     Some(end_time),
///     None,
///     Some(100),
///     Some(true),
///     Some(true),
///     Some(vec![(1, 3)]),
///     Some(vec![(4, 5)]),
///     "bob"
/// )?;
/// ```
///
fn add_new_messagepost_message(
    incoming_file_path: &Path,
    owner: &str,
    text: &str,
    graph_navigation_instance_state: &GraphNavigationInstanceState,
) -> Result<(), io::Error> {

    #[cfg(all(debug_assertions, not(test)))]
    {
        debug_log!("ANMPM graph_navigation_instance_state->{:?}", graph_navigation_instance_state);
        debug_log!("ANMPM: Starting add_new_messagepost_message");
        debug_log!("ANMPM: incoming_file_path: {:?}", incoming_file_path);
        debug_log!("ANMPM: owner: {}", owner);
        debug_log!("ANMPM: text length: {} bytes", text.len());
    }
    let start_date_utc_posix = graph_navigation_instance_state.message_post_start_date_utc_posix; //;: Option<i64>,
    let end_date_utc_posix = graph_navigation_instance_state.message_post_end_date_utc_posix; //;: Option<i64>,

    let gpgtoml_required = graph_navigation_instance_state.message_post_gpgtoml_required; //;: Option<bool>,

    let max_string_length = graph_navigation_instance_state.message_post_max_string_length_int; //;: Option<usize>,
    let is_public = graph_navigation_instance_state.message_post_is_public_bool; //;: Option<bool>,
    let user_confirms = graph_navigation_instance_state.message_post_user_confirms_bool; //;: Option<bool>,

    let integer_ranges = graph_navigation_instance_state.message_post_data_format_specs_integer_ranges_from_to_tuple_array.clone(); //;: Option<Vec<(i32, i32)>>,
    let integer_string_ranges = graph_navigation_instance_state.message_post_data_format_specs_int_string_ranges_from_to_tuple_array.clone(); //;: Option<Vec<(i32, i32)>>,

    let current_node_owner = graph_navigation_instance_state.current_node_owner.clone(); //;: String

    #[cfg(all(debug_assertions, not(test)))]
    {
    debug_log!("ANMPM: integer_ranges: {:?}", integer_ranges);
    debug_log!("ANMPM: integer_string_ranges: {:?}", integer_string_ranges);
    }
    // gpgtoml_required: Option<bool>,
    // max_string_length: Option<usize>,
    // is_public: Option<bool>,
    // user_confirms: Option<bool>,
    // integer_ranges: Option<Vec<(i32, i32)>>,
    // integer_string_ranges: Option<Vec<(i32, i32)>>,
    // current_node_owner: &str,

    // =================================================
    // Debug-Assert (debug builds only), Production-Catch-Handle (always)
    // =================================================

    // Debug-Assert: Owner must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !owner.is_empty(),
        "ANMPM: Owner must not be empty"
    );

    // Production-Catch: Handle empty owner
    if owner.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "ANMPM: Owner must not be empty"
        ));
    }

    // Debug-Assert: Text must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !text.is_empty(),
        "ANMPM: Message text must not be empty"
    );

    // Production-Catch: Handle empty text
    if text.is_empty() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "ANMPM: Message text must not be empty"
        ));
    }

    // Debug-Assert: File path must have a filename
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        incoming_file_path.file_name().is_some(),
        "ANMPM: File path must have a filename"
    );

    // Production-Catch: Handle missing filename
    if incoming_file_path.file_name().is_none() {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "ANMPM: File path must have a filename"
        ));
    }

    // =================================================
    // Step 1: Time Window Check (EARLIEST EXIT POINT)
    // =================================================

    debug_log!("ANMPM: Checking time window");

    let in_time_window = check_time_window(start_date_utc_posix, end_date_utc_posix)?;

    if !in_time_window {
        debug_log!("ANMPM: Outside time window - skipping message creation");
        // Message already printed by check_time_window
        return Ok(());
    }

    debug_log!("ANMPM: Time window check passed");

    // =================================================
    // Step 2: Check for Structured Format & Run Q&A
    // =================================================

    debug_log!("ANMPM: Checking for structured format configuration");


    // Check if structured format is active
    let structured_format_active = match (&integer_ranges, &integer_string_ranges) {
        (Some(int_ranges), _) if !int_ranges.is_empty() => true,
        (_, Some(int_str_ranges)) if !int_str_ranges.is_empty() => true,
        _ => false,
    };

    debug_log!("ANMPM: Structured format active: {}", structured_format_active);

    let final_text = if structured_format_active {
        debug_log!("ANMPM: Running structured format Q&A");

        match structured_format_qa_interactive(
            text,
            integer_ranges.clone(),
            integer_string_ranges.clone(),
            max_string_length,
        )? {
            Some(formatted_text) => {
                debug_log!("ANMPM: Structured Q&A completed: {}", formatted_text);
                formatted_text
            }
            None => {
                debug_log!("ANMPM: Structured Q&A cancelled - skipping message creation");
                return Ok(());
            }
        }
    } else {
        // No structured format - use original text
        debug_log!("ANMPM: No structured format - using original text");
        text.to_string()
    };

    // =================================================
    // Step 3: Max Length Truncation (if not already handled)
    // =================================================

    debug_log!("ANMPM: Applying max length truncation if configured");

    // Note: For structured format, max_length was already applied to write-in text
    // For non-structured or comment text, apply it now
    let final_text_truncated = if !structured_format_active || final_text.starts_with("#comment:") {
        truncate_message_to_max_length(&final_text, max_string_length)?
    } else {
        // Already handled in structured Q&A
        final_text
    };

    debug_log!("ANMPM: Final text length: {}", final_text_truncated.len());

    // =================================================
    // Step 4: Determine Recipients List
    // =================================================

    debug_log!("ANMPM: Determining recipients list");

    // Start with default collaborators list
    let mut recipients_list = graph_navigation_instance_state
        .current_node_teamchannel_collaborators_with_access
        .clone();

    // Check for privacy mode override
    if is_public == Some(false) {
        debug_log!("ANMPM: Privacy mode active - restricting to owner and node owner");
        recipients_list.clear();
        recipients_list.push(owner.to_string());
        if owner != current_node_owner {
            recipients_list.push(current_node_owner.to_string());
        }
    } else {
        // Check for {to:user} syntax
        if let Some(to_clause) = final_text_truncated.find("{to:") {
            if let Some(end_brace) = final_text_truncated[to_clause..].find('}') {
                let recipient_name = final_text_truncated[to_clause + 4..to_clause + end_brace].trim();

                debug_log!("ANMPM: Found clause for recipient: {}", recipient_name);

                recipients_list.clear(); // Clear default list

                // Check if recipient in team channel list and is not sender
                if graph_navigation_instance_state
                    .current_node_teamchannel_collaborators_with_access
                    .contains(&recipient_name.to_string())
                    && recipient_name != owner
                {
                    recipients_list.push(recipient_name.to_string());
                    debug_log!("ANMPM: Recipient validated and added: {}", recipient_name);
                } else {
                    debug_log!(
                        "ANMPM: 'to:' clause but recipient '{}' not found in channel or is sender.",
                        recipient_name
                    );
                }
            }
        }
    }

    debug_log!("ANMPM: Final recipients list: {:?}", recipients_list);

    // =================================================
    // Step 5: User Confirmation (if configured)
    // =================================================

    if user_confirms == Some(true) {
        debug_log!("ANMPM: User confirmation required - showing preview");

        // Clear stdin buffer by prompting for explicit Enter
        // This consumes any leftover input from previous operations
        println!("\nPress ENTER (maybe twice) to continue to preview and confirmation...");
        let mut _buffer_clear = String::new();
        io::stdin().read_line(&mut _buffer_clear)?;


        println!("\n=== Message Preview ===");
        println!("From: {}", owner);
        println!("To: {}", if recipients_list.is_empty() {
            "All collaborators".to_string()
        } else {
            recipients_list.join(", ")
        });
        println!("Text: {}", final_text_truncated);
        println!("Encryption: {}", if gpgtoml_required == Some(true) {
            "Required (gpgtoml)"
        } else {
            "Clearsigned (toml)"
        });
        println!("======================\n");

        // if !read_user_confirmation("Confirm and post this message?")? {
        //     println!("\n Message creation cancelled by user.\n");
        //     debug_log!("ANMPM: User did not confirm - skipping message creation");
        //     return Ok(());
        // }



        print!("Final Check: Do you confirm and post this message? (y)es / no: ");

        // std out??
        io::stdout().flush()?;

        let mut confirmation = String::new();
        io::stdin().read_line(&mut confirmation)?;
        let confirmation = confirmation.trim().to_lowercase();

        debug_log!("ANMPM: confirmation {}", confirmation);
        println!("ANMPM: confirmation {}", confirmation);


        if confirmation != "y" && confirmation != "yes" {
            println!("\n Message creation cancelled by user.\n");
            debug_log!("ANMPM: User did not confirm - skipping message creation");
            return Ok(());
        }

        debug_log!("ANMPM: User confirmed message");
    }

    // =================================================
    // Step 6: Get Parent Directory and Read Metadata
    // =================================================

    debug_log!("ANMPM: Extracting parent directory");

    let parent_dir = incoming_file_path.parent()
        .ok_or_else(|| io::Error::new(
            io::ErrorKind::InvalidInput,
            "ANMPM: File path must have a parent directory"
        ))?;

    // Debug-Assert: Parent directory must not be empty path
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        parent_dir != Path::new(""),
        "ANMPM: Parent directory must not be empty path"
    );

    // Production-Catch: Handle empty parent directory
    if parent_dir == Path::new("") {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "ANMPM: error Parent directory is empty path"
        ));
    }

    debug_log!("ANMPM: Parent directory: {:?}", parent_dir);

    // Read 0.toml to get message browser metadata
    debug_log!("ANMPM: Reading metadata from 0.toml");

    let metadata_path = parent_dir.join("0.toml");
    debug_log!("ANMPM: let metadata_path -> {:?}", metadata_path);

    let metadata_path_string = metadata_path.to_string_lossy();

    let node_name = read_single_line_string_field_from_toml(
        &metadata_path_string,
        "node_name",
    )
    .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("ANMPM: node_name read error: {}", e)))?;

    let filepath_in_node = read_single_line_string_field_from_toml(
        &metadata_path_string,
        "path_in_node",
    )
    .map_err(|e| io::Error::new(io::ErrorKind::Other, format!("ANMPM: path_in_node read error: {}", e)))?;

    debug_log!("ANMPM: Metadata loaded - node: {}, path: {}",
        node_name,
        filepath_in_node
    );

    // =================================================
    // Step 7: Create MessagePostFile struct
    // =================================================

    debug_log!("ANMPM: Creating MessagePostFile");

    let ping: Vec<String> = Vec::new();

    /*
    owner: String, // owner of this item
    node_name: String, // Name of the node this message belongs to
    filepath_in_node: String, // Relative path within the node's directory
    text_message: String, // content-body

    teamchannel_collaborators_with_access: Vec<String>,

    /// sent "to the attention of" list => "ping"
    ping: Vec<String>,

    updated_at_timestamp: u64, // utc posix timestamp
    messagepost_gpgtoml: bool, // Is MessagePostFile file gpg encrypted
    expires_at: u64, // utc posix timestamp
    */

    let mut message = MessagePostFile::new(
        owner,
        &node_name,
        &filepath_in_node,
        &final_text_truncated,
        recipients_list.clone(),
        ping,
        false, // default to clearsigned
        None,
    );

    // Apply gpgtoml_required override
    if let Some(true) = gpgtoml_required {
        debug_log!("ANMPM: Applying gpgtoml_required override");
        message.messagepost_gpgtoml = true;
    }

    debug_log!("ANMPM: MessagePostFile created, gpgtoml: {}", message.messagepost_gpgtoml);

    // =================================================
    // Step 8: Serialize message to TOML
    // =================================================

    debug_log!("ANMPM: Serializing message to TOML");

    let toml_data = match serialize_messagepost_toml(&message) {
        Ok(toml_string) => {
            debug_log!("ANMPM: TOML serialization successful, {} bytes", toml_string.len());
            toml_string
        }
        Err(e) => {
            debug_log!("ANMPM: serialization failed");
            return Err(io::Error::new(
                io::ErrorKind::InvalidInput,
                format!("ANMPM: error serialize_messagepost_toml {}", e)
            ));
        }
    };

    // =================================================
    // Step 9: Save message file based on format setting
    // =================================================

    debug_log!("ANMPM: Saving message file");

    if message.messagepost_gpgtoml {
        debug_log!("ANMPM: Using GPG encrypted format (.gpgtoml)");

        let base_path = incoming_file_path.with_extension("");

        save_message_as_gpgtoml(
            &base_path,
            &toml_data,
        )?;

        debug_log!("ANMPM: GPG encrypted message saved successfully");
    } else {
        debug_log!("ANMPM: Using clearsigned format (.toml)");

        save_message_as_clearsigned_toml(
            incoming_file_path,
            &toml_data,
        )?;

        debug_log!("ANMPM: Clearsigned message saved successfully");
    }

    // =================================================
    // Step 10: Write sync flags for recipients
    // =================================================

    debug_log!("ANMPM: Writing sync flags for recipients");

    let sync_result = write_newfile_sendq_flag(
        &recipients_list,
        incoming_file_path,
    );

    // Log but don't fail if sync flags fail
    if let Err(e) = sync_result {
        debug_log!("ANMPM: Warning: Failed to write sync flags: {}", e);
    } else {
        debug_log!("ANMPM: Sync flags written successfully");
    }

    debug_log!("ANMPM: add_new_messagepost_message completed successfully");

    Ok(())
}

/// Saves a clearsigned 0.toml configuration file for message post browser.
///
/// # Project Context
/// Bootstrap function for team channel creation. Creates the initial
/// configuration file that defines message browser metadata including
/// ownership, access control, and size limits. This file must be
/// cryptographically signed to ensure configuration integrity.
///
/// # Purpose
/// This single-purpose function replaces toml-crate dependency by manually
/// constructing the TOML string from the metadata struct. Only the 8 required
/// fields are serialized; all optional message_post_* fields are ignored.
///
/// # Process Flow
/// 1. Validate input metadata (defensive checks)
/// 2. Manually construct TOML string with exact field ordering
/// 3. Delegate to save_message_as_clearsigned_toml() for file write + GPG signing
///
/// # Field Order (Must Match)
/// - owner
/// - teamchannel_collaborators_with_access
/// - updated_at_timestamp
/// - messageposts_expire_after_n_min
/// - node_name
/// - path_in_node
/// - max_message_size_char
/// - total_max_size_mb
///
/// # Arguments
/// * `metadata` - Metadata struct containing all configuration values
/// * `file_path` - Absolute path where 0.toml should be created
///
/// # Returns
/// * `Ok(())` - File successfully created and clearsigned
/// * `Err(io::Error)` - If validation fails or file operation fails
///
/// # Errors
/// All errors prefixed with "SCMC0:" for traceability
/// - Invalid input (empty owner, empty node_name, empty path)
/// - File write or GPG signing failures (from delegated function)
///
/// # Security
/// The generated file is clearsigned using the local user's GPG key,
/// ensuring authenticity and integrity of the configuration.
fn save_clearsigned_messagepost_config_0toml(
    metadata: &NodeMessagePostBrowserMetadata,
    file_path: &Path,
) -> Result<(), io::Error> {

    debug_log!("SCMC0: Starting save_clearsigned_messagepost_config_0toml");
    debug_log!("SCMC0: Target file path: {:?}", file_path);

    // =================================================
    // Debug-Assert, Test-Assert, Production-Catch
    // =================================================

    // Debug-Assert: Owner must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !metadata.owner.is_empty(),
        "SCMC0: Owner field must not be empty"
    );

    // Production-Catch: Owner must not be empty
    if metadata.owner.is_empty() {
        debug_log!("SCMC0: Error - Owner field is empty");
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "SCMC0: Owner field must not be empty"
        ));
    }

    // Debug-Assert: Node name must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !metadata.node_name.is_empty(),
        "SCMC0: Node name must not be empty"
    );

    // Production-Catch: Node name must not be empty
    if metadata.node_name.is_empty() {
        debug_log!("SCMC0: Error - Node name is empty");
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "SCMC0: Node name must not be empty"
        ));
    }

    // Debug-Assert: Path in node must not be empty
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        !metadata.path_in_node.is_empty(),
        "SCMC0: Path in node must not be empty"
    );

    // Production-Catch: Path in node must not be empty
    if metadata.path_in_node.is_empty() {
        debug_log!("SCMC0: Error - Path in node is empty");
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "SCMC0: Path in node must not be empty"
        ));
    }

    debug_log!("SCMC0: Input validation passed");
    debug_log!("SCMC0: Owner: {}", metadata.owner);
    debug_log!("SCMC0: Node name: {}", metadata.node_name);
    debug_log!("SCMC0: Collaborators count: {}", metadata.teamchannel_collaborators_with_access.len());

    // =================================================
    // Manual TOML String Construction
    // =================================================

    // Build collaborators array string: ["alice", "bob"]
    let collaborators_array = if metadata.teamchannel_collaborators_with_access.is_empty() {
        String::from("[]")
    } else {
        let mut array_string = String::from("[");
        for (i, collaborator) in metadata.teamchannel_collaborators_with_access.iter().enumerate() {
            if i > 0 {
                array_string.push_str(", ");
            }
            array_string.push('"');
            array_string.push_str(collaborator);
            array_string.push('"');
        }
        array_string.push(']');
        array_string
    };

    debug_log!("SCMC0: Constructed collaborators array: {}", collaborators_array);

    // Construct TOML string with exact field ordering
    // Field order must match: owner, collaborators, timestamp, expires,
    // node_name, path, max_char, max_mb
    let toml_content = format!(
        "owner = \"{}\"\n\
         teamchannel_collaborators_with_access = {}\n\
         updated_at_timestamp = {}\n\
         messageposts_expire_after_n_min = {}\n\
         node_name = \"{}\"\n\
         path_in_node = \"{}\"\n\
         max_message_size_char = {}\n\
         total_max_size_mb = {}\n",
        metadata.owner,
        collaborators_array,
        metadata.updated_at_timestamp,
        metadata.messageposts_expire_after_n_min,
        metadata.node_name,
        metadata.path_in_node,
        metadata.max_message_size_char,
        metadata.total_max_size_mb
    );

    debug_log!("SCMC0: TOML content constructed, length: {} bytes", toml_content.len());
    debug_log!("SCMC0: TOML content preview (first 200 chars): {}",
        if toml_content.len() > 200 {
            &toml_content[..200]
        } else {
            &toml_content
        }
    );

    // =================================================
    // Delegate to Existing Clearsigning Function
    // =================================================

    debug_log!("SCMC0: Delegating to save_message_as_clearsigned_toml");

    // Call existing function that handles:
    // - Directory validation/creation
    // - File writing
    // - GPG fingerprint retrieval
    // - Clearsigning operation
    save_message_as_clearsigned_toml(file_path, &toml_content)
        .map_err(|e| {
            debug_log!("SCMC0: Error from save_message_as_clearsigned_toml: {}", e);
            io::Error::new(
                e.kind(),
                format!("SCMC0: Failed to save clearsigned config: {}", e)
            )
        })?;

    debug_log!("SCMC0: Successfully created clearsigned 0.toml at: {:?}", file_path);
    debug_log!("SCMC0: save_clearsigned_messagepost_config_0toml completed");

    Ok(())
}

#[cfg(test)]
mod scmc0_tests {
    use super::*;

    #[test]
    fn test_scmc0_empty_owner_fails() {
        let metadata = NodeMessagePostBrowserMetadata {
            owner: String::new(), // Empty owner
            teamchannel_collaborators_with_access: vec!["alice".to_string()],
            updated_at_timestamp: 1234567890,
            messageposts_expire_after_n_min: 99999,
            node_name: "test_node".to_string(),
            path_in_node: "/test".to_string(),
            max_message_size_char: 4096,
            total_max_size_mb: 512,
            // Special configurations (not for team channel)
            message_post_gpgtoml_required:None,
            message_post_data_format_specs_integer_ranges_from_to_tuple_array: None,
            message_post_data_format_specs_int_string_ranges_from_to_tuple_array: None,
            message_post_max_string_length_int: None,
            message_post_is_public_bool: None,
            message_post_user_confirms_bool : None,
            message_post_start_date_utc_posix: None,
            message_post_end_date_utc_posix: None,
        };

        let temp_path = Path::new("/tmp/test_0.toml");
        let result = save_clearsigned_messagepost_config_0toml(&metadata, temp_path);

        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("SCMC0"));
    }

    #[test]
    fn test_scmc0_empty_collaborators_succeeds() {
        // Test that empty collaborators vec is valid
        let metadata = NodeMessagePostBrowserMetadata {
            owner: "alice".to_string(),
            teamchannel_collaborators_with_access: vec![], // Empty is OK
            updated_at_timestamp: 1234567890,
            messageposts_expire_after_n_min: 99999,
            node_name: "test_node".to_string(),
            path_in_node: "/test".to_string(),
            max_message_size_char: 4096,
            total_max_size_mb: 512,
            // Special configurations (not for team channel)
            message_post_gpgtoml_required:None,
            message_post_data_format_specs_integer_ranges_from_to_tuple_array: None,
            message_post_data_format_specs_int_string_ranges_from_to_tuple_array: None,
            message_post_max_string_length_int: None,
            message_post_is_public_bool: None,
            message_post_user_confirms_bool : None,
            message_post_start_date_utc_posix: None,
            message_post_end_date_utc_posix: None,
        };

        // Note: This will fail at GPG signing stage in test environment
        // but validates that empty collaborators passes our checks
        let temp_path = Path::new("/tmp/test_empty_collab_0.toml");
        let result = save_clearsigned_messagepost_config_0toml(&metadata, temp_path);

        // If it fails, it should be at GPG stage, not our validation
        if let Err(e) = result {
            assert!(!e.to_string().contains("collaborators"));
        }
    }
}

#[derive(Debug, Deserialize, Serialize)]
struct NodeMessagePostBrowserMetadata {
    // every .toml has these four
    owner: String, // owner of this item
    teamchannel_collaborators_with_access: Vec<String>,
    updated_at_timestamp: u64, // utc posix timestamp
    messageposts_expire_after_n_min: u64, // utc posix timestamp

    node_name: String,
    path_in_node: String,
    max_message_size_char: u64,
    total_max_size_mb: u64,


    // Special configurations

    /// message_post_gpgtoml_required
    message_post_gpgtoml_required:  Option<bool>,

    /// Integer validation ranges as tuples (min, max) - inclusive bounds
    message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Integer-string validation ranges as tuples (min, max) for the integer part
    message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,

    /// Maximum string length
    message_post_max_string_length_int: Option<usize>,

    /// Whether posts are public or private
    message_post_is_public_bool: Option<bool>,

    /// Whether user confirmation is required before posting
    message_post_user_confirms_bool: Option<bool>,

    /// Start time for accepting posts (UTC POSIX timestamp)
    message_post_start_date_utc_posix: Option<i64>,

    /// End time for accepting posts (UTC POSIX timestamp)
    message_post_end_date_utc_posix: Option<i64>,
}

impl NodeMessagePostBrowserMetadata {
    fn new(
        node_name: &str,
        owner: String,
        teamchannel_collaborators_with_access: Vec<String>,
        messageposts_expire_after_n_min: u64,
        // Special configurations
        message_post_gpgtoml_required: Option<bool>,
        message_post_data_format_specs_integer_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,
        message_post_data_format_specs_int_string_ranges_from_to_tuple_array: Option<Vec<(i32, i32)>>,
        message_post_max_string_length_int: Option<usize>,
        message_post_is_public_bool: Option<bool>,
        message_post_user_confirms_bool: Option<bool>,
        message_post_start_date_utc_posix: Option<i64>,
        message_post_end_date_utc_posix: Option<i64>,

    ) -> NodeMessagePostBrowserMetadata {
        NodeMessagePostBrowserMetadata {
            node_name: node_name.to_string(),
            path_in_node: "/message_posts_browser".to_string(), // TODO
            max_message_size_char: 4096, // Default: 4096 characters...too big?
            total_max_size_mb: 512, // Default: 1024 MB
            updated_at_timestamp: get_current_unix_timestamp(),
            messageposts_expire_after_n_min: messageposts_expire_after_n_min,  // TODO update this with real something
            teamchannel_collaborators_with_access: teamchannel_collaborators_with_access, // by default use state-struct node members
            owner: owner,


            // Special configurations (only for config 0toml file)

            // message_post_gpgtoml_required
            message_post_gpgtoml_required:  message_post_gpgtoml_required,

            // Integer validation ranges as tuples (min, max) - inclusive bounds
            message_post_data_format_specs_integer_ranges_from_to_tuple_array: message_post_data_format_specs_integer_ranges_from_to_tuple_array,

            // Integer-string validation ranges as tuples (min, max) for the integer part
            message_post_data_format_specs_int_string_ranges_from_to_tuple_array: message_post_data_format_specs_int_string_ranges_from_to_tuple_array,

            // Maximum string length
            message_post_max_string_length_int: message_post_max_string_length_int,

            // Whether posts are public or private
            message_post_is_public_bool: message_post_is_public_bool,

            // Whether user confirmation is required before posting
            message_post_user_confirms_bool: message_post_user_confirms_bool,

            // Start time for accepting posts (UTC POSIX timestamp)
            message_post_start_date_utc_posix:message_post_start_date_utc_posix,

            // End time for accepting posts (UTC POSIX timestamp)
            message_post_end_date_utc_posix: message_post_end_date_utc_posix,

        }
    }
}

/// Gets current Unix timestamp (seconds since epoch)
///
/// ## Project Context
/// Used for creating unique timestamps in archived filenames to prevent
/// collisions when multiple expired messages have the same name.
///
/// ## Memory: ZERO HEAP
/// Returns primitive u64, no allocation.
///
/// ## Returns
/// - Seconds since Unix epoch (1970-01-01 00:00:00 UTC)
///
/// ## Error Handling
/// Returns 0 if system time is before Unix epoch (extremely rare edge case).
/// This prevents panic in production while maintaining function operation.
fn get_current_unix_timestamp() -> u64 {
    match SystemTime::now().duration_since(UNIX_EPOCH) {
        Ok(duration) => duration.as_secs(),
        Err(_) => {
            #[cfg(debug_assertions)]
            debug_log!("MEMTA: system time before Unix epoch, using 0");
            0
        }
    }
}

/// Moves an expired message file to the archive directory with mirrored path structure.
///
/// ## Project Context
/// Part of message lifecycle management system for team channels. When messages
/// expire (based on expires_at field), they must be preserved (not deleted) by
/// moving them to an organized archive. The archive mirrors the original directory
/// structure after "team_channel/" for easy navigation and potential recovery.
///
/// ## Operation Flow
/// 1. Validates source file exists and is readable
/// 2. Records source file size (before any modifications)
/// 3. Extracts path structure after LAST occurrence of "team_channel/"
/// 4. Constructs archive path: {exe_parent}/uma_archive/{relative_path}
/// 5. If no relative path (file directly in team_channel), uses: uma_archive/misc/
/// 6. Creates necessary parent directories in archive
/// 7. Handles filename collisions by appending Unix timestamp before extension
/// 8. Copies file to archive location
/// 9. Verifies copied file size matches original
/// 10. Deletes original file (only after successful verification)
///
/// ## Atomicity & Safety Strategy
/// Uses copy-verify-delete pattern to ensure original file is never lost:
/// - Source file persists until archive copy is verified correct
/// - If copy fails: source remains untouched, nothing archived, error returned
/// - If verification fails: source remains, bad archive copy deleted, error returned
/// - If delete fails: both copies exist (logged but returns Ok - file is archived)
///
/// ## Error Handling
/// All errors return Result with static string (no heap allocation in production).
/// Errors are logged with debug_log! in debug builds. Function never panics.
/// All error messages prefixed with "MEMTA:" for traceability in logs.
///
/// Caller uses:
/// ```rust
/// let _ = move_expired_message_to_archive(entry.path());
/// // Continues processing other files regardless of result
/// ```
///
/// ## Edge Cases Handled
/// - Source file doesn't exist: Returns error
/// - Source disappeared during operation (race condition): Returns error, logs
/// - Path doesn't contain "team_channel": Returns error, logs
/// - Very long paths: OS handles (error on failure)
/// - Unicode in filenames: Preserved correctly
/// - Special characters in paths: Preserved correctly
/// - Concurrent access to file: Copy may fail naturally with IO error
/// - Readonly filesystems: Copy will fail with IO error
/// - Disk full / quota exceeded: Copy will fail with IO error
/// - Destination file exists: Appends Unix timestamp to filename
///
/// ## Parameters
/// - `source_path`: Absolute path to the expired message file (from DirEntry)
///
/// ## Returns
/// - `Ok(())`: File successfully archived and original deleted (or safely skipped)
/// - `Err(&'static str)`: Operation failed, error message with "MEMTA:" prefix
///
/// ## Examples
/// ```rust
/// // Source: /home/data/team_channel/pets/cats/msg.toml
/// // Archive: {exe_parent}/uma_archive/pets/cats/msg.toml
///
/// let result = move_expired_message_to_archive(Path::new("/home/data/team_channel/pets/cats/msg.toml"));
/// match result {
///     Ok(()) => {
///         #[cfg(debug_assertions)]
///         debug_log!("MEMTA: archived successfully");
///     }
///     Err(e) => {
///         #[cfg(debug_assertions)]
///         debug_log!("{}", e);
///         // Continue processing other files
///     }
/// }
/// ```
fn move_expired_message_to_archive(source_path: &Path) -> Result<(), &'static str> {

    debug_log!("MEMTA: source_path {:?}", source_path);
    // Step 1: Validate source file exists and get metadata
    let source_metadata = match fs::metadata(source_path) {
        Ok(meta) => meta,
        Err(_) => {
            #[cfg(debug_assertions)]
            debug_log!("MEMTA: source file not found or not accessible");
            return Err("MEMTA: source not found");
        }
    };

    // Verify it's actually a file (not a directory)
    if !source_metadata.is_file() {
        #[cfg(debug_assertions)]
        debug_log!("MEMTA: source is not a file");
        return Err("MEMTA: not a file");
    }

    // Step 2: Record source file size for later verification
    let source_size = source_metadata.len();

    // Step 3: Find LAST occurrence of "team_channels" in path
    let source_str = match source_path.to_str() {
        Some(s) => s,
        None => {
            #[cfg(debug_assertions)]
            debug_log!("MEMTA: invalid UTF-8 in path");
            return Err("MEMTA: invalid path encoding");
        }
    };

    // Find last occurrence of "/team_channels/"
    let relative_path = if let Some(last_pos) = source_str.rfind("/team_channels/") {
        // Extract everything after "/team_channels/"
        &source_str[last_pos + "/team_channels/".len()..]
    } else {
        // "team_channels" not found in path
        #[cfg(debug_assertions)]
        debug_log!("MEMTA: team_channels not found in path");
        return Err("MEMTA: team_channels not in path");
    };

    // Handle empty relative path
    if relative_path.is_empty() {
        #[cfg(debug_assertions)]
        debug_log!("MEMTA: empty path after team_channels");
        return Err("MEMTA: invalid path structure");
    }

    // Step 4: Get executable parent directory
    let exe_path = match std::env::current_exe() {
        Ok(path) => path,
        Err(_) => {
            #[cfg(debug_assertions)]
            debug_log!("MEMTA: cannot determine exe location");
            return Err("MEMTA: exe dir error");
        }
    };

    let exe_parent = match exe_path.parent() {
        Some(parent) => parent,
        None => {
            #[cfg(debug_assertions)]
            debug_log!("MEMTA: exe has no parent directory");
            return Err("MEMTA: exe dir error");
        }
    };

    // Step 5: Construct archive path
    let mut archive_path = PathBuf::from(exe_parent);
    archive_path.push("uma_archive");

    // Check if we need to add "misc" subdirectory (file directly in team_channels)
    if !relative_path.contains('/') {
        // Just a filename, add misc subdirectory
        archive_path.push("misc");
    }

    // Add the relative path
    archive_path.push(relative_path);

    // Step 6: Handle filename collision - if destination exists, append timestamp
    let final_archive_path = if archive_path.exists() {
        // File exists, need to append timestamp
        let timestamp = get_current_unix_timestamp();

        // Extract filename and extension
        let file_stem = match archive_path.file_stem() {
            Some(name) => name,
            None => {
                #[cfg(debug_assertions)]
                debug_log!("MEMTA: cannot extract filename");
                return Err("MEMTA: filename error");
            }
        };

        let extension = archive_path.extension();

        // Construct new filename: file_1704067200.toml
        let mut new_name = file_stem.to_os_string();
        new_name.push("_");
        new_name.push(timestamp.to_string());

        // Add extension back
        if let Some(ext) = extension {
            new_name.push(".");
            new_name.push(ext);
        }

        // Update path with new filename
        let mut new_archive_path = archive_path.clone();
        new_archive_path.set_file_name(new_name);
        new_archive_path
    } else {
        archive_path
    };

    // Step 7: Create parent directories if they don't exist
    if let Some(parent) = final_archive_path.parent() {
        if let Err(_) = fs::create_dir_all(parent) {
            #[cfg(debug_assertions)]
            debug_log!("MEMTA: failed to create archive directories");
            return Err("MEMTA: archive dir creation failed");
        }
    }

    // Step 8: Copy file to archive
    if let Err(_) = fs::copy(source_path, &final_archive_path) {
        #[cfg(debug_assertions)]
        debug_log!("MEMTA: copy operation failed");
        return Err("MEMTA: copy failed");
    }

    // Step 9: Verify copied file size matches original
    let archive_metadata = match fs::metadata(&final_archive_path) {
        Ok(meta) => meta,
        Err(_) => {
            #[cfg(debug_assertions)]
            debug_log!("MEMTA: cannot read archive file metadata after copy");
            // Try to clean up bad archive copy
            let _ = fs::remove_file(&final_archive_path);
            return Err("MEMTA: archive verify failed");
        }
    };

    let archive_size = archive_metadata.len();

    if archive_size != source_size {
        #[cfg(debug_assertions)]
        debug_log!("MEMTA: size mismatch - src {} bytes, archive {} bytes", source_size, archive_size);
        // Clean up bad archive copy
        let _ = fs::remove_file(&final_archive_path);
        return Err("MEMTA: size mismatch");
    }

    // Step 10: Delete original file (archive verified successful)
    if let Err(_) = fs::remove_file(source_path) {
        #[cfg(debug_assertions)]
        debug_log!("MEMTA: warning - could not delete original (exists in both locations)");
        // File is successfully archived, so return Ok even though delete failed
        // This is pragmatic - the important operation (archiving) succeeded
    }

    #[cfg(debug_assertions)]
    debug_log!("MEMTA: successfully archived");

    Ok(())
}


// =============================================================================
// TESTS
// =============================================================================

#[cfg(test)]
mod mp_arch_tests {
    use super::*;
    use std::fs;
    use std::path::PathBuf;

    /// Test helper: creates temporary test directory structure
    fn setup_test_env() -> (PathBuf, PathBuf) {
        let temp_base = std::env::temp_dir();
        let test_root = temp_base.join(format!("memta_test_{}", get_current_unix_timestamp()));

        let team_channels_dir = test_root.join("team_channels").join("pets").join("cats");
        fs::create_dir_all(&team_channels_dir).expect("Failed to create test dirs");

        (test_root, team_channels_dir)
    }

    /// Test helper: cleanup test directories
    fn cleanup_test_env(test_root: &Path) {
        let _ = fs::remove_dir_all(test_root);
    }

    #[test]
    fn test_get_current_unix_timestamp() {
        let timestamp = get_current_unix_timestamp();
        // Timestamp should be reasonable (after 2020, before 2100)
        assert!(timestamp > 1577836800); // 2020-01-01
        assert!(timestamp < 4102444800); // 2100-01-01
    }

    #[test]
    fn test_move_expired_message_basic() {
        let (test_root, team_channels_dir) = setup_test_env();

        // Create test file
        let test_file = team_channels_dir.join("message.toml");
        fs::write(&test_file, b"test content").expect("Failed to write test file");

        // This test would need modification to work with actual exe directory
        // In real implementation, this validates the full path construction

        cleanup_test_env(&test_root);
    }

    #[test]
    fn test_timestamp_format() {
        // Verify timestamp is numeric
        let timestamp = get_current_unix_timestamp();
        let timestamp_str = timestamp.to_string();
        assert!(timestamp_str.chars().all(|c| c.is_ascii_digit()));
        assert!(timestamp_str.len() >= 10); // Unix timestamp is 10+ digits
    }
}

/*
Note: this might get generalized to fit in with vote an other files
but only if that is best
unless there is a clear reason to included created_at, it should not be included
nothing should be included with empirical data in support
*/
#[derive(Debug, Deserialize, Serialize)]
struct MessagePostFile {
    // every .toml has these four
    owner: String, // owner of this item
    node_name: String, // Name of the node this message belongs to
    filepath_in_node: String, // Relative path within the node's directory
    text_message: String, // content-body

    teamchannel_collaborators_with_access: Vec<String>,

    /// sent "to the attention of" list => "ping"
    ping: Vec<String>,

    updated_at_timestamp: u64, // utc posix timestamp
    messagepost_gpgtoml: bool, // Is MessagePostFile file gpg encrypted
    expires_at: u64, // utc posix timestamp
}

impl MessagePostFile {
    fn new(
        // graph_navigation_instance_state: &GraphNavigationInstanceState,
        owner: &str, // owner
        node_name: &str, // node_name
        filepath_in_node: &str, //filepath_in_node
        text_message: &str, // text_message
        recipients_list: Vec<String>, // teamchannel_collaborators_with_access
        ping: Vec<String>, // sent "to the attention of" list => "ping"
        messagepost_gpgtoml: bool,
        expires_at: Option<u64>,  // NEW: Custom expiration, or None for default
    ) -> MessagePostFile {
        debug_log!("impl MessagePostFile: staring 'fn new'");

        let timestamp = get_current_unix_timestamp();

        // // Use custom expiration if provided, otherwise calculate default
        // let expires_at_timestamp = expires_at.unwrap_or_else(|| {
        //     timestamp + (graph_navigation_instance_state.default_im_messages_expiration_days * 24 * 60 * 60)
        // });

        // Get the current time as seconds since UNIX_EPOCH
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or(Duration::from_secs(4444444444444)) // Default to year
            .as_secs();

        // Two years in seconds (approximate - not accounting for leap years)
        let two_years_seconds = 2 * 365 * 24 * 60 * 60;

        // Calculate default expiration: now + 2 years
        let default_expiration = now + two_years_seconds;

        // Use custom expiration if provided, otherwise use calculated default
        let expires_at_timestamp: u64 = expires_at.unwrap_or(default_expiration);

        MessagePostFile {
            owner: owner.to_string(),
            node_name: node_name.to_string(),
            filepath_in_node: filepath_in_node.to_string(),
            text_message: text_message.to_string(),
            teamchannel_collaborators_with_access: recipients_list,
            ping: ping,
            updated_at_timestamp: timestamp,
            expires_at: expires_at_timestamp,  // Use calculated or custom value
            messagepost_gpgtoml: messagepost_gpgtoml,
        }
    }

}

/// Serialize MessagePostFile struct to TOML format string
///
/// This function manually constructs a TOML-formatted string from a `MessagePostFile`
/// struct without using the `serde` or `toml` crates. This approach provides direct
/// control over the serialization process and avoids third-party dependencies.
///
/// # Project Context
///
/// This function is part of the instant messaging file persistence system. It converts
/// a message post data structure into TOML format for storage in the node's file system.
/// The TOML file represents a single message post with metadata including ownership,
/// recipients, timestamps, and encryption settings.
///
/// The function is used when writing message posts to disk, replacing the deprecated
/// `toml::to_string()` approach with a manual serialization that gives full control
/// over the output format and error handling.
///
/// # TOML Format
///
/// The generated TOML has the following structure:
///
/// ```toml
/// owner = "username"
/// node_name = "nodename"
/// filepath_in_node = "/path/to/file"
/// text_message = """message content"""
/// teamchannel_collaborators_with_access = [
///     "user1",
///     "user2",
/// ]
/// updated_at_timestamp = 1234567890
/// messagepost_gpgtoml = false
/// expires_at = 18446744073709551615
/// ```
///
/// # String Handling
///
/// - Simple string fields (owner, node_name, filepath_in_node) use basic TOML strings with escaping
/// - The text_message field uses multi-line string format (triple quotes) to safely handle
///   message content that may contain newlines, quotes, and other special characters
/// - Array elements are individually escaped and formatted
///
/// # Parameters
///
/// - `message`: Reference to the `MessagePostFile` struct to serialize
///
/// # Returns
///
/// - `Ok(String)`: TOML-formatted string representation of the message post
/// - `Err(ThisProjectError)`: If serialization encounters an error
///
/// # Error Handling
///
/// Returns errors via Result type for consistency and future extensibility.
/// The function is designed to handle all valid `MessagePostFile` instances without
/// panicking.
///
/// # Usage Example
///
/// ```rust
/// let message = MessagePostFile::new(/*...*/);
/// match serialize_messagepost_config_0toml(&message) {
///     Ok(toml_string) => {
///         // Write to file or transmit
///         write_to_file(&toml_string)?;
///     }
///     Err(e) => {
///         // Handle serialization error with project-appropriate recovery
///         log_error("SMPC0T: serialization failed");
///         return Err(e);
///     }
/// }
/// ```
fn serialize_messagepost_toml(message: &MessagePostFile) -> Result<String, ThisProjectError> {
    let mut toml_string = String::new();

    // Serialize owner field - identifies who created this message post
    toml_string.push_str(&format!("owner = \"{}\"\n", escape_toml_basic_string(&message.owner)));

    // Serialize node_name field - identifies which node this message belongs to
    toml_string.push_str(&format!("node_name = \"{}\"\n", escape_toml_basic_string(&message.node_name)));

    // Serialize filepath_in_node field - relative path within node directory structure
    toml_string.push_str(&format!("filepath_in_node = \"{}\"\n", escape_toml_basic_string(&message.filepath_in_node)));

    // Serialize text_message using multi-line string format
    // This is appropriate for message content which may be multi-line
    toml_string.push_str(&format!("text_message = \"{}\"\n", message.text_message));

    // Serialize the recipients list as a TOML array
    // This contains all users who have access to view this message post
    serialize_string_array_to_toml(&mut toml_string, "teamchannel_collaborators_with_access", &message.teamchannel_collaborators_with_access)?;
    serialize_string_array_to_toml(&mut toml_string, "ping", &message.ping)?;

    // Serialize updated_at_timestamp - POSIX UTC timestamp of last update
    toml_string.push_str(&format!("updated_at_timestamp = {}\n", message.updated_at_timestamp));

    // Serialize messagepost_gpgtoml - boolean indicating if file is GPG encrypted
    // TOML booleans are lowercase: true or false
    toml_string.push_str(&format!("messagepost_gpgtoml = {}\n", message.messagepost_gpgtoml));

    // Serialize expires_at - POSIX UTC timestamp when message expires (u64::MAX means no expiration)
    toml_string.push_str(&format!("expires_at = {}\n", message.expires_at));

    Ok(toml_string)
}

/// Escape string for TOML basic string format (double-quoted strings)
///
/// Escapes special characters in strings to ensure TOML compliance per the TOML specification.
/// This prevents parsing errors when special characters appear in string values.
///
/// # Project Context
///
/// Used by manual TOML serialization to ensure string values in configuration files
/// are properly formatted. This is critical for metadata fields like owner names,
/// node names, and file paths that may contain characters with special meaning in TOML.
///
/// # TOML Basic String Requirements
///
/// According to TOML spec, basic strings (double-quoted) must escape:
/// - Backslash (\) -> \\\\
/// - Double quote (") -> \\\"
/// - Backspace (\b) -> \\b
/// - Tab (\t) -> \\t
/// - Newline (\n) -> \\n
/// - Form feed (\f) -> \\f
/// - Carriage return (\r) -> \\r
///
/// # Parameters
///
/// - `s`: The string slice to escape
///
/// # Returns
///
/// A new `String` with all special characters properly escaped for TOML basic string format
///
/// # Memory Considerations
///
/// Pre-allocates string capacity based on input length. This is a reasonable estimate
/// that avoids most reallocations while not over-allocating for strings with few
/// escape sequences.
fn escape_toml_basic_string(s: &str) -> String {
    // Pre-allocate with source length as baseline (most strings won't need much escaping)
    let mut escaped = String::with_capacity(s.len());

    for ch in s.chars() {
        match ch {
            '\\' => escaped.push_str("\\\\"),
            '"' => escaped.push_str("\\\""),
            '\x08' => escaped.push_str("\\b"),  // backspace
            '\t' => escaped.push_str("\\t"),
            '\n' => escaped.push_str("\\n"),
            '\x0C' => escaped.push_str("\\f"),  // form feed
            '\r' => escaped.push_str("\\r"),
            _ => escaped.push(ch),
        }
    }

    escaped
}

/// Serialize a vector of strings to TOML array format
///
/// Converts a vector of strings into TOML array syntax with proper formatting,
/// indentation, and escaping. Each array element is placed on its own line for
/// readability and easier diff tracking in version control.
///
/// # Project Context
///
/// Used for serializing the `teamchannel_collaborators_with_access` field in message
/// post TOML files. This field lists all users who have permission to view the message.
/// Each username is individually escaped and formatted as a TOML string array element.
///
/// The array format follows the pattern used elsewhere in the project for IP address
/// lists and other string arrays, maintaining consistency across TOML files.
///
/// # TOML Array Format
///
/// Generates arrays with this structure:
/// ```toml
/// key_name = [
///     "element1",
///     "element2",
/// ]
/// ```
///
/// Trailing commas are included (valid in TOML) for easier maintenance and cleaner diffs.
///
/// # Parameters
///
/// - `toml_string`: Mutable reference to the string being constructed
/// - `key`: The TOML key name for this array field
/// - `values`: Reference to the vector of strings to serialize
///
/// # Returns
///
/// - `Ok(())`: Successfully appended array to toml_string
/// - `Err(ThisProjectError)`: If serialization encounters an error
///
/// # Error Handling
///
/// Returns Result for API consistency and future extensibility. Current implementation
/// succeeds for all valid inputs but the Result return type allows for future error
/// conditions (e.g., maximum array size limits) without breaking the interface.
fn serialize_string_array_to_toml(
    toml_string: &mut String,
    key: &str,
    values: &Vec<String>
) -> Result<(), ThisProjectError> {
    // Open array with key
    toml_string.push_str(&format!("{} = [\n", key));

    // Add each element on its own line with indentation
    // Each element is escaped to handle special characters in usernames
    for value in values {
        toml_string.push_str(&format!("    \"{}\",\n", escape_toml_basic_string(value)));
    }

    // Close array
    toml_string.push_str("]\n");

    Ok(())
}

/// Creates a new team-channel directory, subdirectories, and metadata files.
///
/// This function establishes the directory structure and configuration files needed for a new team
/// channel. It creates all necessary directories, assigns ports to the owner, and initializes
/// the channel with default settings. All paths are resolved relative to the executable location
/// rather than the current working directory, ensuring consistent behavior regardless of where
/// the program is executed from.
///
/// # Directory Structure Created
///
/// ```
/// project_graph_data/team_channels/[team_channel_name]/
///  message_posts_browser/
///     0.toml (metadata file)
///  task_browser/
///      1_planning/
///      2_started/
///      3_done/
/// ```
///
/// # Arguments
///
/// * `team_channel_name` - The name of the new team channel.
/// * `owner` - The username of the channel owner.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>` - `Ok(())` on success, or a `ThisProjectError`
///   describing the error.
///
/// # Errors
///
/// This function can fail with a `ThisProjectError` in the following cases:
/// * If creating any directory fails
/// * If saving TOML files fails
/// * If retrieving project area data fails
/// * If creating or saving the CoreNode fails
fn create_new_team_channel(
    team_channel_name: String,
    owner: String,
    // teamchannel_collaborators_with_access: Vec<String>,
) -> Result<(), ThisProjectError> {
    /*
    // uses
    use std::collections::HashMap;
    use std::fs;
    use std::path::{Path, PathBuf};
    use rand::Rng;

    // Import the path management module
    use crate::manage_absolute_executable_directory_relative_paths::make_input_path_name_abs_executabledirectoryrelative_nocheck;
    use crate::manage_absolute_executable_directory_relative_paths::prepare_file_parent_directories_abs_executabledirectoryrelative;

    */
    debug_log("Starting CTC create_new_team_channel()");


    let corenode_gpgtoml = match q_and_a_get_corenode_gpgtoml() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA1 Process: {}", e);
            return Err(e);
        }
    };

    // Get the base directory path relative to executable location
    let team_channels_dir_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "project_graph_data/team_channels"
    ) {
        Ok(path) => path,
        Err(e) => {
            debug_log!("CTC: Error creating team_channels_dir path: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    };

    let new_channel_path = team_channels_dir_path.join(&team_channel_name);
    debug_log!("CTC: New channel path: {:?}", new_channel_path);

    // 1. Create Directory Structure (with error handling)
    // Create message_posts_browser directory
    let instant_msg_path = new_channel_path.join("message_posts_browser");
    match fs::create_dir_all(&instant_msg_path) {
        Ok(_) => debug_log!("CTC: Created message_posts_browser directory"),
        Err(e) => {
            debug_log!("CTC: Error creating message_posts_browser directory: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    }

    // Create task_browser directory
    let task_browser_path = new_channel_path.join("task_browser");
    match fs::create_dir_all(&task_browser_path) {
        Ok(_) => debug_log!("CTC: Created task_browser directory"),
        Err(e) => {
            debug_log!("CTC: Error creating task_browser directory: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    }

    // Create task browser columns
    let column_names = ["1_planning", "2_started", "3_done"];
    for col_name in column_names.iter() {
        let col_path = task_browser_path.join(col_name);
        match fs::create_dir_all(&col_path) {
            Ok(_) => debug_log!("CTC: Created task column directory: {}", col_name),
            Err(e) => {
                debug_log!("CTC: Error creating task column directory {}: {}", col_name, e);
                return Err(ThisProjectError::IoError(e));
            }
        }
    }



    // Generate collaborator port assignments

    /*
    full system v1
    */
    debug_log!("CTC: create_new_team_channel(): Starting port assignment generation for owner '{}'", owner);
    debug_log!("CTC: Retrieving project area data...");

    // Generate collaborator port assignments with global collision prevention
    debug_log!("CTC: create_new_team_channel(): Starting port assignment generation for owner '{}'", owner);

    let (teamchannel_collaborators_with_access, abstract_collaborator_port_assignments) = match create_teamchannel_port_assignments(&owner) {
        Ok((collab_list, port_assigns)) => {
            debug_log!(
                "CTC: create_new_team_channel(): Successfully generated port assignments for {} collaborators with {} pairs",
                collab_list.len(),
                port_assigns.len()
            );

            // Log details about each pair
            for (pair_name, assignments) in &port_assigns {
                debug_log!("CTC: create_new_team_channel(): Pair '{}':", pair_name);
                for assignment in &assignments[0].collaborator_ports {
                    debug_log!(
                        "  - {}: ready={}, intray={}, gotit={}",
                        assignment.user_name,
                        assignment.ready_port,
                        assignment.intray_port,
                        assignment.gotit_port
                    );
                }
            }

            (collab_list, port_assigns)
        }
        Err(e) => {
            let error_msg = format!(
                "CTC: Failed to create port assignments for team channel: {}",
                e.to_string()
            );
            eprintln!("ERROR: {}", error_msg);
            return Err(ThisProjectError::from(error_msg));
        }
    };

    debug_log!("CTC: create_new_team_channel(): Port assignments complete. Collaborators: {:?}", teamchannel_collaborators_with_access);

    // 2. Create and Save 0.toml Metadata (with error handling)
    let metadata_path = instant_msg_path.join("0.toml");
    let metadata = NodeMessagePostBrowserMetadata::new(
        &team_channel_name,
        owner.clone(),
        teamchannel_collaborators_with_access.clone(),
        99999, // default message expiry in minutes, 99_999 ~ 2-months

        // Special configurations (not for team channel)
        None,
        None,
        None,
        None,
        None,
        None,
        None,
        None,
    );

    match save_clearsigned_messagepost_config_0toml(&metadata, &metadata_path) {
        Ok(_) => debug_log!("CTC: Saved clearsigned metadata to 0.toml"),
        Err(e) => {
            debug_log!("CTC: Error saving metadata: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    }

    // match save_toml_to_file(&metadata, &metadata_path) {
    //     Ok(_) => debug_log!("CTC: Saved metadata to 0.toml"),
    //     Err(e) => {
    //         debug_log!("CTC: Error saving metadata: {}", e);
    //         return Err(ThisProjectError::IoError(e));
    //     }
    // }

    // Log the results
    debug_log!("CTC: create_new_team_channel(): Collaborators with access: {:?}", teamchannel_collaborators_with_access);
    for (pair_name, assignments) in &abstract_collaborator_port_assignments {
        debug_log!("CTC: create_new_team_channel(): Pair '{}' has {} port assignments",
            pair_name,
            assignments.len()
        );
    }

    // Retrieve project area data
    debug_log!("CTC: Retrieving project area data...");

    let pa1_process = match q_and_a_get_pa1_process() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA1 Process: {}", e);
            return Err(e);
        }
    };

    let pa2_schedule = match q_and_a_get_pa2_schedule() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA2 Schedule: {}", e);
            return Err(e);
        }
    };

    let pa3_users = match q_and_a_get_pa3_users() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA3 Users: {}", e);
            return Err(e);
        }
    };

    let pa4_features = match q_and_a_get_pa4_features() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA4 Features: {}", e);
            return Err(e);
        }
    };

    let pa5_mvp = match q_and_a_get_pa5_mvp() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA5 MVP: {}", e);
            return Err(e);
        }
    };

    let pa6_feedback = match q_and_a_get_pa6_feedback() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA6 Feedback: {}", e);
            return Err(e);
        }
    };

    let use_padnet = match q_and_a_get_use_padnet() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting use_padnet Feedback: {}", e);
            return Err(e);
        }
    };


    debug_log!("CTC: All project area data retrieved successfully");

    // 3. Create and Save CoreNode
    debug_log!("CTC: Creating CoreNode...");

    // option to save as .gpgtoml
    let new_node_result = CoreNode::new(
        team_channel_name.clone(),
        corenode_gpgtoml,
        team_channel_name,
        new_channel_path,
        owner,
        teamchannel_collaborators_with_access,
        abstract_collaborator_port_assignments,
        // Project Areas
        pa1_process,
        pa2_schedule,
        pa3_users,
        pa4_features,
        pa5_mvp,
        pa6_feedback,
        // Message Post Configuration - all None when no values
        None,  // message_post_gpgtoml_required
        None,  // message_post_data_format_specs_integer_ranges_from_to_tuple_array
        None,  // message_post_data_format_specs_int_string_ranges_from_to_tuple_array
        None,  // message_post_max_string_length_int
        None,  // message_post_is_public_bool
        None,  // message_post_user_confirms_bool
        None,  // message_post_start_date_utc_posix
        None,  // message_post_end_date_utc_posix

        use_padnet,
    );

    debug_log!("CTC: CoreNode creation complete, saving...");

    // User Q&A: Ask user to choose file format for node
    println!("\n=== Node File Format Selection ===");
    println!("Choose the format for saving the node file:");
    println!();
    println!("1. 'gpgtoml' - GPG encrypted clearsigned file (node.gpgtoml) [DEFAULT - RECOMMENDED]");
    println!("   - Maximum security: encrypted AND signed");
    println!("   - Only you can decrypt with your private key");
    println!("   - Integrity verified through clearsigning");
    println!();
    println!("2. 'clearsign' - Clearsigned only file (node.toml)");
    println!("   - Signed for integrity verification");
    println!("   - Contents readable by anyone");
    println!("   - Suitable for public/shared nodes");
    println!();
    print!("Enter your choice [gpgtoml/clearsign] (press Enter for default 'gpgtoml'): ");

    // Flush stdout to ensure the prompt appears
    std::io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    // Read user input
    let mut user_input = String::new();
    std::io::stdin().read_line(&mut user_input)
        .map_err(|e| {
            debug_log!("Error reading user input: {}", e);
            ThisProjectError::IoError(e)
        })?;

    // Trim and convert to lowercase for case-insensitive comparison
    let choice = user_input.trim().to_lowercase();

    // Determine which save method to use based on user input
    let use_encrypted = match choice.as_str() {
        "" => {
            // Empty input = use default (encrypted)
            println!("Using default: GPG encrypted clearsigned format (node.gpgtoml)");
            true
        },
        "gpgtoml" | "gpg" | "encrypted" | "secure" => {
            println!("Selected: GPG encrypted clearsigned format (node.gpgtoml)");
            true
        },
        "clearsign" | "clear" | "signed" | "toml" => {
            println!("Selected: Clearsigned only format (node.toml)");
            false
        },
        _ => {
            // Invalid input = use default with warning
            println!("Invalid input '{}'. Using default: GPG encrypted clearsigned format (node.gpgtoml)", choice);
            true
        }
    };

    // Handle the CoreNode creation result with chosen save method
    match new_node_result {
        Ok(new_node) => {
            if use_encrypted {
                // Save as GPG encrypted clearsigned file (node.gpgtoml)
                debug_log!("CoreNode created successfully, saving as encrypted file... -> new_node.save_node_as_gpgtoml()");
                match new_node.save_node_as_gpgtoml() {
                    Ok(_) => {
                        debug_log!("save_node_as_gpgtoml: CoreNode saved successfully as node.gpgtoml");
                        println!("\n Node successfully saved as encrypted file: {}/node.gpgtoml",
                                new_node.directory_path.display());
                        Ok(())
                    },
                    Err(e) => {
                        debug_log!("save_node_as_gpgtoml: Error saving CoreNode: {}", e);
                        eprintln!("\n Error saving node as encrypted file: {}", e);
                        Err(ThisProjectError::IoError(e))
                    }
                }
            } else {
                // Save as clearsigned only file (node.toml)
                debug_log!("CoreNode created successfully, saving as clearsigned file... -> new_node.save_node_to_clearsigned_file()");
                match new_node.save_node_to_clearsigned_file() {
                    Ok(_) => {
                        debug_log!("save_node_to_clearsigned_file: CoreNode saved successfully as node.toml");
                        println!("\n Node successfully saved as clearsigned file: {}/node.toml",
                                new_node.directory_path.display());
                        Ok(())
                    },
                    Err(e) => {
                        debug_log!("save_node_to_clearsigned_file: Error saving CoreNode: {}", e);
                        eprintln!("\n Error saving node as clearsigned file: {}", e);
                        Err(ThisProjectError::IoError(e))
                    }
                }
            }
        },
        Err(e) => {
            debug_log!("Error creating CoreNode: {}", e);
            eprintln!("\n Error creating CoreNode: {}", e);
            Err(e)
        }
    }
}


/// Helper function to prompt the user for a `u8` value.
fn prompt_for_u8(prompt: &str) -> u8 {
    loop {
        print!("{}", prompt);
        io::stdout().flush().unwrap();

        let mut input = String::new();
        io::stdin()
            .read_line(&mut input)
            .expect("Failed to read input");

        match input.trim().parse::<u8>() {
            Ok(value) => return value,
            Err(_) => {
                println!("Invalid input. Please enter a number between 0 and 255.");
                continue;
            }
        }
    }
}

/// Helper function to prompt the user for a `usize` value.
fn prompt_for_usize(prompt: &str) -> usize {
    loop {
        print!("{}", prompt);
        io::stdout().flush().unwrap();

        let mut input = String::new();
        io::stdin()
            .read_line(&mut input)
            .expect("Failed to read input");

        match input.trim().parse::<usize>() {
            Ok(value) => return value,
            Err(_) => {
                println!("Invalid input. Please enter a number between 1 and 128.");
                continue;
            }
        }
    }
}

// todo: deprecated?
/// Updates an existing CoreNode by walking the user through optional field updates.
///
/// This function loads an existing CoreNode from disk, presents the current values of
/// updatable fields to the user, and allows them to optionally update each field through
/// a Q&A process. The user can choose to keep existing values (default) or enter new ones.
/// After all updates are collected, the modified node is saved back to disk.
///
/// # Updatable Fields
///
/// The following fields can be updated:
/// - **Team channel collaborators list** (primary update field)
/// - **Port assignments** (regenerated if collaborators change)
/// - **Project Areas**: pa1_process, pa2_schedule, pa3_users, pa4_features, pa5_mvp, pa6_feedback
/// - **Message Post Configuration**: All Option fields for message post settings
///
/// # Preserved Fields
///
/// The following fields are NOT modified:
/// - Core identity fields (owner, node_name, node_unique_id, directory_path)
/// - Directory structure (no filesystem changes except the node TOML file)
///
/// # Arguments
///
/// * `node_path` - The absolute path to the CoreNode TOML file to update
///
/// # Returns
///
/// * `Result<(), ThisProjectError>` - `Ok(())` on successful update and save,
///   or a `ThisProjectError` describing what went wrong
///
/// # Errors
///
/// This function can fail with a `ThisProjectError` in the following cases:
/// * If the node file cannot be loaded from the specified path
/// * If the node file cannot be parsed as a valid CoreNode
/// * If saving the updated node back to disk fails
/// * If user input cannot be read during Q&A
/// * If port assignment generation fails when collaborators are updated
///
/// # Example
///
/// ```
/// let node_path = PathBuf::from("/absolute/path/to/node.toml");
/// match update_core_node(node_path) {
///     Ok(()) => println!("Node updated successfully"),
///     Err(e) => eprintln!("Failed to update node: {}", e),
/// }
/// ```
fn update_core_node(
    node_path: PathBuf,
) -> Result<(), ThisProjectError> {
    // Log function entry
    debug_log!("UCN: Starting update_core_node for path: {:?}", node_path);

    // Step 1: Load the existing CoreNode from disk
    // Uses load_core_node_from_toml_file to read and parse the node.toml file
    let mut existing_node = match load_core_node_from_toml_file(&node_path) {
        Ok(node) => {
            debug_log!("UCN: Successfully loaded CoreNode from {:?}", node_path);
            node
        }
        Err(e) => {
            debug_log!("UCN: Failed to load CoreNode from {:?}: {}", node_path, e);
            // Map the error to ThisProjectError::InvalidData as per the error handling pattern
            return Err(ThisProjectError::InvalidData(e));
        }
    };

    // require node owner is local owerner user
    // local owner user name
    let local_owner_username = get_local_owner_username();

    println!("\n=== CoreNode Update Wizard ===");
    println!("local_owner_username: {}", local_owner_username);
    println!("Node: {}", existing_node.node_name);
    println!("Description: {}", existing_node.description_for_tui);
    println!("Owner: {}", existing_node.owner);
    println!("\nYou will be prompted to update various fields.");
    println!("Press Enter to keep existing values, or type new values when prompted.\n");

    // Safety: require node owner is local owerner user
    if existing_node.owner != local_owner_username {
        debug_log("Only owner of node can edit.");
        return Ok(());
    }

    // Step 2: Update Team Channel Collaborators (main field)
    println!("\n--- TEAM CHANNEL COLLABORATORS UPDATE ---");
    println!("Current collaborators with access: {:?}", existing_node.teamchannel_collaborators_with_access);
    print!("Do you want to update the collaborators list? [y/N]: ");

    // Flush stdout to ensure prompt appears
    use std::io::{self, Write};
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut input = String::new();
    io::stdin().read_line(&mut input).map_err(|e| ThisProjectError::IoError(e))?;

    let update_collaborators = input.trim().to_lowercase() == "y";
    let mut collaborators_changed = false;

    if update_collaborators {
        // Get new collaborators list
        println!("Enter new collaborators (comma-separated usernames):");
        println!("Note: The owner '{}' will be automatically included.", existing_node.owner);
        print!("> ");
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut collab_input = String::new();
        io::stdin().read_line(&mut collab_input).map_err(|e| ThisProjectError::IoError(e))?;

        // Parse collaborators, ensuring owner is included
        let mut new_collaborators: Vec<String> = collab_input
            .trim()
            .split(',')
            .map(|s| s.trim().to_string())
            .filter(|s| !s.is_empty())
            .collect();

        // Ensure owner is in the list
        if !new_collaborators.contains(&existing_node.owner) {
            new_collaborators.insert(0, existing_node.owner.clone());
        }

        // Check if collaborators actually changed
        collaborators_changed = new_collaborators != existing_node.teamchannel_collaborators_with_access;

        if collaborators_changed {
            existing_node.teamchannel_collaborators_with_access = new_collaborators;
            debug_log!("UCN: Team channel collaborators updated to: {:?}", existing_node.teamchannel_collaborators_with_access);

            // Step 3: Regenerate port assignments if collaborators changed
            println!("\nRegenerating port assignments for updated collaborators...");

            let (updated_collaborators, new_port_assignments) =
                match create_teamchannel_port_assignments(&existing_node.owner) {
                    Ok((collab_list, port_assigns)) => {
                        debug_log!(
                            "UCN: Successfully regenerated port assignments for {} collaborators",
                            collab_list.len()
                        );
                        (collab_list, port_assigns)
                    }
                    Err(e) => {
                        let error_msg = format!(
                            "UCN: Failed to regenerate port assignments: {}",
                            e.to_string()
                        );
                        eprintln!("ERROR: {}", error_msg);
                        return Err(ThisProjectError::from(error_msg));
                    }
                };

            // Update the node with new port assignments
            existing_node.teamchannel_collaborators_with_access = updated_collaborators;
            existing_node.abstract_collaborator_port_assignments = new_port_assignments;
            println!("Port assignments regenerated successfully.");
        } else {
            println!("Collaborators unchanged.");
        }
    }

    // Step 4: Optionally update port assignments (if collaborators didn't change)
    if !collaborators_changed {
        println!("\n--- PORT ASSIGNMENTS UPDATE ---");
        print!("Do you want to regenerate port assignments? [y/N]: ");
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut port_input = String::new();
        io::stdin().read_line(&mut port_input).map_err(|e| ThisProjectError::IoError(e))?;

        if port_input.trim().to_lowercase() == "y" {
            println!("Regenerating port assignments...");

            let (_, new_port_assignments) =
                match create_teamchannel_port_assignments(&existing_node.owner) {
                    Ok((collab_list, port_assigns)) => {
                        debug_log!("UCN: Port assignments regenerated");
                        (collab_list, port_assigns)
                    }
                    Err(e) => {
                        let error_msg = format!(
                            "UCN: Failed to regenerate port assignments: {}",
                            e.to_string()
                        );
                        eprintln!("ERROR: {}", error_msg);
                        return Err(ThisProjectError::from(error_msg));
                    }
                };

            existing_node.abstract_collaborator_port_assignments = new_port_assignments;
            println!("Port assignments regenerated successfully.");
        }
    }

    // Step 5: Update Project Areas
    println!("\n--- PROJECT AREAS UPDATE ---");

    // PA1 Process
    println!("\nPA1 Process (current value: {})", existing_node.pa1_process);
    print!("Update PA1 Process? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa1_input = String::new();
    io::stdin().read_line(&mut pa1_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa1_input.trim().to_lowercase() == "y" {
        existing_node.pa1_process = match q_and_a_get_pa1_process() {
            Ok(data) => {
                debug_log!("UCN: PA1 Process updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA1 Process: {}", e);
                return Err(e);
            }
        };
    }

    // PA2 Schedule (Vec<u64> - needs Debug formatting)
    println!("\nPA2 Schedule (current value: {:?})", existing_node.pa2_schedule);
    print!("Update PA2 Schedule? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa2_input = String::new();
    io::stdin().read_line(&mut pa2_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa2_input.trim().to_lowercase() == "y" {
        existing_node.pa2_schedule = match q_and_a_get_pa2_schedule() {
            Ok(data) => {
                debug_log!("UCN: PA2 Schedule updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA2 Schedule: {}", e);
                return Err(e);
            }
        };
    }

    // PA3 Users
    println!("\nPA3 Users (current value: {})", existing_node.pa3_users);
    print!("Update PA3 Users? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa3_input = String::new();
    io::stdin().read_line(&mut pa3_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa3_input.trim().to_lowercase() == "y" {
        existing_node.pa3_users = match q_and_a_get_pa3_users() {
            Ok(data) => {
                debug_log!("UCN: PA3 Users updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA3 Users: {}", e);
                return Err(e);
            }
        };
    }

    // PA4 Features
    println!("\nPA4 Features (current value: {})", existing_node.pa4_features);
    print!("Update PA4 Features? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa4_input = String::new();
    io::stdin().read_line(&mut pa4_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa4_input.trim().to_lowercase() == "y" {
        existing_node.pa4_features = match q_and_a_get_pa4_features() {
            Ok(data) => {
                debug_log!("UCN: PA4 Features updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA4 Features: {}", e);
                return Err(e);
            }
        };
    }

    // PA5 MVP
    println!("\nPA5 MVP (current value: {})", existing_node.pa5_mvp);
    print!("Update PA5 MVP? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa5_input = String::new();
    io::stdin().read_line(&mut pa5_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa5_input.trim().to_lowercase() == "y" {
        existing_node.pa5_mvp = match q_and_a_get_pa5_mvp() {
            Ok(data) => {
                debug_log!("UCN: PA5 MVP updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA5 MVP: {}", e);
                return Err(e);
            }
        };
    }

    // PA6 Feedback
    println!("\nPA6 Feedback (current value: {})", existing_node.pa6_feedback);
    print!("Update PA6 Feedback? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut pa6_input = String::new();
    io::stdin().read_line(&mut pa6_input).map_err(|e| ThisProjectError::IoError(e))?;

    if pa6_input.trim().to_lowercase() == "y" {
        existing_node.pa6_feedback = match q_and_a_get_pa6_feedback() {
            Ok(data) => {
                debug_log!("UCN: PA6 Feedback updated");
                data
            }
            Err(e) => {
                debug_log!("UCN: Error updating PA6 Feedback: {}", e);
                return Err(e);
            }
        };
    }

    // Step 6: Update Message Post Configuration (Optional fields)
    println!("\n--- MESSAGE POST CONFIGURATION UPDATE ---");
    print!("Update message post configuration fields? [y/N]: ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut msg_config_input = String::new();
    io::stdin().read_line(&mut msg_config_input).map_err(|e| ThisProjectError::IoError(e))?;

    if msg_config_input.trim().to_lowercase() == "y" {
        // Helper function to update optional fields
        // For now, we'll provide simple text input for these fields
        // In a real implementation, you might want more sophisticated Q&A functions

        println!("\nNote: Press Enter to keep existing value, or enter new value.");

        // Max string length
        print!("Max string length (current: {:?}): ", existing_node.message_post_max_string_length_int);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut max_len_input = String::new();
        io::stdin().read_line(&mut max_len_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !max_len_input.trim().is_empty() {
            match max_len_input.trim().parse::<usize>() {
                Ok(val) => {
                    existing_node.message_post_max_string_length_int = Some(val);
                    debug_log!("UCN: Max string length updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid number, keeping existing value.");
                }
            }
        }

        // Is public boolean
        print!("Is public? (true/false, current: {:?}): ", existing_node.message_post_is_public_bool);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut is_public_input = String::new();
        io::stdin().read_line(&mut is_public_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !is_public_input.trim().is_empty() {
            match is_public_input.trim().parse::<bool>() {
                Ok(val) => {
                    existing_node.message_post_is_public_bool = Some(val);
                    debug_log!("UCN: Is public updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid boolean, keeping existing value.");
                }
            }
        }

        // User confirms boolean
        print!("User confirms? (true/false, current: {:?}): ", existing_node.message_post_user_confirms_bool);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut user_confirms_input = String::new();
        io::stdin().read_line(&mut user_confirms_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !user_confirms_input.trim().is_empty() {
            match user_confirms_input.trim().parse::<bool>() {
                Ok(val) => {
                    existing_node.message_post_user_confirms_bool = Some(val);
                    debug_log!("UCN: User confirms updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid boolean, keeping existing value.");
                }
            }
        }

        // Start date (POSIX timestamp)
        print!("Start date (POSIX timestamp, current: {:?}): ", existing_node.message_post_start_date_utc_posix);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut start_date_input = String::new();
        io::stdin().read_line(&mut start_date_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !start_date_input.trim().is_empty() {
            match start_date_input.trim().parse::<i64>() {
                Ok(val) => {
                    existing_node.message_post_start_date_utc_posix = Some(val);
                    debug_log!("UCN: Start date updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid timestamp, keeping existing value.");
                }
            }
        }

        // End date (POSIX timestamp)
        print!("End date (POSIX timestamp, current: {:?}): ", existing_node.message_post_end_date_utc_posix);
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut end_date_input = String::new();
        io::stdin().read_line(&mut end_date_input).map_err(|e| ThisProjectError::IoError(e))?;

        if !end_date_input.trim().is_empty() {
            match end_date_input.trim().parse::<i64>() {
                Ok(val) => {
                    existing_node.message_post_end_date_utc_posix = Some(val);
                    debug_log!("UCN: End date updated to: {}", val);
                }
                Err(_) => {
                    println!("Invalid timestamp, keeping existing value.");
                }
            }
        }

        // Note: The integer ranges and string ranges fields would need more complex parsing
        // For now, leaving them as-is unless you have specific Q&A functions for them
        println!("\nNote: Integer ranges and string ranges configuration not updated in this version.");
    }

    // Update the timestamp to reflect the modification
    use std::time::{SystemTime, UNIX_EPOCH};
    existing_node.updated_at_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| ThisProjectError::from(format!("System time error: {}", e)))?
        .as_secs();

    // // Step 7: Save the updated node back to disk
    // println!("\n--- SAVING UPDATES ---");
    // println!("Saving updated CoreNode to {:?}...", node_path);

    // match existing_node.save_node_to_clearsigned_file() {
    //     Ok(_) => {
    //         debug_log!("UCN: CoreNode successfully saved to {:?}", node_path);
    //         println!("CoreNode updated and saved successfully!");
    //         Ok(())
    //     }
    //     Err(e) => {
    //         debug_log!("UCN: Failed to save CoreNode: {}", e);
    //         eprintln!("ERROR: Failed to save updated node: {}", e);
    //         Err(ThisProjectError::IoError(e))
    //     }
    // }

    // Step 7: Save the updated node back to disk
    println!("\n--- SAVING UPDATES ---");

    // User Q&A: Ask user to choose file format for node
    println!("\n=== Node File Format Selection ===");
    println!("Choose the format for saving the node file:");
    println!();
    println!("1. 'gpgtoml' - GPG encrypted clearsigned file (node.gpgtoml) [DEFAULT - RECOMMENDED]");
    println!("   - Maximum security: encrypted AND signed");
    println!("   - Only you can decrypt with your private key");
    println!("   - Integrity verified through clearsigning");
    println!();
    println!("2. 'clearsign' - Clearsigned only file (node.toml)");
    println!("   - Signed for integrity verification");
    println!("   - Contents readable by anyone");
    println!("   - Suitable for public/shared nodes");
    println!();
    print!("Enter your choice [gpgtoml/clearsign] (press Enter for default 'gpgtoml'): ");

    // Flush stdout to ensure the prompt appears
    std::io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    // Read user input
    let mut user_input = String::new();
    std::io::stdin().read_line(&mut user_input)
        .map_err(|e| {
            debug_log!("UCN: Error reading user input: {}", e);
            ThisProjectError::IoError(e)
        })?;

    // Trim and convert to lowercase for case-insensitive comparison
    let choice = user_input.trim().to_lowercase();

    // Determine which save method to use based on user input
    let use_encrypted = match choice.as_str() {
        "" => {
            // Empty input = use default (encrypted)
            println!("Using default: GPG encrypted clearsigned format (node.gpgtoml)");
            true
        },
        "gpgtoml" | "gpg" | "encrypted" | "secure" => {
            println!("Selected: GPG encrypted clearsigned format (node.gpgtoml)");
            true
        },
        "clearsign" | "clear" | "signed" | "toml" => {
            println!("Selected: Clearsigned only format (node.toml)");
            false
        },
        _ => {
            // Invalid input = use default with warning
            println!("Invalid input '{}'. Using default: GPG encrypted clearsigned format (node.gpgtoml)", choice);
            true
        }
    };

    // Save with chosen method
    println!("Saving updated CoreNode to {:?}...", node_path);

    if use_encrypted {
        // Save as GPG encrypted clearsigned file (node.gpgtoml)
        match existing_node.save_node_as_gpgtoml() {
            Ok(_) => {
                debug_log!("UCN: CoreNode successfully saved as encrypted file to {:?}", node_path);
                println!(" CoreNode updated and saved successfully as node.gpgtoml!");
                Ok(())
            }
            Err(e) => {
                debug_log!("UCN: Failed to save CoreNode as encrypted file: {}", e);
                eprintln!("ERROR: Failed to save updated node as encrypted file: {}", e);
                Err(ThisProjectError::IoError(e))
            }
        }
    } else {
        // Save as clearsigned only file (node.toml)
        match existing_node.save_node_to_clearsigned_file() {
            Ok(_) => {
                debug_log!("UCN: CoreNode successfully saved as clearsigned file to {:?}", node_path);
                println!(" CoreNode updated and saved successfully as node.toml!");
                Ok(())
            }
            Err(e) => {
                debug_log!("UCN: Failed to save CoreNode as clearsigned file: {}", e);
                eprintln!("ERROR: Failed to save updated node as clearsigned file: {}", e);
                Err(ThisProjectError::IoError(e))
            }
        }
    }
}

/// Creates a new (core)Node directory, subdirectories, and metadata files.
/// Handles errors and returns a Result to indicate success or failure.
///
/// # Arguments
///
/// * `path_to_node` - Base path where the node will be created
/// * `teamchannel_collaborators_with_access` - List of collaborators
/// * `team_channel_name` - Name of the team channel
///
/// # Returns
///
/// * `Result<(), ThisProjectError>` - `Ok(())` on success, or a `ThisProjectError`
fn create_core_node(
    node_path: PathBuf,
    teamchannel_collaborators_with_access: Vec<String>,
    use_padnet: Option<bool>,
) -> Result<(), ThisProjectError> {
    debug_log!("start create_core_node(), node_path -> {:?}", node_path);

    // Get user input for node name
    println!("Enter node name:");
    let mut node_name = String::new();
    io::stdin().read_line(&mut node_name)?;
    let node_name = node_name.trim().to_string();

    let corenode_gpgtoml = match q_and_a_get_corenode_gpgtoml() {
        Ok(data) => data,
        Err(e) => {
            debug_log!("CTC: Error getting PA1 Process: {}", e);
            return Err(e);
        }
    };

    // Get user input for description
    println!("Enter project description:");
    let mut description = String::new();
    io::stdin().read_line(&mut description)?;
    let description = description.trim().to_string();

    // Create the specific node directory path
    let node_specific_path = node_path.join(&node_name);
    debug_log!("Creating node at specific path: {:?}", node_specific_path);

    // Create the main node directory
    fs::create_dir_all(&node_specific_path)?;

    // local owner user name
    let owner = get_local_owner_username();

    // Get user input for planning fields
    // Project Areas
    let pa1_process = q_and_a_get_pa1_process()?;
    let pa2_schedule = q_and_a_get_pa2_schedule()?;
    let pa3_users = q_and_a_get_pa3_users()?;
    let pa4_features = q_and_a_get_pa4_features()?;
    let pa5_mvp = q_and_a_get_pa5_mvp()?;
    let pa6_feedback = q_and_a_get_pa6_feedback()?;

    // Get user input for message post configuration fields
    let messageposts_expire_after_n_min = q_and_a_get_message_messageposts_expire_after_n_min()?;
    print!("\n");
    let message_post_gpgtoml_required = q_and_a_get_message_post_gpgtoml_required()?;
    print!("\n");
    let message_post_integer_ranges = q_and_a_get_message_post_integer_ranges()?;
    print!("\n");
    let message_post_int_string_ranges = q_and_a_get_message_post_int_string_ranges()?;
    print!("\n");
    let message_post_max_string_length = q_and_a_get_message_post_max_string_length()?;
    print!("\n");
    let message_post_is_public = q_and_a_get_message_post_is_public()?;
    print!("\n");
    let message_post_user_confirms = q_and_a_get_message_post_user_confirms()?;
    print!("\n");
    let message_post_start_date = q_and_a_get_message_post_start_date()?;
    print!("\n");
    let message_post_end_date = q_and_a_get_message_post_end_date(message_post_start_date)?;

    // Create subdirectories within the node directory
    let message_dir = node_specific_path.join("message_posts_browser");
    let task_browser_dir = node_specific_path.join("task_browser");

    fs::create_dir_all(&message_dir)?;
    fs::create_dir_all(&task_browser_dir)?;

    // Create task browser columns
    for col_name in ["1_planning", "2_started", "3_done"].iter() {
        let col_path = task_browser_dir.join(col_name);
        fs::create_dir_all(&col_path)?;
        // TODO: Create column nodes (recursive call for later)
        // create_core_node(col_path, teamchannel_collaborators_with_access.clone(), format!("{}_{}", node_name, col_name))?;
        // TODO maybe custom shallow node with no tasks option needed...
    }

    // Create and Save metadata
    let metadata_path = message_dir.join("0.toml");
    let metadata = NodeMessagePostBrowserMetadata::new(
        &node_name,
        owner.clone(),
        teamchannel_collaborators_with_access.clone(),
        messageposts_expire_after_n_min,
        // Special configurations
        message_post_gpgtoml_required,
        message_post_integer_ranges.clone(),
        message_post_int_string_ranges.clone(),
        message_post_max_string_length,
        message_post_is_public,
        message_post_user_confirms,
        message_post_start_date,
        message_post_end_date,
    );
    save_toml_to_file(&metadata, &metadata_path)?;

    // Create CoreNode instance
    let new_node_result = CoreNode::new(
        node_name.clone(),                 // node_name
        corenode_gpgtoml,
        description,                       // description_for_tui
        node_specific_path.clone(),        // directory_path
        owner,                             // owner
        teamchannel_collaborators_with_access,
        HashMap::new(),                    // for ports

        // Project Areas TODO TODO
        pa1_process,
        pa2_schedule,
        pa3_users,
        pa4_features,
        pa5_mvp,
        pa6_feedback,

        // Message Post Configuration
        message_post_gpgtoml_required,
        message_post_integer_ranges,
        message_post_int_string_ranges,
        message_post_max_string_length,
        message_post_is_public,
        message_post_user_confirms,
        message_post_start_date,
        message_post_end_date,

        // Padnet
        use_padnet,
    );

    match new_node_result {
        Ok(new_node) => {
            // Save node.toml in the specific node directory
            new_node.save_node_to_clearsigned_file()?;
            debug_log!("Successfully created node: {:?}", node_specific_path);
            Ok(())
        }
        Err(e) => {
            debug_log!("Error creating CoreNode: {}", e);
            Err(e)
        }
    }
}


/// Calculate directory hash for task board structure (two levels deep)
///
/// # Purpose
///
/// Generates a hash of task board state by examining both column directories
/// and the task directories within them. This two-level hashing is necessary
/// because tasks are nested: tasks live inside column directories.
///
/// # Task Board Structure
///
/// ```text
/// task_board/
///   1_plan/              <- Level 1: Column directories
///     task_alpha/        <- Level 2: Task directories
///     task_beta/
///   2_doing/
///     task_gamma/
///   3_done/
///     task_delta/
/// ```
///
/// # What Changes Trigger Hash Change
///
/// - Column directory added/removed/renamed
/// - Task directory added/removed/renamed within any column
/// - Task moved between columns
///
/// # What Does NOT Trigger Hash Change
///
/// - File content changes within task directories
/// - Timestamp changes
/// - Permission changes
///
/// This is intentional - we only detect structural changes (tasks moving/appearing),
/// not content edits within existing tasks.
///
/// # Hashing Algorithm
///
/// 1. For each column directory (sorted):
///    - Add column directory name to hash input
///    - For each task within column (sorted):
///      - Add task directory name to hash input
/// 2. Hash the complete concatenated string
///
/// # Parameters
///
/// * `path` - Path to task board directory
///
/// # Returns
///
/// * `Ok(String)` - Hash string representing current state
/// * `Err(io::Error)` - If directory cannot be read
///
/// # Example
///
/// ```no_run
/// let hash1 = get_task_directory_hash(Path::new("/tmp/uma/team/board"))?;
/// // ... task moves from plan to doing ...
/// let hash2 = get_task_directory_hash(Path::new("/tmp/uma/team/board"))?;
/// assert_ne!(hash1, hash2); // Hashes differ after task move
/// ```
fn get_task_directory_hash(path: &Path) -> io::Result<String> {
    use std::collections::BTreeMap;
    use std::collections::hash_map::DefaultHasher;
    use std::hash::{Hash, Hasher};

    debug_log!("GTH: Getting task directory hash for: {:?}", path);

    let mut hash_input = String::new();

    // Collect all column directories (1_plan, 2_doing, etc.)
    let mut columns: BTreeMap<String, Vec<String>> = BTreeMap::new();

    // Read level 1: column directories
    for entry in fs::read_dir(path)? {
        let entry = entry?;
        let file_name = entry.file_name().to_string_lossy().into_owned();

        if entry.file_type()?.is_dir() {
            // This is a column directory
            let mut tasks = Vec::new();

            // Read level 2: task directories within this column
            if let Ok(task_entries) = fs::read_dir(entry.path()) {
                for task_entry in task_entries {
                    if let Ok(task_entry) = task_entry {
                        if let Ok(task_type) = task_entry.file_type() {
                            if task_type.is_dir() {
                                tasks.push(task_entry.file_name().to_string_lossy().into_owned());
                            }
                        }
                    }
                }
            }

            // Sort tasks for consistent hashing
            tasks.sort();
            columns.insert(file_name, tasks);
        }
    }

    // Build hash input string from sorted structure
    for (column_name, tasks) in columns.iter() {
        hash_input.push_str(column_name);
        hash_input.push(':');
        for task in tasks {
            hash_input.push_str(task);
            hash_input.push(',');
        }
        hash_input.push(';');
    }

    // Calculate hash
    let mut hasher = DefaultHasher::new();
    hash_input.hash(&mut hasher);
    let hash_value = hasher.finish();

    debug_log!("GTH: Hash input string: {}", hash_input);
    debug_log!("GTH: Hash value: {}", hash_value);

    Ok(format!("{:x}", hash_value))
}

/// Passive Task View Mode - Auto-Refresh Task Board Display
///
/// # Purpose
///
/// Runs a passive (read-only, no input) task board viewer that automatically
/// refreshes when the task board structure changes. Monitors task board directory
/// for structural changes (tasks added/removed/moved) and updates display.
///
/// # Task Board Structure
///
/// Expects Kanban-style board with column directories containing task directories:
/// ```text
/// task_board/
///   1_plan/
///     task_alpha/
///     task_beta/
///   2_doing/
///     task_gamma/
///   3_done/
///     task_delta/
/// ```
///
/// # Change Detection
///
/// Uses two-level directory hashing to detect:
/// - Tasks added to any column
/// - Tasks removed from any column
/// - Tasks moved between columns
/// - Column directories added/removed
///
/// Does NOT detect:
/// - File content changes within tasks
/// - Metadata/timestamp changes
///
/// # Refresh Behavior
///
/// - Checks for changes every 10 seconds (configurable)
/// - Only refreshes display when structure changes detected
/// - Avoids unnecessary redraws for better performance
///
/// # Display Format
///
/// Shows task board as table with columns and tasks listed under each column.
/// No pagination (shows all tasks), no input prompts (passive view).
///
/// # Error Handling
///
/// - Initial display error: Returns error (can't start without display)
/// - Hash calculation error: Logs and continues (keeps showing last good state)
/// - Refresh display error: Logs and continues (keeps monitoring)
///
/// # Parameters
///
/// * `path` - Path to task board directory
///
/// # Returns
///
/// * `Ok(())` - Never returns normally (infinite loop until killed)
/// * `Err(io::Error)` - Only if initial setup fails
///
/// # Related Functions
///
/// - `get_task_directory_hash()` - Detects structural changes
/// - `passive_display_tasks()` - Renders task board
/// - `optional_passive_mode()` - Launches this function
fn run_passive_task_mode(path: &Path) -> io::Result<()> {
    debug_log("RPTM: Starting passive task mode");
    debug_log!("RPTM: Task board path: {:?}", path);

    // ============================================================
    // CONFIGURATION: Set refresh rate
    // ============================================================
    let refresh_rate: f32 = 10.0; // seconds between checks
    debug_log!("RPTM: Refresh rate: {} seconds", refresh_rate);

    // ============================================================
    // INITIALIZATION: Get initial state and display
    // ============================================================
    let mut last_directory_state = match get_task_directory_hash(path) {
        Ok(hash) => {
            debug_log!("RPTM: Initial hash: {}", hash);
            hash
        }
        Err(e) => {
            debug_log!("RPTM: Failed to get initial hash: {}", e);
            return Err(e);
        }
    };

    // Initial display
    debug_log("RPTM: Displaying initial task board");
    tiny_tui::passive_display_tasks(path)?;

    // ============================================================
    // REFRESH LOOP: Monitor and update display
    // ============================================================
    debug_log("RPTM: Entering refresh loop");

    loop {
        // Check current state
        let current_directory_state = match get_task_directory_hash(path) {
            Ok(hash) => hash,
            Err(e) => {
                debug_log!("RPTM: Failed to get current hash (continuing with last state): {}", e);
                // Continue loop - keep showing last good state
                thread::sleep(Duration::from_secs_f32(refresh_rate));
                continue;
            }
        };

        // Compare states
        if current_directory_state != last_directory_state {
            debug_log!("RPTM: Directory state changed, refreshing display");
            debug_log!("RPTM: Old hash: {}", last_directory_state);
            debug_log!("RPTM: New hash: {}", current_directory_state);

            // Clear screen and redisplay
            print!("\x1B[2J\x1B[1;1H");

            match tiny_tui::passive_display_tasks(path) {
                Ok(_) => {
                    debug_log!("RPTM: Display refreshed successfully");
                    last_directory_state = current_directory_state;
                }
                Err(e) => {
                    debug_log!("RPTM: Failed to refresh display (keeping last state): {}", e);
                    // Don't update last_directory_state - will retry next cycle
                }
            }
        } else {
            debug_log!("RPTM: No changes detected");
        }

        // Sleep until next check
        thread::sleep(Duration::from_secs_f32(refresh_rate));
    }
}

// /// for passive view mode
// fn run_passive_task_mode(path: &Path) -> io::Result<()> {
//     debug_log("Starting passive task mode...");

//     // 1. Read refresh rate from uma.toml (similar to log mode)
//     // let refresh_rate = get_refresh_rate()?;
//     let refresh_rate: f32 = 10.0;

//     // 2. Initialize last known state
//     let mut last_directory_state = get_task_directory_hash(path)?;

//     // 3. Initial display
//     tiny_tui::passive_display_tasks(path)?;

//     // 4. Enter refresh loop
//     loop {
//         let current_directory_state = get_task_directory_hash(path)?;

//         if current_directory_state != last_directory_state {
//             print!("\x1B[2J\x1B[1;1H"); // Clear screen
//             tiny_tui::passive_display_tasks(path)?;
//             last_directory_state = current_directory_state;
//         }

//         thread::sleep(Duration::from_secs_f32(refresh_rate));
//     }
// }


/// for passive view mode
/// Passive Message View Mode Implementation
///
/// This function implements the core loop for the passive message viewer terminal,
/// which runs as a separate process from the main Uma application.
///
/// # System Architecture:
/// 1. Main Uma Application:
///    - User enters "m" command
///    - Launches new terminal with --passive_message_mode flag
///    - Continues with normal operation
///
/// 2. Passive View Process (this function):
///    - Runs in separate terminal
///    - Monitors message directory
///    - Updates display when changes detected
///
/// # Command Line Launch:
/// Launched via: uma --passive_message_mode [path_to_message_dir]
/// Example: uma --passive_message_mode /home/user/team1/channel1/message_posts_browser
///
/// # Operational Flow:
/// 1. Directory Monitoring:
///    - Calculates hash of directory state
///    - Detects changes by comparing hashes
///    - Refresh rate set by uma.toml (default: 5.0 seconds)
///
/// 2. Display Updates:
///    - Clears screen when changes detected
///    - Reads all message files
///    - Formats and displays messages
///    - Maintains chronological order
///
/// # Directory Structure Expected:
/// ```text
/// message_posts_browser/
///  0.toml (metadata)
///  1__user1.toml (message)
///  2__user2.toml (message)
///  3__user1.toml (message)
/// ```
///
/// # Message File Format:
/// TOML files containing:
/// - owner: String (username)
/// - text_message: String (content)
/// - timestamp: Optional<DateTime>
///
/// # Error Handling:
/// - Returns io::Error for file system issues
/// - Continues running on non-fatal errors
/// - Logs errors for debugging
///
/// # Display Format:
/// ```text
/// Channel: team1/channel1
///
/// 1. user1: message content
/// 2. user2: another message
/// 3. user1: third message
/// ```
///
/// # Important Notes:
/// - View-only mode (no message creation/editing)
/// - Independent process (no connection to main Uma)
/// - Must be manually closed (Ctrl+C)
/// - Does not maintain state between refreshes
/// - All data read fresh from files each update
///
/// # Related Components:
/// - get_directory_hash(): Generates state hash
/// - passive_display_messages(): Renders message list
/// - Main Uma's message mode launcher
/// - Message file TOML structure
///
/// # Configuration:
/// - Refresh rate from uma.toml
/// - Default refresh: 5.0 seconds
/// - Directory path from command line
///
/// # Dependencies:
/// - std::path for path handling
/// - std::fs for file operations
/// - std::thread for sleep
/// - std::io for error handling
/// - toml for message file parsing
///
/// This implementation prioritizes:
/// - Reliability over performance
/// - Simple direct file reading over caching
/// - Clear display over complex features
/// - Independence from main Uma process
fn run_passive_message_mode(path: &Path) -> io::Result<()> {
    debug_log("Starting passive message mode...");

    // 1. Read refresh rate from uma.toml (similar to log mode)
    // let refresh_rate = get_refresh_rate()?;
    let refresh_rate: f32 = 5.0;

    // 2. Initialize last known state
    let mut last_directory_state = get_directory_hash(path)?;

    // 3. Initial display
    passive_display_messages(path)?;

    // 4. Enter refresh loop
    loop {
        let current_directory_state = get_directory_hash(path)?;

        if current_directory_state != last_directory_state {
            print!("\x1B[2J\x1B[1;1H"); // Clear screen
            passive_display_messages(path)?;
            last_directory_state = current_directory_state;
        }

        thread::sleep(Duration::from_secs_f32(refresh_rate));
    }
}

/// Passive Message Display with GPG Support (Read-Only Auto-Refresh View)
///
/// # Purpose
///
/// Loads and displays instant messages in passive (read-only) view mode with
/// full GPG support. This function handles both plain clearsigned `.toml` files
/// and encrypted `.gpgtoml` files, matching the interactive view's capabilities
/// while maintaining passive-only operation (no user input, auto-refresh only).
///
/// This is the passive-view equivalent of `load_messagepost_messages()`, with key differences:
/// - No interactive prompts (if empty, shows empty list)
/// - All errors are logged and skipped (never halts viewing)
/// - No state management (reads fresh each time)
/// - Fixed display height (18 lines, scrolldown default)
///
/// # Process Flow
///
/// 1. **Setup Phase:**
///    - Read GPG fingerprint from uma.toml
///    - Get uma temp directory path
///    - If either fails: log error, show empty display, return Ok
///
/// 2. **Collection Phase:**
///    - Collect all file entries from target directory (max depth 1)
///    - Sort entries by numeric prefix in filename (1__, 2__, 3__, etc.)
///    - Filter out metadata file (0.toml)
///
/// 3. **Processing Phase (per file):**
///    - Get readable temp copy via `get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml()`
///      - For `.toml`: verifies clearsign and creates temp readable copy
///      - For `.gpgtoml`: decrypts and creates temp readable copy
///    - Read `owner` field from temp copy
///    - Read `text_message` field from temp copy
///    - Add formatted message to display list
///    - Clean up temp copy via `cleanup_collaborator_temp_file()`
///    - On ANY error: log with "PDM:" prefix and skip to next file
///
/// 4. **Display Phase:**
///    - Render complete message list via `simple_render_list_passive()`
///    - Shows bottom N messages (scrolldown default, N=18)
///
/// # Message File Formats Supported
///
/// - `.toml` files: Clearsigned TOML format (authenticated, verifiable)
///   - Contains GPG clearsign armor wrapping TOML content
///   - Verified during temp copy creation
///
/// - `.gpgtoml` files: Encrypted TOML format (confidential, authenticated)
///   - Contains GPG encrypted message
///   - Decrypted during temp copy creation
///
/// - `0.toml`: Metadata file (excluded from message list)
///
/// - Expected filename format: `<number>__<identifier>.toml` or `.gpgtoml`
///   - Examples: `1__alice.toml`, `2__bob.gpgtoml`, `15__charlie.toml`
///
/// # Sorting Behavior
///
/// Messages are sorted by extracting the numeric prefix before the first `__`
/// in the filename:
/// - `1__alice.toml`  1
/// - `2__bob.gpgtoml`  2
/// - `15__charlie.toml`  15
/// - Files without numeric prefix are placed at the end (sorted as u64::MAX)
///
/// # Error Handling Philosophy (Passive View)
///
/// **Critical principle: Never interrupt viewing**
///
/// All errors are handled with "log and skip" approach:
/// - GPG fingerprint read failure  log, show empty display, return Ok
/// - Temp directory access failure  log, show empty display, return Ok
/// - Individual file read errors  log with "PDM:" prefix, skip file, continue
/// - Temp copy creation errors  log, skip file, continue
/// - Field read errors  log, skip file, continue
/// - Cleanup errors  log, continue (already read)
///
/// Error logs include:
/// - Unique function prefix "PDM:" (PassiveDisplayMessages)
/// - File path (debug mode only)
/// - Error description
/// - Action taken (skipping)
///
/// # Comparison with Interactive Version
///
/// **Same:**
/// - File reading logic (GPG handling, temp copies)
/// - Field extraction (owner, text_message)
/// - Sorting algorithm
/// - Message format
///
/// **Different:**
/// - No first-message prompt (shows empty if no messages)
/// - No state management (no App struct)
/// - All errors skip silently (no user prompts)
/// - Fixed display height
/// - No pagination controls
///
/// # Security Notes
///
/// - Requires valid GPG fingerprint in uma.toml
/// - Verifies clearsigned messages
/// - Decrypts encrypted messages using local GPG key
/// - Temp files cleaned up after reading
/// - No data written (read-only operation)
///
/// # Parameters
///
/// * `path` - Directory path containing message files (message_posts_browser)
///
/// # Returns
///
/// * `Ok(())` - Always returns Ok (errors logged and handled internally)
/// * `Err(io::Error)` - Only for catastrophic directory access issues (rare)
///
/// # Platform Support
///
/// - Linux, macOS, BSD variants, Android, Redox
/// - Requires GPG installed and configured
/// - Requires uma.toml with GPG fingerprint
///
/// # Related Functions
///
/// - `load_messagepost_messages()` - Interactive version with state management
/// - `get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml()` - Gets readable temp copy
/// - `cleanup_collaborator_temp_file()` - Cleans up temp files
/// - `simple_render_list_passive()` - Renders message list
/// - `run_passive_message_mode()` - Refresh loop that calls this function
///
/// # Example Usage
///
/// ```no_run
/// use std::path::Path;
///
/// let message_dir = Path::new("/path/to/team/channel/message_posts_browser");
/// passive_display_messages(message_dir)?;
/// // Displays messages, handling both .toml and .gpgtoml files
/// // All errors logged and skipped, never interrupts display
/// ```
///
/// # Debug Logging
///
/// All log messages prefixed with "PDM:" for easy filtering:
/// - "PDM: Starting passive message display"
/// - "PDM: Failed to read GPG fingerprint: [error]"
/// - "PDM: Failed to get temp directory: [error]"
/// - "PDM: Failed to get readable copy of [file]: [error] (skipping)"
/// - "PDM: Failed to read owner from [file]: [error] (skipping)"
/// - "PDM: Failed to read text_message from [file]: [error] (skipping)"
/// - "PDM: Successfully loaded N messages, M files skipped"
pub fn passive_display_messages(path: &Path) -> io::Result<()> {
    debug_log!("PDM: Starting passive message display for path: {:?}", path);

    // Initialize empty message list
    let mut message_list: Vec<String> = Vec::new();

    // ============================================================
    // SETUP PHASE: Get GPG fingerprint and temp directory
    // ============================================================

    // Get GPG fingerprint from uma.toml for decryption/verification
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => {
            debug_log!("PDM: GPG fingerprint retrieved: {}", fingerprint);
            fingerprint
        }
        Err(e) => {
            debug_log!("PDM: Failed to read GPG fingerprint from uma.toml: {} (showing empty display)", e);
            // Show empty display and return - cannot process any files without GPG
            tiny_tui::simple_render_list_passive(&message_list, path);
            return Ok(());
        }
    };

    // Get temp directory for creating readable copies
    let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
        Ok(temp_path) => {
            debug_log!("PDM: Temp directory path retrieved: {:?}", temp_path);
            temp_path
        }
        Err(e) => {
            debug_log!("PDM: Failed to get temp directory path: {} (showing empty display)", e);
            // Show empty display and return - cannot create temp copies without temp dir
            tiny_tui::simple_render_list_passive(&message_list, path);
            return Ok(());
        }
    };

    // ============================================================
    // COLLECTION PHASE: Gather and sort message files
    // ============================================================

    debug_log!("PDM: Collecting file entries from directory");

    // Collect all file entries from directory (max depth 1)
    let mut entries: Vec<_> = WalkDir::new(path)
        .max_depth(1)
        .into_iter()
        .filter_map(|entry| entry.ok())
        .filter(|entry| entry.path().is_file())
        .collect();

    debug_log!("PDM: Found {} file entries", entries.len());

    // Sort entries by numeric prefix in filename (1__, 2__, 3__, etc.)
    entries.sort_by_key(|entry| {
        entry
            .path()
            .file_name()
            .and_then(|n| n.to_str())
            .and_then(|s| s.split("__").next()) // Get part before "__"
            .and_then(|num_str| num_str.parse::<u64>().ok()) // Parse as number
            .unwrap_or(u64::MAX) // Put unparseable names at end
    });

    debug_log!("PDM: Entries sorted by numeric prefix");

    // ============================================================
    // PROCESSING PHASE: Read and process each message file
    // ============================================================

    let mut loaded_count = 0;
    let mut skipped_count = 0;

    for entry in entries {
        // Get filename for logging and filtering
        let file_name = match entry.path().file_name() {
            Some(name) => name.to_string_lossy().to_string(),
            None => {
                debug_log!("PDM: Entry has no filename: {:?} (skipping)", entry.path());
                skipped_count += 1;
                continue;
            }
        };

        // Skip metadata file (0.toml)
        if file_name == "0.toml" {
            debug_log!("PDM: Skipping metadata file: {}", file_name);
            continue;
        }

        debug_log!("PDM: Processing message file: {}", file_name);

        // ------------------------------------------------------------
        // Get readable temp copy (handles both .toml and .gpgtoml)
        // ------------------------------------------------------------
        let message_readcopy_path = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
            entry.path(),
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ) {
            Ok(temp_path) => {
                debug_log!("PDM: Created temp readable copy at: {}", temp_path);
                temp_path
            }
            Err(e) => {
                debug_log!(
                    "PDM: Failed to get readable copy of {:?}: {:?} (skipping)",
                    entry.path(),
                    e
                );
                skipped_count += 1;
                continue;
            }
        };

        // ------------------------------------------------------------
        // Read owner field from temp copy
        // ------------------------------------------------------------
        let owner = match read_single_line_string_field_from_toml(
            &message_readcopy_path,
            "owner",
        ) {
            Ok(owner_value) => {
                // Validate owner is not empty
                if owner_value.is_empty() {
                    debug_log!("PDM: Owner field is empty in {} (skipping)", file_name);
                    skipped_count += 1;
                    // Clean up temp file before continuing
                    let _ = cleanup_collaborator_temp_file(
                        &message_readcopy_path,
                        &base_uma_temp_directory_path,
                    );
                    continue;
                }
                owner_value
            }
            Err(e) => {
                debug_log!(
                    "PDM: Failed to read owner field from {}: {} (skipping)",
                    file_name,
                    e
                );
                skipped_count += 1;
                // Clean up temp file before continuing
                let _ = cleanup_collaborator_temp_file(
                    &message_readcopy_path,
                    &base_uma_temp_directory_path,
                );
                continue;
            }
        };

        // ------------------------------------------------------------
        // Read text_message field from temp copy
        // ------------------------------------------------------------
        let text_message = match read_single_line_string_field_from_toml(
            &message_readcopy_path,
            "text_message",
        ) {
            Ok(text_value) => {
                // Validate text_message is not empty
                if text_value.is_empty() {
                    debug_log!("PDM: text_message field is empty in {} (skipping)", file_name);
                    skipped_count += 1;
                    // Clean up temp file before continuing
                    let _ = cleanup_collaborator_temp_file(
                        &message_readcopy_path,
                        &base_uma_temp_directory_path,
                    );
                    continue;
                }
                text_value
            }
            Err(e) => {
                debug_log!(
                    "PDM: Failed to read text_message field from {}: {} (skipping)",
                    file_name,
                    e
                );
                skipped_count += 1;
                // Clean up temp file before continuing
                let _ = cleanup_collaborator_temp_file(
                    &message_readcopy_path,
                    &base_uma_temp_directory_path,
                );
                continue;
            }
        };

        // ------------------------------------------------------------
        // Clean up temp file (ignore cleanup errors)
        // ------------------------------------------------------------
        if let Err(e) = cleanup_collaborator_temp_file(
            &message_readcopy_path,
            &base_uma_temp_directory_path,
        ) {
            debug_log!(
                "PDM: Failed to cleanup temp file for {} (continuing): {}",
                file_name,
                e
            );
            // Continue anyway - we already got the data we needed
        }

        // ------------------------------------------------------------
        // Add formatted message to display list
        // ------------------------------------------------------------
        debug_log!(
            "PDM: Successfully loaded message from {}: owner={}, text_len={}",
            file_name,
            owner,
            text_message.len()
        );

        message_list.push(format!("{}: {}", owner, text_message));
        loaded_count += 1;
    }

    // ============================================================
    // DISPLAY PHASE: Render message list
    // ============================================================

    debug_log!(
        "PDM: Finished processing. Loaded: {}, Skipped: {}",
        loaded_count,
        skipped_count
    );

    // Display messages using passive renderer (handles scrolldown internally)
    tiny_tui::simple_render_list_passive(&message_list, path);

    Ok(())
}



/// for passive view mode
fn get_directory_hash(path: &Path) -> io::Result<u64> {
    let mut hasher = DefaultHasher::new();

    for entry in WalkDir::new(path).max_depth(1) {
        let entry = entry?;
        if entry.path().is_file() {
            let metadata = entry.metadata()?;
            metadata.modified()?.hash(&mut hasher);
            metadata.len().hash(&mut hasher);
        }
    }

    Ok(hasher.finish())
}

/*
Q&A Functions for 6pa, 6 Project Areas
*/

/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa1_process() -> Result<String, ThisProjectError> {
    println!("Enter Process statement: Project Process: Workflow Type, STEM Integration, Values, Agenda, Methods, Coordinated Decisions, (Data/System)Ecology: Collapse & Productivity (default option: Agile, Kahneman-Tversky, Definition-Studies)
:");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Agile, Kahneman-Tversky, Definition-Studies".to_string();
    }


    Ok(input.to_string())
}

/// Gets schedule information and converts to required format for create_core_node()
///
/// This function provides two options for setting the project start time:
/// - Use current UTC time ("now")
/// - Enter a custom date
///
/// After determining the start time, it prompts for project duration and calculates
/// the end timestamp.
///
/// The function will re-prompt for any invalid inputs rather than failing immediately,
/// providing a better user experience.
///
/// # Returns
/// * `Ok(Vec<u64>)` - Vector containing [start_timestamp, end_timestamp, duration_seconds]
/// * `Err(ThisProjectError)` - If input/output operations fail
///
/// # Example Flow
/// ```text
/// Would you like to use current UTC time as your project's start time? (y/n): y
/// Current UTC time selected: 2024-01-15 14:30:45
///
/// Project Schedule: Enter project duration in days: 14
///
/// Project Schedule Summary:
///   Start: 2024-01-15 14:30:45 UTC
///   End: 2024-01-29 14:30:45 UTC
///   Duration: 14 days (1209600 seconds)
/// ```
fn q_and_a_get_pa2_schedule() -> Result<Vec<u64>, ThisProjectError> {
    debug_log("starting q_and_a_get_pa2_schedule()");

    // Get current year for validation once at the start
    let current_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| {
            ThisProjectError::InvalidData(format!("System time error: {}", e))
        })?
        .as_secs() as i64;
    let (current_year, _, _, _, _, _) = timestamp_to_utc_components(current_timestamp);

    // Ask if user wants to use current time as start with retry loop
    let use_now = loop {
        println!("\n'Now'? -> Use current UTC time as project's start time? (y)es / (n)o");
        print!("> ");

        // Ensure prompt is displayed before reading input
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut use_now_input = String::new();
        io::stdin().read_line(&mut use_now_input).map_err(|e| ThisProjectError::IoError(e))?;

        match use_now_input.trim().to_lowercase().as_str() {
            "y" | "yes" | "now" => break true,
            "n" | "no" => break false,
            "" => {
                // Treat empty input as "no" for convenience
                println!("  (Treating empty input as 'no')");
                break false;
            },
            _ => {
                // Invalid input - inform user and loop to retry
                println!("  Invalid input '{}'. Please enter 'y' for yes or 'n' for no.",
                    use_now_input.trim());
                continue;
            }
        }
    };

    // Get start timestamp based on user choice
    let start_timestamp: u64 = if use_now {
        // Use current UTC time
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map_err(|e| {
                ThisProjectError::InvalidData(format!("System time error: {}", e))
            })?;

        let timestamp = now.as_secs();

        // Display the current time for confirmation
        let (year, month, day, hour, minute, second) = timestamp_to_utc_components(timestamp as i64);
        println!("\nCurrent UTC time selected: {:04}-{:02}-{:02} {:02}:{:02}:{:02}",
            year, month, day, hour, minute, second);

        debug_log!("Using current UTC timestamp: {}", timestamp);
        timestamp
    } else {
        // Get custom start date from user
        println!("\nEnter project start date:");

        // Year input with retry loop
        let year: i32 = loop {
            println!("Enter start year (YYYY, {} to 2100):", current_year);
            print!("> ");
            io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

            let mut year_input = String::new();
            io::stdin().read_line(&mut year_input).map_err(|e| ThisProjectError::IoError(e))?;

            // Handle empty input
            if year_input.trim().is_empty() {
                println!("  Year cannot be empty. Please enter a valid year.");
                continue;
            }

            // Try to parse the year
            match year_input.trim().parse::<i32>() {
                Ok(parsed_year) => {
                    // Validate year range
                    if parsed_year < current_year || parsed_year > 2100 {
                        println!("  Year must be between {} and 2100. You entered: {}",
                            current_year, parsed_year);
                        continue;
                    }
                    debug_log!("Parsed year: {}", parsed_year);
                    break parsed_year;
                },
                Err(_) => {
                    println!("  Invalid year format '{}'. Please enter a 4-digit year.",
                        year_input.trim());
                    continue;
                }
            }
        };

        // Month input with retry loop
        let month: u32 = loop {
            println!("Enter start month (1-12):");
            print!("> ");
            io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

            let mut month_input = String::new();
            io::stdin().read_line(&mut month_input).map_err(|e| ThisProjectError::IoError(e))?;

            // Handle empty input
            if month_input.trim().is_empty() {
                println!("  Month cannot be empty. Please enter a value between 1 and 12.");
                continue;
            }

            // Try to parse the month
            match month_input.trim().parse::<u32>() {
                Ok(parsed_month) => {
                    // Validate month range
                    if parsed_month < 1 || parsed_month > 12 {
                        println!("  Month must be between 1 and 12. You entered: {}", parsed_month);
                        continue;
                    }
                    debug_log!("Parsed month: {}", parsed_month);
                    break parsed_month;
                },
                Err(_) => {
                    println!("  Invalid month format '{}'. Please enter a number between 1 and 12.",
                        month_input.trim());
                    continue;
                }
            }
        };

        // Day input with retry loop
        let max_day = get_days_in_month(year, month);
        let day: u32 = loop {
            println!("Enter start day (1-{}):", max_day);
            print!("> ");
            io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

            let mut day_input = String::new();
            io::stdin().read_line(&mut day_input).map_err(|e| ThisProjectError::IoError(e))?;

            // Handle empty input
            if day_input.trim().is_empty() {
                println!("  Day cannot be empty. Please enter a value between 1 and {}.", max_day);
                continue;
            }

            // Try to parse the day
            match day_input.trim().parse::<u32>() {
                Ok(parsed_day) => {
                    // Validate day range
                    if parsed_day < 1 || parsed_day > max_day {
                        println!("  Day must be between 1 and {} for {}/{}. You entered: {}",
                            max_day, year, month, parsed_day);
                        continue;
                    }
                    debug_log!("Parsed day: {}", parsed_day);
                    break parsed_day;
                },
                Err(_) => {
                    println!("  Invalid day format '{}'. Please enter a number between 1 and {}.",
                        day_input.trim(), max_day);
                    continue;
                }
            }
        };

        // Optional time input with retry loop
        let (hour, minute) = loop {
            println!("\nYou've entered the date: {}-{:02}-{:02}", year, month, day);
            println!("Would you like to specify a specific time of day?");
            println!("  - Enter 'y' to set hour and minute");
            println!("  - Enter 'n' or press Enter to use midnight (00:00:00)");
            print!("> ");
            io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

            let mut time_choice = String::new();
            io::stdin().read_line(&mut time_choice).map_err(|e| ThisProjectError::IoError(e))?;

            match time_choice.trim().to_lowercase().as_str() {
                "y" | "yes" => {
                    println!("\nSetting time of day for {}-{:02}-{:02}:", year, month, day);

                    // Get hour with retry loop
                    let hour: u32 = loop {
                        println!("Enter hour (0-23, 24-hour format):");
                        println!("  Examples: 0 = midnight, 12 = noon, 23 = 11 PM");
                        print!("> ");
                        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

                        let mut hour_input = String::new();
                        io::stdin().read_line(&mut hour_input).map_err(|e| ThisProjectError::IoError(e))?;

                        // Handle empty input
                        if hour_input.trim().is_empty() {
                            println!("  Hour cannot be empty. Please enter a value between 0 and 23.");
                            continue;
                        }

                        // Try to parse the hour
                        match hour_input.trim().parse::<u32>() {
                            Ok(parsed_hour) => {
                                if parsed_hour > 23 {
                                    println!("  Hour must be between 0 and 23. You entered: {}", parsed_hour);
                                    continue;
                                }
                                break parsed_hour;
                            },
                            Err(_) => {
                                println!("  Invalid hour format '{}'. Please enter a number between 0 and 23.",
                                    hour_input.trim());
                                continue;
                            }
                        }
                    };

                    // Get minute with retry loop
                    let minute: u32 = loop {
                        println!("Enter minute (0-59):");
                        print!("> ");
                        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

                        let mut minute_input = String::new();
                        io::stdin().read_line(&mut minute_input).map_err(|e| ThisProjectError::IoError(e))?;

                        // Handle empty input
                        if minute_input.trim().is_empty() {
                            println!("  Minute cannot be empty. Please enter a value between 0 and 59.");
                            continue;
                        }

                        // Try to parse the minute
                        match minute_input.trim().parse::<u32>() {
                            Ok(parsed_minute) => {
                                if parsed_minute > 59 {
                                    println!("  Minute must be between 0 and 59. You entered: {}", parsed_minute);
                                    continue;
                                }
                                break parsed_minute;
                            },
                            Err(_) => {
                                println!("  Invalid minute format '{}'. Please enter a number between 0 and 59.",
                                    minute_input.trim());
                                continue;
                            }
                        }
                    };

                    println!("  Time set to {:02}:{:02} (24-hour format)", hour, minute);
                    break (hour, minute);
                },
                "n" | "no" | "" => {
                    // Use default midnight time
                    println!("  Using default time: 00:00 (midnight)");
                    break (0, 0);
                },
                _ => {
                    println!("  Invalid choice '{}'. Please enter 'y' for yes or 'n' for no.",
                        time_choice.trim());
                    continue;
                }
            }
        };

        // Use the accurate timestamp conversion function
        let timestamp = utc_components_to_timestamp(year, month, day, hour, minute, 0)?;

        // Confirm the selected start time with full clarity
        println!("\nProject start date and time confirmed:");
        println!("  Date: {:04}-{:02}-{:02} (YYYY-MM-DD)", year, month, day);
        println!("  Time: {:02}:{:02}:00 UTC (HH:MM:SS)", hour, minute);
        println!("  Full: {:04}-{:02}-{:02} {:02}:{:02}:00 UTC", year, month, day, hour, minute);

        // Confirm the selected start time
        println!("\nProject start time: {:04}-{:02}-{:02} {:02}:{:02}:00 UTC",
            year, month, day, hour, minute);

        debug_log!("Calculated start timestamp: {}", timestamp);
        timestamp as u64
    };

    // Duration input with retry loop
    let days: u64 = loop {
        println!("\nProject Schedule: Enter project duration in days (1-3650):");
        print!("> ");
        io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

        let mut days_input = String::new();
        io::stdin().read_line(&mut days_input).map_err(|e| ThisProjectError::IoError(e))?;

        // Handle empty input
        if days_input.trim().is_empty() {
            println!("  Duration cannot be empty. Please enter a number between 1 and 3650.");
            continue;
        }

        // Try to parse the days
        match days_input.trim().parse::<u64>() {
            Ok(parsed_days) => {
                // Validate days range
                if parsed_days == 0 || parsed_days > 3650 {
                    println!("  Duration must be between 1 and 3650 days. You entered: {}", parsed_days);
                    continue;
                }
                debug_log!("Parsed days: {}", parsed_days);
                break parsed_days;
            },
            Err(_) => {
                println!("  Invalid duration format '{}'. Please enter a number between 1 and 3650.",
                    days_input.trim());
                continue;
            }
        }
    };

    // Calculate end timestamp and duration
    let seconds_per_day: u64 = 24 * 60 * 60;
    let duration_seconds = days * seconds_per_day;
    debug_log!("Calculated duration in seconds: {}", duration_seconds);

    let end_timestamp = start_timestamp + duration_seconds;
    debug_log!("Calculated end timestamp: {}", end_timestamp);

    // Display summary
    let (start_year, start_month, start_day, start_hour, start_minute, start_second) =
        timestamp_to_utc_components(start_timestamp as i64);
    let (end_year, end_month, end_day, end_hour, end_minute, end_second) =
        timestamp_to_utc_components(end_timestamp as i64);

    println!("\nProject Schedule Summary:");
    println!("  Start: {:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC",
        start_year, start_month, start_day, start_hour, start_minute, start_second);
    println!("  End:   {:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC",
        end_year, end_month, end_day, end_hour, end_minute, end_second);
    println!("  Duration: {} days ({} seconds)", days, duration_seconds);

    // Final validation (should never fail with proper input validation)
    if end_timestamp < start_timestamp {
        return Err(ThisProjectError::InvalidInput("End time cannot be before start time".into()));
    }

    let result = vec![
        start_timestamp,
        end_timestamp,
        duration_seconds
    ];
    debug_log!("Returning schedule info: {:?}", result);

    Ok(result)
}


/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa3_users() -> Result<String, ThisProjectError> {
    println!("Enter User Statement, Users: Stakeholders & Needs & Goals Evaluation (of users): Who are users? What are their needs?");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Pending: Users & Stakeholder Needs & Goals Evaluation".to_string();
    }

    Ok(input.to_string())
}

/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa4_features() -> Result<String, ThisProjectError> {
    println!("Enter Feature Statement: Features: User-Features & Subfeatures/Under-The-Hood Features -> From a user-story standpoint, what is this project making? Under-the-hood, what is this projet making?");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Pending: User-Features & Subfeatures/Under-The-Hood Features".to_string();
    }

    Ok(input.to_string())
}

/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa5_mvp() -> Result<String, ThisProjectError> {
    println!("Enter MVP Statement: MVP: 'MVP's (Minimum Viable Products); Tools & 'Tool Stack / Tech Stack'");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Pending: MVP & Techstack".to_string();
    }

    Ok(input.to_string())
}

/// Gets user input for agenda process selection of create_core_node()
fn q_and_a_get_pa6_feedback() -> Result<String, ThisProjectError> {
    println!("Enter Feedback Statement: Feedback: Tests, Communication, Signals, Documentation & Iteration, Organizational, System, and 'Ecological' Effects, (~agile) -> Based on what signals will you define failure and orient to measure productivity.");
    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        let input: String = "Pending: MVP & Techstack".to_string();
    }

    Ok(input.to_string())
}

/*
Message-Post Q&A functions
*/

/// Gets user input for message post integer validation ranges
///
/// # Returns
/// * `Result<Option<Vec<(i32, i32)>>, ThisProjectError>` - Vector of integer range tuples or None
fn q_and_a_get_message_post_integer_ranges() -> Result<Option<Vec<(i32, i32)>>, ThisProjectError> {

    // Section Blurb
    println!("\n\nMessage-Posts: optional modular customization of the Message-Post section of this node.");
    println!("for example, using this message post for: elections/votes/poles, surveys, questionnaires, data-collection for analysis, etc.\n");

    // Question for User
    println!("Integer-Choices, if applicable:");
    println!("For preset answers/choices for Message-Posts, such as poles or questionnaires with options taking the \"multile-choice\" form: 1. breakfast  2. second-breakfast 3. supper");
    println!("where the user enters only the integer (commonly a letter for \"multile-choice\")");
    println!("to indicate that they are selecting the option that corresponds to that integer (commonly a letter):");
    println!("Enter the range (or ranges) of how many integer-only options the user can select from.");
    println!("I.e. enter a list of integer ranges that the user will be able select from, using integers, dashes, and commas: Format: min1-max1,min2-max2,");
    println!("Example -> 1-10,20-30,50-100   E.g. for 1. breakfast  2. second-breakfast 3. supper, the format would be -> 1-3");
    println!("Write-in options are dealt with below, this for one or more ranges of values where the user only enters the integer of their selection.");
    println!("...or press Enter to skip if this format does not apply to your project-node.");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        return Ok(None);
    }

    // Parse the ranges
    let mut ranges = Vec::new();
    for range_str in input.split(',') {
        let parts: Vec<&str> = range_str.trim().split('-').collect();
        if parts.len() != 2 {
            return Err(ThisProjectError::InvalidInput(format!("Invalid range format: {}", range_str)));
        }

        let min = parts[0].parse::<i32>()
            .map_err(|_| ThisProjectError::InvalidInput(format!("Invalid minimum value: {}", parts[0])))?;
        let max = parts[1].parse::<i32>()
            .map_err(|_| ThisProjectError::InvalidInput(format!("Invalid maximum value: {}", parts[1])))?;

        if min > max {
            return Err(ThisProjectError::InvalidInput(format!("Minimum {} is greater than maximum {}", min, max)));
        }

        ranges.push((min, max));
    }

    Ok(Some(ranges))
}

/// Gets user input for message post integer-string validation ranges
///
/// Prompts the user to enter integer ranges for integer-string pair options.
/// These are used for write-in choices where users provide both an integer
/// selection and a string value (e.g., "3:lilac" for a color choice).
///
/// # Input Format
/// - Single integers: "5" (interpreted as range 5-5)
/// - Ranges: "5-10" (range from 5 to 10)
/// - Multiple values: "2,5-10,12" (single value 2, range 5-10, single value 12)
/// - Empty input skips this configuration
///
/// # Returns
/// * `Result<Option<Vec<(i32, i32)>>, ThisProjectError>` - Vector of integer range tuples for int-string pairs or None
///
/// # Errors
/// * `ThisProjectError::InvalidInput` - If the input format is invalid
/// * `ThisProjectError::IoError` - If there's an I/O error reading input
fn q_and_a_get_message_post_int_string_ranges() -> Result<Option<Vec<(i32, i32)>>, ThisProjectError> {

    println!("Integer:Write-In choices, if applicable:");
    println!("For write-in answers/choices for Message-Posts, such as the third part of this form: 1. mustard-yellow  2. pink 3. write in your choice of colour");
    println!("Or the third AND fourth parts of this form: 1. blue  2. yellow  3. write in: your choice of colour  4. write in: exceptional reason to avoid colour");
    println!("Here the user enters BOTH an integer AND (after a colon) their write-in character-string -> integer:string -> 3:lilac");
    println!("As with integer-only above, these can be single, continuous ranges, or (lists) discontinuous options (ranges or singles)");
    println!("If applicable, enter integer ranges for integer-string pair options (format: min-max,min-max,... or single values like 5 or press Enter to skip):");
    println!("Example: 2,5-10,12");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        return Ok(None);
    }

    // Parse the ranges with support for single integers
    let mut ranges = Vec::new();

    // Split by comma to handle multiple entries
    for range_str in input.split(',') {
        let trimmed = range_str.trim();

        // Check if it contains a dash (range) or is a single value
        if trimmed.contains('-') {
            // Handle range format (e.g., "5-10")
            let parts: Vec<&str> = trimmed.split('-').collect();

            // Validate that we have exactly 2 parts
            if parts.len() != 2 {
                return Err(ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Invalid range format: '{}'. Expected format: 'min-max'", trimmed)
                ));
            }

            // Parse minimum value
            let min = parts[0].parse::<i32>()
                .map_err(|_| ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Invalid minimum value: '{}'", parts[0])
                ))?;

            // Parse maximum value
            let max = parts[1].parse::<i32>()
                .map_err(|_| ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Invalid maximum value: '{}'", parts[1])
                ))?;

            // Validate that min <= max
            if min > max {
                return Err(ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Minimum {} is greater than maximum {}", min, max)
                ));
            }

            ranges.push((min, max));
        } else {
            // Handle single integer (e.g., "5" becomes "5-5")
            let single_value = trimmed.parse::<i32>()
                .map_err(|_| ThisProjectError::InvalidInput(
                    format!("q_and_a_get_message_post_int_string_ranges error Invalid integer value: '{}'", trimmed)
                ))?;

            // Add as a range where min equals max
            ranges.push((single_value, single_value));
        }
    }

    Ok(Some(ranges))
}

/// Gets user input for maximum string length in integer-string pairs
///
/// # Returns
/// * `Result<Option<usize>, ThisProjectError>` - Maximum string length or None
fn q_and_a_get_message_messageposts_expire_after_n_min() -> Result<u64, ThisProjectError> {
    println!("Enter default-lifetime of post in minutes (or press Enter for 9999999):");
    println!("Example: 42 (Massages respire after 42 minutes.");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        return Ok(99999);
    }

    let max_length = input.parse::<u64>()
        .map_err(|_| ThisProjectError::InvalidInput(format!("Invalid maximum string length: {}", input)))?;

    Ok(max_length)
}


/// Gets user input for maximum string length in integer-string pairs
///
/// # Returns
/// * `Result<Option<usize>, ThisProjectError>` - Maximum string length or None
fn q_and_a_get_message_post_max_string_length() -> Result<Option<usize>, ThisProjectError> {
    println!("Enter maximum string length (max number of write-in characters) for integer-string pairs (or press Enter to skip):");
    println!("Example: 42");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim();
    if input.is_empty() {
        return Ok(None);
    }

    let max_length = input.parse::<usize>()
        .map_err(|_| ThisProjectError::InvalidInput(format!("Invalid maximum string length: {}", input)))?;

    Ok(Some(max_length))
}


/// Gets user input for whether message posts should be public
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether posts are public or None
fn q_and_a_get_message_post_is_public() -> Result<Option<bool>, ThisProjectError> {
    println!("Should message posts be public? -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(None);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(Some(true)),
        "no" | "n" | "false" | "0" => Ok(Some(false)),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}

/// Gets user input for whether user confirmation is required before posting
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether user confirmation is required or None
fn q_and_a_get_message_post_user_confirms() -> Result<Option<bool>, ThisProjectError> {
    println!("Require user confirmation before posting messages?  -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(None);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(Some(true)),
        "no" | "n" | "false" | "0" => Ok(Some(false)),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}


/// Gets user input for whether user confirmation is required before posting
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether user confirmation is required or None
fn q_and_a_get_message_post_gpgtoml_required() -> Result<Option<bool>, ThisProjectError> {
    println!("Require all message post are gpgtoml encrypted?  -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(None);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(Some(true)),
        "no" | "n" | "false" | "0" => Ok(Some(false)),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}


/// Gets user input for whether user confirmation is required before posting
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether user confirmation is required or None
fn q_and_a_get_corenode_gpgtoml() -> Result<bool, ThisProjectError> {
    println!("This Node is gpgtoml encrypted?  -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(false);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(true),
        "no" | "n" | "false" | "0" => Ok(false),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}

/// Gets user input for message post start date with component-based input
///
/// This function provides multiple input options:
/// - "now" - Uses current UTC time
/// - Component-based input - Guides user through entering year, month, day, hour, minute
/// - Skip option - Returns None if user doesn't want to set a start date
///
/// The function validates each component and converts the final date/time to a UTC POSIX timestamp.
///
/// # Returns
/// * `Ok(Some(i64))` - Start date as UTC POSIX timestamp if user provided valid input
/// * `Ok(None)` - If user chose to skip
/// * `Err(ThisProjectError)` - If input/output operations fail or validation fails
///
/// # Example Flow
/// ```text
/// Enter start date for accepting posts:
/// - Type "now" for current UTC time
/// - Type "custom" to enter a specific date
/// - Press Enter to skip
/// > now
/// Start date set to current UTC time: 2024-01-15 14:30:45
/// Timestamp: 1705329045
/// ```
fn q_and_a_get_message_post_start_date() -> Result<Option<i64>, ThisProjectError> {
    // Log function entry
    debug_log("Starting q_and_a_get_message_post_start_date()");

    // Display options to user
    println!("Enter start date for accepting posts:");
    println!("  - Type \"now\" for current UTC time");
    println!("  - Type \"custom\" to enter a specific date");
    println!("  - Press Enter to skip");
    print!("> ");

    // Ensure prompt is displayed before reading input
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    // Read user choice
    let mut choice = String::new();
    io::stdin().read_line(&mut choice).map_err(|e| ThisProjectError::IoError(e))?;

    let choice = choice.trim().to_lowercase();

    // Handle user choice
    match choice.as_str() {
        "" => {
            // User pressed Enter - skip setting start date
            debug_log("User chose to skip start date");
            Ok(None)
        },
        "now" => {
            // Use current UTC time
            handle_now_option()
        },
        "custom" => {
            // Guide through component-based input
            handle_custom_date_input()
        },
        _ => {
            // Invalid option
            Err(ThisProjectError::InvalidInput(
                format!("Invalid option '{}'. Please choose 'now', 'custom', or press Enter to skip.", choice)
            ))
        }
    }
}


/// Gets user input for whether user confirmation is required before posting
///
/// # Returns
/// * `Result<Option<bool>, ThisProjectError>` - Whether user confirmation is required or None
fn q_and_a_get_use_padnet() -> Result<Option<bool>, ThisProjectError> {
    println!("Team Channel uses One-Time-Pad Network-Layer?  (requires make/share 'pad') -> (y)es / (n)o / Press-Enter to skip):");

    let mut input = String::new();
    io::stdout().flush()?;
    io::stdin().read_line(&mut input)?;

    let input = input.trim().to_lowercase();
    if input.is_empty() {
        return Ok(None);
    }

    match input.as_str() {
        "yes" | "y" | "true" | "1" => Ok(Some(true)),
        "no" | "n" | "false" | "0" => Ok(Some(false)),
        _ => Err(ThisProjectError::InvalidInput(format!("Invalid boolean value: {}. Use yes/no", input)))
    }
}


/// Handles the "now" option by getting current UTC time
///
/// # Returns
/// * `Ok(Some(i64))` - Current UTC timestamp
/// * `Err(ThisProjectError)` - If system time retrieval fails
fn handle_now_option() -> Result<Option<i64>, ThisProjectError> {
    debug_log("User selected 'now' option");

    // Get current system time
    let now = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| {
            ThisProjectError::InvalidData(format!("System time error: {}", e))
        })?;

    let timestamp = now.as_secs() as i64;

    // Calculate and display human-readable UTC time
    let (year, month, day, hour, minute, second) = timestamp_to_utc_components(timestamp);

    println!("\nStart date set to current UTC time:");
    println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:{:02}",
        year, month, day, hour, minute, second);
    println!("  Timestamp: {}", timestamp);

    debug_log!("Current UTC timestamp: {}", timestamp);

    Ok(Some(timestamp))
}

/// Handles custom date input by guiding user through component entry
///
/// # Returns
/// * `Ok(Some(i64))` - Custom date as UTC timestamp
/// * `Err(ThisProjectError)` - If input validation fails
fn handle_custom_date_input() -> Result<Option<i64>, ThisProjectError> {
    debug_log("User selected custom date input");

    // Get current year for validation
    let current_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| {
            ThisProjectError::InvalidData(format!("System time error: {}", e))
        })?
        .as_secs() as i64;

    let (current_year, _, _, _, _, _) = timestamp_to_utc_components(current_timestamp);

    // Year input and validation
    println!("\nEnter start year (YYYY, e.g., {})", current_year);
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut year_input = String::new();
    io::stdin().read_line(&mut year_input).map_err(|e| ThisProjectError::IoError(e))?;

    let year: i32 = year_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid year: '{}'", year_input.trim()))
    })?;

    // Validate year range (current year - 10 to current year + 10)
    if year < current_year - 10 || year > current_year + 10 {
        return Err(ThisProjectError::InvalidInput(
            format!("Year must be between {} and {}", current_year - 10, current_year + 10)
        ));
    }
    debug_log!("Parsed year: {}", year);

    // Month input and validation
    println!("Enter start month (1-12):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut month_input = String::new();
    io::stdin().read_line(&mut month_input).map_err(|e| ThisProjectError::IoError(e))?;

    let month: u32 = month_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid month: '{}'", month_input.trim()))
    })?;

    if month < 1 || month > 12 {
        return Err(ThisProjectError::InvalidInput("Month must be between 1 and 12".into()));
    }
    debug_log!("Parsed month: {}", month);

    // Day input and validation
    let max_day = get_days_in_month(year, month);
    println!("Enter start day (1-{}):", max_day);
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut day_input = String::new();
    io::stdin().read_line(&mut day_input).map_err(|e| ThisProjectError::IoError(e))?;

    let day: u32 = day_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid day: '{}'", day_input.trim()))
    })?;

    if day < 1 || day > max_day {
        return Err(ThisProjectError::InvalidInput(
            format!("Day must be between 1 and {} for {}/{}", max_day, year, month)
        ));
    }
    debug_log!("Parsed day: {}", day);

    // Hour input and validation
    println!("Enter start hour (0-23, 24-hour format):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut hour_input = String::new();
    io::stdin().read_line(&mut hour_input).map_err(|e| ThisProjectError::IoError(e))?;

    let hour: u32 = hour_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid hour: '{}'", hour_input.trim()))
    })?;

    if hour > 23 {
        return Err(ThisProjectError::InvalidInput("Hour must be between 0 and 23".into()));
    }
    debug_log!("Parsed hour: {}", hour);

    // Minute input and validation
    println!("Enter start minute (0-59):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut minute_input = String::new();
    io::stdin().read_line(&mut minute_input).map_err(|e| ThisProjectError::IoError(e))?;

    let minute: u32 = minute_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid minute: '{}'", minute_input.trim()))
    })?;

    if minute > 59 {
        return Err(ThisProjectError::InvalidInput("Minute must be between 0 and 59".into()));
    }
    debug_log!("Parsed minute: {}", minute);

    // Note about timezone
    println!("\nNote: Time will be interpreted as UTC");

    // Calculate timestamp from components
    let timestamp = utc_components_to_timestamp(year, month, day, hour, minute, 0)?;

    // Display confirmation
    println!("\nStart date set to:");
    println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:00",
        year, month, day, hour, minute);
    println!("  Timestamp: {}", timestamp);

    debug_log!("Successfully created start date timestamp: {}", timestamp);

    Ok(Some(timestamp))
}

/// Determines the number of days in a given month, accounting for leap years
///
/// # Arguments
/// * `year` - The year (used for leap year calculation)
/// * `month` - The month (1-12)
///
/// # Returns
/// * `u32` - Number of days in the month
fn get_days_in_month(year: i32, month: u32) -> u32 {
    match month {
        1 | 3 | 5 | 7 | 8 | 10 | 12 => 31,
        4 | 6 | 9 | 11 => 30,
        2 => {
            // Check for leap year
            if is_leap_year(year) {
                29
            } else {
                28
            }
        },
        _ => unreachable!("Month already validated to be 1-12"),
    }
}

/// Checks if a given year is a leap year
///
/// # Arguments
/// * `year` - The year to check
///
/// # Returns
/// * `bool` - true if leap year, false otherwise
fn is_leap_year(year: i32) -> bool {
    (year % 4 == 0 && year % 100 != 0) || (year % 400 == 0)
}

/// Converts UTC date/time components to a Unix timestamp
///
/// # Arguments
/// * `year` - Year (e.g., 2024)
/// * `month` - Month (1-12)
/// * `day` - Day of month (1-31)
/// * `hour` - Hour (0-23)
/// * `minute` - Minute (0-59)
/// * `second` - Second (0-59)
///
/// # Returns
/// * `Ok(i64)` - Unix timestamp (seconds since 1970-01-01 00:00:00 UTC)
/// * `Err(ThisProjectError)` - If date is invalid
fn utc_components_to_timestamp(
    year: i32,
    month: u32,
    day: u32,
    hour: u32,
    minute: u32,
    second: u32
) -> Result<i64, ThisProjectError> {
    // Validate inputs
    if year < 1970 {
        return Err(ThisProjectError::InvalidInput("Year must be 1970 or later".into()));
    }

    // Calculate days since epoch (1970-01-01)
    let mut days: i64 = 0;

    // Add days for complete years
    for y in 1970..year {
        days += if is_leap_year(y) { 366 } else { 365 };
    }

    // Add days for complete months in current year
    for m in 1..month {
        days += get_days_in_month(year, m) as i64;
    }

    // Add remaining days
    days += (day - 1) as i64;

    // Convert to seconds and add time components
    let seconds_per_day: i64 = 24 * 60 * 60;
    let seconds_per_hour: i64 = 60 * 60;
    let seconds_per_minute: i64 = 60;

    let timestamp = days * seconds_per_day
        + (hour as i64) * seconds_per_hour
        + (minute as i64) * seconds_per_minute
        + (second as i64);

    debug_log!("Converted date components to timestamp: {}", timestamp);

    Ok(timestamp)
}

/// Converts a Unix timestamp to UTC date/time components
///
/// This function performs the reverse operation of utc_components_to_timestamp,
/// breaking down a timestamp into human-readable date and time components.
///
/// # Arguments
/// * `timestamp` - Unix timestamp (seconds since 1970-01-01 00:00:00 UTC)
///
/// # Returns
/// * `(year, month, day, hour, minute, second)` - Tuple of date/time components
fn timestamp_to_utc_components(timestamp: i64) -> (i32, u32, u32, u32, u32, u32) {
    // Constants for time calculations
    let seconds_per_day: i64 = 24 * 60 * 60;
    let seconds_per_hour: i64 = 60 * 60;
    let seconds_per_minute: i64 = 60;

    // Calculate total days since epoch
    let total_days = timestamp / seconds_per_day;
    let remaining_seconds = timestamp % seconds_per_day;

    // Calculate time components from remaining seconds
    let hour = (remaining_seconds / seconds_per_hour) as u32;
    let minute = ((remaining_seconds % seconds_per_hour) / seconds_per_minute) as u32;
    let second = (remaining_seconds % seconds_per_minute) as u32;

    // Calculate year by iterating from 1970
    let mut year = 1970;
    let mut days_counted: i64 = 0;

    loop {
        let days_in_year = if is_leap_year(year) { 366 } else { 365 };
        if days_counted + days_in_year > total_days {
            break;
        }
        days_counted += days_in_year;
        year += 1;
    }

    // Calculate remaining days in the current year
    let mut days_in_year = (total_days - days_counted) as u32;

    // Calculate month and day
    let mut month = 1;
    loop {
        let days_in_month = get_days_in_month(year, month);
        if days_in_year < days_in_month {
            break;
        }
        days_in_year -= days_in_month;
        month += 1;
        if month > 12 {
            // This shouldn't happen with valid timestamps, but handle it gracefully
            month = 12;
            days_in_year = get_days_in_month(year, 12) - 1;
            break;
        }
    }

    // Day is 1-based (days_in_year is 0-based)
    let day = days_in_year + 1;

    (year, month, day, hour, minute, second)
}

/// Gets user input for message post end date with multiple input methods
///
/// This function provides options for entering an end date:
/// - Duration-based input - Specify duration from start date (requires start date)
/// - Component-based input - Enter specific date/time components
/// - Skip option - Returns None if user doesn't want to set an end date
///
/// The function validates all inputs and ensures the end date is after the start date.
///
/// # Arguments
/// * `start_date_timestamp` - Optional start date timestamp for validation and duration calculation
///
/// # Returns
/// * `Ok(Some(i64))` - End date as UTC POSIX timestamp if user provided valid input
/// * `Ok(None)` - If user chose to skip
/// * `Err(ThisProjectError)` - If input/output operations fail or validation fails
///
/// # Example Flow
/// ```text
/// Enter end date for accepting posts:
/// - Type "duration" to specify duration from start date
/// - Type "custom" to enter a specific date
/// - Press Enter to skip
/// > duration
/// Enter duration from start date:
/// Years (press Enter for 0):
/// Months (press Enter for 0):
/// Weeks (press Enter for 0): 2
/// Days (press Enter for 0):
/// Hours (press Enter for 0):
/// Minutes (press Enter for 0):
///
/// End date set to: 2024-01-29 14:30:00 UTC (2 weeks from start)
/// ```
fn q_and_a_get_message_post_end_date(start_date_timestamp: Option<i64>) -> Result<Option<i64>, ThisProjectError> {
    // Log function entry
    debug_log("Starting q_and_a_get_message_post_end_date()");

    // Display options to user
    println!("\nEnter end date for accepting posts:");

    // Only show duration option if start date exists
    if start_date_timestamp.is_some() {
        println!("  - Type \"duration\" to specify duration from start date");
    }

    println!("  - Type \"custom\" to enter a specific date");
    println!("  - Press Enter to skip");

    // If start date exists, show it for reference
    if let Some(start_ts) = start_date_timestamp {
        let (year, month, day, hour, minute, second) = timestamp_to_utc_components(start_ts);
        println!("\n  Note: Start date is {:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC",
            year, month, day, hour, minute, second);
    }

    print!("> ");

    // Ensure prompt is displayed before reading input
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    // Read user choice
    let mut choice = String::new();
    io::stdin().read_line(&mut choice).map_err(|e| ThisProjectError::IoError(e))?;

    let choice = choice.trim().to_lowercase();

    // Handle user choice
    match choice.as_str() {
        "" => {
            // User pressed Enter - skip setting end date
            debug_log("User chose to skip end date");
            Ok(None)
        },
        "duration" => {
            // Check if start date exists
            match start_date_timestamp {
                Some(start_ts) => handle_duration_based_end_date(start_ts),
                None => Err(ThisProjectError::InvalidInput(
                    "Cannot specify duration without a start date. Please use 'custom' option instead.".into()
                ))
            }
        },
        "custom" => {
            // Guide through component-based input
            handle_custom_end_date_input(start_date_timestamp)
        },
        _ => {
            // Invalid option
            let mut error_msg = format!("Invalid option '{}'. Please choose ", choice);
            if start_date_timestamp.is_some() {
                error_msg.push_str("'duration', 'custom', or press Enter to skip.");
            } else {
                error_msg.push_str("'custom' or press Enter to skip.");
            }
            Err(ThisProjectError::InvalidInput(error_msg))
        }
    }
}

/// Handles duration-based end date calculation
///
/// Guides user through entering duration components and calculates end date
/// from the provided start date.
///
/// # Arguments
/// * `start_timestamp` - Start date timestamp to calculate from
///
/// # Returns
/// * `Ok(Some(i64))` - Calculated end date timestamp
/// * `Err(ThisProjectError)` - If input validation fails
fn handle_duration_based_end_date(start_timestamp: i64) -> Result<Option<i64>, ThisProjectError> {
    debug_log("User selected duration-based end date");

    println!("\nEnter duration from start date:");
    println!("(Press Enter to skip any unit, entering 0 has the same effect)");

    // Years input
    print!("\nYears (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut years_input = String::new();
    io::stdin().read_line(&mut years_input).map_err(|e| ThisProjectError::IoError(e))?;

    let years: u32 = if years_input.trim().is_empty() {
        0
    } else {
        years_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid years: '{}'", years_input.trim()))
        })?
    };

    if years > 100 {
        return Err(ThisProjectError::InvalidInput("Years must be 100 or less".into()));
    }

    // Months input
    print!("Months (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut months_input = String::new();
    io::stdin().read_line(&mut months_input).map_err(|e| ThisProjectError::IoError(e))?;

    let months: u32 = if months_input.trim().is_empty() {
        0
    } else {
        months_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid months: '{}'", months_input.trim()))
        })?
    };

    if months > 12 * 100 { // Reasonable upper limit
        return Err(ThisProjectError::InvalidInput("Months value is too large".into()));
    }

    // Weeks input
    print!("Weeks (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut weeks_input = String::new();
    io::stdin().read_line(&mut weeks_input).map_err(|e| ThisProjectError::IoError(e))?;

    let weeks: u32 = if weeks_input.trim().is_empty() {
        0
    } else {
        weeks_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid weeks: '{}'", weeks_input.trim()))
        })?
    };

    // Days input
    print!("Days (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut days_input = String::new();
    io::stdin().read_line(&mut days_input).map_err(|e| ThisProjectError::IoError(e))?;

    let days: u32 = if days_input.trim().is_empty() {
        0
    } else {
        days_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid days: '{}'", days_input.trim()))
        })?
    };

    // Hours input
    print!("Hours (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut hours_input = String::new();
    io::stdin().read_line(&mut hours_input).map_err(|e| ThisProjectError::IoError(e))?;

    let hours: u32 = if hours_input.trim().is_empty() {
        0
    } else {
        hours_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid hours: '{}'", hours_input.trim()))
        })?
    };

    // Minutes input
    print!("Minutes (press Enter for 0): ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut minutes_input = String::new();
    io::stdin().read_line(&mut minutes_input).map_err(|e| ThisProjectError::IoError(e))?;

    let minutes: u32 = if minutes_input.trim().is_empty() {
        0
    } else {
        minutes_input.trim().parse().map_err(|_| {
            ThisProjectError::InvalidInput(format!("Invalid minutes: '{}'", minutes_input.trim()))
        })?
    };

    // Validate that at least some duration was specified
    if years == 0 && months == 0 && weeks == 0 && days == 0 && hours == 0 && minutes == 0 {
        return Err(ThisProjectError::InvalidInput(
            "Duration must be greater than zero. At least one time unit must be specified.".into()
        ));
    }

    // Calculate end timestamp
    // Note: For months and years, we need to handle them specially due to varying lengths
    let (start_year, start_month, start_day, start_hour, start_minute, start_second) =
        timestamp_to_utc_components(start_timestamp);

    // Calculate target date components
    let mut target_year = start_year + years as i32;
    let mut target_month = start_month + months;

    // Handle month overflow
    while target_month > 12 {
        target_month -= 12;
        target_year += 1;
    }

    // For day calculation, we need to be careful about month boundaries
    let mut target_day = start_day;

    // Adjust day if it would be invalid in the target month
    let max_day_in_target_month = get_days_in_month(target_year, target_month);
    if target_day > max_day_in_target_month {
        target_day = max_day_in_target_month;
    }

    // Convert to timestamp for the year/month adjusted date
    let intermediate_timestamp = utc_components_to_timestamp(
        target_year, target_month, target_day, start_hour, start_minute, start_second
    )?;

    // Now add weeks, days, hours, and minutes as seconds
    let seconds_per_minute: i64 = 60;
    let seconds_per_hour: i64 = 60 * 60;
    let seconds_per_day: i64 = 24 * 60 * 60;
    let seconds_per_week: i64 = 7 * seconds_per_day;

    let additional_seconds =
        (weeks as i64 * seconds_per_week) +
        (days as i64 * seconds_per_day) +
        (hours as i64 * seconds_per_hour) +
        (minutes as i64 * seconds_per_minute);

    let end_timestamp = intermediate_timestamp + additional_seconds;

    // Build duration description
    let mut duration_parts = Vec::new();
    if years > 0 { duration_parts.push(format!("{} year{}", years, if years == 1 { "" } else { "s" })); }
    if months > 0 { duration_parts.push(format!("{} month{}", months, if months == 1 { "" } else { "s" })); }
    if weeks > 0 { duration_parts.push(format!("{} week{}", weeks, if weeks == 1 { "" } else { "s" })); }
    if days > 0 { duration_parts.push(format!("{} day{}", days, if days == 1 { "" } else { "s" })); }
    if hours > 0 { duration_parts.push(format!("{} hour{}", hours, if hours == 1 { "" } else { "s" })); }
    if minutes > 0 { duration_parts.push(format!("{} minute{}", minutes, if minutes == 1 { "" } else { "s" })); }

    let duration_description = duration_parts.join(", ");

    // Display the calculated end date
    let (end_year, end_month, end_day, end_hour, end_minute, end_second) =
        timestamp_to_utc_components(end_timestamp);

    println!("\nEnd date set to:");
    println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:{:02}",
        end_year, end_month, end_day, end_hour, end_minute, end_second);
    println!("  Duration: {} from start date", duration_description);
    println!("  Timestamp: {}", end_timestamp);

    debug_log!("Successfully calculated end date with duration: {}", duration_description);

    Ok(Some(end_timestamp))
}


/// Handles custom end date input by guiding user through component entry
///
/// # Arguments
/// * `start_date_timestamp` - Optional start date timestamp for validation
///
/// # Returns
/// * `Ok(Some(i64))` - Custom end date as UTC timestamp
/// * `Err(ThisProjectError)` - If input validation fails
fn handle_custom_end_date_input(start_date_timestamp: Option<i64>) -> Result<Option<i64>, ThisProjectError> {
    debug_log("User selected custom end date input");

    // Get current year for validation
    let current_timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| {
            ThisProjectError::InvalidData(format!("System time error: {}", e))
        })?
        .as_secs() as i64;

    let (current_year, _, _, _, _, _) = timestamp_to_utc_components(current_timestamp);

    // Calculate minimum year based on start date if provided
    let min_year = if let Some(start_ts) = start_date_timestamp {
        let (start_year, _, _, _, _, _) = timestamp_to_utc_components(start_ts);
        start_year
    } else {
        current_year - 10
    };

    // Year input and validation
    println!("\nEnter end year (YYYY, e.g., {})", current_year);
    if let Some(start_ts) = start_date_timestamp {
        let (start_year, _, _, _, _, _) = timestamp_to_utc_components(start_ts);
        println!("  (Must be {} or later based on start date)", start_year);
    }
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut year_input = String::new();
    io::stdin().read_line(&mut year_input).map_err(|e| ThisProjectError::IoError(e))?;

    let year: i32 = year_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid year: '{}'", year_input.trim()))
    })?;

    // Validate year range
    if year < min_year || year > current_year + 50 {
        return Err(ThisProjectError::InvalidInput(
            format!("Year must be between {} and {}", min_year, current_year + 50)
        ));
    }
    debug_log!("Parsed year: {}", year);

    // Month input and validation
    println!("Enter end month (1-12):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut month_input = String::new();
    io::stdin().read_line(&mut month_input).map_err(|e| ThisProjectError::IoError(e))?;

    let month: u32 = month_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid month: '{}'", month_input.trim()))
    })?;

    if month < 1 || month > 12 {
        return Err(ThisProjectError::InvalidInput("Month must be between 1 and 12".into()));
    }
    debug_log!("Parsed month: {}", month);

    // Day input and validation
    let max_day = get_days_in_month(year, month);
    println!("Enter end day (1-{}):", max_day);
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut day_input = String::new();
    io::stdin().read_line(&mut day_input).map_err(|e| ThisProjectError::IoError(e))?;

    let day: u32 = day_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid day: '{}'", day_input.trim()))
    })?;

    if day < 1 || day > max_day {
        return Err(ThisProjectError::InvalidInput(
            format!("Day must be between 1 and {} for {}/{}", max_day, year, month)
        ));
    }
    debug_log!("Parsed day: {}", day);

    // Hour input and validation
    println!("Enter end hour (0-23, 24-hour format):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut hour_input = String::new();
    io::stdin().read_line(&mut hour_input).map_err(|e| ThisProjectError::IoError(e))?;

    let hour: u32 = hour_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid hour: '{}'", hour_input.trim()))
    })?;

    if hour > 23 {
        return Err(ThisProjectError::InvalidInput("Hour must be between 0 and 23".into()));
    }
    debug_log!("Parsed hour: {}", hour);

    // Minute input and validation
    println!("Enter end minute (0-59):");
    print!("> ");
    io::stdout().flush().map_err(|e| ThisProjectError::IoError(e))?;

    let mut minute_input = String::new();
    io::stdin().read_line(&mut minute_input).map_err(|e| ThisProjectError::IoError(e))?;

    let minute: u32 = minute_input.trim().parse().map_err(|_| {
        ThisProjectError::InvalidInput(format!("Invalid minute: '{}'", minute_input.trim()))
    })?;

    if minute > 59 {
        return Err(ThisProjectError::InvalidInput("Minute must be between 0 and 59".into()));
    }
    debug_log!("Parsed minute: {}", minute);

    // Note about timezone
    println!("\nNote: Time will be interpreted as UTC");

    // Calculate timestamp from components
    let end_timestamp = utc_components_to_timestamp(year, month, day, hour, minute, 0)?;

    // Validate that end date is after start date
    if let Some(start_ts) = start_date_timestamp {
        if end_timestamp <= start_ts {
            let (start_year, start_month, start_day, start_hour, start_minute, start_second) =
                timestamp_to_utc_components(start_ts);

            return Err(ThisProjectError::InvalidInput(
                format!(
                    "End date must be after start date ({:04}-{:02}-{:02} {:02}:{:02}:{:02} UTC)",
                    start_year, start_month, start_day, start_hour, start_minute, start_second
                )
            ));
        }

        // Calculate and display duration
        let duration_seconds = end_timestamp - start_ts;
        let duration_days = duration_seconds / (24 * 60 * 60);
        let duration_hours = (duration_seconds % (24 * 60 * 60)) / (60 * 60);

        println!("\nDuration: {} days, {} hours", duration_days, duration_hours);
    }

    // Display confirmation
    println!("\nEnd date set to:");
    println!("  UTC: {:04}-{:02}-{:02} {:02}:{:02}:00",
        year, month, day, hour, minute);
    println!("  Timestamp: {}", end_timestamp);

    debug_log!("Successfully created end date timestamp: {}", end_timestamp);

    Ok(Some(end_timestamp))
}

/// Recursively moves all contents from the source directory to the destination directory.
/// Deletes the source directory if it is empty after moving all its contents.
/// use std::fs;
/// use std::path::Path;
///
/// e.g.
/// // Call the function to move the directory
/// if let Err(error) = move_directory_from_path_to_path("path/to/old/directory", "path/to/new/directory") {
///     eprintln!("An error occurred: {}", error);
/// }
fn move_directory_from_path_to_path<SourceDirectory: AsRef<Path>, DestinationDirectory: AsRef<Path>>(
    source_directory: SourceDirectory,
    destination_directory: DestinationDirectory,
) -> std::io::Result<()> {
    let source_path = source_directory.as_ref();
    let destination_path = destination_directory.as_ref();

    // Iterate through all entries in the source directory
    for entry_result in fs::read_dir(source_path)? {
        let entry = entry_result?;
        let file_type = entry.file_type()?;

        // If the entry is a directory, create it in the destination directory and move its contents
        if file_type.is_dir() {
            fs::create_dir_all(destination_path.join(entry.file_name()))?;
            move_directory_from_path_to_path(entry.path(), destination_path.join(entry.file_name()))?;
        }
        // If the entry is a file, move it to the destination directory
        else {
            fs::rename(entry.path(), destination_path.join(entry.file_name()))?;
        }
    }

    // Remove the source directory if it is empty
    fs::remove_dir(source_path)?;
    Ok(())
}


/// gpg get public key long from public key-id
/// use std::process::Command;
/// use std::io::{self, Write};
fn get_gpg_armored_public_key_via_key_id(key_id: &str) -> io::Result<String> {
    /*
   // Prompt the user for the key ID
    print!("Enter the GPG key ID: ");
    if let Err(e) = io::stdout().flush() {
        eprintln!("Failed to flush stdout: {}", e);
        return;
    }

    let mut key_id = String::new();
    if let Err(e) = io::stdin().read_line(&mut key_id) {
        eprintln!("Failed to read line: {}", e);
        return;
    }

    let key_id = key_id.trim(); // Remove any trailing newline or whitespace

    match get_gpg_armored_public_key_via_key_id(key_id) {
        Ok(armored_key) => {
            println!("Armored Public Key:\n{}", armored_key);
        }
        Err(e) => {
            eprintln!("Error: {}", e);
        }
    }

    */
    // Construct the GPG command to export the public key in armored format
    let output = StdCommand::new("gpg")
        .arg("--armor")
        .arg("--export")
        .arg(key_id)
        .output()?;

    // Check if the command was successful
    if output.status.success() {
        // Convert the output to a string
        let armored_key = String::from_utf8_lossy(&output.stdout).to_string();
        Ok(armored_key)
    } else {
        // If the command failed, return an error
        Err(io::Error::new(
            io::ErrorKind::Other,
            format!("Failed to export public key: {}", String::from_utf8_lossy(&output.stderr)),
        ))
    }
}


fn gpg_clearsign_file_to_sendbytes(
    file_path: &Path,
) -> Result<Vec<u8>, ThisProjectError> {
    // 1. Create a unique temporary file path in the OS temp directory.
    let mut temp_dir = std::env::temp_dir();
    let temp_file_name = format!("uma_temp_{}.toml", get_current_unix_timestamp()); // Or use a UUID for stronger uniqueness
    temp_dir.push(temp_file_name);

    // 2. Copy the original file to the temporary location.
    fs::copy(file_path, &temp_dir)?;

    // 3. Clearsign the temporary file, capturing the output.  Redirect stderr for error handling.
    let clearsign_output = StdCommand::new("gpg")
        .arg("--clearsign")
        .arg("--output")
        .arg("-") // Redirect to stdout
        .arg(&temp_dir)
        .stderr(std::process::Stdio::piped())
        .output()?;

    // Handle potential GPG errors.
    if !clearsign_output.status.success() {
        let stderr = String::from_utf8_lossy(&clearsign_output.stderr);
        return Err(ThisProjectError::GpgError(format!(
            "GPG clearsign failed: {}",
            stderr
        )));
    }
    let clearsigned_bytes = clearsign_output.stdout;

    // 4. Clean up the temporary file.
    fs::remove_file(&temp_dir)?; // TODO Handle potential error

    debug_log!(
        "(inHRCD)gpg_clearsign_file_to_sendbytes clearsigned_bytes {:?}",
        clearsigned_bytes
    );

    // 5. Return the encrypted, clearsigned bytes.
    Ok(clearsigned_bytes)
}

fn gpg_encrypt_to_bytes(data: &[u8], recipient_public_key: &str) -> Result<Vec<u8>, ThisProjectError> {
    debug_log!(
        "(inHRCD) STARTING @-|i|- gpg_encrypt_to_bytes() data {:?}",
        data
    );

    // 1. Create a temporary file for the public key.
    let mut temp_key_file = std::env::temp_dir();
    temp_key_file.push("uma_temp_key.asc");
    let mut file = File::create(&temp_key_file)?;
    file.write_all(recipient_public_key.as_bytes())?;

    debug_log!("(inHRCD) gpg_encrypt_to_bytes() temp_key_file path {:?}", temp_key_file);

    // 2. GPG encrypt, reading the recipient key from the temporary file.
    let mut gpg = StdCommand::new("gpg")
        .arg("--encrypt")
        .arg("--recipient-file")
        .arg(&temp_key_file)
        .stdin(Stdio::piped())       // Correct usage for stdin
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .spawn()?;


    // Write data to stdin.
    if let Some(mut stdin) = gpg.stdin.take() {
        stdin.write_all(data)?;
    } else {
        // Consider a better error type...
        return Err(ThisProjectError::GpgError("Failed to open GPG's stdin".into()));
    };

    let output = gpg.wait_with_output()?;

    debug_log!(
        "(inHRCD) gpg_encrypt_to_bytes() output {:?}",
        output
    );

    // 3. Clean up the temporary key file.
    remove_file(temp_key_file)?;

    if output.status.success() {
        Ok(output.stdout)
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(ThisProjectError::GpgError(format!("GPG encryption failed: {}", stderr)))
    }
}

/// Decrypts GPG-encrypted data from a byte slice using a provided GPG private key.
///
/// # Purpose
/// This function takes encrypted data as bytes and a GPG private key, and attempts to decrypt
/// the data using the GPG command-line tool. It handles the decryption process by creating
/// temporary files and using GPG in a non-interactive, batch mode.
///
/// # Security Considerations
/// - Temporary files are created and immediately deleted after use
/// - Uses batch mode to prevent interactive prompts
/// - Minimizes potential security risks associated with key handling
///
/// # Arguments
/// * `data` - A byte slice containing the encrypted data to be decrypted
/// * `your_gpg_key` - A string containing the GPG private key used for decryption
///
/// # Returns
/// * `Ok(Vec<u8>)` - The decrypted data as a vector of bytes if decryption is successful
/// * `Err(ThisProjectError)` - An error if decryption fails, with details about the failure
///
/// # Errors
/// This function can return errors in several scenarios:
/// - Invalid or incorrect GPG key
/// - Corrupted encrypted data
/// - GPG command-line tool not installed or accessible
/// - Insufficient permissions
/// - Temporary file creation or deletion failures
///
/// # Example
/// ```rust
/// let encrypted_data: &[u8] = // ... some encrypted bytes
/// let private_key: &str = // ... GPG private key
/// match gpg_decrypt_from_bytes(encrypted_data, private_key) {
///     Ok(decrypted_data) => {
///         // Use decrypted data
///         println!("Decryption successful!");
///     },
///     Err(e) => {
///         // Handle decryption error
///         eprintln!("Decryption failed: {:?}", e);
///     }
/// }
/// ```
///
/// # Notes
/// - Requires GPG to be installed on the system
/// - Temporary files are created in the system's temporary directory
/// - The function uses non-interactive GPG mode to prevent hanging on prompts
///
/// # Performance
/// - Creates temporary files for key and encrypted data
/// - Spawns a GPG subprocess for decryption
/// - Recommended for moderate-sized encrypted data
///
/// # Thread Safety
/// - Not guaranteed to be thread-safe due to temporary file creation
/// - Should be used with caution in multi-threaded contexts
fn gpg_decrypt_from_bytes(data: &[u8], your_gpg_key: &str) -> Result<Vec<u8>, ThisProjectError> {
    debug_log("gpg_decrypt_from_bytes()-1. Start! ");

    // 1. Create temporary files
    let mut temp_key_file = std::env::temp_dir();
    temp_key_file.push("uma_temp_privkey.asc");
    fs::write(&temp_key_file, your_gpg_key)?;

    let mut temp_encrypted_file = std::env::temp_dir();
    temp_encrypted_file.push("uma_temp_encrypted.gpg");
    fs::write(&temp_encrypted_file, data)?;

    // 2. Run GPG decryption
    let mut child = StdCommand::new("gpg")
        .arg("--decrypt")
        .arg("--batch")  // Non-interactive mode
        .arg("--yes")    // Assume yes to prompts
        .arg("--quiet")  // Minimal output
        .arg("--no-tty") // No terminal interaction
        .arg("-") // Read from stdin
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .spawn()?;

    // Write the encrypted data to the child process's standard input
    if let Some(stdin) = child.stdin.as_mut() {
        stdin.write_all(data)?;
        stdin.flush()?;
    }

    let output = child.wait_with_output()?;

    debug_log!("gpg_decrypt_from_bytes()-4. output {:?}", output);

    // 3. Remove temporary files (important for security)
    fs::remove_file(temp_key_file)?;
    fs::remove_file(temp_encrypted_file)?;

    // 4. Handle output and errors
    if output.status.success() {
        Ok(output.stdout)
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(ThisProjectError::GpgError(format!("GPG decryption failed: {}", stderr)))
    }
}

fn extract_clearsign_data(clearsigned_data: &[u8]) -> Result<Vec<u8>, ThisProjectError> {
    let clearsigned_string = String::from_utf8_lossy(clearsigned_data);

    // Split at the beginning of the signature
    let parts: Vec<&str> = clearsigned_string
        .split("-----BEGIN PGP SIGNATURE-----")
        .collect();

    if parts.len() < 2 {
        return Err(ThisProjectError::GpgError("Invalid clearsigned data: Missing signature".into()));
    }

    // Extract the message part (before the signature)
    let message_part = parts[0];

    // Split the message part by lines and skip the PGP header lines
    let message_lines: Vec<&str> = message_part
        .lines()
        .skip_while(|line|
            line.starts_with("-----BEGIN PGP SIGNED MESSAGE-----") ||
            line.starts_with("Hash:") ||
            line.trim().is_empty()
        )
        .collect();

    // Join the remaining lines
    let message_content = message_lines.join("\n");

    Ok(message_content.as_bytes().to_vec())
}


fn optional_padnetopt_to_gpg_bytes(
    file_path: &Path,
    recipient_public_key: &str,
    remote_collaborator_gpg_publickey_id: &String,

) -> Result<Vec<u8>, ThisProjectError> {

    /*

    */


    let file_bytes2send = wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes(
        &file_path,
        &recipient_public_key,
        // &room_sync_input.remote_collaborator_gpg_publickey_id,
    )?;

    Ok(file_bytes2send)
}


/// Prepares file contents for secure sending by clearsigning and encrypting them.
///
/// This function reads the contents of the file at the given `file_path`,
/// clearsigns the content using GPG to ensure integrity and non-repudiation,
/// and then encrypts the clearsigned content using the provided
/// `recipient_public_key` for confidentiality.
///
/// # Arguments
///
/// * `file_path`: The path to the file whose contents should be processed.
/// * `recipient_public_key`: The recipient's GPG public key used for encryption.
///
/// # Returns
///
/// * `Ok(Vec<u8>)`: A vector of bytes containing the encrypted, clearsigned file content on success.
/// * `Err(ThisProjectError)`: An error if file reading, clearsigning, or encryption fails.
fn wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes(
    file_path: &Path,
    recipient_public_key: &str
) -> Result<Vec<u8>, ThisProjectError> {

    // 1. Clearsign the file contents.
    let clearsigned_content = gpg_clearsign_file_to_sendbytes(file_path)?;

    // 2. Encrypt the clearsigned content.
    let encrypted_content = gpg_encrypt_to_bytes(&clearsigned_content, recipient_public_key)?;

    debug_log!(
        "(in HRCD) wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes  encrypted_content {:?}",
        &encrypted_content
    );

    Ok(encrypted_content)
}

/// Maximum allowed file size for OTP processing operations (in bytes).
///
/// # Project Context
/// This system processes small TOML configuration files through a secure
/// pipeline: clearsigning  GPG encryption  One-Time Pad XOR. These files
/// are typically configuration or command files, expected to be under 100KB
/// in normal operation.
///
/// # Security & Reliability Rationale
/// This limit defends against:
/// - **Accidental Processing**: User mistakenly selects large file (e.g., log file, database)
/// - **Malicious Input**: Attacker attempts memory exhaustion via oversized input
/// - **Resource Exhaustion**: Prevents excessive memory allocation for Vec<u8> buffers
/// - **OTP Pad Exhaustion**: Large files would rapidly consume one-time pad material
/// - **Disk Space Issues**: Prevents filling temp directory with huge intermediate files
///
/// # Size Selection Logic
/// - **1MB (1,048,576 bytes)** chosen as defensive upper bound
/// - Typical TOML files: 1KB - 50KB (plenty of headroom)
/// - GPG clearsigning adds ~1KB overhead (signature block)
/// - GPG encryption adds ~1-2KB overhead (headers, armor)
/// - XOR operation is 1:1 byte mapping (no size increase)
/// - Even with all overhead, 100KB input  ~105KB final size
/// - 1MB limit provides 10x safety margin for legitimate files
///
/// # Failure Mode
/// If file exceeds this limit:
/// - Operation fails early (before GPG processing)
/// - Clear error message to user
/// - No partial processing or temp file creation
/// - No OTP pad material consumed
///
/// # Example Sizes for Context
/// ```text
/// Small TOML file:        5 KB  (  5,120 bytes)
/// Medium TOML file:      50 KB  ( 51,200 bytes)
/// Large TOML file:      200 KB  (204,800 bytes)
/// This limit:         1,048 KB  (1,048,576 bytes)
/// Too large:          5,000 KB  (5,120,000 bytes)  REJECTED
/// ```
const MAX_PROCESSABLE_FILE_SIZE_BYTES: usize = 1_048_576; // 1 MB

/// Number of retry attempts when creating unique temporary files.
///
/// # Project Context
/// During OTP encryption pipeline, we create temporary files for intermediate
/// processing steps. In multi-threaded or high-frequency scenarios, filename
/// collisions are possible despite timestamp-based unique naming.
///
/// # Rationale
/// - 5 attempts balances reliability vs. fast-fail behavior
/// - Each attempt gets new nanosecond timestamp (high uniqueness)
/// - Normal case: succeeds on first attempt
/// - Collision case: succeeds within 2-3 attempts
/// - 5 attempts failing suggests systemic issue (disk full, permissions)
const TEMP_FILE_CREATION_RETRY_ATTEMPTS: u32 = 5;

/// Delay in milliseconds between temporary file creation retry attempts.
///
/// # Project Context
/// Minimal delay allows rapid retry while ensuring different timestamps.
///
/// # Rationale
/// - 1ms is sufficient for nanosecond timestamp to change
/// - Minimal impact on operation latency (max 5ms total delay)
/// - Prevents tight busy-loop if filesystem is slow to update
const TEMP_FILE_RETRY_DELAY_MS: u64 = 1;

/// Processes a file through the complete secure transmission pipeline with OTP encryption.
///
/// # Project Context
/// This is the complete "sender" operation for secure file transmission in the Uma system.
/// It transforms a plaintext TOML configuration file through multiple security layers:
/// 1. **Clearsigning** (GPG): Ensures integrity and non-repudiation (proves sender identity)
/// 2. **Encryption** (GPG): Ensures confidentiality (only recipient can decrypt)
/// 3. **OTP XOR** (Padnet): Adds information-theoretic security (unbreakable if pad is secure)
///
/// The combination provides:
/// - Authenticity: Clearsignature proves who sent it
/// - Confidentiality: Encryption prevents eavesdropping
/// - Perfect Secrecy: OTP makes cryptanalysis mathematically impossible
///
/// # Critical Security Properties
/// - **Atomic**: Complete success or complete failure (no partial processing)
/// - **Cleanup**: All temporary files deleted even on error
/// - **Size Limits**: Defends against accidental/malicious large file processing
/// - **Pad Consumption**: Only consumes OTP pad material on successful completion
///
/// # Pipeline Steps
/// ```text
/// Input: original.toml (plaintext TOML file)
///   
/// [1] GPG Clearsign  Vec<u8> (signed message)
///   
/// [2] GPG Encrypt  Vec<u8> (encrypted message)
///   
/// [3] Write to temp_file_1 (intermediate storage)
///   
/// [4] XOR with OTP Pad  temp_file_2 (OTP encrypted)
///   
/// [5] Read temp_file_2  Vec<u8> (final payload)
///   
/// [6] Cleanup temp files (security hygiene)
///   
/// Output: (Vec<u8>, PadIndex) - ready for transmission
/// ```
///
/// # Arguments
/// * `original_target_file_path` - Absolute path to plaintext TOML file to process
/// * `recipient_public_key` - Recipient's GPG public key (ASCII-armored format)
/// * `padnet_directory_path` - Absolute path to OTP padset directory
///
/// # Returns
/// * `Ok((Vec<u8>, PadIndex))` - Success:
///   - `Vec<u8>`: Final OTP-encrypted bytes (ready to transmit)
///   - `PadIndex`: Starting pad index used (recipient needs this to decrypt)
/// * `Err(ThisProjectError)` - Operation failed at any stage
///
/// # Error Handling Strategy
/// All errors result in complete rollback:
/// - Temporary files are deleted (even if error occurs)
/// - No partial output is returned
/// - OTP pad material is only consumed if entire pipeline succeeds
/// - Clear error messages with function prefix "PWPCTGTOTSB"
///
/// # Cleanup Guarantee
/// Uses `TempFileCleanupGuard` RAII pattern to ensure temp files are deleted:
/// - On success: Files deleted before return
/// - On error: Files deleted before error propagation
/// - On panic: Files deleted by Drop trait (defense-in-depth)
///
/// # Example Usage
/// ```rust,no_run
/// use std::path::Path;
///
/// let toml_file = Path::new("/home/user/config/message.toml");
/// let recipient_key = "-----BEGIN PGP PUBLIC KEY BLOCK-----\n...";
/// let padset_dir = Path::new("/home/user/.uma/padsets/alice");
///
/// match padnet_wrapper_path_to_clearsign_to_gpgencrypt_to_otp_to_send_bytes(
///     toml_file,
///     recipient_key,
///     padset_dir,
/// ) {
///     Ok((encrypted_bytes, pad_index)) => {
///         println!("Ready to send: {} bytes", encrypted_bytes.len());
///         println!("Tell recipient to start from pad index: {:?}", pad_index);
///         // ... send encrypted_bytes over network ...
///     },
///     Err(e) => {
///         eprintln!("Encryption pipeline failed: {}", e);
///         // No cleanup needed - handled automatically
///     }
/// }
/// ```
///
/// # Security Considerations
/// - Original file is read but never modified
/// - Intermediate files contain sensitive data (restrictive permissions)
/// - All temp files deleted (no sensitive data left on disk)
/// - Size limits prevent resource exhaustion attacks
/// - OTP pads are consumed destructively (cannot be reused)
///
/// # Performance Characteristics
/// For typical small TOML files (< 100KB):
/// - Clearsigning: ~50-100ms (GPG process spawn)
/// - Encryption: ~50-100ms (GPG process spawn)
/// - File I/O: ~5-10ms total
/// - XOR operation: ~1-5ms
/// - **Total**: ~100-250ms typical
///
/// # Failure Modes
/// - File too large: Fails immediately, no processing
/// - GPG clearsign fails: No temp files created
/// - GPG encrypt fails: No temp files created
/// - Temp file creation fails: Previous temp files cleaned up
/// - XOR operation fails: All temp files cleaned up, no pad consumed
/// - Read result fails: Temp files cleaned up, pad WAS consumed (unrecoverable)
///
/// # Related Functions
/// - `gpg_clearsign_file_to_sendbytes`: Step 1 (clearsigning)
/// - `gpg_encrypt_to_bytes`: Step 2 (encryption)
/// - `padnet_writer_strict_cleanup_xor_file_to_resultpath`: Step 4 (OTP)
/// - `write_bytes_to_file_atomic`: Helper for temp file writing
/// - `read_file_to_bytes`: Helper for reading OTP result
fn padnet_wrapper_path_to_clearsign_to_gpgencrypt_to_otp_to_send_bytes(
    original_target_file_path: &Path,
    recipient_public_key: &str,
    padnet_directory_path: &Path,
) -> Result<(Vec<u8>, PadIndex), ThisProjectError> {

    // =============================================================================
    // Input Validation (fail fast before any processing)
    // =============================================================================

    // Debug assertions for development
    #[cfg(all(debug_assertions, not(test)))]
    {
        debug_assert!(
            original_target_file_path.is_absolute(),
            "PWPCTGTOTSB: original_target_file_path must be absolute"
        );
        debug_assert!(
            padnet_directory_path.is_absolute(),
            "PWPCTGTOTSB: padnet_directory_path must be absolute"
        );
    }

    // Production safety checks
    if !original_target_file_path.is_absolute() {
        return Err(ThisProjectError::InvalidInput(
            "PWPCTGTOTSB: original_target_file_path must be absolute".to_string()
        ));
    }
    if !padnet_directory_path.is_absolute() {
        return Err(ThisProjectError::InvalidInput(
            "PWPCTGTOTSB: padnet_directory_path must be absolute".to_string()
        ));
    }

    // Check that original file exists and is within size limits
    // This prevents wasting GPG processing time on invalid inputs
    let original_metadata = fs::metadata(original_target_file_path)
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                e.kind(),
                format!("PWPCTGTOTSB: cannot access original file: {}", e),
            ))
        })?;

    let original_size = original_metadata.len() as usize;
    if original_size > MAX_PROCESSABLE_FILE_SIZE_BYTES {
        return Err(ThisProjectError::FileTooLarge {
            path: original_target_file_path.to_path_buf(),
            size_bytes: original_size,
            max_allowed: MAX_PROCESSABLE_FILE_SIZE_BYTES,
        });
    }

    // =============================================================================
    // Setup: Initialize cleanup guard for automatic temp file deletion
    // =============================================================================

    let mut cleanup_guard = TempFileCleanupGuard::new();

    // =============================================================================
    // Step 1: Clearsign the original file (integrity + non-repudiation)
    // =============================================================================

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Step 1 - Clearsigning file");

    let clearsigned_content = gpg_clearsign_file_to_sendbytes(original_target_file_path)
        .map_err(|e| {
            // Enhance error with context
            ThisProjectError::GpgError(format!(
                "PWPCTGTOTSB: clearsign failed: {}", e
            ))
        })?;

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Clearsigned {} bytes", clearsigned_content.len());

    // =============================================================================
    // Step 2: Encrypt the clearsigned content (confidentiality)
    // =============================================================================

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Step 2 - Encrypting clearsigned content");

    let encrypted_content = gpg_encrypt_to_bytes(&clearsigned_content, recipient_public_key)
        .map_err(|e| {
            ThisProjectError::GpgError(format!(
                "PWPCTGTOTSB: encryption failed: {}", e
            ))
        })?;

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Encrypted {} bytes", encrypted_content.len());

    // =============================================================================
    // Step 3: Create temporary file #1 for GPG-encrypted data (XOR input)
    // =============================================================================

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Step 3 - Creating temp file for encrypted data");

    let temp_gpg_encrypted_path = create_unique_temp_filepathbuf(
        &std::env::temp_dir(),
        "uma_gpg_encrypted",
        TEMP_FILE_CREATION_RETRY_ATTEMPTS,
        TEMP_FILE_RETRY_DELAY_MS,
    ).map_err(|e| {
        ThisProjectError::IoError(std::io::Error::new(
            e.kind(),
            format!("PWPCTGTOTSB: failed to create temp file #1: {}", e),
        ))
    })?;

    // Register temp file for cleanup
    cleanup_guard.add(temp_gpg_encrypted_path.clone());

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Created temp file: {:?}", temp_gpg_encrypted_path);

    // Write encrypted content to temp file
    write_bytes_to_file_atomic(&encrypted_content, &temp_gpg_encrypted_path)
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("PWPCTGTOTSB: failed to write encrypted data to temp file: {}", e),
            ))
        })?;

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Wrote {} bytes to temp file #1", encrypted_content.len());

    // =============================================================================
    // Step 4: Create temporary file #2 for XOR result (OTP output)
    // =============================================================================

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Step 4 - Creating temp file for XOR result");

    let temp_xor_result_path = create_unique_temp_filepathbuf(
        &std::env::temp_dir(),
        "uma_xor_result",
        TEMP_FILE_CREATION_RETRY_ATTEMPTS,
        TEMP_FILE_RETRY_DELAY_MS,
    ).map_err(|e| {
        ThisProjectError::IoError(std::io::Error::new(
            e.kind(),
            format!("PWPCTGTOTSB: failed to create temp file #2: {}", e),
        ))
    })?;

    // Register temp file for cleanup
    cleanup_guard.add(temp_xor_result_path.clone());

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Created temp file: {:?}", temp_xor_result_path);

    // =============================================================================
    // Step 5: XOR encrypt with OTP pad (information-theoretic security)
    // =============================================================================

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Step 5 - XOR encrypting with OTP pad");

    let pad_index = padnet_writer_strict_cleanup_xor_file_to_resultpath(
        &temp_gpg_encrypted_path,  // Input: GPG-encrypted file
        &temp_xor_result_path,      // Output: OTP-encrypted file
        padnet_directory_path,      // Padset directory
    ).map_err(|e| {
        // Convert PadnetError to ThisProjectError
        ThisProjectError::PadnetError(format!(
            "PWPCTGTOTSB: OTP encryption failed: {:?}", e
        ))
    })?;

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: OTP encryption complete, pad index: {:?}", pad_index);

    // =============================================================================
    // Step 6: Read OTP-encrypted result back into memory
    // =============================================================================

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Step 6 - Reading OTP result into memory");

    let final_otp_encrypted_bytes = read_file_to_bytes(&temp_xor_result_path)
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                std::io::ErrorKind::Other,
                format!("PWPCTGTOTSB: failed to read OTP result: {}", e),
            ))
        })?;

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Read {} final bytes", final_otp_encrypted_bytes.len());

    // =============================================================================
    // Step 7: Cleanup temporary files (security hygiene)
    // =============================================================================

    #[cfg(debug_assertions)]
    eprintln!("PWPCTGTOTSB: Step 7 - Cleaning up temporary files");

    // Explicit cleanup (Drop will handle it too, but we want logging)
    if let Err(errors) = cleanup_guard.cleanup() {
        // Log warnings but don't fail the operation
        // The encryption succeeded, cleanup failures are non-critical
        #[cfg(debug_assertions)]
        for error_msg in errors {
            eprintln!("PWPCTGTOTSB cleanup warning: {}", error_msg);
        }
    }

    // =============================================================================
    // Success: Return encrypted bytes and pad index
    // =============================================================================

    #[cfg(debug_assertions)]
    eprintln!(
        "PWPCTGTOTSB: SUCCESS - {} bytes ready for transmission",
        final_otp_encrypted_bytes.len()
    );

    Ok((final_otp_encrypted_bytes, pad_index))
}

/// RAII guard for automatic cleanup of temporary files.
///
/// # Project Context
/// During OTP encryption pipeline, we create temporary files that must be
/// deleted even if errors occur. This guard ensures cleanup happens via
/// Rust's Drop trait, preventing temp file leaks from early returns or
/// error paths.
///
/// # Security Rationale
/// Temporary files contain sensitive data (GPG encrypted content). Leaving
/// these files on disk is a security risk. This guard guarantees cleanup
/// even if:
/// - Function returns early due to error
/// - Panic occurs (though we avoid panic in production)
/// - Developer adds new error path and forgets manual cleanup
///
/// # Usage Pattern
/// ```rust,no_run
/// use std::path::Path;
///
/// fn example() -> Result<(), ThisProjectError> {
///     let mut cleanup_guard = TempFileCleanupGuard::new();
///
///     // Create temp file
///     let temp_path = create_unique_temp_filepathbuf(...)?;
///     cleanup_guard.add(temp_path.clone());
///
///     // Use temp file...
///     // If error occurs here, Drop trait ensures cleanup
///
///     // Success path: files still cleaned up automatically
///     Ok(())
/// } //  Drop trait called here, temp files deleted
/// ```
///
/// # Error Handling Philosophy
/// Cleanup failures are logged but do not cause function failure because:
/// - The primary operation may have succeeded
/// - OS will eventually clean temp directory
/// - Failing the entire operation due to cleanup failure is overly strict
/// - Cleanup errors are typically non-critical (file already deleted, etc.)
///
/// # Implementation Notes
/// - Uses Vec<PathBuf> to track multiple temp files
/// - Drop trait guarantees execution even on panic (defense-in-depth)
/// - Deletion failures are handled gracefully (no panic)
/// - Each file deletion is independent (one failure doesn't stop others)
struct TempFileCleanupGuard {
    /// Paths to temporary files that need deletion
    /// Stored as PathBuf for owned values (no lifetime issues)
    temp_file_paths: Vec<PathBuf>,
}

impl TempFileCleanupGuard {
    /// Creates a new cleanup guard with no files tracked.
    ///
    /// # Returns
    /// Empty guard ready to track temporary files
    ///
    /// # Example
    /// ```rust
    /// let mut guard = TempFileCleanupGuard::new();
    /// ```
    fn new() -> Self {
        TempFileCleanupGuard {
            temp_file_paths: Vec::new(),
        }
    }

    /// Adds a temporary file path to be cleaned up.
    ///
    /// # Arguments
    /// * `path` - Absolute path to temporary file
    ///
    /// # Project Context
    /// Call this immediately after creating each temp file to ensure
    /// it will be cleaned up even if subsequent operations fail.
    ///
    /// # Example
    /// ```rust,no_run
    /// # use std::path::PathBuf;
    /// # let mut guard = TempFileCleanupGuard::new();
    /// let temp_path = PathBuf::from("/tmp/uma_temp_12345.bin");
    /// guard.add(temp_path);
    /// ```
    fn add(&mut self, path: PathBuf) {
        self.temp_file_paths.push(path);
    }

    /// Manually trigger cleanup of all tracked files.
    ///
    /// # Project Context
    /// Normally cleanup happens automatically via Drop trait. Use this
    /// method if you need explicit control over cleanup timing or want
    /// to handle cleanup errors specially.
    ///
    /// # Error Handling
    /// Deletion failures are collected but do not stop cleanup of
    /// remaining files. Returns all errors encountered for logging.
    ///
    /// # Returns
    /// * `Ok(())` - All files deleted successfully
    /// * `Err(Vec<String>)` - One or more deletions failed (with error messages)
    ///
    /// # Example
    /// ```rust,no_run
    /// # let mut guard = TempFileCleanupGuard::new();
    /// match guard.cleanup() {
    ///     Ok(()) => println!("All temp files cleaned"),
    ///     Err(errors) => {
    ///         for err in errors {
    ///             eprintln!("Cleanup warning: {}", err);
    ///         }
    ///     }
    /// }
    /// ```
    fn cleanup(&mut self) -> Result<(), Vec<String>> {
        let mut errors = Vec::new();

        // Attempt to delete each tracked file
        for path in &self.temp_file_paths {
            // Try to delete the file
            if let Err(e) = fs::remove_file(path) {
                // Only report error if file exists (not already deleted)
                // ErrorKind::NotFound is acceptable (file already gone)
                if e.kind() != std::io::ErrorKind::NotFound {
                    // Security: Only include filename in error, not full path
                    let filename = path.file_name()
                        .and_then(|n| n.to_str())
                        .unwrap_or("unknown");
                    errors.push(format!(
                        "TFCG cleanup failed for {}: {}",
                        filename, e
                    ));
                }
            }
        }

        // Clear the vector (whether deletions succeeded or not)
        self.temp_file_paths.clear();

        if errors.is_empty() {
            Ok(())
        } else {
            Err(errors)
        }
    }
}

/// Automatic cleanup when guard goes out of scope.
///
/// # Project Context
/// This is the critical safety mechanism. When the guard is dropped
/// (function returns, scope ends, etc.), all tracked temp files are
/// automatically deleted.
///
/// # Error Handling
/// Cleanup errors are logged to stderr but do not panic. This is
/// intentional because:
/// - Drop trait should never panic (Rust best practice)
/// - Primary operation may have succeeded
/// - Cleanup failure is non-critical compared to operation success
///
/// # Implementation Note
/// Uses eprintln! for error output. In production, consider routing
/// to proper logging system instead.
impl Drop for TempFileCleanupGuard {
    fn drop(&mut self) {
        // Attempt cleanup
        if let Err(errors) = self.cleanup() {
            // Log errors but do not panic in Drop
            // In production, route to proper logging system
            for error_msg in errors {
                #[cfg(debug_assertions)]
                eprintln!("Warning: {}", error_msg);

                // In production: consider silent failure or structured logging
                // eprintln! in production could leak sensitive info
            }
        }
    }
}

/// Reads a file into a byte vector with defensive size checking.
///
/// # Project Context
/// In the OTP encryption pipeline, we read the XOR-encrypted output file
/// back into memory for transmission. This function ensures:
/// - Files don't exceed memory safety limits
/// - Clear errors for oversized files
/// - Protection against malicious or accidental large file processing
/// - Consistent byte reading (handles short reads)
///
/// # Security & Reliability Strategy
/// 1. Check file size BEFORE reading (prevents memory exhaustion)
/// 2. Reject files exceeding MAX_PROCESSABLE_FILE_SIZE_BYTES
/// 3. Pre-allocate exact buffer size (efficient, no reallocation)
/// 4. Read entire file in single operation
/// 5. Verify bytes read matches file size (detect partial reads)
///
/// # Size Limit Rationale
/// - Protects against memory exhaustion attacks
/// - Prevents accidental processing of wrong files (logs, databases)
/// - Ensures OTP pad material not wasted on invalid inputs
/// - 1MB limit appropriate for TOML config files
///
/// # Arguments
/// * `file_path` - Absolute path to file to read
///
/// # Returns
/// * `Ok(Vec<u8>)` - Complete file contents as byte vector
/// * `Err(ThisProjectError)` - Operation failed, see error for details
///
/// # Error Conditions
/// - `FileTooLarge`: File exceeds MAX_PROCESSABLE_FILE_SIZE_BYTES
/// - `IoError`: File not found
/// - `IoError`: Permission denied (cannot read file)
/// - `IoError`: Hardware error during read
/// - `IoError`: Partial read (file changed during read)
/// - `InvalidInput`: Path is not absolute
///
/// # Example
/// ```rust,no_run
/// use std::path::Path;
///
/// let temp_path = Path::new("/tmp/uma_xor_result.bin");
///
/// match read_file_to_bytes(temp_path) {
///     Ok(bytes) => println!("Read {} bytes", bytes.len()),
///     Err(e) => eprintln!("Read failed: {}", e),
/// }
/// ```
///
/// # Performance Considerations
/// - Single metadata call to check size
/// - Pre-allocated buffer (no reallocation)
/// - Single read operation for files < 1MB (efficient)
/// - Typical read time for 1MB file: < 5ms on SSD
///
/// # Edge Cases Handled
/// - Empty files (0 bytes): Returns Ok(empty Vec)
/// - Files exactly at limit (1,048,576 bytes): Accepted
/// - Files over limit by 1 byte: Rejected
/// - File deleted between size check and read: Returns IoError
/// - File grows during read: Partial read detected and rejected
fn read_file_to_bytes(
    file_path: &Path,
) -> Result<Vec<u8>, ThisProjectError> {
    use std::fs::{self, File};
    use std::io::Read;

    // Debug assertion: ensure we have an absolute path
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        file_path.is_absolute(),
        "RFTB: file_path must be absolute, got: {:?}",
        file_path
    );

    // Production safety check: verify path is absolute
    if !file_path.is_absolute() {
        return Err(ThisProjectError::InvalidInput(
            "RFTB: file path must be absolute".to_string()
        ));
    }

    // Get file metadata to check size before reading
    // This prevents loading huge files into memory
    let metadata = fs::metadata(file_path)
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                e.kind(),
                format!("RFTB: failed to get file metadata: {}", e),
            ))
        })?;

    // Get file size as usize for comparison
    // Note: On 32-bit systems, files > 4GB would overflow here
    // This is acceptable since our max is 1MB
    let file_size = metadata.len() as usize;

    // Defensive size check: reject unexpectedly large files
    // Protects against memory exhaustion and accidental wrong file processing
    if file_size > MAX_PROCESSABLE_FILE_SIZE_BYTES {
        return Err(ThisProjectError::FileTooLarge {
            path: file_path.to_path_buf(),
            size_bytes: file_size,
            max_allowed: MAX_PROCESSABLE_FILE_SIZE_BYTES,
        });
    }

    // Open file for reading
    let mut file = File::open(file_path)
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                e.kind(),
                format!("RFTB: failed to open file: {}", e),
            ))
        })?;

    // Pre-allocate buffer with exact size
    // This is efficient: allocates once, no reallocation needed
    let mut buffer = vec![0u8; file_size];

    // Read entire file into buffer
    // read_exact ensures we read exactly file_size bytes or error
    file.read_exact(&mut buffer)
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                e.kind(),
                format!("RFTB: failed to read file contents: {}", e),
            ))
        })?;

    // Success: return complete file contents
    Ok(buffer)
}

/// Writes byte data to a file atomically with defensive error handling.
///
/// # Project Context
/// In the OTP encryption pipeline, we need to write intermediate encrypted
/// data to temporary files. This function ensures:
/// - Complete write or complete failure (no partial files)
/// - Defensive handling of disk full, permissions, hardware errors
/// - Secure file permissions (readable/writable by owner only)
/// - Clear error messages for debugging
///
/// # Operation Strategy
/// 1. Create new file (fail if already exists - prevents race conditions)
/// 2. Set restrictive permissions (0600 on Unix - owner only)
/// 3. Write all bytes in single operation
/// 4. Flush to ensure data written to disk
/// 5. Explicit sync to guarantee durability
///
/// # Security Considerations
/// - File permissions set to 0600 (Unix) - only file owner can read/write
/// - Files contain sensitive encrypted data
/// - No world-readable temp files
/// - Fail-safe: if permissions can't be set, file is still created (OS defaults)
///
/// # Arguments
/// * `data` - Byte slice containing data to write
/// * `file_path` - Absolute path where file should be created
///
/// # Returns
/// * `Ok(())` - File successfully written and synced to disk
/// * `Err(ThisProjectError)` - Operation failed, see error for details
///
/// # Error Conditions
/// - `IoError`: File already exists (race condition)
/// - `IoError`: Permission denied (cannot create file in directory)
/// - `IoError`: Disk full (no space available)
/// - `IoError`: Hardware error (disk failure)
/// - `IoError`: Parent directory doesn't exist
///
/// # Example
/// ```rust,no_run
/// use std::path::Path;
///
/// let data = b"encrypted content here";
/// let temp_path = Path::new("/tmp/uma_temp_12345.bin");
///
/// match write_bytes_to_file_atomic(data, temp_path) {
///     Ok(()) => println!("Data written successfully"),
///     Err(e) => eprintln!("Write failed: {}", e),
/// }
/// ```
///
/// # Platform Notes
/// - Unix: File permissions set to 0600 (owner read/write only)
/// - Windows: Uses default file permissions (no chmod equivalent)
/// - All platforms: Fail if file exists prevents race conditions
///
/// # Performance Considerations
/// - Single write operation (efficient for small files)
/// - Flush ensures OS buffer written to disk
/// - Sync ensures disk cache written to physical media
/// - For 1MB files: typically completes in < 10ms on SSD
fn write_bytes_to_file_atomic(
    data: &[u8],
    file_path: &Path,
) -> Result<(), ThisProjectError> {
    use std::fs::{OpenOptions};
    use std::io::Write;

    // Debug assertion: ensure we have an absolute path
    // This is active in debug builds but not production
    #[cfg(all(debug_assertions, not(test)))]
    debug_assert!(
        file_path.is_absolute(),
        "WBTFA: file_path must be absolute, got: {:?}",
        file_path
    );

    // Production safety check: verify path is absolute
    if !file_path.is_absolute() {
        return Err(ThisProjectError::InvalidInput(
            "WBTFA: file path must be absolute".to_string()
        ));
    }

    // Create file with restrictive options
    // - create_new(true): Fail if file exists (prevents race conditions)
    // - write(true): Enable write operations
    // - truncate(false): Not needed since create_new ensures empty file
    let mut file = OpenOptions::new()
        .create_new(true)  // Atomic: fail if exists
        .write(true)
        .open(file_path)
        .map_err(|e| {
            // Enhance error with context
            ThisProjectError::IoError(std::io::Error::new(
                e.kind(),
                format!("WBTFA: failed to create file: {}", e),
            ))
        })?;

    // Set secure file permissions (Unix only)
    // On Windows, this is a no-op (not supported)
    #[cfg(unix)]
    {
        use std::os::unix::fs::PermissionsExt;
        let permissions = std::fs::Permissions::from_mode(0o600); // Owner: rw-, Group: ---, Other: ---

        // Try to set permissions, but don't fail if we can't
        // File was created successfully, permissions are defense-in-depth
        if let Err(e) = std::fs::set_permissions(file_path, permissions) {
            // Log warning in debug builds
            #[cfg(debug_assertions)]
            eprintln!("WBTFA warning: could not set file permissions: {}", e);

            // In production: continue (file created, just with default permissions)
            // This is acceptable because temp directory should have restricted access
        }
    }

    // Write all bytes in single operation
    // This is efficient for small files (our use case: < 1MB)
    file.write_all(data)
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                e.kind(),
                format!("WBTFA: failed to write data: {}", e),
            ))
        })?;

    // Flush OS buffer to ensure bytes reach OS kernel
    file.flush()
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                e.kind(),
                format!("WBTFA: failed to flush: {}", e),
            ))
        })?;

    // Sync file to disk (ensures durability)
    // This is important for encrypted data - must not be lost
    file.sync_all()
        .map_err(|e| {
            ThisProjectError::IoError(std::io::Error::new(
                e.kind(),
                format!("WBTFA: failed to sync: {}", e),
            ))
        })?;

    Ok(())
}

// // TODO: this may be mostly right: directing to readcopy .toml?
// // or... readcopy clearsigned toml?
// // or... new struct serialized to .toml?
// /// Prepares file contents for secure sending by clearsigning and encrypting them.
// ///
// /// This function reads the contents of the file at the given `file_path`,
// /// clearsigns the content using GPG to ensure integrity and non-repudiation,
// /// and then encrypts the clearsigned content using the provided
// /// `recipient_public_key` for confidentiality.
// ///
// /// # Arguments
// ///
// /// * `file_path`: The path to the file whose contents should be processed.
// /// * `recipient_public_key`: The recipient's GPG public key used for encryption.
// ///
// /// # Returns
// ///
// /// * `Ok(Vec<u8>)`: A vector of bytes containing the encrypted, clearsigned file content on success.
// /// * `Err(ThisProjectError)`: An error if file reading, clearsigning, or encryption fails.
// fn padnet_wrapper_path_to_clearsign_to_gpgencrypt_to_otp_to_send_bytes(
//     file_path: &Path,
//     recipient_public_key: &str,
//     padnet_directory_path: &Path,
// ) -> Result<Vec<u8, >, ThisProjectError> {

//     // 1. Clearsign the file contents.
//     let clearsigned_content = gpg_clearsign_file_to_sendbytes(file_path)?;

//     // 2. Encrypt the clearsigned content.
//     let encrypted_content = gpg_encrypt_to_bytes(&clearsigned_content, recipient_public_key)?;

//     let (padnet_index_array, _) = match padnet_writer_strict_cleanup_continuous_xor_file(
//         &path_sendfile_readcopy_path, // path_to_target_file
//         &temp_filepath_padnet, // result_path (XOR'd bytes file)
//         &padnet_directory_path, // path_to_padset
//     ) {
//         Ok((idx, bytes)) => {
//             println!("   Encrypted {} bytes", bytes);
//             println!("   Starting index: {:?}", idx);
//             (idx, bytes)
//         }
//         Err(e) => {
//             println!("   Failed: {}", e);
//             continue;
//         }
//     };

//     debug_log!(
//         "(in HRCD) wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes  encrypted_content {:?}",
//         &encrypted_content
//     );

//     Ok(encrypted_content)
// }



// /// string-mod: remove_non_alphanumeric
// /// takes a string slice (&str) as input and returns a new String that
// /// contains only the ASCII alphanumeric characters from the input string.
// /// The original string is not modified.
// ///
// fn remove_non_alphanumeric(s: &str) -> String {
//     s.chars().filter(|c| c.is_ascii_alphanumeric()).collect()
// }

// /// save for every member with access in channel...
// fn write_newfile_sendq_flag(
//     recipients_list: Vec<String>,
//     file_path: Path,
// ) {
//     team_channel_name = get_current_team_channel_name_from_nav_path();
//     // e.g. sync_data/teamtest/new_file_path_flags/bob}

//     // // maybe iterate through recipients_list

//     // 1. make paths (for each participant in list)
//     // make parent path if not yet exists

//     // 2. save files to paths

// }



/// Writes a new file send queue flag for each recipient in the given list.
///
/// Creates a flag file for each recipient in the `recipients_list` under the directory:
/// `sync_data/{team_channel_name}/sendqueue_updates/{recipient_name}/{timestamp_flagfile_name}.txt`,
/// where `filename` is the sanitized filename of `file_path`.
///
/// # Arguments
///
/// * `recipients_list`: A vector of recipient usernames.
/// * `file_path`: The path to the file to be added to the send queue.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on success, or a `ThisProjectError` if an error occurs during directory or file creation.
fn write_newfile_sendq_flag(
    recipients_list: &[String], // Use a slice for efficiency
    file_path: &Path, // Use a reference to avoid unnecessary cloning
) -> Result<(), ThisProjectError> {
    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

    let timestamp_flagfile_name = get_current_unix_timestamp();

    for recipient in recipients_list {

        let mut flag_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
            "sync_data"
        )?;
        flag_path.push(&team_channel_name);
        flag_path.push("sendqueue_updates");
        flag_path.push(recipient);
        flag_path.push(format!("{}.txt", timestamp_flagfile_name));

        if let Some(parent_dir) = flag_path.parent() {
            create_dir_all(parent_dir)?;
        }

        let file_path_string = file_path.to_string_lossy(); // For writing to the flag file

        // Create flag file (empty file acts as a flag). Handle potential errors.
        match File::create(&flag_path) {
            Ok(mut file) => {
                if let Err(e) = file.write_all(file_path_string.as_bytes()) {
                    debug_log!(
                        "write_newfile_sendq_flag(): Error writing file path to flag file: {}",
                        e
                    );
                    return Err(e.into());  // Or handle error appropriately
                } else {
                    debug_log!("write_newfile_sendq_flag(): Flag file created: {:?} contents: {:?}", flag_path, file_path_string);

                }
            },
            Err(e) => {
                debug_log!(
                    "write_newfile_sendq_flag(): Error creating flag file: {}",
                    e
                );
                return Err(e.into());
            }
        }
    }
    Ok(())
}

/*

// Example usage (in file receiving):

// ... after receiving and decrypting a node file ...

// 1. Create lookup table:
let node_id_to_path = create_node_id_to_path_lookup(&team_channel_path)?;


// 2. Access node data (must match `node_unique_id_str` from `create_node_id_to_path_lookup`):
let node_unique_id_str = received_toml.get("node_unique_id").and_then(Value::as_str).map(|s| s.to_owned()).unwrap_or_default();
if let Some(existing_path) = node_id_to_path.get(&node_unique_id_str) {
    // Node exists, handle move/replace:

    // 3. Remove old node directory
    std::fs::remove_dir_all(existing_path)?;

    // ... (your node saving logic)
} else {
    // Node is new, save it:
    // ... (your node saving logic)

}
*/
/// Creates a lookup table of node unique IDs to their full file paths.
///
/// This function iterates through the team channel directory, identifies node directories (those containing a `node.toml` file),
/// extracts the node's unique ID from the `node.toml`, and stores the ID and full file path in a HashMap.
///
/// # Arguments
///
/// * `team_channel_path`: The path to the team channel directory.
///
/// # Returns
///
/// * `Result<HashMap<String, PathBuf>, ThisProjectError>`:  A HashMap mapping node unique IDs to their paths, or a `ThisProjectError` if an error occurs.
fn create_node_id_to_path_lookup(
    team_channel_path: &Path,
) -> Result<HashMap<String, PathBuf>, ThisProjectError> {
    let mut node_lookup: HashMap<String, PathBuf> = HashMap::new();

    for entry in WalkDir::new(team_channel_path) {
        let entry = entry?;
        let path = entry.path();

        if path.is_dir() { // A. Nodes only (directories)
            let node_toml_path = path.join("node.toml");
            if node_toml_path.exists() {
                // Found a node directory
                let toml_string = std::fs::read_to_string(&node_toml_path)?;

                // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
                let toml_value: Value = toml::from_str(&toml_string)?;

                // B. Extract node unique ID
                // let node_unique_id = toml_value.get("node_unique_id").and_then(Value::as_integer).unwrap_or(0) as u64;

                // Updated to get unique_id as hex_string:
                let node_unique_id_str = toml_value.get("node_unique_id").and_then(Value::as_str).map(|s| s.to_owned()).unwrap_or_default();
                if node_unique_id_str.is_empty() {
                    continue; // Skip this node if no valid ID
                }


                // C. Get full file path
                let full_path = path.to_path_buf();

                // Add to lookup table:
                node_lookup.insert(node_unique_id_str, full_path);
            }
        }
    }

    Ok(node_lookup)
}

/// Retrieves the local owner username from the uma.toml configuration file.
///
/// # Returns
///
/// A String containing the username if successful, or an empty string if any error occurs.
fn get_local_owner_username() -> String {
    debug_log!(
        "___ Step 1: Reading LOCAL OWNER USER's name from {}",
        UMA_TOML_CONFIGFILE_PATH_STR,
    );

    // Get absolute path to uma.toml configuration file
    let absolute_uma_toml_path = match make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(
        UMA_TOML_CONFIGFILE_PATH_STR
        ) {
        Ok(path) => path,
        Err(e) => {
            println!("Error: ___ Failed to locate uma.toml configuration file: {}", e);
            return String::new(); // Return empty string on error
        }
    };

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = match absolute_uma_toml_path.to_str() {
        Some(path_str) => path_str,
        None => {
            println!("Error: __ Unable to convert UMA TOML path to string");
            return String::new(); // Return empty string on error
        }
    };

    // Read LOCAL OWNER USER's name from uma.toml
    match read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ) {
        Ok(username) => {
            debug_log!("___ LOCAL OWNER USER's name is: {}", username);
            username  // Return the username string on success
        },
        Err(e) => {
            println!("Error: ___ Failed to read LOCAL OWNER USER's name: {}", e);
            String::new()  // Return empty string on error
        }
    }
}

/// ## State, Initialization & Network
/// If as a vignette, let's look at a brief walkthrough of Alice starting up Uma as she embarks on a build with Bob.
///
/// 1. Alice starts Uma
/// 2. Uma run initialization:
/// Initialization checks:
/// - is this the first time (here we will assume it is not the first setup)
/// (perhaps, is there a hash-salt to check the uma.toml configuration file)
/// - node-graph navigation is set up as starting from square one: location is ~home_square_one=true, because Alice has not yet picked which team_channel she wants to use/sync-with/view/join/enter however said.
/// - a mostly blank ~GraphNavigationState is filled-in (or filled-out)
/// - CWD (current working directory (path)) is set to home_square_one, which is not in any team_channel
/// - a basic home_square_one TUI is displayed showing what team_channels Alice can join/view/enter etc. (ones she has been invited to and has been sent and has loaded the team_channel configuration files for)
/// - Uma listens for Alice's 'command' which can be the number of a listed team_channel (to go to) or options such as log-view, quit, help, make a new team, etc.
/// - Alice picks alice_and_bobs_best_team_ever channel, option: "1"
/// Now Uma needs to do three important things:
/// 1. Uma needs to update graph navigation as with any 'move' within the dungeon-of-rooms of graph nodes.
/// 2. Uma needs change from being at home-base-square-one (no context for 'state') to being in a channel with users and configurations: there is now 'state' to fill-in for the ~graph_navigation_state.
/// 3. Uma needs to set up the uma_network, which in particular involves:
/// - getting the 'actual list' of collaborators in that team-channel to connect with (which is an intersection of the team-owner's (potential) team-members list and Alice's actual whole 'address-book' of all real contacts on all teams.
/// - uma_network needs the port-assignments from the team_channel toml (set by the team-owner, so there is no port-collision or source-of-truth mixup)
/// - uma_network needs the ip (ipv6, ipv4, etc.) for each collaborator, which comes from that collaborator-owned toml (and probably that collaborator's public gpg key)
///
/// Note: If Alice returns to home, all this 'state' is deleted and Uma returns to home-square-one as if she restarted the program. (In fact...it might even be easiest to literally restart to make that process clean.)
///
/// ip availability is also read and recorded in sync-state stored
/// as a combined-index that included type data (hopefully works with other signal types too)
/// return true for online, false for offline
fn initialize_uma_application() -> Result<bool, Box<dyn std::error::Error>> {
    // Welcome to Uma Land!!
    debug_log("Staring initialize_uma_application()");

    // --- 1. CHECK FOR & SETUP uma.toml ---
    // let uma_toml_path = Path::new("uma.toml");


    // Check for uma.toml file relative to the executable's directory
    let uma_toml_path_result = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(
        UMA_TOML_CONFIGFILE_PATH_STR
    );

    // // Handle the result appropriately
    // let uma_toml_path = match uma_toml_path_result {
    //     Ok(file_path) => {
    //         // File exists, we can proceed with using it
    //         debug_log!("Found uma.toml at: {:?}", file_path);
    //         file_path
    //     },
    //     Err(io_error) => {
    //         if io_error.kind() == std::io::ErrorKind::NotFound {
    //             // File doesn't exist - handle this specific case
    //             return Err(format!("Configuration file uma.toml not found in executable directory").into());
    //         } else if io_error.kind() == std::io::ErrorKind::InvalidInput {
    //             // Path exists but is a directory
    //             return Err(format!("uma.toml exists but is a directory, not a file").into());
    //         } else {
    //             // Other I/O errors
    //             return Err(format!("Error accessing uma.toml: {}", io_error).into());
    //         }
    //     }
    // };

    // This will pass an empty 'uma_toml_path' ahead if initial setup is needed
    let uma_toml_path = match uma_toml_path_result {
        Ok(file_path) => {
            // Path is valid (whether file exists or not)
            debug_log!("Determined uma.toml path at: {:?}", file_path);
            file_path
        },
        Err(io_error) => {
            // Only treat certain errors as fatal
            if io_error.kind() == std::io::ErrorKind::InvalidInput {
                // Path exists but is a directory
                return Err(format!("uma.toml exists but is a directory, not a file").into());
            } else if io_error.kind() == std::io::ErrorKind::NotFound {
                // For first-time setup, NotFound is expected - construct the default path
                let mut default_path = std::env::current_exe().map_err(|e|
                    format!("Failed to determine executable path: {}", e)
                )?;
                default_path.pop(); // Remove executable name
                default_path.push(UMA_TOML_CONFIGFILE_PATH_STR);
                debug_log!("Using default uma.toml path: {:?}", default_path);
                default_path
            } else {
                // Other I/O errors
                return Err(format!("Error accessing uma.toml: {}", io_error).into());
            }
        }
    };

    // looks to see if setup is needed
    if !uma_toml_path.exists() {
        /*
        This uses the struct method 'new' to make a standard
        default but name-less file
        then Q&A user into sets that owner-name.

        either way, 'owner' needs to be available
        if a new chanel needs to be created (as the owner)
        */
        // Prompt for owner and create uma.toml
        println!("Welcome to the Uma Collaboration Tools.");
        println!("Please enter your username.");
        println!("This nickname will be the local-owner-user for this Uma 'instance.'");
        println!("Changing 'uma_local_owner_user = ___' in uma.toml");
        println!("will change the local-owner-user when running Uma.");
        println!("Please enter your username:");

        // let mut owner_input = String::new();
        // io::stdin().read_line(&mut owner_input).unwrap();  // TODO remove this unwrap!!!!!!!!!!!!!!!!!!!!!

        // let owner = owner_input.trim().to_string();

        // let local_user_metadata = LocalUserUma::new(owner); // Create LocalUserUma

        // if let Err(e) = local_user_metadata.save_owner_to_file(&uma_toml_path) {
        //     eprintln!("Failed to create uma.toml: {}", e);
        //     // Handle the error (e.g., exit gracefully)
        //     return Ok(false);
        // }


        // // Get armored public key, using key-id (full fingerprint in)
        // let mut full_fingerprint_key_id_string = String::new();
        // match q_and_a_user_selects_gpg_key_full_fingerprint() {
        //     Ok(temp_fullfingerprint_key_idstring) => {

        //         println!("Selected key id (full fingerprint in): {}", temp_fullfingerprint_key_idstring);
        //         full_fingerprint_key_id_string = temp_fullfingerprint_key_idstring;
        // }
        //     Err(e) => eprintln!("Error selecting full_fingerprint_key_id_string: {}", e.to_string()),
        // }

        // Initialize Uma configuration
        // println!("Welcome to the Uma Collaboration Tools.");
        // println!("Please enter your username.");
        // println!("This nickname will be the local-owner-user for this Uma 'instance.'");
        // println!("Changing 'uma_local_owner_user = ___' in uma.toml");
        // println!("will change the local-owner-user when running Uma.");
        // println!("Please enter your username:");

        // Read owner username with error handling
        let mut owner_input = String::new();
        if let Err(e) = io::stdin().read_line(&mut owner_input) {
            eprintln!("Failed to read username input: {}", e);
            return Ok(false);
        }
        let owner = owner_input.trim().to_string();

        // Validate owner input
        if owner.is_empty() {
            eprintln!("Username cannot be empty");
            return Ok(false);
        }

        // Get GPG key fingerprint
        let full_fingerprint_key_id_string = match q_and_a_user_selects_gpg_key_full_fingerprint() {
            Ok(fingerprint) => {
                println!("Selected key id (full fingerprint): {}", fingerprint);
                fingerprint
            }
            Err(e) => {
                eprintln!("Error selecting GPG key fingerprint: {}", e);
                return Ok(false);
            }
        };

        // Create LocalUserUma instance with both required fields
        let local_user_metadata = LocalUserUma::new(owner, full_fingerprint_key_id_string);

        // Save configuration to uma.toml file
        if let Err(e) = local_user_metadata.save_to_uma_toml_file(&uma_toml_path) {
            eprintln!("Failed to create uma.toml: {}", e);
            return Ok(false);
        }

        debug_log!("uma.toml created successfully!");
    }





    // // ... 2. Load user metadata from the now-existing uma.toml
    // let user_metadata = match toml::from_str::<LocalUserUma>(&fs::read_to_string(&uma_toml_path)?) {
    //     Ok(metadata) => {
    //         debug_log!("uma.toml loaded successfully!");
    //         metadata
    //     },
    //     Err(e) => {
    //         eprintln!("Failed to load or parse uma.toml: {}", e);
    //         return Ok(false);
    //     }
    // };

    // // Set the uma_local_owner_user from the loaded metadata
    // let uma_local_owner_user = user_metadata.uma_local_owner_user;


    // Read only the owner username from uma.toml
    let uma_local_owner_user = match LocalUserUma::read_owner_from_file() {
        Ok(owner) => {
            debug_log!("Owner username loaded successfully: {}", owner);
            owner
        },
        Err(e) => {
            eprintln!("Failed to read owner username from uma.toml: {}", e);
            return Ok(false);
        }
    };

    // using path relative to exe-parent:
    // Ensure directory exists relative to the executable
    let project_graph_directory_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("project_graph_data");

    // Handle any errors that might occur during directory creation or verification
    let project_graph_directory = match project_graph_directory_result {
        Ok(directory_path) => directory_path,
        Err(io_error) => {
            // Log the error and handle appropriately for your application
            return Err(format!("Failed to ensure project graph directory exists: {}", io_error).into());
        }
    };

    debug_log!("IUA: project_graph_directory -> {:?}", project_graph_directory);

    // // Check if the data directory exists
    // let invites_outgoing_pathbuf = Path::new("invites_updates/invites_outgoing_pathbuf/export");
    // if !invites_outgoing_pathbuf.exists() {
    //     // If the directory does not exist, create it
    //     fs::create_dir_all(invites_outgoing_pathbuf).expect("Failed to create invites_outgoing_pathbuf directory");
    // }

    // not yet working
    // export_addressbook()?;


    // TODO
    // look for a file in import_export_invites/addressbook_invite/export
    // try to read it as a gpg key
    // export your addressbook file clearsigned by you and encrypted with the public gpg key in that file

    // // relative version
    // // Check if the sync_data directory exists,
    // // and recursively erase all old files.
    // // This is 'session' state for sync which must
    // // be new each start-up session.
    // // Make a fresh session sync directory
    // // note: each 'local instance' should be specific
    // // to the location of the uma executable file
    // // more than one user may be running on a given computer
    // let sync_data_directory = Path::new("sync_data");
    // if sync_data_directory.exists() {
    //     // If the directory exists, remove it recursively
    //     if let Err(e) = remove_dir_all(sync_data_directory) {
    //         // Handle the error appropriately, e.g., log it and continue, or return an error if you want to stop initialization
    //         debug_log!("Error removing sync_data directory: {}", e);
    //         // Or: return Err(e.into()); // Or handle the error differently
    //     }
    // }
    // // Create the directory fresh for the new session.
    // fs::create_dir_all(sync_data_directory).expect("Failed to create sync_data directory");


    // Check if the sync_data directory exists relative to the executable location,
    // and recursively erase all old files.
    // This is 'session' state for sync which must
    // be new each start-up session.
    // Make a fresh session sync directory.
    // note: each 'local instance' should be specific
    // to the location of the uma executable file
    // more than one user may be running on a given computer.
    // Using executable-relative paths ensures that multiple instances running
    // from different locations won't interfere with each other's sync data.

    // Get the path to the sync_data directory relative to the executable's location
    let sync_data_directory_result = make_input_path_name_abs_executabledirectoryrelative_nocheck("sync_data");

    match sync_data_directory_result {
        Ok(sync_data_directory) => {
            // Check if the directory exists
            match abs_executable_directory_relative_exists(&sync_data_directory) {
                Ok(exists) => {
                    if exists {
                        // Directory exists, remove it recursively to start fresh
                        debug_log!("Clearing existing sync_data directory at: {}", sync_data_directory.display());
                        if let Err(remove_err) = remove_dir_all(&sync_data_directory) {
                            // Handle the error appropriately, log it and continue
                            debug_log!("Error removing sync_data directory: {}", remove_err);
                            // We'll still attempt to create the directory below
                        }
                    }

                    // Create the directory fresh for the new session, whether it was previously
                    // removed successfully or didn't exist at all
                    match fs::create_dir_all(&sync_data_directory) {
                        Ok(_) => {
                            debug_log!("Successfully created fresh sync_data directory at: {}", sync_data_directory.display());
                        },
                        Err(create_err) => {
                            // This is a more serious error as we need the directory
                            debug_log!("Critical error: Failed to create sync_data directory: {}", create_err);
                            // Depending on app requirements, you might want to handle this more severely
                            // or implement a fallback mechanism
                        }
                    }
                },
                Err(check_err) => {
                    debug_log!("Error checking if sync_data directory exists: {}", check_err);
                    // Attempt to create the directory anyway
                    if let Err(create_err) = fs::create_dir_all(&sync_data_directory) {
                        debug_log!("Critical error: Failed to create sync_data directory: {}", create_err);
                    }
                }
            }
        },
        Err(path_err) => {
            // Failed to determine the executable-relative path
            debug_log!("Error determining sync_data directory path: {}", path_err);

            // Fallback to using a relative path as a last resort
            let fallback_sync_data_directory = make_input_path_name_abs_executabledirectoryrelative_nocheck(
                "sync_data"
            )?;
            debug_log!("Falling back to current directory relative path for sync_data");

            if fallback_sync_data_directory.exists() {
                if let Err(remove_err) = remove_dir_all(fallback_sync_data_directory.clone()) {
                    debug_log!("Error removing fallback sync_data directory: {}", remove_err);
                }
            }

            if let Err(create_err) = fs::create_dir_all(fallback_sync_data_directory) {
                debug_log!("Critical error: Failed to create fallback sync_data directory: {}", create_err);
                // This is a critical failure point - consider how your application should handle it
            }
        }
    }

    /////////////////////
    // Log Housekeeping
    /////////////////////
    debug_log("IUA: Log Housekeeping");

    // 1. Create the archive directory if it doesn't exist, relative to the executable.
    // This directory stores archived logs and is not intended for syncing
    let archive_dir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("uma_archive/logs");

    let uma_archive_dir = match archive_dir_result {
        Ok(dir_path) => dir_path,
        Err(io_error) => {
            eprintln!("Warning: Failed to create uma_archive/logs directory: {}", io_error);
            // Create a fallback directory in case the executable-relative path fails
            let mut fallback_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(
                "uma_archive"
            )?;

            // fallback_dir.push("uma_archive");
            fallback_dir.push("logs");

            // Try to create the fallback directory
            if !fallback_dir.exists() {

                if let Err(e) = fs::create_dir_all(&fallback_dir) {
                    eprintln!("Critical: Failed to create fallback archive directory: {}", e);
                    // Return a sensible default to allow the program to continue
                    make_input_path_name_abs_executabledirectoryrelative_nocheck(
                        "uma_archive/logs"
                    )?
                } else {
                    fallback_dir
                }
            } else {
                fallback_dir
            }
        }
    };

    // 2. Get the current timestamp.
    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_else(|_| {
            eprintln!("Warning: System time appears to be before Unix epoch");
            std::time::Duration::from_secs(0) // Fallback to epoch if time is weird
        })
        .as_secs();

    // 3. Construct the new archive file path.
    let archived_log_path = uma_archive_dir.join(format!("uma__{}.log", timestamp));
    debug_log!("IUA archived_log_path -> {:?}", archived_log_path);

    // 4. Get the source log file path relative to the executable
    let source_log_path_result = make_input_path_name_abs_executabledirectoryrelative_nocheck("uma.log");

    match source_log_path_result {
        Ok(source_log_path) => {
            // Check if the source log file exists before trying to rename it
            if Path::new(&source_log_path).exists() {
                // Rename (move) the uma.log file to the archive directory
                if let Err(e) = fs::rename(&source_log_path, &archived_log_path) {
                    eprintln!("Failed to archive uma.log: {}", e);
                    // Handle the error, but don't stop initialization.
                }
            } else {
                // No log file to archive, this might be the first run
                eprintln!("Notice: No uma.log file found to archive");
            }
        },
        Err(io_error) => {
            // Log the error and continue
            eprintln!("Warning: Failed to determine uma.log path: {}", io_error);
            debug_log!("Could not archive log file: Failed to determine executable-relative path");
            // Do NOT attempt with a relative path - just continue the program
            // No fallback to a relative path - this would defeat the purpose
        }
    }

    // relative path version
    // /////////////////////
    // // Log Housekeeping
    // /////////////////////

    // // 1. Create the archive directory if it doesn't exist.
    // // saves archives not in the project_graph_data directory, not for sync
    // let mut uma_archive_dir = PathBuf::new(); // Start with an empty PathBuf safe path os
    // uma_archive_dir.push("uma_archive");    // Push the 'uma_archive' directory
    // uma_archive_dir.push("logs");            // Push the 'logs' subdirectory

    // if !uma_archive_dir.exists() {
    //     fs::create_dir_all(&uma_archive_dir).expect("Failed to create uma_archive directory");
    // }

    // // 2. Get the current timestamp.
    // let timestamp = SystemTime::now()
    //     .duration_since(UNIX_EPOCH)
    //     .expect("Time went backwards!")
    //     .as_secs();

    // // 3. Construct the new archive file path.
    // let archived_log_path = uma_archive_dir.join(format!("uma__{}.log", timestamp));

    // // 4. Rename (move) the uma.log file to the archive directory.
    // if let Err(e) = fs::rename("uma.log", &archived_log_path) {
    //     eprintln!("Failed to archive uma.log: {}", e); // Handle the error, but don't stop initialization.
    // }


    debug_log("next IUA runs fn  check_all_ports_in_team_channels()");

    // Check for port collisions across all team channels
    if let Err(e) = check_all_ports_in_team_channels_clearsign_validated() {
        eprintln!("Error: {}", e); // Print the error message
        debug_log!("Error: {}", e);
        // Handle the error as needed (e.g., exit UMA)
        return Ok(false);
    }

    debug_log("next IUA get_local_ip_addresses");
    let _ = get_local_ip_addresses();



    debug_log("next IUA ensure some dirs exist");


    /////////////////////////////
    // ensure directories exist
    /////////////////////////////

    // assumes 'project_graph_directory' path is exe-parent based
    // Ensure project_graph_data/team_channels directory exists
    let team_channels_dir = project_graph_directory.join("team_channels");
    if !team_channels_dir.exists() {
        fs::create_dir_all(&team_channels_dir).expect("Failed to create team_channels directory");
    }

    debug_log!("IUA: team_channels_dir -> {:?}", team_channels_dir);


    // invite/update
    let outgoing_dir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        "invites_updates/outgoing"
    );
    debug_log!("IUA: outgoing_dir_result outgoing -> {:?}", outgoing_dir_result);
    let incoming_dir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
        "invites_updates/incoming"
    );
    debug_log!("IUA: incoming_dir_result outgoing -> {:?}", incoming_dir_result);

    // Get the UME temp directory path with error handling
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| format!(
            "Failed to get UME temp directory path: {:?}",
            io_err
        ))?;

    // Clear contents: TODO (dev: xcomment this out to track remaining files)
    if let Err(e) = remove_dir_contents_if_exists(&base_uma_temp_directory_path) {
        eprintln!("Error clearing directory: {}", e);
    }


    // Ensure base_uma_temp_directory_path exists
    if !base_uma_temp_directory_path.exists() {
        fs::create_dir_all(&base_uma_temp_directory_path).expect("Failed to create base_uma_temp_directory_path directory");
    }

    // debug_log!("IUA: base_uma_temp_directory_path -> {:?}", base_uma_temp_directory_path);


    debug_log!("IUA: base_uma_temp_directory_path -> {:?}", base_uma_temp_directory_path);

    // // using path relative to exe-parent:
    // // Ensure directory exists relative to the executable
    // let team_channelsdir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("team_channels");

    // // Handle any errors that might occur during directory creation or verification
    // let team_channels_dir = match team_channelsdir_result {
    //     Ok(directory_path) => directory_path,
    //     Err(io_error) => {
    //         // Log the error and handle appropriately for your application
    //         return Err(format!("Failed to ensure team_channels directory exists: {}", io_error).into());
    //     }
    // };


    // assumes 'project_graph_directory' path is exe-parent based
    // Ensure COLLABORATOR_ADDRESSBOOK_PATH_STR directory exists
    let collaborator_files_address_book_dir = project_graph_directory.join("collaborator_files_address_book");
    if !collaborator_files_address_book_dir.exists() {
        fs::create_dir_all(&collaborator_files_address_book_dir).expect("Failed to create collaborator_files_address_book directory");
    }

    // // using path relative to exe-parent:
    // // Ensure directory exists relative to the executable
    // let collaborator_files_addressbook_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("collaborator_files_address_book");

    // // Handle any errors that might occur during directory creation or verification
    // let collaborator_files_address_book_dir = match collaborator_files_addressbook_result {
    //     Ok(directory_path) => directory_path,
    //     Err(io_error) => {
    //         // Log the error and handle appropriately for your application
    //         return Err(format!("Failed to ensure collaborator_files_address_book directory exists: {}", io_error).into());
    //     }
    // };


    // assumes 'project_graph_directory' path is exe-parent based
    // Ensure project_graph_data/session_state_items directory exists
    let session_state_dir = project_graph_directory.join("session_state_items");
    if !session_state_dir.exists() {
        fs::create_dir_all(&session_state_dir).expect("Failed to create session_state_items directory");
    }

    // // using path relative to exe-parent:
    // // Ensure directory exists relative to the executable
    // let session_statedir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("session_state_items");

    // // Handle any errors that might occur during directory creation or verification
    // let session_state_dir = match session_statedir_result {
    //     Ok(directory_path) => directory_path,
    //     Err(io_error) => {
    //         // Log the error and handle appropriately for your application
    //         return Err(format!("Failed to ensure session_state_items exists: {}", io_error).into());
    //     }
    // };


    // assumes 'project_graph_directory' path is exe-parent basedpath
    // Ensure project_graph_data/sync_state_items directory exists
    let sync_state_dir = project_graph_directory.join("sync_state_items");
    if !sync_state_dir.exists() {
        fs::create_dir_all(&sync_state_dir).expect("Failed to create sync_state_items directory");
    }


    // // using path relative to exe-parent:
    // // Ensure directory exists relative to the executable
    // let sync_statedir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path("sync_state_items");

    // // Handle any errors that might occur during directory creation or verification
    // let sync_state_dir = match sync_statedir_result {
    //     Ok(directory_path) => directory_path,
    //     Err(io_error) => {
    //         // Log the error and handle appropriately for your application
    //         return Err(format!("Failed to ensure sync_state_items directory exists: {}", io_error).into());
    //     }
    // };

    debug_log("IUA ensured some dirs existed...");
    // println!("IUA ensured some dirs existed...");


    // To stop sync from starting before a channel is entered:
    let _ = initialize_ok_to_start_sync_flag_to_false();

    // Check if there are any directories in project_graph_data/team_channels
    debug_log("let number_of_team_channels = fs::read_dir(&team_channels_dir)");

    // if !dir_at_path_is_empty_returns_false(COLLABORATOR_ADDRESSBOOK_PATH_STR) {
    debug_log!(
        "if !dir_at_path_is_empty_returns_false(Path::new({})) ",
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
    );



    // if !dir_at_path_is_empty_returns_false(Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)) {
    if !dir_at_path_is_empty_returns_false(
        &collaborator_files_address_book_dir
            ) {

        debug_log("IUA if !dir_at_path_is_empty_returns_false");

        // If there are no existing users, prompt the user to add a new user
        println!("Welcome to the application!");
        println!("To get started, please add a new user.");

        // Prompt the user to enter a username
        println!("Enter a username:");
        let mut username_input = String::new(); // Use a temporary variable for input

        let username_for_function: String = match std::io::stdin().read_line(&mut username_input) {
            Ok(_) => {
                // Successfully read input, trim it, and this will be the value of username_for_function
                let trimmed = username_input.trim().to_string();
                if trimmed.is_empty() {
                    eprintln!("Username cannot be empty.");
                    // Handle empty username case, perhaps by returning or panicking
                    // For now, let's panic as an example, but you should handle it gracefully.
                    panic!("Username was empty after trimming.");
                }
                println!("Hello, (trimmed): '{}'", trimmed); // Debug: Check the trimmed value
                trimmed
            },
            Err(io_error) => {
                // Handle the error appropriately
                eprintln!("Failed to read input: {}", io_error);
                // You must return or panic here, as username_for_function needs a value.
                // Or provide a default, though that's unlikely for a username.
                panic!("Failed to read username: {}", io_error);
            }
        };

        // choice...
        // Get IP address input method
        // 3. Auto-detect IP Addresses
        let detected_addresses = get_local_ip_addresses().expect("Failed to auto-detect IP addresses");
        let mut ipv4_addresses: Option<Vec<Ipv4Addr>> = None;
        let mut ipv6_addresses: Option<Vec<Ipv6Addr>> = None;

        for addr in detected_addresses {
            match addr {
                IpAddr::V4(v4) => {
                    if ipv4_addresses.is_none() {
                        ipv4_addresses = Some(Vec::new());
                    }
                    ipv4_addresses.as_mut().unwrap().push(v4);
                }
                IpAddr::V6(v6) => {
                    if ipv6_addresses.is_none() {
                        ipv6_addresses = Some(Vec::new());
                    }
                    ipv6_addresses.as_mut().unwrap().push(v6);
                }
            }
        }

        // // Prompt the user to enter an IP address
        // println!("Enter an ipv6_addresses:");
        // let mut ipv6_address = String::new();
        // io::stdin().read_line(&mut ipv6_address).unwrap();
        // let ipv6_address: Ipv6Addr = ipv6_address.trim().parse().unwrap(); // Parse into Ipv6Addr
        // show user their gpg key id list
        // new Q&A workflow, not requiring the user to open a new terminal and use gpg cli

        // Get armored public key, using key-id (full fingerprint in)
        let full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
            Ok(fingerprint) => fingerprint,
            Err(e) => {
                eprintln!("IUA Failed to read GPG fingerprint from uma.toml: {}", e);
                return Ok(false);
            }
        };

        // Get armored public key, using key-id (full fingerprint in)
        let mut gpg_key_public = String::new();
        match get_gpg_armored_public_key_via_key_id(&full_fingerprint_key_id_string) {
            Ok(armored_key) => {
                println!("Armored Public Key:\n{}", armored_key);
                gpg_key_public = armored_key;
            }
            Err(e) => {
                eprintln!("IUA Error: {}", e);
            }
        }

        println!("GPG key entered:\n{}", gpg_key_public); // Confirmation (remove in production)
        debug_log("IUA GPG key entered");

        // // Salt List!
        debug_log("IUA Salt List");
        // Generate salt list (4 random u128 values)
        let new_usersalt_list: Vec<u128> = (0..4)
            .map(|_| rand::rng().random())
            .collect();

        println!("Using salts: {:?}", new_usersalt_list);
        debug_log!("IUA Using salts: {:?}", new_usersalt_list);

        // // Add a new user to Uma file system
        let _ = make_new_collaborator_addressbook_toml_file(
            username_for_function,
            new_usersalt_list,
            ipv4_addresses,
            ipv6_addresses,
            full_fingerprint_key_id_string,
            gpg_key_public,
            60,   // Example sync_interval (in seconds)
            get_current_unix_timestamp(),
        );

        // // Save the updated collaborator list to the data directory
        // let toml_data = toml::to_string(&collaborator_list).expect("Failed to serialize collaborator list");
        // fs::write(collaborator_list_file, toml_data).expect("Failed to write collaborator list file");

        debug_log("User added successfully!");
        println!("User added successfully!");
    }

    /////////////////////////////
    // Check & Make Team Channel
    /////////////////////////////
    // let number_of_team_channels = fs::read_dir(&team_channels_dir)
    //     .unwrap()
    //     .filter(|entry| entry.as_ref().unwrap().path().is_dir())
    //     .count();

    // No unwrap calls: Uses pattern matching to handle errors gracefully
    // Handles the potential error from fs::read_dir
    // Handles potential errors for each directory entry separately
    // Graceful error recovery: Continues processing entries even if some fail
    // Provides  context in error messages
    // Default value: Returns 0 if unable to read the directory
    // assigns a usize to number_of_team_channels
    // Count subdirectories with proper error handling
    let number_of_team_channels = match fs::read_dir(&team_channels_dir) {
        Ok(entries) => {
            // Filter and count only the directories, safely handling entry errors
            entries
                .filter_map(|entry_result| {
                    // Safely handle potential errors for each directory entry
                    match entry_result {
                        Ok(entry) => {
                            // Check if this entry is a directory
                            if entry.path().is_dir() {
                                Some(()) // Count this directory
                            } else {
                                None // Not a directory, don't count
                            }
                        },
                        Err(e) => {
                            println!("IUA Error accessing directory entry: {}", e);
                            None // Skip this entry due to error
                        }
                    }
                })
                .count()
        },
        Err(e) => {
            println!("IUA Error reading directory {}: {}", team_channels_dir.display(), e);
            0 // Default to 0 channels if directory can't be read
        }
    };


    // let number_of_team_channels = count_subdirectories_executabledirectoryrelative_default_zero(&team_channels_dir);

    if number_of_team_channels == 0 {
        debug_log("IUA if number_of_team_channels == 0");

        // If no team channels exist, create the first one
        println!("There are no existing team channels. Let's create one.");
        println!("Enter a name for a new Team-Channel:");

        let mut team_channel_name = String::new();
        io::stdin().read_line(&mut team_channel_name).unwrap();
        let team_channel_name = team_channel_name.trim().to_string();

        // TUI Setup, TODO
        /*
        If there is an umi.toml,
        and it has tui_height/tui_height that are not 80/24
        use those new values (from umi.toml) for
        tui_height =
        tui_width =

        or maybe this gets done in the project-manager-thread (not the sink thread)
        */

        // // In initialize_uma_application, when creating the first channel:
        // // Get the owner from somewhere (e.g., user input or instance metadata)
        // let owner = "initial_owner".to_string(); // Replace with actual owner

        let _ = create_new_team_channel(
            team_channel_name,
            uma_local_owner_user.clone(),
        );
    }

    // TODO
    // maybe check for node file made?

    debug_log("IUA after create_new_team_channel()");


    //////////////////////////////////////////////////////////////////////////
    // --- Band: Network Band Finder: IP Validity Check and Flag Setting ---
    /////////////////////////////////////////////////////////////////////////

    // let (ipv4_list, ipv6_list) = load_local_ip_lists_to_ipvec(&user_metadata.uma_local_owner_user)?;
    // let (str_ipv4list, str_ipv6list) = load_local_iplists_as_stringtype(&user_metadata.uma_local_owner_user)?;

    // // currently only using ipv6
    // let local_user_ipv6_address = find_valid_local_owner_ip_address(
    //     &ipv6_list
    // )
    //     .ok_or(ThisProjectError::NetworkError("No valid local IPv6 address found".to_string()))?;

    // // // Instead of cloning the first address, use the result of the selector:
    // // ipv6_addr_1 = Some(local_user_ipv6_address); // No need to clone or dereference as the variable now directly holds the Ipv6Addr
    // // ipv6_addr_2 = ipv6_addr_1.clone(); // Clone the selected address for ipv6_addr_2 if needed

    // // get index of valid IP v6
    // let ip_index = get_index_byof_ip(
    //     &str_ipv4list,
    //     &str_ipv6list,
    //     &local_user_ipv6_address.to_string(), // as ip_address
    // );

    // debug_log!(
    //     "Found IP/index <{:?} {:?}>",
    //     local_user_ipv6_address,
    //     ip_index
    // );


    // Network Detection or Work Offline?

    // println!("\nSign-In: You are your GPG: Who are you?");

    // // Get armored public key, using key-id (full fingerprint in)
    // let mut full_fingerprint_key_id_string = String::new();
    // match q_and_a_user_selects_gpg_key_full_fingerprint() {
    //     Ok(temp_fullfingerprint_key_idstring) => {

    //         println!("Selected key id (full fingerprint in): {}", temp_fullfingerprint_key_idstring);
    //         full_fingerprint_key_id_string = temp_fullfingerprint_key_idstring;
    // }
    //     Err(e) => eprintln!("Error selecting full_fingerprint_key_id_string: {}", e.to_string()),
    // }

    // Get armored public key, using key-id (full fingerprint in)
    let full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
            return Ok(false);
        }
    };

    // Call get_band__find_valid_network_index_and_type to retrieve band info and online status
    let (
        network_found_ok,
        network_type,
        network_index,
        this_ipv4,
        this_ipv6,
    ) = get_band__find_valid_network_index_and_type(
        &uma_local_owner_user,
        &full_fingerprint_key_id_string,
        );


    println!("IUA next: get_band__find_valid_network_index_and_type");
    println!(
        "IUA: network_found_ok -> {:?}",
        network_found_ok
        );
    println!(
        "IUA: network_type -> {:?}\n",
        network_type
        );


    // Handle offline mode if no network connection is found
    if !network_found_ok {  // Check the flag *before* writing/saving values to prevent corrupting or creating bad data from invalid inputs.
        debug_log!("No valid network connection found. Entering offline mode.");
        return Ok(false); // Return false to signal offline mode; do not initialize sync, do not continue processing those invalid or undefined network type and IP values. Halt immediately in this specific scenario and set `network_found_ok` boolean flag to `false` consistent with best practice for what you stated was the desired and specified handling for this exact use-case: halt Uma.
    }



    // set network data state-file(s) in sync_data/ directory:
    if let Err(e) = write_local_band__save_network_band__type_index( // Check if writing to sync data state files fails
        network_type, // network type, as String
        network_index, // network index, as u8
        this_ipv4,  //ipv4, as std::net::Ipv4Addr
        this_ipv6, // ipv6, as std::net::Ipv6Addr
    ) { // then handle that error: do not allow bad values to propagate to other parts of the system, halt uma and or handle in other specified way if this error can occur for other reasons not related to invalid IP retrieval.
        // Handle error, halt uma or do something else as per your specs if failure to save band configuration is an error distinct from failure to find a valid IP address.
        // e.g. debug_log("Error saving network configuration: {}", e);
        return Err(Box::new(e)); // Or handle the error as needed, including halting Uma with an informative message
    };

    debug_log("IUA: all done");

    Ok(true) // Indicate online mode only when valid IP data has been obtained, parsed, converted, and written to sync data state files correctly
}

/// Exports the user's public GPG key to a specified location for sharing.
///
/// This function performs the following steps:
/// 1. Retrieves the username from the configuration file
/// 2. Locates the corresponding collaborator file for that user
/// 3. Extracts the GPG public key ID from the collaborator file
/// 4. Uses GPG to export the public key in ASCII-armored format
/// 5. Saves the exported key to the specified output directory
///
/// # Path Handling
/// IMPORTANT: Both the config_path and output_directory parameters are treated as paths
/// relative to the executable's directory location, NOT the current working directory.
/// They will be automatically converted to absolute paths based on the executable's location.
/// This ensures consistent behavior regardless of where the program is executed from.
///
/// # Arguments
/// * `config_path` - Path to the uma.toml configuration file (relative to executable directory)
/// * `output_directory` - Directory where the exported key should be saved (relative to executable directory)
///
/// # Returns
/// * `Result<String, ThisProjectError>` - Returns the path to the exported key file on success,
///   or an appropriate error if any step fails
///
/// # Errors
/// * `ThisProjectError::InvalidInput` - If paths cannot be converted to strings
/// * `ThisProjectError::TomlVanillaDeserialStrError` - If reading from TOML files fails
/// * `ThisProjectError::IoError` - If file operations fail, including if required directories don't exist
/// * `ThisProjectError::GpgError` - If the GPG key export operation fails
pub fn export_public_gpg_key_converts_to_abs_path(
    config_path: &Path,
    output_directory: &Path,
) -> Result<String, ThisProjectError> {

    debug_log("\n\n EPGKCTAP Starting -> fn export_public_gpg_key_converts_to_abs_path()");

    // Convert config_path to an absolute path relative to the executable directory
    let absolute_config_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(config_path)
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;

    // Convert config path to string for TOML reading functions
    let config_path_str = absolute_config_path.to_str()
        .ok_or_else(|| ThisProjectError::InvalidInput("EPGKCTAP Cannot convert config path to string".to_string()))?;

    // Read username from the configuration file, mapping any reading errors to our error type
    let uma_localowneruser_username = read_single_line_string_field_from_toml(config_path_str, "uma_local_owner_user")
        .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
            format!("EPGKCTAP Failed to read uma_localowneruser_username from config: {}", error_message)
        ))?;

    debug_log!("EPGKCTAP uma_localowneruser_username {}", uma_localowneruser_username);

    // clearsigned toml and .gpgtoml

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| GpgError::PathError(format!("SLABIK Failed to locate uma.toml configuration file: {}", e)))?;

    debug_log!("EPGKCTAP UMA TOML absolute path: {}", absolute_uma_toml_path.display());
    debug_log!("EPGKCTAP UMA TOML file exists: {}", absolute_uma_toml_path.exists());

    // Get local owner username from configuration - REFACTORED FOR DEBUGGING
    // Convert PathBuf to string first
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| GpgError::PathError("EPGKCTAP Unable to convert UMA TOML path to string".to_string()))?;

    // Log the exact string that will be used by the TOML reader
    debug_log!("EPGKCTAP Attempting to read from UMA TOML file at path string: {}", absolute_uma_toml_path_str);

    // Now attempt to read the actual field value
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| GpgError::ValidationError(format!("EPGKCTAP Failed to read local owner username: {}", e)))?;

    debug_log!("EPGKCTAP Successfully read local_owner_user_name: {}", &local_owner_user_name);
    println!("Local owner username (whose address book we are sharing): {}", local_owner_user_name);

    let absolute_addressbook_directory_pathbuf = match get_addressbook_directory_path() {
        Ok(path) => path,
        Err(e) => {
            debug_log!("EPGKCTAP Failed to get absolute path: {}", e);
            return Err(ThisProjectError::GpgError(
                format!("EPGKCTAP GPG key export failed: get_addressbook_directory_path {}", e)
            ));
        }
    };

    // Check for both file types
    let toml_path = absolute_addressbook_directory_pathbuf
        .join(format!("{}__collaborator.toml", local_owner_user_name));
    let gpgtoml_path = absolute_addressbook_directory_pathbuf
        .join(format!("{}__collaborator.gpgtoml", local_owner_user_name));

    // Determine which file exists and use that path
    let raw_addressbook_path = if toml_path.exists() {
        // Prefer plain .toml if both exist
        toml_path
    } else if gpgtoml_path.exists() {
        gpgtoml_path
    } else {
        // Neither exists, skip this directory
        #[cfg(debug_assertions)]
        debug_log!(
            "EPGKCTAP Skipping directory (no node.toml or node.gpgtoml): {:?}",
            &absolute_addressbook_directory_pathbuf
        );
        return Err(ThisProjectError::GpgError(format!(
            "EPGKCTAP Err Invalid path encoding for addressbook file: {}",
            absolute_addressbook_directory_pathbuf.display()
        )));
    };

    // Get GPG fingerprint (could move this outside the loop if same for all)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "EPGKCTAP error Failed to read GPG fingerprint for: {} (skipping)",
                e
            );
            // continue; // Skip this directory, continue with next
            return Err(ThisProjectError::GpgError(
                "EPGKCTAP error gpg_full_fingerprint_key_id_string".to_string()));
        }
    };

    // Get temp directory path (could move this outside the loop if same for all)
    let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
        Ok(path) => path,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "SLABIK error Failed to get temp directory path: {} (skipping)",
                e
            );
            return Err(ThisProjectError::GpgError(
                "EPGKCTAP error get_base_uma_temp_directory_path".to_string()));
        }
    };

    // Get readable copy
    let user_config_path_str = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &raw_addressbook_path,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ) {
        Ok(path) => path,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "EPGKCTAP Failed to get read copy for {:?}: {:?} (skipping)",
                raw_addressbook_path,
                e
            );
            return Err(ThisProjectError::GpgError(
                "EPGKCTAP error get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml".to_string()));
        }
    };

    debug_log!("EPGKCTAP Absolute local owner address book path user_config_path_str: {}", user_config_path_str);


    // // Convert the collaborator files directory to an absolute path based on the executable's location
    // // AND verify that the directory exists (returns error if not found or not a directory)
    // let addressbook_files_directory_relative = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    // let addressbook_files_directory_absolute = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(
    //     addressbook_files_directory_relative
    // ).map_err(|io_error| ThisProjectError::IoError(io_error))?;

    // // Construct the path to the user's collaborator file, which contains their GPG key ID
    // let collaborator_filename = format!("{}__collaborator.toml", uma_localowneruser_username);
    // let user_config_path = addressbook_files_directory_absolute.join(collaborator_filename);

    debug_log!("EPGKCTAP user_config_path_str {}", user_config_path_str);

    // // Convert the collaborator file path to string for TOML reading
    // let user_config_path_str = user_config_path.to_str()
    //     .ok_or_else(|| ThisProjectError::InvalidInput("Cannot convert collaborator file path to string".to_string()))?;

    debug_log!("EPGKCTAP user_config_path_str {}", user_config_path_str);
    println!("user_config_path_str {}", user_config_path_str);

    // Extract the GPG key ID from the collaborator file
    let gpg_key_id = read_singleline_string_from_clearsigntoml(&user_config_path_str, "gpg_publickey_id")
        .map_err(|error_message| ThisProjectError::TomlVanillaDeserialStrError(
            format!("EPGKCTAP export_public_gpg_key_converts_to_abs_path() Failed read_singleline_string_from_clearsigntoml() to read GPG key ID from clearsigntoml collaborator file: {}", error_message)
        ))?;

    // Convert output_directory to an absolute path relative to the executable directory
    // Create the directory if it doesn't exist
    let absolute_output_directory = make_input_path_name_abs_executabledirectoryrelative_nocheck(output_directory)
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;

    // Ensure the output directory exists, creating it if necessary
    fs::create_dir_all(&absolute_output_directory)
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;

    // Define the output file path where the exported key will be saved
    let output_file_path = absolute_output_directory.join("key.asc");

    debug_log!("EPGKCTAP output_file_path {}", output_file_path.display());

    // Call GPG to export the public key in ASCII-armored format
    let gpg_export_result = StdCommand::new("gpg")
        .arg("--armor")           // ASCII-armored format for text-based sharing
        .arg("--export")          // Export operation
        .arg(&gpg_key_id)         // The key ID to export
        .output()
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;

    debug_log!("EPGKCTAP gpg_export_result {:?}", gpg_export_result);

    // Verify the GPG command executed successfully
    if !gpg_export_result.status.success() {
        // If GPG failed, extract the error message and return it
        let gpg_error_message = String::from_utf8_lossy(&gpg_export_result.stderr);
        return Err(ThisProjectError::GpgError(
            format!("EPGKCTAP GPG key export failed: {}", gpg_error_message)
        ));
    }

    // Write the exported key to the output file
    fs::write(&output_file_path, &gpg_export_result.stdout)
        .map_err(|io_error| ThisProjectError::IoError(io_error))?;
    /*
    Check for invitation:
    for share key... just give instructions?

    look here fn export_addressbook()
    encrypt with theirs and clearsign wtih theirs?
    ?
    use tomlclearsign files??? yes...

    1. is there a key in invtes_updates/incoming/gpg_key_for_invites_here
    2. if so:
    (look for an invite function or command with some of this code...)
    3. get current owner user name
    4. get current owner user addressbook path
    5. get key-id for current owner user? or not need clearsign?
    6. use key in folder to encrypt file at path step 4
    6. put the result in outgoing named whateer .asc

    */

    // Return the path to the exported key file as a string
    let result_path = output_file_path.to_string_lossy().into_owned();

    debug_log!("\n\n EPGKCTAP Ending -> fn export_public_gpg_key_converts_to_abs_path(), result_path -> {:?}", &result_path);

    Ok(result_path)
}

/*
// KEEP this for later !!!!
/// Process address book sharing for a specific recipient
///
/// # Arguments
/// * `recipient_name` - Name of the recipient to share with
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
fn generic_share_address_book(recipient_name: &str) -> Result<(), GpgError> {
    println!("\nProcessing address book share for recipient: {}", recipient_name);

    // Path to your address book
    let address_book_path = Path::new("address_book.toml");

    // Your GPG signing key ID (in production, this would come from config)
    println!("\nTo get your signing key ID, run: $ gpg --list-keys --keyid-format=long");
    print!("Enter your GPG signing key ID: ");
    io::stdout().flush()
        .map_err(|e| GpgError::GpgOperationError(format!("Failed to flush stdout: {}", e)))?;

    let mut signing_key_id = String::new();
    io::stdin()
        .read_line(&mut signing_key_id)
        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;
    let signing_key_id = signing_key_id.trim();

    // Validate signing key
    if signing_key_id.is_empty() {
        return Err(GpgError::ValidationError("No signing key ID provided".to_string()));
    }

    // PLACEHOLDER: In production, this would look up the recipient's public key
    // from your address book using recipient_name
    println!("\nEnter path to recipient's public key file:");
    let mut recipient_key_path_str = String::new();
    io::stdin()
        .read_line(&mut recipient_key_path_str)
        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;
    let recipient_public_key_path = Path::new(recipient_key_path_str.trim());

    // Verify the public key file exists
    if !recipient_public_key_path.exists() {
        return Err(GpgError::PathError(format!(
            "Recipient's public key not found at: {}",
            recipient_public_key_path.display()
        )));
    }

    println!("\nProcessing with:");
    println!("Your signing key ID: {}", signing_key_id);
    println!("Recipient's public key: {}", recipient_public_key_path.display());
    println!("Address book file: {}", address_book_path.display());

    // Use our existing function to clearsign and encrypt the address book
    clearsign_and_encrypt_file_for_recipient(
        address_book_path,
        signing_key_id,
        recipient_public_key_path
    )?;

    println!("\nAddress book has been clearsigned and encrypted for {}!", recipient_name);
    println!("The encrypted file is in: invites_updates/outgoing/address_book.gpgtoml");

    Ok(())
}
// KEEP this for later !!!!
*/

/// Share a team channel with an existing remote collaborator
///
/// This function securely shares a team channel file with a remote collaborator
/// by clearsigning it with the local owner's GPG key and encrypting it with the
/// remote collaborator's public GPG key.
///
/// The process follows these steps:
/// note: steps also involve ready-copy making functions
/// that add-to and combine some overall steps
/// 1. Locate the team channel's node.toml file
/// 2. Read local owner username from uma.toml
/// 3. Get local owner's GPG key ID from their address book file
/// 4. Get remote collaborator's public GPG key from their address book file
/// 5. Clearsign the team channel file with local owner's GPG key
/// 6. Encrypt the clearsigned file with remote collaborator's public key
/// 7. Save the resulting encrypted file to the outgoing directory
///
/// # Arguments
/// * `remote_collaborator_username` - Username of the existing remote collaborator
/// * `team_channel_name` - Name of the team channel to share
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any step fails, with detailed error information
///
/// # File Paths
/// * Team channel file: `{exe-parent}/project_graph_data/team_channels/{team-channel-name}/node.toml`
/// * Local owner's address book: `{exe-parent}/project_graph_data/collaborator_files_address_book/{local-owner}__collaborator.toml`
/// * Remote collaborator's address book: `{exe-parent}/project_graph_data/collaborator_files_address_book/{remote-collaborator}__collaborator.toml`
/// * Output file: `{exe-parent}/invites_updates/outgoing/{team-channel-name}__team_channel__{remote-collaborator}.gpgtoml`
fn share_team_channel_with_existing_collaborator_converts_to_abs(
    remote_collaborator_username: &str,
    team_channel_name: &str
) -> Result<(), GpgError> {
    // Start debug logging for this function
    debug_log!("TCS: Starting team channel sharing process");
    debug_log!("TCS: Remote collaborator username: {}", remote_collaborator_username);
    debug_log!("TCS: Team channel name: {}", team_channel_name);

    // ======== STEP 1: Locate the team channel node.toml file ========
    debug_log!("TCS: STEP 1 - Locating team channel node.toml file");

    // Get absolute path to the team channels directory
    let relative_team_channels_directory_path = "project_graph_data/team_channels";
    let absolute_team_channels_directory_path = gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_team_channels_directory_path)
        .map_err(|e| GpgError::PathError(format!(
            "TCS: Failed to locate team channels directory: {}", e
        )))?;

    debug_log!("TCS: Team channels directory absolute path: {}",
               absolute_team_channels_directory_path.display());

    // Create path to the specific team channel directory
    let absolute_specific_team_channel_directory_path = absolute_team_channels_directory_path.join(team_channel_name);

    // // Create path to the team channel's node.toml file
    // let absolute_team_channel_node_toml_path = absolute_specific_team_channel_directory_path.join("node.toml");

    // // let absolute_team_channel_node_toml_path = absolute_specific_team_channel_directory_path.join("node.toml");



    // debug_log!("TCS: Team channel node.toml path: {}",
    //            absolute_team_channel_node_toml_path.display());

    // // todo node.toml or node.gpgtoml
    // //
    // // Verify the team channel node.toml file exists
    // if !absolute_team_channel_node_toml_path.exists() {

    //     debug_log!("TCS: Team channel node.toml file not found at: {}",
    //     absolute_team_channel_node_toml_path.display());

    //     return Err(GpgError::PathError(format!(
    //         "TCS: Team channel node.toml file not found at: {}",
    //         absolute_team_channel_node_toml_path.display()
    //     )));
    // }

    // A. Check for either node.toml or node.gpgtoml
    let node_toml_path = absolute_specific_team_channel_directory_path.join("node.toml");
    let node_gpgtoml_path = absolute_specific_team_channel_directory_path.join("node.gpgtoml");

    let node_file_path = if node_toml_path.exists() {
        debug_log!("TCS: Found node.toml");
        node_toml_path
    } else if node_gpgtoml_path.exists() {
        debug_log!("TCS: Found node.gpgtoml");
        node_gpgtoml_path
    } else {
        return Err(GpgError::PathError(
            "TCS: Neither node.toml nor node.gpgtoml found in team channel directory".to_string()
        ));
    };

    // B. Get readable temp copy (handles decryption if .gpgtoml)
    debug_log!("TCS: Getting readable copy of node file, node_file_path {:?}", node_file_path);

    // Get GPG fingerprint
    let gpg_fingerprint = LocalUserUma::read_gpg_fingerprint_from_file()
        .map_err(|e| GpgError::PathError(
            format!("TCS: Failed to read GPG fingerprint from uma.toml: {}", e)
        ))?;

    // Get temp directory
    let temp_dir = get_base_uma_temp_directory_path()
        .map_err(|e| GpgError::PathError(
            format!("TCS: Failed to get temp directory path: {}", e)
        ))?;

    // Get readable copy
    let absolute_team_channel_node_toml_path = get_pathstring_to_temp_plaintoml_verified_extracted(
        &node_file_path,
        &gpg_fingerprint,
        &temp_dir,
    ).map_err(|e| GpgError::PathError(
        format!("TCS: Failed to get readable copy of node file: {:?}", e)
    ))?;

    debug_log!("TCS: Node readcopy path: {}", absolute_team_channel_node_toml_path);

    // Now use node_readcopy_path to read fields...

    // ///////////////////

    debug_log!("TCS: Successfully verified team channel node.toml file exists");

    // ======== STEP 2: Get local owner username from uma.toml ========
    debug_log!(
        "TCS: STEP 2 - Reading local owner username from {}",
        UMA_TOML_CONFIGFILE_PATH_STR,
    );

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_uma_toml_path)
        .map_err(|e| GpgError::PathError(format!(
            "TCS: Failed to locate uma.toml configuration file: {}", e
        )))?;

    debug_log!("TCS: uma.toml absolute path: {}",
               absolute_uma_toml_path.display());

    // Convert PathBuf to string for TOML reading functions
    let absolute_uma_toml_path_string = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| GpgError::PathError(
            "TCS: Unable to convert uma.toml path to string".to_string()
        ))?;

    // Read local owner username from uma.toml configuration
    let local_owner_username = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_string,
        "uma_local_owner_user",
    ).map_err(|e| GpgError::ValidationError(format!(
        "TCS: Failed to read local owner username from uma.toml: {}", e
    )))?;

    debug_log!("TCS: Successfully read local owner username: {}", local_owner_username);

    // ======== STEP 3  read-copy ========

    ///////////////////////////////////////
    // make read-copy of .gpgtoml or .toml
    ///////////////////////////////////////
    /*
    // remove temp file
    cleanup_collaborator_temp_file(&addressbook_readcopy_path_string);
    */

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Convert the error to GpgError
            return Err(GpgError::ValidationError(format!(
                "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            )));
        }
    };

    // Get the UME temp directory path with proper GpgError conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| GpgError::ValidationError(
            format!("Failed to get UME temp directory path: {}", io_err)
        ))?;

    // Extract the addressbook path string with proper error conversion to GpgError
    let local_owner_addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &local_owner_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| {
        // Convert the error to GpgError
        GpgError::ValidationError(format!(
            "Failed to get addressbook path for user '{}': {:?}",
            local_owner_username,
            e
        ))
    })?;

    // ======== STEP 4 Read local owner's GPG key ID  ========
    // Read local owner's GPG key ID from their address book
    let local_owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        &local_owner_addressbook_readcopy_path_string, // &str
        "gpg_publickey_id"
    ).map_err(|e| {
        debug_log!("TCS: ERROR - Failed to read GPG key ID with field name 'gpg_publickey_id'");
        GpgError::ValidationError(format!(
            "TCS: Failed to read local owner's GPG key ID from address book: {}", e
        ))
    })?;
    // remove temp file
    let _  = cleanup_collaborator_temp_file(
        &local_owner_addressbook_readcopy_path_string,
        &base_uma_temp_directory_path,
        );

    debug_log!("TCS: Successfully read local owner's GPG key ID: {}", local_owner_gpg_key_id);
    println!("Local owner's GPG key ID (for signing): {}", local_owner_gpg_key_id);

    // ======== STEP 5: Get remote collaborator's public GPG key ========
    debug_log!("TCS: STEP 5 - Getting remote collaborator's public GPG key");


    // Get the UME temp directory path with proper GpgError conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| GpgError::ValidationError(
            format!("Failed to get UME temp directory path: {}", io_err)
        ))?;

    // // read cpoy of collaborator's address book file
    // Extract the addressbook path string with proper error conversion to GpgError
    let remote_collaborator_addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &remote_collaborator_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| {
        // Convert the error to GpgError
        GpgError::ValidationError(format!(
            "Failed to get addressbook path for user '{}': {:?}",
            local_owner_username,
            e
        ))
    })?;

    debug_log!("TCS: remote_collaborator_addressbook_readcopy_path_string -> {}", remote_collaborator_addressbook_readcopy_path_string);


    /*
    // remove temp file
    cleanup_collaborator_temp_file(&remote_collaborator_addressbook_readcopy_path_string);
    */
    // TODO: remove temp files upon any error

    // Read remote collaborator's public GPG key from their address book
    let remote_collaborator_public_gpg_key = read_multiline_string_from_clearsigntoml(
        &remote_collaborator_addressbook_readcopy_path_string,
        "gpg_key_public"
    ).map_err(|e| GpgError::ValidationError(format!(
        "TCS: Failed to read remote collaborator's public GPG key from address book: {}", e
    )))?;

    debug_log!("TCS: remote_collaborator_public_gpg_key -> {}", remote_collaborator_public_gpg_key);


    // remove temp file
    let _ = cleanup_collaborator_temp_file(
        &remote_collaborator_addressbook_readcopy_path_string,
        &base_uma_temp_directory_path,
        );

    debug_log!("TCS: Successfully read remote collaborator's public GPG key");

    // ======== STEP 6: Prepare output directory ========
    debug_log!("TCS: STEP 6 - Preparing output directory");

    // Get absolute path to output directory
    let relative_output_directory_path = "invites_updates/outgoing";
    let absolute_output_directory_path = gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_output_directory_path)
        .map_err(|e| GpgError::PathError(format!(
            "TCS: Failed to locate output directory: {}", e
        )))?;

    debug_log!("TCS: Output directory absolute path: {}",
               absolute_output_directory_path.display());

    // Create output directory if it doesn't exist
    fs::create_dir_all(&absolute_output_directory_path)
        .map_err(|e| GpgError::FileSystemError(e))?;

    debug_log!("TCS: Successfully created/verified output directory");

    // ======== STEP 7: Create temporary file for remote collaborator's public key ========
    debug_log!("TCS: STEP 7 - Creating temporary file for remote collaborator's public key");

    // Create path for temporary public key file
    let temporary_remote_collaborator_public_key_file_path = absolute_output_directory_path
        .join(format!("{}_tmp_pubkey.asc", remote_collaborator_username));

    debug_log!("TCS: Temporary public key file path: {}",
               temporary_remote_collaborator_public_key_file_path.display());

    // Write remote collaborator's public key to temporary file
    fs::write(&temporary_remote_collaborator_public_key_file_path, remote_collaborator_public_gpg_key)
        .map_err(|e| GpgError::FileSystemError(e))?;

    debug_log!("TCS: Successfully wrote remote collaborator's public key to temporary file");

    // ======== STEP 8: Clearsign and encrypt team channel file ========
    debug_log!("TCS: STEP 8 - Clearsigning and encrypting team channel file");

    // Display information about the process
    println!("\nProcessing with the following parameters:");
    println!("Team channel file: {}", absolute_team_channel_node_toml_path);
    println!("Local owner's GPG key ID (for signing): {}", local_owner_gpg_key_id);
    println!("Remote collaborator's public key file: {}", temporary_remote_collaborator_public_key_file_path.display());
    println!("Encrypting team channel '{}' for user '{}'", team_channel_name, remote_collaborator_username);

    let path_absoluteteam_channel_node_toml_path = Path::new(&absolute_team_channel_node_toml_path);

    // Clearsign and encrypt the team channel node.toml file
    clearsign_and_encrypt_file_for_recipient(
        &path_absoluteteam_channel_node_toml_path,
        &local_owner_gpg_key_id,
        &temporary_remote_collaborator_public_key_file_path
    )?;

    debug_log!("TCS: Successfully clearsigned and encrypted team channel file");

    // Generate the expected output file path for user information
    let expected_encrypted_output_filename = format!("{}__team_channel__{}.gpgtoml",
                                                  team_channel_name,
                                                  remote_collaborator_username);
    let expected_encrypted_output_file_path = absolute_output_directory_path.join(&expected_encrypted_output_filename);

    // ======== STEP 9: Clean up temporary files ========
    debug_log!("TCS: STEP 9 - Cleaning up temporary files");

    // Remove temporary public key file
    if let Err(e) = fs::remove_file(&temporary_remote_collaborator_public_key_file_path) {
        debug_log!("TCS: Warning - Failed to remove temporary public key file: {}", e);
        eprintln!("Warning: Failed to remove temporary public key file: {}", e);
        // Continue execution - this is not a critical error
    } else {
        debug_log!("TCS: Successfully removed temporary public key file");
    }

    // ======== STEP 10: Confirm successful completion ========
    debug_log!("TCS: STEP 10 - Confirming successful completion");

    // Verify output file exists (extra safety check)
    if !expected_encrypted_output_file_path.exists() {
        debug_log!("TCS: WARNING - Cannot find expected output file at: {}",
                   expected_encrypted_output_file_path.display());
        println!("\nProcessing completed, but cannot verify output file location.");
        println!("Please check the invites_updates/outgoing directory for the encrypted file.");
    } else {
        debug_log!("TCS: Successfully verified output file exists at: {}",
                   expected_encrypted_output_file_path.display());
        println!("\nTeam channel '{}' has been successfully shared with '{}'!",
                 team_channel_name, remote_collaborator_username);
        println!("The encrypted team channel file is saved to:");
        println!("{}", expected_encrypted_output_file_path.display());
    }

    debug_log!("TCS: Team channel sharing completed successfully");

    Ok(())
}

/// Share the Local Owner User's (LOU) address book with an existing collaborator
///
/// This function handles the secure sharing of the LOCAL OWNER USER'S address book file
/// with an existing collaborator whose information is already in the system.
///
/// Specifically, this function:
/// 1. Identifies the local owner user's address book file (their collaborator.toml)
/// 2. Retrieves the local owner user's GPG key ID for signing
/// 3. Retrieves the recipient's public GPG key for encryption
/// 4. Clearsigns the LOCAL OWNER USER'S address book file using the owner's GPG key
/// 5. Encrypts this signed file with the recipient's public key
/// 6. Saves the encrypted file to the outgoing directory for sharing
///
/// # Path Handling
/// IMPORTANT: All file and directory paths in this function are resolved relative to the
/// executable's directory location, NOT the current working directory. This ensures consistent
/// behavior regardless of where the program is executed from.
///
/// The function automatically converts all paths to absolute paths based on the executable's
/// location before performing any file operations.
///
/// # Arguments
/// * `recipient_name` - Name of the existing collaborator to share the LOCAL OWNER USER'S address book with
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
///
/// # Errors
/// * `GpgError::PathError` - If required files/directories don't exist or can't be created
/// * `GpgError::ValidationError` - If required data can't be read from configuration files
/// * `GpgError::EncryptionError` - If GPG encryption operations fail
///
/// # File Flow
/// - Source file: {EXECUTABLE_DIR}/project_graph_data/collaborator_files_address_book/{LOCAL_OWNER_USER}__collaborator.toml
/// - Output file: {EXECUTABLE_DIR}/invites_updates/outgoing/{LOCAL_OWNER_USER}__collaborator.gpgtoml
///
/// uses: constant Path to incoming public GPG key file
/// const INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR: &str = "invites_updates/incoming/key.asc";
///
/// For safe tmml handling as 'clearsign_toml', singleline and multiline fields
/// from addressbook files are read with:
/// read_singleline_string_from_clearsigntoml();
/// read_multiline_string_from_clearsigntoml();
fn share_lou_address_book_with_existingcollaborator(recipient_name: &str) -> Result<(), GpgError> {
    // 'SLABE' is an achronym for this function to idenitfy this function in logs
    debug_log("\nstarting -> SLABE share_lou_address_book_with_existingcollaborator()");
    debug_log!("SLABE Sharing LOCAL OWNER USER'S address book with existing collaborator: {}", recipient_name);

    // Create output directory using absolute path relative to executable
    let relative_output_dir = "invites_updates/outgoing";
    let absolute_output_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_output_dir)
        .map_err(|e| GpgError::PathError(format!("Failed to resolve output directory path: {}", e)))?;

    // Absolute path logging
    debug_log!("SLABE Output directory absolute path: {}", absolute_output_dir.display());
    debug_log!("SLABE Output directory exists? {}", absolute_output_dir.exists());

    // Create the output directory if it doesn't exist
    fs::create_dir_all(&absolute_output_dir)
        .map_err(|e| GpgError::PathError(format!("Failed to create output directory: {}", e)))?;

    debug_log!("SLABE Output directory created successfully? {}", absolute_output_dir.exists());
    debug_log!("SLABE absolute_output_dir {}", &absolute_output_dir.display());

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| GpgError::PathError(format!("Failed to locate uma.toml configuration file: {}", e)))?;

    debug_log!("SLABE UMA TOML absolute path: {}", absolute_uma_toml_path.display());
    debug_log!("SLABE UMA TOML file exists: {}", absolute_uma_toml_path.exists());

    // Get local owner username from configuration
    // This identifies WHICH address book we will be sharing (the LOCAL OWNER USER'S)
    // Get local owner username from configuration - REFACTORED FOR DEBUGGING
    // Convert PathBuf to string first
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| GpgError::PathError("SLABE Unable to convert UMA TOML path to string".to_string()))?;

    // Log the exact string that will be used by the TOML reader
    debug_log!("SLABE Attempting to read from UMA TOML file at path string: {}", absolute_uma_toml_path_str);

    // Now attempt to read the actual field value
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user",
    ).map_err(|e| GpgError::ValidationError(format!("SLABE Failed to read local owner username: {}", e)))?;

    debug_log!("SLABE Successfully read local_owner_user_name: {}", &local_owner_user_name);

    println!("Local owner username (whose address book we are sharing): {}", local_owner_user_name);
    debug_log!("SLABE local_owner_user_name {}", &local_owner_user_name);

    // Get absolute path to the collaborator files directory
    let relative_collab_dir = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    let absolute_collab_dir = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_collab_dir)
        .map_err(|e| GpgError::PathError(format!("Failed to locate collaborator files directory: {}", e)))?;


    ///////////////////////////////////////
    // make read-copy of .gpgtoml or .toml
    ///////////////////////////////////////

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Convert the error to GpgError
            return Err(GpgError::ValidationError(format!(
                "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            )));
        }
    };

    // Get the UME temp directory path with proper GpgError conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| GpgError::ValidationError(
            format!("Failed to get UME temp directory path: {}", io_err)
        ))?;

    // Extract the addressbook path string with proper error conversion to GpgError
    let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &local_owner_user_name,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| {
        // Convert the error to GpgError
        GpgError::ValidationError(format!(
            "Failed to get addressbook path for user '{}': {:?}",
            local_owner_user_name,
            e
        ))
    })?;

    let addressbookreadcopy_path = Path::new(&addressbook_readcopy_path_string);

    // Log the exact path string being used for TOML reading
    debug_log!("SLABE Attempting to read GPG key ID from file at path: {}", addressbook_readcopy_path_string);

    // Now attempt to read the GPG key ID field
    let owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        &addressbook_readcopy_path_string,
        "gpg_publickey_id"
    ).map_err(|e| {
        debug_log!("ERROR: SLABE Failed to read GPG key ID with field name 'gpg_key_id'");
        GpgError::ValidationError(format!("SLABE Failed to read LOCAL OWNER USER'S GPG key ID: {}", e))
    })?;

    debug_log!("SLABE Successfully read owner_gpg_key_id: {}", &owner_gpg_key_id);

    // // Get LOCAL OWNER USER'S GPG key ID - this is used to reference the private key for signing
    // // We are using the LOCAL OWNER USER'S key to sign THEIR OWN address book
    // let owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
    //     absolute_local_owner_address_book_path.to_str().ok_or_else(||
    //         GpgError::PathError("SLABE Unable to convert local owner address book path to string".to_string())
    //     )?,
    //     "gpg_key_id"
    // ).map_err(|e| GpgError::ValidationError(format!("SLABE Failed to read LOCAL OWNER USER'S GPG key ID: {}", e)))?;

    println!("LOCAL OWNER USER'S GPG key ID (for signing their address book): {}", owner_gpg_key_id);

    // TODO: this may need to be updated for read-copies and .gpgtoml option
    //
    // Path to recipient's collaborator file (absolute path)
    let recipient_collab_filename = format!("{}__collaborator.toml", recipient_name);
    let absolute_recipient_collab_path = absolute_collab_dir.join(&recipient_collab_filename);

    // Check if recipient's collaborator file exists
    if !absolute_recipient_collab_path.exists() {
        return Err(GpgError::PathError(format!(
            "Recipient's collaborator file not found at: {}",
            absolute_recipient_collab_path.display()
        )));
    }

    // Get recipient's public GPG key - this is used for encryption
    // We encrypt the LOCAL OWNER USER'S address book with the recipient's public key
    // so only they can decrypt it
    let recipient_public_gpg_key = read_multiline_string_from_clearsigntoml(
        absolute_recipient_collab_path.to_str().ok_or_else(||
            GpgError::PathError("Unable to convert recipient collaborator path to string".to_string())
        )?,
        "gpg_key_public"
    ).map_err(|e| GpgError::ValidationError(format!("Failed to read recipient's public GPG key: {}", e)))?;

    // Create a temporary file to store the recipient's public key
    // This is used by the GPG encryption process
    let temp_key_path = absolute_output_dir.join(format!("{}_pubkey.asc", recipient_name));
    fs::write(&temp_key_path, recipient_public_gpg_key)
        .map_err(|e| GpgError::PathError(format!("Failed to write temporary key file: {}", e)))?;

    println!("\nProcessing with:");
    println!("LOCAL OWNER USER'S signing key ID: {}", owner_gpg_key_id);
    println!("Recipient's public key file: {}", temp_key_path.display());
    println!(
        "LOCAL OWNER USER'S address book file to be shared: {}",
        addressbook_readcopy_path_string,
        );

    // Use our existing function to clearsign and encrypt the LOCAL OWNER USER'S address book
    // We are:
    // 1. Taking the LOCAL OWNER USER'S address book file as input
    // 2. Signing it with the LOCAL OWNER USER'S private key (via their key ID)
    // 3. Encrypting it with the recipient's public key
    clearsign_and_encrypt_file_for_recipient(
        &addressbookreadcopy_path, // THE LOCAL OWNER USER'S ADDRESS BOOK (absolute path)
        &owner_gpg_key_id,         // LOCAL OWNER USER'S KEY FOR SIGNING
        &temp_key_path,             // RECIPIENT'S PUBLIC KEY FOR ENCRYPTION (absolute path)
    )?;

    // remove temp file
    let _ = cleanup_collaborator_temp_file(
        &addressbook_readcopy_path_string,
        &base_uma_temp_directory_path,
        );

    // Clean up the temporary key file
    if let Err(e) = fs::remove_file(&temp_key_path) {
        eprintln!("Warning: Failed to remove temporary key file: {}", e);
    }

    println!("\nLOCAL OWNER USER'S address book has been clearsigned and encrypted for {}!", recipient_name);
    println!("The encrypted LOCAL OWNER USER'S address book file is saved to:");
    println!("{}", absolute_output_dir.join(format!("{}__collaborator.gpgtoml", local_owner_user_name)).display());

    println!("Press Enter to continue...");

    // this does nothing, press enter to proceed.
    let mut input = String::new();
    let _ = io::stdin()
        .read_line(&mut input)
        .map_err(|e| format!("Failed to read input: {:?}", e));


    // TODO check file exits?
    debug_log("SLABE end!, The encrypted LOCAL OWNER USER'S address book file was saved...");

    Ok(())
}

/// Prompts the user to choose between saving encrypted or clearsigned format
///
/// This function presents a choice to the user about how to save the validated
/// collaborator addressbook file. The encrypted format (.gpgtoml) is recommended
/// and is the default choice.
///
/// # Returns
/// * `Ok(true)` - User chose to keep encrypted .gpgtoml format (default/recommended)
/// * `Ok(false)` - User chose to save as clearsigned .toml (readable but not encrypted)
/// * `Err(GpgError)` - If there's an error reading user input
///
/// # Behavior
/// - Pressing Enter (empty input) selects the default encrypted format
/// - Any input starting with 'y' or 'Y' selects encrypted format
/// - Any input starting with 'n' or 'N' selects clearsigned format
/// - Any other input re-prompts the user
fn prompt_user_for_save_format_choice() -> Result<bool, GpgError> {
    loop {
        // Display the choice prompt with clear guidance
        println!("\n=== File Format Choice ===");
        println!("The incoming encrypted file has been successfully validated and verified.");
        println!("\nHow would you like to save this collaborator's addressbook?");
        println!();
        println!("  1. Keep encrypted .gpgtoml format (RECOMMENDED, DEFAULT)");
        println!("     - Maintains encryption at rest");
        println!("     - More secure storage");
        println!("     - Press Enter or type 'yes'");
        println!();
        println!("  2. Save as clearsigned .toml file");
        println!("     - Human-readable format");
        println!("     - Still signed but NOT encrypted");
        println!("     - Type 'no' to select this option");
        println!();
        println!("Choice: Press Enter for encrypted (default), or type 'clearsigned' to clearly authorized clearsigned:");

        // Read user input
        let mut user_input = String::new();
        io::stdin()
            .read_line(&mut user_input)
            .map_err(|e| {
                let error_msg = format!("Failed to read user input for format choice: {}", e);
                println!("Error: {}", error_msg);
                GpgError::ValidationError(error_msg)
            })?;

        // Trim whitespace and convert to lowercase for comparison
        let trimmed_input = user_input.trim().to_lowercase();

        // Process user choice
        match trimmed_input.as_str() {
            // Empty input (just Enter) or explicit yes = encrypted format
            "" | "y" | "yes" | "1" => {
                println!("Selected: Encrypted .gpgtoml format (recommended)");
                return Ok(true);
            },
            // Explicit no = clearsigned format
            "n" | "no" | "2" | "clearsign" | "clearsigned" => {
                println!("Selected: Clearsigned .toml format (not encrypted)");
                return Ok(false);
            },
            // Invalid input - loop again
            _ => {
                println!("Invalid choice. Please press Enter for default, or type 'no' for clearsigned.");
                continue;
            }
        }
    }
}

/// Process an incoming encrypted collaborator addressbook file
///
/// This function handles the secure processing of a GPG-encrypted clearsigned file
/// received from a collaborator. It performs the following steps:
///
/// 1. Reads the LOCAL OWNER USER's name from uma.toml
/// 2. Locates the LOCAL OWNER USER's addressbook file to extract their GPG key ID
/// 3. Finds the encrypted file in the incoming directory (must be a single .asc/.gpg file)
/// 4. Decrypts the file using the LOCAL OWNER USER's private key (identified by the key ID)
/// 5. Verifies the clearsign signature on the decrypted content
/// 6. Extracts the remote collaborator's username from the verified content
/// 7. Saves the verified clearsigned file to the collaborator addressbook directory
/// 8. Moves the original encrypted file to the processed directory
///
/// # Key Workflow Details
/// - The LOCAL OWNER USER's GPG key ID is read from their own addressbook file
/// - This key ID is needed to identify which private key to use for decryption
/// - Both decryption and signature verification must succeed for the process to complete
///
/// # File Format Options
/// After successful validation and verification, users can choose how to save the file:
///
/// * **Encrypted Format (.gpgtoml)** - DEFAULT/RECOMMENDED
///   - Keeps the original GPG-encrypted file as received
///   - Maintains encryption at rest for better security
///   - File remains encrypted with the recipient's public key
///   - Saved as: `{REMOTE_COLLABORATOR}__collaborator.gpgtoml`
///
/// * **Clearsigned Format (.toml)** - OPTIONAL
///   - Extracts and saves the clearsigned TOML content
///   - Human-readable but NOT encrypted
///   - Still contains GPG signature for authenticity
///   - Saved as: `{REMOTE_COLLABORATOR}__collaborator.toml`
///
/// The choice is presented after verification succeeds. Pressing Enter selects
/// the default encrypted format for maximum security.
///
/// # Path Handling
/// All file and directory paths are resolved relative to the executable's directory location,
/// NOT the current working directory. This ensures consistent behavior regardless of where
/// the program is executed from.
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
///
/// # Errors
/// * `GpgError::PathError` - If required files/directories don't exist or can't be accessed
/// * `GpgError::ValidationError` - If signature verification fails or required data is missing
/// * `GpgError::GpgOperationError` - If GPG decryption or verification operations fail
///
/// # File Flow
/// - LOCAL OWNER USER's addressbook: {EXECUTABLE_DIR}/project_graph_data/collaborator_files_address_book/{LOCAL_OWNER_USER}__collaborator.toml
/// - Source encrypted file: {EXECUTABLE_DIR}/invites_updates/incoming/*.asc or *.gpg
/// - Output file: {EXECUTABLE_DIR}/project_graph_data/collaborator_files_address_book/{REMOTE_COLLABORATOR}__collaborator.toml
/// - Moved original: {EXECUTABLE_DIR}/invites_updates/processed/{original_filename}
pub fn process_incoming_encrypted_collaborator_addressbook() -> Result<(), GpgError> {
    // 'PIECA' is an acronym for this function to identify it in logs
    debug_log("\nstarting -> PIECA fn process_incoming_encrypted_collaborator_addressbook()");

    // STEP 1: Get LOCAL OWNER USER's name from uma.toml
    // This identifies which addressbook file contains our GPG key ID
    debug_log!(
        "PIECA Step 1: Reading LOCAL OWNER USER's name from {}",
        UMA_TOML_CONFIGFILE_PATH_STR
    );

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIECA Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read LOCAL OWNER USER's name from uma.toml
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("PIECA Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIECA LOCAL OWNER USER's name is: {}", local_owner_user_name);
    println!("Processing as LOCAL OWNER USER: {}", local_owner_user_name);

    // STEP 2: Locate the LOCAL OWNER USER's addressbook file and extract their GPG key ID
    debug_log!("PIECA Step 2: Locating LOCAL OWNER USER's addressbook file to get GPG key ID");

    // Get absolute path to the collaborator files directory
    let relative_collab_dir = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    let absolute_addressbook_directory_pathbuf = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_collab_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to locate collaborator files directory: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // // Path to the LOCAL OWNER USER's addressbook file (absolute path)
    // let local_owner_address_book_filename = format!("{}__collaborator.toml", local_owner_user_name);
    // let absolute_local_owner_address_book_path = absolute_collab_dir.join(&local_owner_address_book_filename);

    // Check for both file types
    let toml_path = absolute_addressbook_directory_pathbuf
        .join(format!("{}__collaborator.toml", local_owner_user_name));
    let gpgtoml_path = absolute_addressbook_directory_pathbuf
        .join(format!("{}__collaborator.gpgtoml", local_owner_user_name));

    // Determine which file exists and use that path
    let raw_addressbook_path = if toml_path.exists() {
        // Prefer plain .toml if both exist
        toml_path
    } else if gpgtoml_path.exists() {
        gpgtoml_path
    } else {
        // Neither exists, skip this directory
        #[cfg(debug_assertions)]
        debug_log!(
            "Skipping directory (no node.toml or node.gpgtoml): {:?}",
            &absolute_addressbook_directory_pathbuf
        );
        return Err(GpgError::PathError(format!(
            "CAPITCCV Err Invalid path encoding for addressbook file: {}",
            absolute_addressbook_directory_pathbuf.display()
        )));
    };


    debug_log!("PIECA LOCAL OWNER USER's addressbook path: {}", raw_addressbook_path.display());

    // Verify the LOCAL OWNER USER's addressbook file exists
    if !raw_addressbook_path.exists() {
        let error_msg = format!(
            "PIECA LOCAL OWNER USER's addressbook file not found at: {}",
            raw_addressbook_path.display()
        );
        println!("Error: {}", error_msg);
        return Err(GpgError::PathError(error_msg));
    }

    debug_log!("PIECA LOCAL OWNER USER's addressbook file exists");

    // // Convert the LOCAL OWNER USER's addressbook path to string for TOML reading
    // let absolute_local_owner_address_book_path_str = raw_addressbook_path
    //     .to_str()
    //     .ok_or_else(|| {
    //         let error_msg = format!(
    //             "PIECA Unable to convert LOCAL OWNER USER's addressbook path to string: {}",
    //             raw_addressbook_path.display()
    //         );
    //         println!("Error: {}", error_msg);
    //         GpgError::PathError(error_msg)
    //     })?;


    // Get GPG fingerprint (could move this outside the loop if same for all)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "SLABIK error Failed to read GPG fingerprint for: {} (skipping)",
                e
            );
            // continue; // Skip this directory, continue with next
            return Err(GpgError::PathError(
                "SLABIK error gpg_full_fingerprint_key_id_string".to_string()));
        }
    };

    // Get temp directory path (could move this outside the loop if same for all)
    let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
        Ok(path) => path,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "SLABIK error Failed to get temp directory path: {} (skipping)",
                e
            );
            return Err(GpgError::PathError(
                "SLABIK error get_base_uma_temp_directory_path".to_string()));
        }
    };

    // Get readable copy
    let specific_readcopy_addressbook_path = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &raw_addressbook_path,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ) {
        Ok(path) => path,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "CAPITCCV Failed to get read copy for {:?}: {:?} (skipping)",
                raw_addressbook_path,
                e
            );
            return Err(GpgError::PathError(
                "SLABIK error get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml".to_string()));
        }
    };

    // Read the LOCAL OWNER USER's GPG key ID from their addressbook file
    // This is the key ID needed to identify which private key to use for decryption
    debug_log!("PIECA Attempting to read GPG key ID from LOCAL OWNER USER's addressbook file");

    let local_owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        &specific_readcopy_addressbook_path,
        "gpg_publickey_id"
    ).map_err(|e| {
        let error_msg = format!("PIECA Failed to read LOCAL OWNER USER's GPG key ID: {}", e);
        debug_log!("ERROR: {}", error_msg);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIECA Successfully read LOCAL OWNER USER's GPG key ID: {}", local_owner_gpg_key_id);

    // STEP 3: Find the encrypted file in the incoming directory
    debug_log!("PIECA Step 3: Locating encrypted file in incoming directory");

    // Resolve the incoming directory path (relative to executable)
    let relative_incoming_dir = "invites_updates/incoming";
    let absolute_incoming_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_incoming_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to resolve incoming directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    debug_log!("PIECA Scanning for encrypted files in: {}", absolute_incoming_dir.display());

    // Loop until we find exactly one .asc or .gpg file, or user cancels
    let encrypted_file_path = loop {
        // Scan the directory for .asc or .gpg files
        let mut encrypted_files = Vec::new();

        match fs::read_dir(&absolute_incoming_dir) {
            Ok(entries) => {
                for entry in entries {
                    if let Ok(entry) = entry {
                        let path = entry.path();
                        if path.is_file() {
                            if let Some(extension) = path.extension() {
                                if extension == "asc" || extension == "gpg" {
                                    encrypted_files.push(path);
                                }
                            }
                        }
                    }
                }
            },
            Err(e) => {
                let error_msg = format!("PIECA Failed to read incoming directory: {}", e);
                println!("Error: {}", error_msg);
                return Err(GpgError::PathError(error_msg));
            }
        }

        // Process based on how many files were found
        match encrypted_files.len() {
            0 => {
                println!("No encrypted files (.asc or .gpg) found in {}", absolute_incoming_dir.display());
                println!("Please place the encrypted collaborator file in this directory.");
                println!("Press Enter to try again, or type 'exit' to cancel.");

                let mut input = String::new();
                if let Err(e) = io::stdin().read_line(&mut input) {
                    let error_msg = format!("PIECA Failed to read user input: {}", e);
                    println!("Error: {}", error_msg);
                    return Err(GpgError::ValidationError(error_msg));
                }

                if input.trim().to_lowercase() == "exit" {
                    return Err(GpgError::ValidationError("Operation cancelled by user".to_string()));
                }

                // Loop continues to check again
            },
            1 => {
                // Exactly one file found, we can proceed
                debug_log!("PIECA Found one encrypted file: {}", encrypted_files[0].display());
                println!("Found encrypted file: {}", encrypted_files[0].display());
                break encrypted_files[0].clone();
            },
            _ => {
                println!("Multiple encrypted files found in {}:", absolute_incoming_dir.display());
                for (index, file) in encrypted_files.iter().enumerate() {
                    println!("  {}. {}", index + 1, file.file_name().unwrap_or_default().to_string_lossy());
                }
                println!("Please keep only the file you want to process and remove the others.");
                println!("Press Enter to try again, or type 'exit' to cancel.");

                let mut input = String::new();
                if let Err(e) = io::stdin().read_line(&mut input) {
                    let error_msg = format!("PIECA Failed to read user input: {}", e);
                    println!("Error: {}", error_msg);
                    return Err(GpgError::ValidationError(error_msg));
                }

                if input.trim().to_lowercase() == "exit" {
                    return Err(GpgError::ValidationError("Operation cancelled by user".to_string()));
                }

                // Loop continues to check again
            }
        }
    };

    // Extract the filename for later use
    let encrypted_filename = encrypted_file_path.file_name()
        .ok_or_else(|| {
            let error_msg = "PIECA Failed to extract filename from encrypted file path".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?
        .to_string_lossy()
        .to_string();

    debug_log!("PIECA Processing encrypted file: {}", encrypted_filename);

    // STEP 4: Create processed directory for moving files after processing
    debug_log!("PIECA Step 4: Setting up processed directory");

    let relative_processed_dir = "invites_updates/processed";
    let absolute_processed_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_processed_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to resolve processed directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Create the processed directory if it doesn't exist
    fs::create_dir_all(&absolute_processed_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to create processed directory: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // STEP 5: Set up temporary directory for processing
    debug_log!("PIECA Step 5: Setting up temporary directory for decryption and verification");

    let temp_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck("temp_gpg_processing")
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to create temp directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    fs::create_dir_all(&temp_dir)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to create temp directory: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Temporary file to hold decrypted and clearsigned content
    let temp_clearsigned_path = temp_dir.join("temp_clearsigned.toml");

    // STEP 6: Decrypt and verify the signature using the LOCAL OWNER USER's key
    debug_log!("PIECA Step 6: Decrypting file and verifying signature");
    println!("Decrypting file using LOCAL OWNER USER's key ID: {}", local_owner_gpg_key_id);
    println!("and verifying signature...");

    // Call the function that does GPG decryption and verification
    // This uses the LOCAL OWNER USER's key ID to identify which private key to use
    let decrypt_result = extract_verify_store_gpg_encrypted_clearsign_toml(
        &encrypted_file_path,
        &local_owner_gpg_key_id,
        &temp_clearsigned_path
    );

    // maybe step here to gpg if flag?

    if let Err(e) = &decrypt_result {
        let error_msg = format!("PIECA Failed to decrypt or verify file: {:?}", e);
        println!("Error: {}", error_msg);
        println!("This could mean:");
        println!("1. The file is not properly encrypted or signed");
        println!("2. The file wasn't encrypted for your GPG key");
        println!("3. You don't have the sender's public key in your keyring");

        // Clean up temp directory before returning
        if let Err(clean_err) = fs::remove_dir_all(&temp_dir) {
            debug_log!("PIECA Warning: Failed to remove temporary directory: {}", clean_err);
        }

        return Err(GpgError::GpgOperationError(error_msg));
    }

    println!("File successfully decrypted and signature verified!");
    debug_log!("PIECA Successfully decrypted and verified file");

    // // STEP 7: Extract collaborator username from the verified content
    // debug_log!("PIECA Step 7: Extracting collaborator username from verified content");

    // // Convert temporary file path to string for TOML reading
    // let temp_clearsigned_path_str = temp_clearsigned_path
    //     .to_str()
    //     .ok_or_else(|| {
    //         let error_msg = "PIECA Unable to convert temp file path to string".to_string();
    //         println!("Error: {}", error_msg);
    //         GpgError::PathError(error_msg)
    //     })?;

    // // Read the username from the clearsigned TOML
    // // This is the remote collaborator whose addressbook we just received
    // let remote_collaborator_username = read_singleline_string_from_clearsigntoml(
    //     temp_clearsigned_path_str,
    //     "user_name"
    // ).map_err(|e| {
    //     let error_msg = format!("PIECA Failed to read remote collaborator's username: {}", e);
    //     println!("Error: {}", error_msg);
    //     println!("The decrypted file doesn't contain a valid 'user_name' field.");
    //     GpgError::ValidationError(error_msg)
    // })?;

    // debug_log!("PIECA Extracted remote collaborator's username: {}", remote_collaborator_username);
    // println!("Received addressbook from collaborator: {}", remote_collaborator_username);

    // // STEP 8: Save the verified clearsigned file to the collaborator directory
    // debug_log!("PIECA Step 8: Saving verified clearsigned file to collaborator directory");

    // // Create the output filename using the extracted username
    // let output_filename = format!("{}__collaborator.toml", remote_collaborator_username);
    // let output_file_path = absolute_collab_dir.join(&output_filename);

    // debug_log!("PIECA Saving verified clearsigned file to: {}", output_file_path.display());

    // // Copy the verified clearsigned file to the collaborator directory
    // fs::copy(&temp_clearsigned_path, &output_file_path)
    //     .map_err(|e| {
    //         let error_msg = format!("PIECA Failed to save verified clearsigned file: {}", e);
    //         println!("Error: {}", error_msg);
    //         GpgError::GpgOperationError(error_msg)
    //     })?;

    // println!("Successfully saved collaborator addressbook to: {}", output_file_path.display());

    // STEP 7: Extract collaborator username from the verified content
    debug_log!("PIECA Step 7: Extracting collaborator username from verified content");

    // Convert temporary file path to string for TOML reading
    let temp_clearsigned_path_str = temp_clearsigned_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIECA Unable to convert temp file path to string".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read the username from the clearsigned TOML
    // This is the remote collaborator whose addressbook we just received
    let remote_collaborator_username = read_singleline_string_from_clearsigntoml(
        temp_clearsigned_path_str,
        "user_name"
    ).map_err(|e| {
        let error_msg = format!("PIECA Failed to read remote collaborator's username: {}", e);
        println!("Error: {}", error_msg);
        println!("The decrypted file doesn't contain a valid 'user_name' field.");
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIECA Extracted remote collaborator's username: {}", remote_collaborator_username);
    println!("Received addressbook from collaborator: {}", remote_collaborator_username);

    // STEP 7.5: Ask user for preferred save format
    debug_log!("PIECA Step 7.5: Prompting user for save format preference");

    let save_encrypted_format = prompt_user_for_save_format_choice()
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to get user format choice: {}", e);
            println!("Error: {}", error_msg);
            e
        })?;

    // STEP 8: Save the file in the user's chosen format
    debug_log!("PIECA Step 8: Saving file in {} format to collaborator directory",
              if save_encrypted_format { "encrypted .gpgtoml" } else { "clearsigned .toml" });

    // Create the output filename based on user's choice
    let output_filename = if save_encrypted_format {
        // User chose to keep the encrypted format
        format!("{}__collaborator.gpgtoml", remote_collaborator_username)
    } else {
        // User chose clearsigned format (current behavior)
        format!("{}__collaborator.toml", remote_collaborator_username)
    };

    let output_file_path = absolute_addressbook_directory_pathbuf.join(&output_filename);

    debug_log!("PIECA Saving file to: {}", output_file_path.display());

    // Save the file based on user's choice
    if save_encrypted_format {
        // Copy the original encrypted file directly (it's already been validated)
        debug_log!("PIECA Copying original encrypted .gpgtoml file");
        fs::copy(&encrypted_file_path, &output_file_path)
            .map_err(|e| {
                let error_msg = format!("PIECA Failed to save encrypted .gpgtoml file: {}", e);
                println!("Error: {}", error_msg);
                GpgError::GpgOperationError(error_msg)
            })?;
        println!("Successfully saved encrypted collaborator addressbook to: {}", output_file_path.display());
    } else {
        // Copy the verified clearsigned file (original behavior)
        debug_log!("PIECA Copying extracted clearsigned .toml file");
        fs::copy(&temp_clearsigned_path, &output_file_path)
            .map_err(|e| {
                let error_msg = format!("PIECA Failed to save clearsigned .toml file: {}", e);
                println!("Error: {}", error_msg);
                GpgError::GpgOperationError(error_msg)
            })?;
        println!("Successfully saved clearsigned collaborator addressbook to: {}", output_file_path.display());
    }

    // STEP 9: Move the original encrypted file to the processed directory
    debug_log!("PIECA Step 9: Moving original encrypted file to processed directory");

    let processed_file_path = absolute_processed_dir.join(&encrypted_filename);

    debug_log!("PIECA Moving original encrypted file to: {}", processed_file_path.display());

    // Use fs::rename to move the file
    fs::rename(&encrypted_file_path, &processed_file_path)
        .map_err(|e| {
            let error_msg = format!("PIECA Failed to move original encrypted file: {}", e);
            println!("Warning: {}", error_msg);
            GpgError::GpgOperationError(error_msg)
        })?;

    println!("Original encrypted file moved to: {}", processed_file_path.display());

    // STEP 10: Clean up the temporary directory
    debug_log!("PIECA Step 10: Cleaning up temporary directory");

    if let Err(e) = fs::remove_dir_all(&temp_dir) {
        debug_log!("PIECA Warning: Failed to remove temporary directory: {}", e);
    }

    debug_log!("PIECA Successfully processed addressbook from collaborator: {}", remote_collaborator_username);
    println!("Successfully processed addressbook from collaborator: {}", remote_collaborator_username);

    println!("Press Enter to continue...");

    // this does nothing, press enter to proceed.
    let mut input = String::new();
    let _ = io::stdin()
        .read_line(&mut input)
        .map_err(|e| format!("Failed to read input: {:?}", e));

    // OK!
    debug_log("PIECA PIECA!!");

    Ok(())
}

/// Share the Local Owner User's (LOU) address book with a new collaborator using their incoming key
///
/// This function handles the secure sharing of the LOCAL OWNER USER'S address book file
/// with a new collaborator whose public GPG key has been placed in the incoming directory.
///
/// Specifically, this function:
/// 1. Identifies the local owner user's address book file (their collaborator.toml)
/// 2. Retrieves the local owner user's GPG key ID for signing
/// 3. Uses the recipient's public key from the incoming directory for encryption
/// 4. Clearsigns the LOCAL OWNER USER'S address book file using the owner's GPG key
/// 5. Encrypts this signed file with the recipient's public key
/// 6. Saves the encrypted file to the outgoing directory for sharing
///
/// # Path Handling
/// IMPORTANT: All file and directory paths in this function are resolved relative to the
/// executable's directory location, NOT the current working directory. This ensures consistent
/// behavior regardless of where the program is executed from.
///
/// The function automatically converts all paths to absolute paths based on the executable's
/// location before performing any file operations.
///
/// This process differs from sharing with an existing collaborator because it uses
/// a public key file provided externally rather than one already in the address book.
///
/// This enables secure sharing of contact information while ensuring:
/// - The recipient can verify the file came from the claimed sender (via signature)
/// - Only the intended recipient can decrypt the file (via their public key encryption)
///
/// # Arguments
/// * `recipient_name` - Name of the new collaborator to share the LOCAL OWNER USER'S address book with
///                      (used for labeling purposes only, as their info isn't in the system yet)
///
/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
///
/// # Errors
/// * `GpgError::PathError` - If required files/directories don't exist or can't be created
/// * `GpgError::ValidationError` - If required data can't be read from configuration files
/// * `GpgError::EncryptionError` - If GPG encryption operations fail
///
/// # File Flow
/// - Source file: {EXECUTABLE_DIR}/project_graph_data/collaborator_files_address_book/{LOCAL_OWNER_USER}__collaborator.toml
/// - Recipient key: {EXECUTABLE_DIR}/invites_updates/incoming/key.asc (must be placed there before calling this function)
/// - Output file: {EXECUTABLE_DIR}/invites_updates/outgoing/{LOCAL_OWNER_USER}__collaborator.gpgtoml
///
/// # Dependencies
/// - Uses constant INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR for the location of the incoming key
/// - For safe toml handling as 'clearsign_toml', fields from addressbook files are read with:
///   - read_singleline_string_from_clearsigntoml() for single-line fields
///   - read_multiline_string_from_clearsigntoml() for multi-line fields
fn share_lou_addressbook_with_incomingkey() -> Result<(), GpgError> {
    println!("\nSharing LOCAL OWNER USER'S address book with new collaborator.");
    println!("Using their public key from incoming directory");
    debug_log("\nstarting -> SLABIK fn share_lou_addressbook_with_incomingkey()");

    // Create output directory using absolute path relative to executable
    let relative_output_dir = "invites_updates/outgoing";
    let absolute_output_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_output_dir)
        .map_err(|e| GpgError::PathError(format!("SLABIK Failed to resolve output directory path: {}", e)))?;

    debug_log!("SLABIK Output directory absolute path: {}", absolute_output_dir.display());
    debug_log!("SLABIK Output directory exists? {}", absolute_output_dir.exists());

    // Create the output directory if it doesn't exist
    fs::create_dir_all(&absolute_output_dir)
        .map_err(|e| GpgError::PathError(format!("Failed to create output directory: {}", e)))?;

    debug_log!("SLABIK Output directory created successfully? {}", absolute_output_dir.exists());

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| GpgError::PathError(format!("SLABIK Failed to locate uma.toml configuration file: {}", e)))?;

    debug_log!("SLABIK UMA TOML absolute path: {}", absolute_uma_toml_path.display());
    debug_log!("SLABIK UMA TOML file exists: {}", absolute_uma_toml_path.exists());

    // Get local owner username from configuration - REFACTORED FOR DEBUGGING
    // Convert PathBuf to string first
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| GpgError::PathError("SLABIK Unable to convert UMA TOML path to string".to_string()))?;

    // Log the exact string that will be used by the TOML reader
    debug_log!("SLABIK Attempting to read from UMA TOML file at path string: {}", absolute_uma_toml_path_str);

    // Now attempt to read the actual field value
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| GpgError::ValidationError(format!("Failed to read local owner username: {}", e)))?;

    debug_log!("SLABIK Successfully read local_owner_user_name: {}", &local_owner_user_name);
    println!("Local owner username (whose address book we are sharing): {}", local_owner_user_name);

    let absolute_addressbook_directory_pathbuf = match get_addressbook_directory_path() {
        Ok(path) => path,
        Err(e) => {
            debug_log!("CAPITCCV Failed to get absolute path: {}", e);

            return Err(GpgError::PathError(
                "SLABIK absolute_addressbook_directory_pathbuf not found".to_string()));
        }
    };

    // Check for both file types
    let toml_path = absolute_addressbook_directory_pathbuf
        .join(format!("{}__collaborator.toml", local_owner_user_name));
    let gpgtoml_path = absolute_addressbook_directory_pathbuf
        .join(format!("{}__collaborator.gpgtoml", local_owner_user_name));

    // Determine which file exists and use that path
    let raw_addressbook_path = if toml_path.exists() {
        // Prefer plain .toml if both exist
        toml_path
    } else if gpgtoml_path.exists() {
        gpgtoml_path
    } else {
        // Neither exists, skip this directory
        #[cfg(debug_assertions)]
        debug_log!(
            "Skipping directory (no node.toml or node.gpgtoml): {:?}",
            &absolute_addressbook_directory_pathbuf
        );
        return Err(GpgError::PathError(format!(
            "CAPITCCV Err Invalid path encoding for addressbook file: {}",
            absolute_addressbook_directory_pathbuf.display()
        )));
    };

    // Get GPG fingerprint (could move this outside the loop if same for all)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "SLABIK error Failed to read GPG fingerprint for: {} (skipping)",
                e
            );
            // continue; // Skip this directory, continue with next
            return Err(GpgError::PathError(
                "SLABIK error gpg_full_fingerprint_key_id_string".to_string()));
        }
    };

    // Get temp directory path (could move this outside the loop if same for all)
    let base_uma_temp_directory_path = match get_base_uma_temp_directory_path() {
        Ok(path) => path,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "SLABIK error Failed to get temp directory path: {} (skipping)",
                e
            );
            return Err(GpgError::PathError(
                "SLABIK error get_base_uma_temp_directory_path".to_string()));
        }
    };

    // Get readable copy
    let specific_readcopy_addressbook_path = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &raw_addressbook_path,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ) {
        Ok(path) => path,
        Err(e) => {
            #[cfg(debug_assertions)]
            debug_log!(
                "CAPITCCV Failed to get read copy for {:?}: {:?} (skipping)",
                raw_addressbook_path,
                e
            );
            return Err(GpgError::PathError(
                "SLABIK error get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml".to_string()));
        }
    };

    debug_log!("SLABIK Absolute local owner address book path: {}", specific_readcopy_addressbook_path);

    // Log the exact path string being used for TOML reading
    debug_log!("SLABIK Attempting to read GPG key ID from file at path: {}", specific_readcopy_addressbook_path);

    // Now attempt to read the GPG key ID field
    let owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        &specific_readcopy_addressbook_path,
        "gpg_publickey_id"
    ).map_err(|e| {
        debug_log!("ERROR: SLABIK Failed to read GPG key ID with field name 'gpg_publickey_id'");
        GpgError::ValidationError(format!("SLABIK Failed to read LOCAL OWNER USER'S GPG key ID: {}", e))
    })?;

    debug_log!("SLABIK Successfully read owner_gpg_key_id: {}", &owner_gpg_key_id);
    println!("LOCAL OWNER USER'S GPG key ID (for signing their address book): {}", owner_gpg_key_id);

    // Path to recipient's public key file in the incoming directory with absolute path
    let relative_incoming_key_path = INCOMING_PUBLICGPG_KEYASC_FILEPATH_STR;
    println!("SLABIK relative_incoming_key_path {}", relative_incoming_key_path);


    let absolute_recipient_public_key_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_incoming_key_path)
        .map_err(|e| GpgError::PathError(format!(
            "SLABIK Recipient's public key not found at: {} - Error: {}",
            relative_incoming_key_path, e
        )))?;

    debug_log!("SLABIK Absolute recipient public key path: {}", absolute_recipient_public_key_path.display());
    debug_log!("SLABIK Recipient public key file exists: {}", absolute_recipient_public_key_path.exists());

    println!("\nProcessing with:");
    println!("LOCAL OWNER USER'S signing key ID: {}", owner_gpg_key_id);
    println!("Recipient's public key file: {}", absolute_recipient_public_key_path.display());
    println!("LOCAL OWNER USER'S address book file to be shared: {}", specific_readcopy_addressbook_path);

    let path_addressbook_path = Path::new(&specific_readcopy_addressbook_path);


    // Use our existing function to clearsign and encrypt the LOCAL OWNER USER'S address book
    // We are:
    // 1. Taking the LOCAL OWNER USER'S address book file as input
    // 2. Signing it with the LOCAL OWNER USER'S private key (via their key ID)
    // 3. Encrypting it with the recipient's public key from the incoming directory
    clearsign_and_encrypt_file_for_recipient(
        &path_addressbook_path,   // THE LOCAL OWNER USER'S ADDRESS BOOK (absolute path)
        &owner_gpg_key_id,                        // LOCAL OWNER USER'S KEY FOR SIGNING
        &absolute_recipient_public_key_path       // RECIPIENT'S PUBLIC KEY FOR ENCRYPTION (absolute path)
    )?;

    // Get the output file path for display
    let absolute_output_file_path = absolute_output_dir.join(format!("{}__collaborator.gpgtoml", local_owner_user_name));

    println!("\nLOCAL OWNER USER'S address book has been clearsigned and encrypted.");
    println!("The encrypted LOCAL OWNER USER'S address book file is saved to:");
    println!("{}", absolute_output_file_path.display());

    println!("\nImportant: After sending this file to the recipient, you may want to add them");
    println!("to your address book using their public key from: {}", absolute_recipient_public_key_path.display());

    println!("Press Enter to continue...");
    // this does nothing, press enter to proceed.
    let mut input = String::new();
    let _ = io::stdin()
        .read_line(&mut input)
        .map_err(|e| format!("Failed to read input: {:?}", e));

    debug_log!("\nSLABIK  Completed fn share_lou_addressbook_with_incomingkey() successfully");
    Ok(())
}

/// Process an incoming encrypted team channel file
///
/// This function handles the secure processing of a GPG-encrypted clearsigned team channel file
/// received from a remote collaborator. It performs the following steps:
///
/// 1. Reads the LOCAL OWNER USER's name from uma.toml
/// 2. Locates the LOCAL OWNER USER's addressbook file to extract their GPG key ID
/// 3. Finds the encrypted file in the incoming teamchannels directory (must be a single .asc/.gpg file)
/// 4. Decrypts the file using the LOCAL OWNER USER's private key (identified by the key ID)
/// 5. Extracts the team channel owner's name from the decrypted content
/// 6. Locates the team channel owner's addressbook file to extract their GPG public key
/// 7. Verifies the clearsign signature using the team channel owner's public key
/// 8. Extracts the team channel name from the verified content
/// 9. Creates the team channel directory structure and prompts for save format
/// 10. Saves the team channel file in the user's chosen format (encrypted or clearsigned)
/// 11. Moves the original encrypted file to the processed directory
///
/// # Path Handling
/// All file and directory paths are resolved relative to the executable's directory location,
/// NOT the current working directory. This ensures consistent behavior regardless of where
/// the program is executed from.
///
/// # File Format Options
/// After successful validation and verification, users can choose how to save the team channel file:
///
/// * **Encrypted Format (node.gpgtoml)** - DEFAULT/RECOMMENDED
///   - Keeps the original GPG-encrypted file as received
///   - Maintains encryption at rest for better security
///   - File remains encrypted with the recipient's public key
///   - Saved as: `{TEAM_CHANNEL_NAME}/node.gpgtoml`
///
/// * **Clearsigned Format (node.toml)** - OPTIONAL
///   - Saves the clearsigned TOML content
///   - Human-readable but NOT encrypted
///   - Still contains GPG signature for authenticity
///   - Saved as: `{TEAM_CHANNEL_NAME}/node.toml`
///
/// The choice is presented after verification succeeds. Pressing Enter selects
/// the default encrypted format for maximum security. Only one file format is saved
/// based on the user's choice (unlike earlier versions that saved both).
///

/// # Returns
/// * `Ok(())` if the operation succeeds
/// * `Err(GpgError)` if any operation fails
///
/// # Errors
/// * `GpgError::PathError` - If required files/directories don't exist or can't be accessed
/// * `GpgError::ValidationError` - If signature verification fails or required data is missing
/// * `GpgError::GpgOperationError` - If GPG decryption or verification operations fail
pub fn process_incoming_encrypted_teamchannel() -> Result<(), GpgError> {
    // 'PIET' is an acronym for this function to identify it in logs
    debug_log!("\nStarting -> PIET fn process_incoming_encrypted_teamchannel()");

    // STEP 1: Get LOCAL OWNER USER's name from uma.toml
    debug_log!("
        PIET Step 1: Reading LOCAL OWNER USER's name from {}",
        UMA_TOML_CONFIGFILE_PATH_STR,
    );

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIET Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read LOCAL OWNER USER's name from uma.toml
    let local_owner_user_name = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("PIET Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIET LOCAL OWNER USER's name is: {}", local_owner_user_name);
    println!("Processing as LOCAL OWNER USER: {}", local_owner_user_name);

    // STEP 2: Locate the LOCAL OWNER USER's addressbook file and extract their GPG key ID
    debug_log!("PIET Step 2: Locating LOCAL OWNER USER's addressbook file to get GPG key ID");

    // // Get absolute path to the collaborator files directory
    // let relative_collab_dir = COLLABORATOR_ADDRESSBOOK_PATH_STR;
    // let absolute_collab_dir = make_dir_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_collab_dir)
    //     .map_err(|e| {
    //         let error_msg = format!("PIET Failed to locate collaborator files directory: {}", e);
    //         println!("Error: {}", error_msg);
    //         GpgError::PathError(error_msg)
    //     })?;

    // // Path to the LOCAL OWNER USER's addressbook file (absolute path)
    // let local_owner_address_book_filename = format!("{}__collaborator.toml", local_owner_user_name);
    // let absolute_local_owner_address_book_path = absolute_collab_dir.join(&local_owner_address_book_filename);

    // debug_log!("PIET LOCAL OWNER USER's addressbook path: {}", absolute_local_owner_address_book_path.display());

    // // Verify the LOCAL OWNER USER's addressbook file exists
    // if !absolute_local_owner_address_book_path.exists() {
    //     let error_msg = format!(
    //         "PIET LOCAL OWNER USER's addressbook file not found at: {}",
    //         absolute_local_owner_address_book_path.display()
    //     );
    //     println!("Error: {}", error_msg);
    //     return Err(GpgError::PathError(error_msg));
    // }

    // debug_log!("PIET LOCAL OWNER USER's addressbook file exists");

    // // Convert the LOCAL OWNER USER's addressbook path to string for TOML reading
    // let absolute_local_owner_address_book_path_str = absolute_local_owner_address_book_path
    //     .to_str()
    //     .ok_or_else(|| {
    //         let error_msg = format!(
    //             "PIET Unable to convert LOCAL OWNER USER's addressbook path to string: {}",
    //             absolute_local_owner_address_book_path.display()
    //         );
    //         println!("Error: {}", error_msg);
    //         GpgError::PathError(error_msg)
    //     })?;

    let absolute_addressbook_directory_pathbuf = match get_addressbook_directory_path() {
        Ok(path) => path,
        Err(e) => {
            debug_log!("PIET Failed to get absolute path: {}", e);
            return Err(GpgError::GpgOperationError(format!(
                "PIET error Failed absolute_addressbook_directory_pathbuf: {}",
                e
            )));
        }
    };

    // Check for both file types
    let toml_path = absolute_addressbook_directory_pathbuf
        .join(format!("{}__collaborator.toml", local_owner_user_name));
    let gpgtoml_path = absolute_addressbook_directory_pathbuf
        .join(format!("{}__collaborator.gpgtoml", local_owner_user_name));

    // Determine which file exists and use that path
    let raw_addressbook_path = if toml_path.exists() {
        // Prefer plain .toml if both exist
        toml_path
    } else if gpgtoml_path.exists() {
        gpgtoml_path
    } else {
        // Neither exists, skip this directory
        #[cfg(debug_assertions)]
        debug_log!(
            "PIET Skipping directory (no node.toml or node.gpgtoml): {:?}",
            &absolute_addressbook_directory_pathbuf
        );
        return Err(GpgError::GpgOperationError(format!(
            "PIET Err Invalid path encoding for addressbook file: {}",
            absolute_addressbook_directory_pathbuf.display()
        )));
    };


    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(GpgError::GpgOperationError(format!(
                "PIET: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            )));
        }
    };

    // Get the UME temp directory path with explicit String conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|e| {
            let error_msg = format!("PIET Failed to resolve incoming teamchannels directory path: {}", e);
            println!("PIET Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;


    // Get readable copy
    let specific_readcopy_addressbook_path = match get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &raw_addressbook_path,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ) {
        Ok(path) => path,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(GpgError::GpgOperationError(format!(
                "PIET: specific_readcopy_addressbook_path: {}",
                e
            )));
        }
    };


    // Read the LOCAL OWNER USER's GPG key ID from their addressbook file
    debug_log!("PIET Attempting to read GPG key ID from LOCAL OWNER USER's addressbook file");

    let local_owner_gpg_key_id = read_singleline_string_from_clearsigntoml(
        &specific_readcopy_addressbook_path,
        "gpg_publickey_id"
    ).map_err(|e| {
        let error_msg = format!("PIET Failed to read LOCAL OWNER USER's GPG key ID: {}", e);
        debug_log!("ERROR: {}", error_msg);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIET Successfully read LOCAL OWNER USER's GPG key ID: {}", local_owner_gpg_key_id);

    // STEP 3: Find the encrypted file in the incoming teamchannels directory
    debug_log!("PIET Step 3: Locating encrypted file in incoming teamchannels directory");

    // Resolve the incoming teamchannels directory path (relative to executable)
    let relative_incoming_dir = "invites_updates/incoming";
    let absolute_incoming_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_incoming_dir)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to resolve incoming teamchannels directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Create the directory if it doesn't exist
    if let Err(e) = fs::create_dir_all(&absolute_incoming_dir) {
        let error_msg = format!("PIET Failed to create incoming teamchannels directory: {}", e);
        println!("Error: {}", error_msg);
        return Err(GpgError::GpgOperationError(error_msg));
    }

    debug_log!("PIET Scanning for encrypted files in: {}", absolute_incoming_dir.display());

    // Loop until we find exactly one .asc or .gpg file, or user cancels
    let encrypted_file_path = loop {
        // Scan the directory for .asc or .gpg files
        let mut encrypted_files = Vec::new();

        match fs::read_dir(&absolute_incoming_dir) {
            Ok(entries) => {
                for entry in entries {
                    if let Ok(entry) = entry {
                        let path = entry.path();
                        if path.is_file() {
                            if let Some(extension) = path.extension() {
                                if extension == "asc" || extension == "gpg" {
                                    encrypted_files.push(path);
                                }
                            }
                        }
                    }
                }
            },
            Err(e) => {
                let error_msg = format!("PIET Failed to read incoming teamchannels directory: {}", e);
                println!("Error: {}", error_msg);
                return Err(GpgError::GpgOperationError(error_msg));
            }
        }

        // Process based on how many files were found
        match encrypted_files.len() {
            0 => {
                println!("No encrypted files (.asc or .gpg) found in {}", absolute_incoming_dir.display());
                println!("Please place the encrypted team channel file in this directory.");
                println!("Press Enter to try again, or type 'exit' to cancel.");

                let mut input = String::new();
                if let Err(e) = io::stdin().read_line(&mut input) {
                    let error_msg = format!("PIET Failed to read user input: {}", e);
                    println!("Error: {}", error_msg);
                    return Err(GpgError::ValidationError(error_msg));
                }

                if input.trim().to_lowercase() == "exit" {
                    return Err(GpgError::ValidationError("Operation cancelled by user".to_string()));
                }

                // Loop continues to check again
            },
            1 => {
                // Exactly one file found, we can proceed
                debug_log!("PIET Found one encrypted file: {}", encrypted_files[0].display());
                println!("Found encrypted file: {}", encrypted_files[0].display());
                break encrypted_files[0].clone();
            },
            _ => {
                println!("Multiple encrypted files found in {}:", absolute_incoming_dir.display());
                for (index, file) in encrypted_files.iter().enumerate() {
                    println!("  {}. {}", index + 1, file.file_name().unwrap_or_default().to_string_lossy());
                }
                println!("Please keep only the file you want to process and remove the others.");
                println!("Press Enter to try again, or type 'exit' to cancel.");

                let mut input = String::new();
                if let Err(e) = io::stdin().read_line(&mut input) {
                    let error_msg = format!("PIET Failed to read user input: {}", e);
                    println!("Error: {}", error_msg);
                    return Err(GpgError::ValidationError(error_msg));
                }

                if input.trim().to_lowercase() == "exit" {
                    return Err(GpgError::ValidationError("Operation cancelled by user".to_string()));
                }

                // Loop continues to check again
            }
        }
    };

    // Extract the filename for later use
    let encrypted_filename = encrypted_file_path.file_name()
        .ok_or_else(|| {
            let error_msg = "PIET Failed to extract filename from encrypted file path".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?
        .to_string_lossy()
        .to_string();

    debug_log!("PIET Processing encrypted file: {}", encrypted_filename);

    // STEP 4: Create processed directory for moving files after processing
    debug_log!("PIET Step 4: Setting up processed directory");

    let relative_processed_dir = "invites_updates/processed";
    let absolute_processed_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_processed_dir)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to resolve processed directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Create the processed directory if it doesn't exist
    if let Err(e) = fs::create_dir_all(&absolute_processed_dir) {
        let error_msg = format!("PIET Failed to create processed directory: {}", e);
        println!("Error: {}", error_msg);
        return Err(GpgError::GpgOperationError(error_msg));
    }

    // STEP 5: Set up temporary directory for processing
    debug_log!("PIET Step 5: Setting up temporary directory for decryption and verification");

    let temp_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck("temp_gpg_processing")
        .map_err(|e| {
            let error_msg = format!("PIET Failed to create temp directory path: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    if let Err(e) = fs::create_dir_all(&temp_dir) {
        let error_msg = format!("PIET Failed to create temp directory: {}", e);
        println!("Error: {}", error_msg);
        return Err(GpgError::GpgOperationError(error_msg));
    }

    // Temporary file to hold decrypted (but not yet verified) content
    let temp_decrypted_path = temp_dir.join("temp_decrypted.toml");

    // STEP 6: Decrypt the file using the LOCAL OWNER USER's key
    debug_log!("PIET Step 6: Decrypting file using LOCAL OWNER USER's key");
    println!("Decrypting file using LOCAL OWNER USER's key ID: {}", local_owner_gpg_key_id);

    // Decrypt the file without verification at this stage
    let decrypt_result = decrypt_gpgfile_to_output(
        &encrypted_file_path,
        &temp_decrypted_path
    );

    if let Err(e) = &decrypt_result {
        let error_msg = format!("PIET Failed to decrypt file: {:?}", e);
        println!("Error: {}", error_msg);
        println!("This could mean:");
        println!("1. The file is not properly encrypted or signed");
        println!("2. The file wasn't encrypted for your GPG key");
        println!("3. You don't have the sender's public key in your keyring");

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    debug_log!("PIET Successfully decrypted file");

    // STEP 7: Extract team channel owner from decrypted (but not yet verified) content
    debug_log!("PIET Step 7: Extracting team channel owner from decrypted content");

    // Convert temporary file path to string for TOML reading
    let temp_decrypted_path_str = temp_decrypted_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIET Unable to convert temp file path to string".to_string();
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            GpgError::PathError(error_msg)
        })?;

    // Read the team channel owner from the decrypted content
    // Note: Reading from unverified content, but we need it to find the right public key for verification
    let unverified_content = match fs::read_to_string(&temp_decrypted_path) {
        Ok(content) => content,
        Err(e) => {
            let error_msg = format!("PIET Failed to read decrypted content: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            return Err(GpgError::GpgOperationError(error_msg));
        }
    };

    // Parse to find the owner field in the clearsigned content
    let team_channel_owner = unverified_content.lines()
        .find_map(|line| {
            if line.trim().starts_with("owner =") {
                let parts: Vec<&str> = line.split('=').collect();
                if parts.len() >= 2 {
                    let value = parts[1].trim();
                    // Remove quotes if present
                    let clean_value = value.trim_matches('"').trim_matches('\'');
                    Some(clean_value.to_string())
                } else {
                    None
                }
            } else {
                None
            }
        })
        .ok_or_else(|| {
            let error_msg = "PIET Failed to find owner field in decrypted content".to_string();
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            GpgError::ValidationError(error_msg)
        })?;

    debug_log!("PIET Extracted team channel owner: {}", team_channel_owner);
    println!("PIET Team channel owned by: {}", team_channel_owner);

    // STEP 8: Get team channel owner's public key for verification
    debug_log!("PIET Step 8: Getting team channel owner's public key for verification");

    // // TODO maybe needs to be updated for readcopy and .gpg-option
    // // Path to the team channel owner's addressbook file
    // let team_channel_owner_address_book_filename = format!("{}__collaborator.toml", team_channel_owner);
    // let absolute_team_channel_owner_address_book_path = absolute_collab_dir.join(&team_channel_owner_address_book_filename);

    // debug_log!("PIET Team channel owner's addressbook path: {}", absolute_team_channel_owner_address_book_path.display());

    // // Verify the team channel owner's addressbook file exists
    // if !absolute_team_channel_owner_address_book_path.exists() {
    //     let error_msg = format!(
    //         "PIET Team channel owner's addressbook file not found at: {}",
    //         absolute_team_channel_owner_address_book_path.display()
    //     );
    //     println!("Error: {}", error_msg);
    //     println!("You need to import the team channel owner's addressbook first.");

    //     // Clean up temp directory before returning
    //     let _ = fs::remove_dir_all(&temp_dir);

    //     return Err(GpgError::PathError(error_msg));
    // }

    // A. Check for either node.toml or node.gpgtoml
    // let node_toml_path = absolute_specific_team_channel_directory_path.join("node.toml");
    let cl_team_channel_owner_address_book_filename = format!("{}__collaborator.toml", team_channel_owner);
    let cl_absolute_team_channel_owner_address_book_path = absolute_addressbook_directory_pathbuf.join(&cl_team_channel_owner_address_book_filename);

    // let node_gpgtoml_path = absolute_specific_team_channel_directory_path.join("node.gpgtoml");
    let gpg_team_channel_owner_address_book_filename = format!("{}__collaborator.gpgtoml", team_channel_owner);
    let gpg_absolute_team_channel_owner_address_book_path = absolute_addressbook_directory_pathbuf.join(&gpg_team_channel_owner_address_book_filename);


    let absolute_team_channel_owner_address_book_path = if cl_absolute_team_channel_owner_address_book_path.exists() {
        debug_log!("PIET: Found .toml");
        cl_absolute_team_channel_owner_address_book_path
    } else if gpg_absolute_team_channel_owner_address_book_path.exists() {
        debug_log!("PIET: Found .gpgtoml");
        gpg_absolute_team_channel_owner_address_book_path
    } else {
        debug_log("PIET: Neither .toml nor .gpgtoml found in  directory");
        return Err(GpgError::PathError(
            "PIET: Neither .toml nor .gpgtoml found in  directory".to_string()
        ));
    };

    // B. Get readable temp copy (handles decryption if .gpgtoml)
    debug_log!("PIET: Getting readable copy of file");

    // Get GPG fingerprint
    let gpg_fingerprint = LocalUserUma::read_gpg_fingerprint_from_file()
        .map_err(|e| GpgError::PathError(
            format!("PIET: Failed to read GPG fingerprint from uma.toml: {}", e)
        ))?;

    // Get temp directory
    let temp_dir = get_base_uma_temp_directory_path()
        .map_err(|e| GpgError::PathError(
            format!("PIET: Failed to get temp directory path: {}", e)
        ))?;

    // Get readable copy
    let absolute_team_channel_owner_address_book_path_str = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &absolute_team_channel_owner_address_book_path,
        &gpg_fingerprint,
        &temp_dir,
    ).map_err(|e| GpgError::PathError(
        format!("PIET: Failed to get readable copy of node file: {:?}", e)
    ))?;

    debug_log!("PIET: Node readcopy path: {}", absolute_team_channel_owner_address_book_path_str);

    // Now use node_readcopy_path to read fields...

    // ////////////////////////

    // // Convert the team channel owner's addressbook path to string for TOML reading
    // let absolute_team_channel_owner_address_book_path_str = absolute_team_channel_owner_address_book_path
    //     .to_str()
    //     .ok_or_else(|| {
    //         let error_msg = format!(
    //             "PIET Unable to convert team channel owner's addressbook path to string: {}",
    //             absolute_team_channel_owner_address_book_path.display()
    //         );
    //         println!("Error: {}", error_msg);

    //         // Clean up temp directory before returning
    //         let _ = fs::remove_dir_all(&temp_dir);

    //         GpgError::PathError(error_msg)
    //     })?;

    // Read the team channel owner's public GPG key from their addressbook
    let team_channel_owner_public_key = read_multiline_string_from_clearsigntoml(
        &absolute_team_channel_owner_address_book_path_str,
        "gpg_key_public"
    ).map_err(|e| {
        let error_msg = format!("PIET Failed to read team channel owner's public GPG key: {}", e);
        println!("Error: {}", error_msg);

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIET Successfully read team channel owner's public GPG key");

    // Create temporary file for the team channel owner's public key
    let temp_public_key_path = temp_dir.join("temp_public_key.asc");

    // Write public key to temporary file
    if let Err(e) = fs::write(&temp_public_key_path, team_channel_owner_public_key) {
        let error_msg = format!("PIET Failed to write team channel owner's public key to temp file: {}", e);
        println!("Error: {}", error_msg);

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    // STEP 9: Verify the clearsign signature using team channel owner's public key
    debug_log!("PIET Step 9: Verifying clearsign signature using team channel owner's public key");
    println!("Verifying signature using team channel owner's public key...");

    // Temporary file to hold verified content
    let temp_verified_path = temp_dir.join("temp_verified.toml");

    // Verify the clearsign signature
    let verify_result = verify_clearsigned_file_and_extract_content_to_output(
        &temp_decrypted_path,
        &temp_public_key_path,
        &temp_verified_path
    );

    if let Err(e) = &verify_result {
        let error_msg = format!("PIET Failed to verify clearsign signature: {:?}", e);
        println!("Error: {}", error_msg);
        println!("The signature could not be verified with the team channel owner's public key.");

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    println!("Signature successfully verified!");
    debug_log!("PIET Successfully verified clearsign signature");

    // STEP 10: Extract team channel name from verified content
    debug_log!("PIET Step 10: Extracting team channel name from verified content");

    // Convert verified file path to string for TOML reading
    let temp_verified_path_str = temp_verified_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "PIET Unable to convert verified file path to string".to_string();
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            GpgError::PathError(error_msg)
        })?;

    // Read the team channel name from the verified content
    let team_channel_name = read_single_line_string_field_from_toml(
        temp_verified_path_str,
        "node_name"
    ).map_err(|e| {
        let error_msg = format!("PIET Failed to read team channel name from verified content: {}", e);
        println!("Error: {}", error_msg);
        println!("The verified file doesn't contain a valid 'team_channel_name' field.");

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("PIET Extracted team channel name: {}", team_channel_name);
    println!("Imported team channel name: {}", team_channel_name);

    // TODO: STEP 11: Check for port conflicts with existing team channels
    // This is intentionally left as a placeholder for future implementation
    debug_log!("PIET Step 11: TODO - Check for port conflicts with existing team channels");

    // STEP 12: Create team channel directory structure
    debug_log!("PIET Step 12: Creating team channel directory structure");

    // Get absolute path to team channels directory
    let relative_team_channels_dir = "project_graph_data/team_channels";
    let absolute_team_channels_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_team_channels_dir)
        .map_err(|e| {
            let error_msg = format!("PIET Failed to resolve team channels directory path: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            GpgError::PathError(error_msg)
        })?;

    // Create the team channels directory if it doesn't exist
    if let Err(e) = fs::create_dir_all(&absolute_team_channels_dir) {
        let error_msg = format!("PIET Failed to create team channels directory: {}", e);
        println!("Error: {}", error_msg);

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    // Create specific team channel directory
    let absolute_specific_team_channel_dir = absolute_team_channels_dir.join(&team_channel_name);

    // Create the specific team channel directory if it doesn't exist
    if let Err(e) = fs::create_dir_all(&absolute_specific_team_channel_dir) {
        let error_msg = format!("PIET Failed to create specific team channel directory: {}", e);
        println!("Error: {}", error_msg);

        // Clean up temp directory before returning
        let _ = fs::remove_dir_all(&temp_dir);

        return Err(GpgError::GpgOperationError(error_msg));
    }

    debug_log!("PIET Created team channel directory: {}", absolute_specific_team_channel_dir.display());

    // // Create paths for node.toml and node.gpg in the team channel directory
    // let node_toml_path = absolute_specific_team_channel_dir.join("node.toml");
    // let node_gpg_path = absolute_specific_team_channel_dir.join("node.gpgtoml");

    // // STEP 13: Save verified content as node.toml
    // debug_log!("PIET Step 13: Saving verified content as node.toml");

    // // Copy verified content to node.toml
    // if let Err(e) = fs::copy(&temp_verified_path, &node_toml_path) {
    //     let error_msg = format!("PIET Failed to save node.toml: {}", e);
    //     println!("Error: {}", error_msg);

    //     // Clean up temp directory before returning
    //     let _ = fs::remove_dir_all(&temp_dir);

    //     return Err(GpgError::GpgOperationError(error_msg));
    // }

    // debug_log!("PIET Saved node.toml to: {}", node_toml_path.display());

    // // STEP 14: Save original encrypted file as node.gpg
    // debug_log!("PIET Step 14: Saving original encrypted file as node.gpg");

    // // Copy original encrypted file to node.gpg
    // if let Err(e) = fs::copy(&encrypted_file_path, &node_gpg_path) {
    //     let error_msg = format!("PIET Failed to save node.gpg: {}", e);
    //     println!("Error: {}", error_msg);

    //     // Clean up temp directory before returning
    //     let _ = fs::remove_dir_all(&temp_dir);

    //     return Err(GpgError::GpgOperationError(error_msg));
    // }

    // debug_log!("PIET Saved node.gpg to: {}", node_gpg_path.display());

    // STEP 12.5: Ask user for preferred save format
    debug_log!("PIET Step 12.5: Prompting user for save format preference");

    let save_encrypted_format = prompt_user_for_save_format_choice()
        .map_err(|e| {
            let error_msg = format!("PIET Failed to get user format choice: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            e
        })?;

    // STEP 13: Save the team channel file in the user's chosen format
    debug_log!("PIET Step 13: Saving team channel file in {} format",
              if save_encrypted_format { "encrypted .gpgtoml" } else { "clearsigned .toml" });

    // Determine the output filename based on user's choice
    let node_filename = if save_encrypted_format {
        // User chose to keep the encrypted format
        "node.gpgtoml"
    } else {
        // User chose clearsigned format
        "node.toml"
    };

    let node_file_path = absolute_specific_team_channel_dir.join(node_filename);

    debug_log!("PIET Saving team channel file to: {}", node_file_path.display());

    // Save the file based on user's choice
    if save_encrypted_format {
        // Copy the original encrypted file directly (it's already been validated)
        debug_log!("PIET Copying original encrypted .gpgtoml file");

        if let Err(e) = fs::copy(&encrypted_file_path, &node_file_path) {
            let error_msg = format!("PIET Failed to save encrypted node.gpgtoml: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            return Err(GpgError::GpgOperationError(error_msg));
        }

        println!("Successfully saved encrypted team channel file to: {}", node_file_path.display());
        debug_log!("PIET Saved node.gpgtoml to: {}", node_file_path.display());
    } else {
        // Copy the verified clearsigned content
        debug_log!("PIET Copying extracted clearsigned .toml file");

        // First, we need to copy the clearsigned content (not just the extracted TOML)
        // The temp_decrypted_path contains the clearsigned version
        if let Err(e) = fs::copy(&temp_decrypted_path, &node_file_path) {
            let error_msg = format!("PIET Failed to save clearsigned node.toml: {}", e);
            println!("Error: {}", error_msg);

            // Clean up temp directory before returning
            let _ = fs::remove_dir_all(&temp_dir);

            return Err(GpgError::GpgOperationError(error_msg));
        }

        println!("Successfully saved clearsigned team channel file to: {}", node_file_path.display());
        debug_log!("PIET Saved node.toml to: {}", node_file_path.display());
    }

    // STEP 14 is now removed - we no longer save both formats


    // STEP 15: Move original encrypted file to processed directory
    debug_log!("PIET Step 15: Moving original encrypted file to processed directory");

    let processed_file_path = absolute_processed_dir.join(&encrypted_filename);

    // Move the original file to the processed directory
    if let Err(e) = fs::rename(&encrypted_file_path, &processed_file_path) {
        let error_msg = format!("PIET Failed to move original encrypted file: {}", e);
        println!("Warning: {}", error_msg);

        // This is a non-critical error, so we'll just log it and continue
        debug_log!("PIET Warning: {}", error_msg);
    } else {
        debug_log!("PIET Moved original encrypted file to: {}", processed_file_path.display());
    }

    // STEP 16: Clean up temporary directory
    debug_log!("PIET Step 16: Cleaning up temporary directory");

    if let Err(e) = fs::remove_dir_all(&temp_dir) {
        debug_log!("PIET Warning: Failed to remove temporary directory: {}", e);
        println!("Warning: Failed to clean up temporary files: {}", e);
        // This is a non-critical error, so we'll just log it and continue
    }

    // STEP 17: Report success to user
    debug_log!("PIET Step 17: Reporting success to user");
    println!("\nTeam channel successfully imported!");
    println!("Team channel name: {}", team_channel_name);
    println!("Team channel owner: {}", team_channel_owner);
    println!("Files saved to: {}", absolute_specific_team_channel_dir.display());

    debug_log!("PIET Successfully completed team channel import process");

    // Wait for user acknowledgment
    println!("\nPress Enter to continue...");
    let mut input = String::new();
    let _ = io::stdin().read_line(&mut input);

    Ok(())
}

/// TODO needs extensive doc string
/// TODO needs absolute file paths, see:  src/manage_absolute_executable_directory_relative_paths.rs
///
/// Invite Wizard
///
/// to inspect files use ```gpg --decrypt FILENAME.THINGY```
///
pub fn invite_wizard() -> Result<(), GpgError> {
    /*
    1. Export your public gpg key to share [Done]
    2. make clearsigned version of your own addressbook .toml
       get user name
       use user name to get their gpg key from their addressbook file
       gpg encrypt the clearsign file
       A. new remote collaborator: separate gpg file
       B. existing addressbook file for them
    3. make clearsigned version of this team-channel if you are owner
       get user name
       use user name to get their gpg key from their addressbook file
       gpg encrypt the clearsign file

       TODO:
       maybe activate HOME reboot-uma command to keep 'out of band'

       invite update
    */
    println!(">> Invite/Update Wizard <<");
    println!("\nThere are three steps...");
    println!("1. sharing gpg");
    println!("2. sharing address-book file");
    println!("3. sharing team-channel");
    println!("4. update a Node that you own");  // update_core_node()
    println!("5. make a set of pads (One Time Pad)");
    println!("\nQ: Which step do you want to do now?");
    println!("(Enter: number + enter)");

    let mut input = String::new();
    io::stdin().read_line(&mut input).expect("invite-wiz: failed to read line");

    let mainchoice: u32 = match input.trim().parse() {
        Ok(num) => num,
        Err(_) => {
            // println!("\nThere are three steps...");
            // println!("1. share gpg");
            // println!("2. share address-book file");
            // println!("3. share team-channel (if you own it)");
            println!("Please try again entering a number ->");
            return Ok(());
        }
    };

    match mainchoice {
        1 => {
            println!("\n\n-- Option 1: share a public gpg key --");

            // later function makes the path absolute relative
            let relative_uma_toml_path = Path::new(UMA_TOML_CONFIGFILE_PATH_STR);

            // // Get absolute path to uma.toml configuration file
            // let relative_uma_toml_path = "uma.toml";
            // let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
            //     .map_err(|e| {
            //         let error_msg = format!("___ Failed to locate uma.toml configuration file: {}", e);
            //         println!("Error: {}", error_msg);
            //         GpgError::PathError(error_msg)
            //     })?;

            // later function makes the path absolute relative
            let output_dir = Path::new("invites_updates/outgoing");

            // let relative_output_dir = "invites_updates/outgoing";
            // let absolute_output_dir = gpg_make_input_path_name_abs_executabledirectoryrelative_nocheck(relative_output_dir)
            //     .map_err(|e| {
            //         let error_msg = format!("invite wizard! Failed to convert 'invites_updates/outgoing' path: {}", e);
            //         println!("Error: {}", error_msg);
            //         GpgError::PathError(error_msg)
            //     })?;

            // this function makes the path absolute relative
            match export_public_gpg_key_converts_to_abs_path(
                &relative_uma_toml_path,
                &output_dir,
                ) {
                Ok(key_path) => println!("\nOK! GPG key exported successfully to: {}", key_path),
                Err(e) => eprintln!("invite wizard! Failed to export GPG key: {}", e),
            }

            // Pause and wait for the user to press Enter
            println!("\nHit enter to proceed...");
            let mut input = String::new();
            io::stdin().read_line(&mut input).expect("Failed to read line");

        },

        2 => {
            println!("\n\n-- Option 2: Sharing an Address-Book-File --");
            println!("\nFROM you, TO them, <-outgoing->");
            println!("Are you sharing your address book file with...");
            println!(" 1. an existing remote-collaborator? or ");
            println!(" 2. a new remote-collaborator?");
            println!(" ");
            println!("Or: FROM them TO you, ->incoming<- ");
            println!(" 3. Do you want to import an address-book-file");
            println!("    being shared with you (by a remote collaborator)?");
            println!(" ");
            println!("(Enter: number + enter)");

            // Re-read another input for subchoice, kind of like... peanut butter...in a sand witch.
            let mut sub_input = String::new();
            io::stdin()
                .read_line(&mut sub_input)
                .map_err(|e| GpgError::GpgOperationError(format!("Failed to read subchoice: {}", e)))?;

            let subchoice: u32 = match sub_input.trim().parse() {
                Ok(num) => num,
                Err(_) => {
                    println!("Please try again entering a number.");
                    return Ok(());
                }
            };


            // Ensure the project graph data directory exists relative to the executable
            let incoming_dir_result = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
                "invites_updates/incoming"
            ) {
                Ok(directory_path) => {
                    debug_log!("IUA: incoming_dir_result outgoing -> {}", directory_path.to_string_lossy());

                    directory_path
                }
                Err(io_error) => {
                    let error_msg = format!(
                        "IWiz Failed to ensure team_channels_dir exists: {}",
                        io_error
                    );
                    debug_log!("IWiz ERROR: {}", error_msg);
                    eprintln!("IWiz ERROR: {}", error_msg);
                    return Err(GpgError::ValidationError("No signing key ID provided".to_string()));
                }
            };


            match subchoice {
                1 => {
                    println!(" --- to existing remote collaborator --- ");
                    println!("What is the user-name of the existing");
                    println!("remote collaborator? (Enter: name + enter)");
                    /*
                        The file where the user's gpg key is located is found here:

                        ```path
                        project_graph_data/collaborator_files_address_book/USERNAMEHERE__collaborator.toml
                        ```


                        within the file, the gpg key (public) is found:
                        gpg_key_public = """KEYHERE"""

                        clearsign read toml?

                    // For toml and clearsigntoml
                    mod read_toml_field;
                    use crate::read_toml_field::{
                        read_field_from_toml,
                        read_basename_fields_from_toml,
                        read_single_line_string,
                        read_multi_line_string,
                        read_integer_array,
                        read_singleline_string_from_clearsigntoml,
                    };

                    reading addressbook files ALW
                    pub fn read_singleline_string_from_clearsigntoml(path_to_clearsigntoml_with_gpgkey: &str, field_name: &str) -> Result<String, String> {
                    */
                    let mut username_of_remote_collaborator = String::new();
                    io::stdin()
                        .read_line(&mut username_of_remote_collaborator)
                        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;

                    debug_log!("wiz: username_of_remote_collaborator -> {}", username_of_remote_collaborator);

                    share_lou_address_book_with_existingcollaborator(username_of_remote_collaborator.trim())?;
                    }
                2 => {

                    // show full path
                    let demo_key_path = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
                        "invites_updates/incoming/key.asc"
                    ) {
                        Ok(directory_path) => {
                            debug_log!("IUA: incoming_dir_result outgoing -> {}", directory_path.to_string_lossy());

                            directory_path
                        }
                        Err(io_error) => {
                            let error_msg = format!(
                                "IWiz Failed to ensure team_channels_dir exists: {}",
                                io_error
                            );
                            debug_log!("IWiz ERROR: {}", error_msg);
                            eprintln!("IWiz ERROR: {}", error_msg);
                            return Err(GpgError::ValidationError("No signing key ID provided".to_string()));
                        }
                    };

                    println!(" --- to new remote collaborator --- ");
                    println!("Please put the remote collaborator's gpg key.asc file");
                    println!(" in this path (in this directory) -> ");
                    println!(" ");
                    println!("```path ");
                    println!("{}", demo_key_path.to_string_lossy());
                    println!("``` ");
                    println!(" ");
                    println!("Then, press Enter when this is done.\n");
                    let mut username_of_remote_collaborator = String::new();
                    io::stdin()
                        .read_line(&mut username_of_remote_collaborator)
                        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;

                    share_lou_addressbook_with_incomingkey()?;

                    }
                    /*
                    e.g.
                    ```path
                    project_graph_data/collaborator_files_address_book/USERNAMEHERE__collaborator.toml
                    ```
                    */

                3 => {

                    // // get make real path
                    // let incoming_dir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
                    //     "invites_updates/incoming"
                    // );
                    // debug_log!("IUA: incoming_dir_result outgoing -> {:?}", incoming_dir_result);


                    println!(" --- FROM a remote collaborator, TO you --- ");
                    println!("Please put their FILENAME.gpgtoml file in the");
                    println!("```path");
                    println!("{}", incoming_dir_result.to_string_lossy());
                    println!("```");
                    println!("directory (folder)");
                    println!("Press enter when this is done.");

                    // this does nothing, press enter to proceed.
                    let mut input = String::new();
                    let _ = io::stdin()
                        .read_line(&mut input)
                        .map_err(|e| format!("Failed to read input: {:?}", e));

                    let _ = process_incoming_encrypted_collaborator_addressbook();
                    /*
                    logic to target that directory...
                    // 1. Scans the incoming directory for .asc files
                    // 2. If exactly one file is found, proceeds with processing
                    // 3. If multiple files are found, prompts the user to clean up the directory
                    // 4. Decrypts the file and verifies the clearsignature
                    // 5. Extracts the collaborator's username from the clearsigned content
                    // 6. Saves the validated clearsigned file to the collaborator address book directory
                    // 7. Moves the original encrypted file to the processed directory
                    */
                    }
                // Handle cases where subchoice is 0 or  4
                _ => {
                    println!("Invalid option. Please select 1, 2, or 3.");
                }
            }
        },
        3 => {
            /*
            1. Team Channel files, clearsigned, and gpg encrypted.
            ideally: channel_name...
            just channel_name.toml?
            gpg+clearsigned+toml
            clearsigned with who's key?
            get key from addressbook?

            team channel only read...at start?

            v1: plain toml...
            simple_clearsign_gpgencrypt(path_in, path_out):
            get file
            clearsign with yours
            gpg sign with theirs
            put in outgoing

            new function: multi-file clearsign validate
            multi-file clearsign read...fields

            read_gpg_multifile_clearsign_stringline
            read_gpg_multifile_clearsign_int_array
            read_gpg_multifile_clearsign_multiline_string

            read_gpg_multifile_clearsign_stringline
            read_gpg_multifile_clearsign_int_array
            read_gpg_multifile_clearsign_multiline_string

            and unpack file:
            use your keyid
            use their key: read and get public key...
            make team-channel folder
            make team-channel node.toml

            */
            println!("\n\n-- Option 3: Sharing a Team-Channel --");
            println!("\n 1. Do you wish to share a Team-Channel that you own");
            println!("    with an existing remote-collaborator?");
            println!(" ");
            println!("Or ");
            println!(" 2. Are you looking to import a Team-Channel");
            println!("    being shared with you (by a remote collaborator/owner)?");
            println!(" ");
            println!("(Enter: number + enter)");

            // Re-read another input for subchoice, kind of like... peanut butter...in a sand witch.
            let mut sub_input = String::new();
            io::stdin()
                .read_line(&mut sub_input)
                .map_err(|e| GpgError::GpgOperationError(format!("Failed to read subchoice: {}", e)))?;

            let subchoice: u32 = match sub_input.trim().parse() {
                Ok(num) => num,
                Err(_) => {
                    println!("Please try again entering a number.");
                    return Ok(());
                }
            };

            match subchoice {
                1 => {
                    println!(" --- to existing remote collaborator --- ");
                    println!("What is remote colaborator's name?");
                    println!("(Enter: name + enter)");
                    /*
                        The file where the user's gpg key is located is found here:

                        ```path
                        project_graph_data/collaborator_files_address_book/USERNAMEHERE__collaborator.toml
                        ```

                        within the file, the gpg key (public) is found:
                        gpg_key_public = """KEYHERE"""

                        clearsign read toml?

                    // For toml and clearsigntoml
                    mod read_toml_field;
                    use crate::read_toml_field::{
                        read_field_from_toml,
                        read_basename_fields_from_toml,
                        read_single_line_string,
                        read_multi_line_string,
                        read_integer_array,
                        read_singleline_string_from_clearsigntoml,
                    };

                    reading addressbook files ALW
                    pub fn read_singleline_string_from_clearsigntoml(path_to_clearsigntoml_with_gpgkey: &str, field_name: &str) -> Result<String, String> {
                    */
                    let mut remotecollaborator_username_input = String::new();
                    io::stdin()
                        .read_line(&mut remotecollaborator_username_input)
                        .map_err(|e| GpgError::GpgOperationError(format!("Failed to read input: {}", e)))?;
                    debug_log!("wiz: remote_collaborator_username -> {}", remotecollaborator_username_input);
                    // share_lou_address_book_with_existingcollaborator(username_of_remote_collaborator.trim())?;
                    // Ensure the team_channel_name is completely trimmed of all whitespace
                    let remote_collaborator_username = remotecollaborator_username_input.trim().trim_end_matches(|c| c == '\n' || c == '\r');

                    // TODO function here to get the remote collaborator's gpg key to finally gpg encrypt with
                    debug_log!("remote_collaborator_username: '{}'", remote_collaborator_username);

                    println!("What is the Team-Channel-Name?");
                    println!("(Enter: name + enter)");

                    let mut team_channel_name_input = String::new();
                    io::stdin()
                        .read_line(&mut team_channel_name_input)
                        .map_err(|e| GpgError::GpgOperationError(format!("wiz: Failed to read input: {}", e)))?;


                    // Ensure the team_channel_name is completely trimmed of all whitespace
                    let team_channel_name = team_channel_name_input.trim().trim_end_matches(|c| c == '\n' || c == '\r');

                    // Additional debug to check exact content
                    debug_log!("Menu: Raw team channel name: '{}'", team_channel_name);
                    debug_log!("Menu: Team channel name length: {}", team_channel_name.len());

                    debug_log!("wiz: name_of_teamchannel -> {}", team_channel_name);

                    /*
                    1. make sure the node.toml file is at
                    {exe-parent}/project_graph_data/team_channels/{team-channel-name}/node.toml
                    2. clearsign it with your own gpg-key-id
                    3. gpg encrypt the clearsign file with the reamote collaborators public key
                    4. put the resulting file in
                    ```path
                    exe-parent/invites_updates/incoming/
                    ```
                    */
                    let _ = share_team_channel_with_existing_collaborator_converts_to_abs(
                        &remote_collaborator_username,
                        &team_channel_name,
                    );

                    }

                2 => {
                    println!(" --- FROM a remote-collaborator & team-channel-owner, TO you --- ");
                    println!("Please put their FILENAME.SUFFIX file, as the only file, in the");
                    println!("```path");
                    println!("invites_updates/incoming/ ");
                    println!("```");
                    println!("directory (folder)");
                    println!("Press enter when this is done.");

                    // this does nothing, press enter to proceed.
                    let mut input = String::new();
                    let _  = io::stdin()
                        .read_line(&mut input)
                        .map_err(|e| format!("Failed to read input: {:?}", e));

                    /*
                    logic to target that directory...
                    1. Scans the incoming directory for .asc file (or any gpg suffix)
                    2. If exactly one file is found, proceeds with processing
                    3. If multiple files are found, prompts the user to clean up the directory press enter to proceed (not loop))
                    4. Decrypts the file (with local owner key-id, standard process) and next verifies the clearsignature:
                    5. Extracts the collaborator's username from the clearsigned content
                    6. gets the collaborator's gpg key from an addressbook file
                    7. uses that to verify the clearsign
                    TODO STEP: checks all team-channel ports for a colission and
                    gives a warning (press enter to proceed, not quit) if collision (not a breaking issue)
                    8. if verified, saves file in two versions: node.toml (clearsign toml); and gpg-encrypted .asc
                    - Saves the validated clearsigned file to the collaborator address book directory
                    (note: the name is always simply node.toml)
                    - Moves the original encrypted file to the processed directory

                    9. Make team-channel folders etc.
                    The current plan is to leave this step minimal
                    and have file-sync fill in whatever is inside.
                    - make directory based on field name
                    - put node.toml file/gpg-file in the dir



                    */

                    //
                    let _ = process_incoming_encrypted_teamchannel();

                    }

                // Handle cases where subchoice is 0 or  4
                _ => {
                    println!("Invalid option. Please select 1, 2, or 3.");
                }
            }
            /*
                somewhere around here:
                1. pick node
                2.
                println!("4. update a team-channel that you own");  // update_core_node()
            */

            // Similar implementation to share_address_book() but with team channel file
            // Would use the same clearsign_and_encrypt_file_for_recipient() function

        }
        4 => {
            // Similar implementation to share_address_book() but with team channel file
            // Would use the same clearsign_and_encrypt_file_for_recipient() function

            /*

            */

            println!("Enter the file-path of the node you want to edit:");

            // Read user input
            let mut input = String::new();
            io::stdin()
                .read_line(&mut input)
                .expect("Failed to read line");

            // Trim whitespace and convert to PathBuf
            let node_path: PathBuf = input.trim().into();

            // let node_path = PathBuf::from("/absolute/path/to/node.toml");

            match update_core_node(node_path) {
                Ok(()) => println!("Node updated successfully"),
                Err(e) => eprintln!("Failed to update node: {}", e),
            }

        }
        5 => {

            // invite/update
            // let outgoing_dir_result = make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
            //     "invites_updates/outgoing"
            // )?;

            let outgoing_dir_result = match make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path(
                "invites_updates/outgoing"
            ) {
                Ok(directory_path) => {
                    debug_log!("IUA: outgoing_dir_result outgoing -> {}", directory_path.to_string_lossy());

                    directory_path
                }
                Err(_) => {
                    return Err(GpgError::ValidationError("IW make_verify_or_create_executabledirectoryrelative_canonicalized_dir_path".to_string()));
                }
            };

            println!("Specify the four array fields for the pad (0-255), max may fill your drive:");
            println!("Resulting Pad Here -> {}", outgoing_dir_result.to_string_lossy());
            println!();
            println!("a 'padnest_0' is a 0-255 numbered directory of pad");
            println!("a 'pad' is a 0-255 numbered directory of page directories");
            println!("a 'page' is a 0-255 numbered directory of 'line' files");
            println!("a 'line' is a 0-255 numbered file containing N bytes");
            println!("e.g. PadIndex::new_standard([0, 0, 0, 1])");
            println!();
            println!("Starting with the first largest dimension [Here, 0, 0, 1])");

            let padnest_0 = prompt_for_u8("How many pad-sets? (0-255): ");
            println!();
            println!("And then 'pads' [0, Here, 0, 1])");
            let pad = prompt_for_u8("How many pads? (0-255): ");
            println!();
            println!("And 'pages' [0, 0, Here, 1])");
            let page = prompt_for_u8("How many pages? (0-255): ");
            println!();
            println!("And 'lines' [0, 0, 0, Here])");
            let line = prompt_for_u8("How many lines? (0-255): ");
            println!();
            let per_line: usize = prompt_for_usize("How many bytes per line? (1-128): ");
            let frame_array = PadIndex::Standard([padnest_0, pad, page, line]);
            println!();
            println!("Share a copy with one collaborator and vice versa.");
            println!("Press Enter to continue...");

            // this does nothing, press enter to proceed.
            let mut input = String::new();
            let _ = io::stdin()
                .read_line(&mut input)
                .map_err(|e| format!("Failed to read input: {:?}", e));



            /*
            /// ## Arguments
            /// * `padset_root` - Absolute path where padset will be created
            /// * `max_pad_index_array` - Index specifying creation bounds (0-based inclusive)
            ///   - Each byte specifies max index to create at that level
            ///   - [0,0,0,1] = 1 nest, 1 pad, 1 page, 2 lines
            ///   - [1,2,3,4] = 2 nests, 3 pads, 4 pages, 5 lines
            ///   - Can be 4 or 8 bytes depending on desired hierarchy depth
            /// * `number_of_bytes_per_line` - How many random bytes per line file (16-4096)
            /// * `dir_checksum_files` - If true, create hashes at pad/page level
            ///
            /// # Returns
            /// * `Ok(())` - Padset created successfully
            /// * `Err(PadnetError)` - Creation failed
            pub fn padnet_make_one_pad_set(
                padset_root: &Path,
                max_pad_index_array: &PadIndex,
                number_of_bytes_per_line: usize,
                dir_checksum_files: ValidationLevel,
            ) -> Result<(), PadnetError> {

            /// Integrity validation strategy for pad directories
            /// Determines if/when dir hashes are created during pad generation
            #[derive(Debug, Clone, Copy)]
            pub enum ValidationLevel {
                /// Hash entire pad directories (pad_XXX level)
                /// Creates hash_pad_XXX files as siblings to pad directories
                PadLevel,

                /// Hash each page directory (page_XXX level)
                /// Creates hash_page_XXX files as siblings to page directories
                PageLevel,

                /// No validation - trust filesystem integrity
                None,
            }
            */

            // let bounds = PadIndex::new_standard([0, 0, 0, 10]); // 11 lines
            match padnet_make_one_pad_set(
                &outgoing_dir_result,
                &frame_array,
                per_line,
                ValidationLevel::PageLevel
            ) {
                Ok(()) => println!("   padset created"),
                Err(e) => {
                    println!("   IS The Fail: {}", e);
                    return Err(GpgError::GpgOperationError("Invalid choice".to_string()));
                }
            }

        }
        _ => {
            return Err(GpgError::GpgOperationError("Invalid choice".to_string()));
        }

        _ => println!("Invalid choice."),
    }
    Ok(())
}

fn handle_command_main_mode(
    input: &str,
    app: &mut App,
    // graph_navigation_instance_state: &GraphNavigationInstanceState
) -> Result<bool, io::Error> {
    /*
    For input command mode
    quit
    command-list/legend
    */

    debug_log(&format!("HCMM handle_command_main_mode(), input->{:?}", input));
    // First, try to handle numeric input
    if let Ok(index) = input.trim().parse::<usize>() {
        let item_index = index - 1; // Adjust for 0-based indexing
        if item_index < app.tui_directory_list.len() {
            // Special handling for team channels directory

            debug_log!("HCMM app.current_path.display().to_string()->{:?}", app.current_path.display().to_string());


            // =====
            // The setting options and factors here are:
            // there are (may be) some bootstrapping steps
            // for the first time you enter a team-channel
            // and are not on home-base
            //
            // is_in_teamchannels_homebase (bool) is whether you are in home-base:
            // "project_graph_data/team_channels"
            //
            // reserved strings: (cannot be name of node)
            // uma
            // project_graph_data
            // team_channels
            // ======
            /*
             * HCMM app.current_path.display().to_string()->"/home/oops/code/uma_productivity_collaboration_tool/target/debug/project_graph_data/team_channels"
             */

            let starting_in_teamchannels_homebase: bool;

            // Get the last two components as an iterator
            let last_two: Vec<_> = app.current_path.iter().rev().take(2).collect();
            let last_two: Vec<_> = last_two.into_iter().rev().collect();

            // Convert to strings for comparison
            let last_two_strs: Vec<String> = last_two
                .into_iter()
                .filter_map(|c| c.to_str())
                .map(|s| s.to_string())
                .collect();

            // Join with "/" for comparison
            let last_two_joined = last_two_strs.join("/");

            if last_two_joined == "project_graph_data/team_channels" {
                // println!("Path matches the last two components!");
                starting_in_teamchannels_homebase = true;
            } else {
                // println!("HCMM Path does not match.");
                debug_log!("HCMM not in: project_graph_data/team_channels");
                starting_in_teamchannels_homebase = false;
            }

            // if app.current_path.display().to_string() == "project_graph_data/team_channels".to_string() {
            if starting_in_teamchannels_homebase {

                let selected_channel = app.tui_directory_list[item_index].clone();
                debug_log(&format!("HCMM Selected channel: {}", selected_channel));


                app.current_path = app.current_path.join(&selected_channel);
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();


                // Simply call the method without trying to handle its result
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml();

                // // current_node_directory_path
                // debug_log(&format!("HCMM current_node_directory_path: {:?}", app.graph_navigation_instance_state.current_node_directory_path));


                // bootstrap: now you are in a channel, start sync
                let set_sync_result = set_sync_start_ok_flag_to_true();

                #[cfg(debug_assertions)]
                debug_log!("HCMM set_sync_result->{:?}", set_sync_result);

            } else {

                // Regular directory navigation
                app.current_path = app.current_path.join(&app.tui_directory_list[item_index]);
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();

                // try?
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

            }
            return Ok(false);  // Continue main loop
        }
    }
    // Then handle text commands:
    let parts: Vec<&str> = input.trim().split_whitespace().collect();
    if let Some(command) = parts.first() {

        match command.to_lowercase().as_str() {
            "h" | "help" => {
                debug_log("Help!");
                // Display help information
                // TODO help wizard or blurb?
            }

            "sharegpg" | "exportgpg" | "requestinvite" => {
                debug_log("Export public GPG Command:");

                // paths are always the same
                // TODO make paths constants
                let uma_config_path = Path::new(UMA_TOML_CONFIGFILE_PATH_STR);
                let output_dir = Path::new("invites_updates/outgoing");

                match export_public_gpg_key_converts_to_abs_path(&uma_config_path, &output_dir) {
                    Ok(key_path) => println!("GPG key exported successfully to: {}", key_path),
                    Err(e) => eprintln!("Failed to export GPG key: {}", e),
                }
            }

            "invite" | "update" => {
                debug_log("invite / update wizard");
                /*
                */
                let gone_home_result = quit_set_continue_uma_to_false();

                println!("Starting Safe Out-of-band -> {:?} [Should say: 'Ok(())']", gone_home_result);
                debug_log!("'invite' Safe out of band: gone_home_result {:?}", gone_home_result);


                let _ = invite_wizard();
            }

            "addnode" | "add_node" | "newnode" | "new" | "addtask" | "add_task" | "add" => {
                debug_log("Command: Add Node");
                // TODO trim down excess terms above

                debug_log!("app.current_path {:?}", app.current_path);

                let _ = create_core_node(
                    app.current_path.clone(), // node_path: PathBuf,
                    app.graph_navigation_instance_state.current_node_teamchannel_collaborators_with_access.clone(),  // teamchannel_collaborators_with_access: Vec<String>,
                    Some(app.graph_navigation_instance_state.use_padnet.clone()), // Padnet Option(bool)
                );
            }

            "bigger" | "big" | "bg" => {
                app.tui_height = (app.tui_height + 1).max(1);  // Height cannot be less than 1
                app.tui_width = (app.tui_width + 1).max(1);  // Width cannot be less than 1
                // ... re-render
            }

            "smaller" | "small" | "sm" => {
                app.tui_height = (app.tui_height - 1).max(1);
                app.tui_width = (app.tui_width - 1).max(1);
                // ... re-render
            }

            "v" | "vote" => {
                debug_log("Vote!");
                // Display help information
            }
            // "p" | "paralax" => {
            //     debug_log("!@#");
            //     // Display help information
            // }
            "collaborator" => {
                debug_log("make node!");
                // add_collaborator_qa(&graph_navigation_instance_state);
                let _ = add_collaborator_qa();
            }

           "d" | "datalab" | "data" => {
                debug_log("Help!");
                // Display help information
            }

           "l" | "log" | "logmode" | "debug" | "debuglog" | "showlog" => {
            debug_log("Starting log mode...ctrl+c to exit");

                // this takes a path n the form of a string
                // as input, outputs size etc.
                // fs::metadata(INPUT_PATH)
                // Get absolute path to uma.toml configuration file

                let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
                let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
                    .map_err(|e| {
                        let error_msg = format!("___ Failed to locate uma.toml configuration file: {}", e);
                        println!("Error: {}", error_msg);
                        io::Error::new(io::ErrorKind::InvalidData, error_msg)
                    })?;

                // Convert PathBuf to string for TOML reading
                let absolute_uma_toml_path_str = absolute_uma_toml_path
                    .to_str()
                    .ok_or_else(|| {
                        let error_msg = "__ Unable to convert UMA TOML path to string".to_string();
                        println!("Error: {}", error_msg);
                        io::Error::new(io::ErrorKind::InvalidData, error_msg)
                    })?;

                // Read log_mode_refresh from uma.toml
                let log_mode_refresh = read_float_f32_field_from_toml(
                    absolute_uma_toml_path_str,
                    "log_mode_refresh"
                ).map_err(|e| {
                    let error_msg = format!(" Failed to read log_mode_refresh: {}", e);
                    println!("Error: {}", error_msg);
                    io::Error::new(io::ErrorKind::InvalidData, error_msg)
                })?;

                debug_log!("log_mode_refresh: {:?}", log_mode_refresh);

                let mut last_log_file_size = fs::metadata(absolute_uma_toml_path_str)
                    .map(|metadata| metadata.len())
                    .unwrap_or(0); // Get initial size, or 0 if error

                // bootstrap, first print
                // File size has changed, read and display new contents
                match fs::read_to_string(absolute_uma_toml_path_str) {
                    Ok(log_contents) => {
                        println!("{}", log_contents); // Print to console for now
                    }
                    Err(e) => {
                        eprintln!("Failed to read uma.log: {}", e);
                    }
                }

                loop { // Enter the refresh loop

                    // Check for file size changes
                    let current_log_file_size = fs::metadata(absolute_uma_toml_path_str)
                        .map(|metadata| metadata.len())
                        .unwrap_or(0);
                    if current_log_file_size != last_log_file_size {

                        // 1. Read and display the log contents.
                        // File size has changed, read and display new contents
                        match fs::read_to_string(absolute_uma_toml_path_str) {
                            Ok(log_contents) => {
                                print!("\x1B[2J\x1B[1;1H"); // Clear the screen
                                println!("{}", log_contents);
                                // Update the last_log_file_size after reading
                                last_log_file_size = current_log_file_size;
                            }
                            Err(e) => {
                                eprintln!("Failed to read uma.log: {}", e);
                            }
                        }
                    }


                    // // 1. Read and display the log contents.
                    // match fs::read_to_string("uma.log") {
                    //     Ok(log_contents) => {
                    //         println!("{}", log_contents); // Print to console for now
                    //     }
                    //     Err(e) => {
                    //         eprintln!("Failed to read uma.log: {}", e);
                    //     }
                    // }

                    // // 1. Read the log_mode_refresh value from uma.toml.
                    // let uma_toml_path = Path::new("uma.toml");
                    // let user_metadata = match toml::from_str::<LocalUserUma>(&fs::read_to_string(uma_toml_path)?) {
                    //     Ok(metadata) => metadata,
                    //     Err(e) => {
                    //         debug_log!("Error reading or parsing uma.toml: {}", e);
                    //         eprintln!("Error reading or parsing uma.toml: {}", e);
                    //         return Ok(false); // Or handle the error differently (e.g., use a default value)
                    //     }
                    // };


                    // 2. Sleep for a short duration.
                    // thread::sleep(Duration::from_secs(log_mode_refresh));
                    thread::sleep(Duration::from_secs_f32(log_mode_refresh)); // Use from_secs_f32

                    // // 3. Check for 'esc' key press to exit.
                    // if let Ok(input) = tiny_tui::get_input() {
                    //     if input == "esc" {
                    //         debug_log("Exiting debug log view.");
                    //         break; // Exit the loop
                    //     }
                    // }
                }
            }
           "storyboard" | "mudd" => {
                debug_log("storyboard");
                // Display help information
            }
            "b" | "back" => {
                debug_log("back mode started");
                app.input_mode = InputMode::MainCommand;
                debug_log("changed to command mode");



                // if app.current_path != PathBuf::from("project_graph_data/team_channels") {
                if app.current_path != make_input_path_name_abs_executabledirectoryrelative_nocheck(
                    "project_graph_data/team_channels"
                )? {
                    // Only move back if not at the root of project_graph_data/team_channels
                    debug_log!(
                        "before pop handle_command_main_mode(), app.current_path {:?}",
                        &app.current_path
                    );

                    app.current_path.pop();
                    debug_log!(
                        "after pop handle_command_main_mode(), app.current_path {:?}",
                        &app.current_path
                    );

                    app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone(); // Update full path after popping.
                    app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // Update internal state too.
                    tiny_tui::render_list(
                        &app.tui_directory_list,
                        &app.current_path,
                        // Projecpa1_process
                        // Project Areas
                        &app.graph_navigation_instance_state.pa1_process,
                        &app.graph_navigation_instance_state.pa2_schedule,
                        &app.graph_navigation_instance_state.pa3_users,
                        &app.graph_navigation_instance_state.pa4_features,
                        &app.graph_navigation_instance_state.pa5_mvp,
                        &app.graph_navigation_instance_state.pa6_feedback,
                        );
                    app.update_directory_list()?;

                } else {
                  debug_log("back, but at root!");
                }
            }
            "home" => {
                /*
                For a clean reset, 'home' quits and restarts,
                ensuring all processes are clean.
                */
                debug_log("Home command received.");

                let _ = quit_set_continue_uma_to_false();

                // //////////////////////////
                // // Enable sync flag here!
                // //////////////////////////
                // TODO: ? also set in initializae-uma?
                // debug_log("About to set sync flag to true! (handle_command_main_mode(), home)");
                // initialize_ok_to_start_sync_flag_to_false();  //TODO turn on to use sync !!! (off for testing)

                // // 1. Reset the current path
                // let mut app_data_dir = PathBuf::from("project_graph_data");
                // app_data_dir.push("team_channels");
                // app.current_path = app_data_dir;
                // debug_log(&format!("Current path reset to: {:?}", app.current_path));

                // // 2. Purge state in GraphNavigationInstanceState
                // app.graph_navigation_instance_state.active_team_channel = String::new();
                // app.graph_navigation_instance_state.current_full_file_path = PathBuf::new();
                // // ... Clear other channel-specific data (e.g., current_node_* fields, collaborator_ports) ...
                // debug_log("GraphNavigationInstanceState - Channel specific data purged.");

                // // 3. Reset the home_square_one flag
                // app.graph_navigation_instance_state.home_square_one = true;
                // debug_log("home_square_one flag set to true.");

                // // 4.  (Optional) Clear the TUI list to reflect the home screen
                // app.tui_directory_list.clear();
                // debug_log("TUI directory list cleared.");

                // 5. (Optional) Trigger a TUI refresh
                // (not needed for default 'current path' print)
                // ... (Your TUI refresh logic) ...
                // debug_log("TUI refresh triggered (if implemented).");
            }


            /*
            Message Mode Handler: Dual-Interface Message Viewing System

            This handler serves two primary functions:
            1. Launches a separate passive-view terminal for real-time message monitoring
            2. Enters the interactive message browsing mode in the main terminal
            /
            # Process Flow:
            1. Path Handling:
               - Clones current directory path
               - Appends "message_posts_browser" subdirectory
               - Validates directory existence (returns Ok(false) if not found)
            /
            2. Passive View Terminal Launch (Linux):
               - Creates a new gnome-terminal instance
               - Passes the current Uma executable path and message directory
               - Uses format: "gnome-terminal -- [uma_path] --passive_message_mode [message_dir]"
               - Launches independently (non-blocking)
            /
            3. Main Terminal Setup:
               - Sets input mode to InsertText
               - Updates current path to message browser directory
               - Initializes message browser interface
            /
            # Directory Structure:
            ```text
            current_path/
             message_posts_browser/
                 0.toml (metadata)
                 1__user1.toml (messages)
                 2__user2.toml (messages)
            ```
            /
            # Error Handling:
            - Checks for message directory existence
            - Safely handles executable path conversion
            - Uses Result for error propagation
            /
            # Platform Support:
            - Linux: Uses gnome-terminal for passive view
            - Other platforms: TBD
            /
            # Dependencies:
            - std::process::Command for terminal launching
            - std::env for executable path
            - PathBuf for path manipulation
            /
            # Safety:
            - No unwrap() calls
            - Safe string conversions via to_string_lossy()
            - Proper error propagation
            /
            # Notes:
            - Passive view terminal operates independently
            - Main terminal maintains interactive mode
            - Message directory must exist before operation
            /
            /
            Passive Message View Mode

            This code implements a separate terminal-window passive message viewer
            that runs independently from the main Uma application.
            /
            # Launch Process:
            1. Triggered when user enters "m" in main Uma application
            2. Creates new terminal window running a separate Uma process
            3. New process runs in passive-view mode (--passive_message_mode)
            /
            # Implementation Details:
            ```rust
            // Main Process (Original Uma Terminal):
            // Launches new terminal for passive view, then continues normal operation
            let mut message_path = app.current_path.clone();
            message_path.push("message_posts_browser");

            // New terminal command structure:
            StdCommand::new("gnome-terminal")
                .arg("--")
                .arg(uma_path_str)               // Path to Uma executable
                .arg("--passive_message_mode")   // Tells Uma to run in passive mode
                .arg(&message_path_str)          // Path to message directory
                .spawn()?;
            ```
            /
            # Key Components:
            1. Directory Validation:
               - Checks if message directory exists before launching
               - Returns Ok(false) if directory not found
            /
            2. Path Handling:
               - Clones and modifies current path
               - Adds "message_posts_browser" subdirectory
               - Converts paths to strings safely using to_string_lossy()
            /
            3. Process Launch:
               - Uses gnome-terminal on Linux
               - Launches Uma in new process with --passive_message_mode flag
               - New process is independent (non-blocking)
            /
            # Command Line Arguments:
            When launched in passive mode, Uma receives:
            1. --passive_message_mode flag
            2. Path to message directory
            /
            # Safety & Error Handling:
            - Safe path conversions
            - No unwrap() calls
            - Proper error propagation with Result
            - Directory existence validation
            /
            # Operational Flow:
            1. User enters "m" in main Uma
            2. New terminal launches with Uma in passive mode
            3. Original Uma continues with normal message operations
            4. New terminal operates independently for message viewing
            /
            # Important Notes:
            - This is a view-only mode
            - No connection maintained between terminals
            - Original Uma process continues independently
            - Passive view must be manually closed when done
            */
            "m" | "message" => {
                debug_log("m selected");

                // /////////////////
                // // Passive View
                // /////////////////
                // let mut this_team_message_path = app.current_path.clone();
                // this_team_message_path.push("message_posts_browser");

                // debug_log!("message_path {:?}", this_team_message_path);

                // // Check if directory exists
                // if !this_team_message_path.exists() {
                //     println!("handle comand 'm', Message directory not found!");
                //     return Ok(false);  // Changed to match expected return type
                // }

                // let message_path_str = this_team_message_path.to_string_lossy().into_owned();

                // #[cfg(target_os = "linux")]
                // {
                //     if let Ok(uma_path) = env::current_exe() {
                //         if let Some(uma_path_str) = uma_path.to_str() {
                //             StdCommand::new("gnome-terminal")
                //                 .arg("--")
                //                 .arg(uma_path_str)
                //                 .arg("--passive_message_mode")
                //                 .arg(&message_path_str)
                //                 .spawn()?;
                //         }
                //     }
                // }

                debug_log(&format!("handle command 'm' app.current_path {:?}", app.current_path));
                // app.input_mode = InputMode::InsertText;
                // app.current_path = app.current_path.join("message_posts_browser");

                // debug_log!(
                //     "app.current_path after joining 'message_posts_browser': {:?}",
                //     app.current_path
                // );

                // // Enter Browser of Messages
                // app.load_messagepost_messages();

                // TODO experimental state refresh
                app.enter_modal_message_posts_browser(app.current_path.clone())?;
            }

            // Tmux Vertical Split Message Passive View Handler
            //
            // Command aliases: "mpv" | "pmv" | "message-passive-vsplit"
            //
            // # Purpose
            //
            // Launches passive message viewer in a new tmux vertical split pane.
            // Unlike the "mp" command which opens a new terminal window, this creates
            // a split within the current tmux session for side-by-side viewing.
            //
            // # User Experience
            //
            // User types "mpv" in main Uma application:
            // - Current pane continues running Uma normally
            // - New vertical pane appears to the right (or left, depending on tmux config)
            // - New pane shows passive message view (auto-refreshing, read-only)
            // - User can switch between panes with tmux keybindings (default: Ctrl+b arrow)
            // - Passive view runs independently until manually closed
            //
            // # Tmux Split Behavior
            //
            // Creates vertical split with:
            // - Direction: Vertical (side-by-side panes)
            // - Command: uma --passive_vsplit_message_mode [path]
            // - Working directory: Inherited from current pane
            // - Size: Equal split (tmux default, user can resize)
            //
            // # Process Flow
            //
            // 1. Validate current path + message_posts_browser directory exists
            // 2. Get path to current Uma executable
            // 3. Build tmux command string
            // 4. Execute: tmux split-window -v "uma --passive_vsplit_message_mode [path]"
            // 5. Main Uma continues in original pane
            // 6. Passive view starts in new split pane
            //
            // # Prerequisites
            //
            // - Must be running inside a tmux session
            // - tmux must be installed and available in PATH
            // - Uma executable must be accessible
            //
            // # Error Handling
            //
            // All errors log and return gracefully (never panic):
            // - Directory not found: Print error, return Ok(false)
            // - Cannot get Uma executable path: Log error, return Ok(false)
            // - tmux command fails: Log error, return Ok(false)
            //
            // If not in tmux session: Command fails silently (tmux returns error)
            //
            // # Command Line Executed
            //
            // ```bash
            // tmux split-window -v "uma --passive_vsplit_message_mode /path/to/message_posts_browser"
            // ```
            //
            // # Related Commands
            //
            // - "mp" / "message-passive": Opens in new terminal window
            // - "mph" / "message-passive-hsplit": Opens in tmux horizontal split
            // - "m" / "message": Opens interactive modal message browser
            //
            // # Related Functions
            //
            // - `optional_passive_mode()`: Handles --passive_vsplit_message_mode flag
            // - `run_passive_message_mode()`: Runs the passive view loop
            // - `passive_display_messages()`: Displays messages in passive view
            "mpv" | "pmv" | "message-passive-vsplit" => {
                debug_log("mpv command selected - launching passive message view in tmux vsplit");

                // ============================================================
                // PATH VALIDATION: Verify message directory exists
                // ============================================================
                let mut this_team_message_path = app.current_path.clone();
                this_team_message_path.push("message_posts_browser");

                debug_log!("mpv: message_path {:?}", this_team_message_path);

                // Check if directory exists
                if !this_team_message_path.exists() {
                    println!("Message directory not found!");
                    debug_log!("mpv: message directory does not exist: {:?}", this_team_message_path);
                    return Ok(false);
                }

                // Convert path to string for command
                let message_path_str = this_team_message_path.to_string_lossy().into_owned();

                // ============================================================
                // EXECUTABLE PATH: Get path to current Uma binary
                // ============================================================
                let uma_path = match env::current_exe() {
                    Ok(path) => path,
                    Err(e) => {
                        debug_log!("mpv: Failed to get current executable path: {}", e);
                        println!("Error: Cannot determine Uma executable path");
                        return Ok(false);
                    }
                };

                let uma_path_str = match uma_path.to_str() {
                    Some(path_str) => path_str,
                    None => {
                        debug_log!("mpv: Failed to convert executable path to string");
                        println!("Error: Invalid executable path");
                        return Ok(false);
                    }
                };

                // ============================================================
                // TMUX COMMAND: Build and execute tmux split command
                // ============================================================
                // Build command string for tmux to execute in new pane
                let uma_command = format!(
                    "{} --passive_vsplit_message_mode {}",
                    uma_path_str,
                    message_path_str
                );

                debug_log!("mpv: Executing tmux command: split-window -v {}", uma_command);

                // Execute tmux split-window command
                match StdCommand::new("tmux")
                    .args(["split-window", "-v", &uma_command])
                    .spawn()
                {
                    Ok(_) => {
                        debug_log!("mpv: Successfully launched passive view in tmux vsplit");
                    }
                    Err(e) => {
                        debug_log!("mpv: Failed to create tmux vsplit: {}", e);
                        println!("Error: Failed to create tmux split. Are you running inside tmux?");
                        return Ok(false);
                    }
                }

                debug_log!("mpv: Command handler completed successfully");
            }

            // Tmux Horizontal Split Message Passive View Handler
            //
            // Command aliases: "mph" | "pmh" | "message-passive-hsplit"
            //
            // # Purpose
            //
            // Launches passive message viewer in a new tmux horizontal split pane.
            // Unlike the "mp" command which opens a new terminal window, this creates
            // a split within the current tmux session for top-bottom viewing.
            //
            // # User Experience
            //
            // User types "mph" in main Uma application:
            // - Current pane continues running Uma normally
            // - New horizontal pane appears below (or above, depending on tmux config)
            // - New pane shows passive message view (auto-refreshing, read-only)
            // - User can switch between panes with tmux keybindings (default: Ctrl+b arrow)
            // - Passive view runs independently until manually closed
            //
            // # Tmux Split Behavior
            //
            // Creates horizontal split with:
            // - Direction: Horizontal (top-bottom panes)
            // - Command: uma --passive_hsplit_message_mode [path]
            // - Working directory: Inherited from current pane
            // - Size: Equal split (tmux default, user can resize)
            //
            // # Process Flow
            //
            // 1. Validate current path + message_posts_browser directory exists
            // 2. Get path to current Uma executable
            // 3. Build tmux command string
            // 4. Execute: tmux split-window -h "uma --passive_hsplit_message_mode [path]"
            // 5. Main Uma continues in original pane
            // 6. Passive view starts in new split pane
            //
            // # Prerequisites
            //
            // - Must be running inside a tmux session
            // - tmux must be installed and available in PATH
            // - Uma executable must be accessible
            //
            // # Error Handling
            //
            // All errors log and return gracefully (never panic):
            // - Directory not found: Print error, return Ok(false)
            // - Cannot get Uma executable path: Log error, return Ok(false)
            // - tmux command fails: Log error, return Ok(false)
            //
            // If not in tmux session: Command fails silently (tmux returns error)
            //
            // # Command Line Executed
            //
            // ```bash
            // tmux split-window -h "uma --passive_hsplit_message_mode /path/to/message_posts_browser"
            // ```
            //
            // # Related Commands
            //
            // - "mp" / "message-passive": Opens in new terminal window
            // - "mpv" / "message-passive-vsplit": Opens in tmux vertical split
            // - "m" / "message": Opens interactive modal message browser
            //
            // # Related Functions
            //
            // - `optional_passive_mode()`: Handles --passive_hsplit_message_mode flag
            // - `run_passive_message_mode()`: Runs the passive view loop
            // - `passive_display_messages()`: Displays messages in passive view
            "mph" | "pmh" | "message-passive-hsplit" => {
                debug_log("mph command selected - launching passive message view in tmux hsplit");

                // ============================================================
                // PATH VALIDATION: Verify message directory exists
                // ============================================================
                let mut this_team_message_path = app.current_path.clone();
                this_team_message_path.push("message_posts_browser");

                debug_log!("mph: message_path {:?}", this_team_message_path);

                // Check if directory exists
                if !this_team_message_path.exists() {
                    println!("Message directory not found!");
                    debug_log!("mph: message directory does not exist: {:?}", this_team_message_path);
                    return Ok(false);
                }

                // Convert path to string for command
                let message_path_str = this_team_message_path.to_string_lossy().into_owned();

                // ============================================================
                // EXECUTABLE PATH: Get path to current Uma binary
                // ============================================================
                let uma_path = match env::current_exe() {
                    Ok(path) => path,
                    Err(e) => {
                        debug_log!("mph: Failed to get current executable path: {}", e);
                        println!("Error: Cannot determine Uma executable path");
                        return Ok(false);
                    }
                };

                let uma_path_str = match uma_path.to_str() {
                    Some(path_str) => path_str,
                    None => {
                        debug_log!("mph: Failed to convert executable path to string");
                        println!("Error: Invalid executable path");
                        return Ok(false);
                    }
                };

                // ============================================================
                // TMUX COMMAND: Build and execute tmux split command
                // ============================================================
                // Build command string for tmux to execute in new pane
                let uma_command = format!(
                    "{} --passive_hsplit_message_mode {}",
                    uma_path_str,
                    message_path_str
                );

                debug_log!("mph: Executing tmux command: split-window -h {}", uma_command);

                // Execute tmux split-window command
                match StdCommand::new("tmux")
                    .args(["split-window", "-h", &uma_command])
                    .spawn()
                {
                    Ok(_) => {
                        debug_log!("mph: Successfully launched passive view in tmux hsplit");
                    }
                    Err(e) => {
                        debug_log!("mph: Failed to create tmux hsplit: {}", e);
                        println!("Error: Failed to create tmux split. Are you running inside tmux?");
                        return Ok(false);
                    }
                }

                debug_log!("mph: Command handler completed successfully");
            }

            // Message Passive Mode Handler - New Terminal Window
            //
            // Command aliases: "mp" | "pm" | "message-passive"
            //
            // # Purpose
            //
            // Launches passive message viewer in a new terminal window.
            // Attempts platform-appropriate terminal emulator with fallback options.
            //
            // # Platform Support
            //
            // - Linux: gnome-terminal, xterm (fallback)
            // - Android/Termux: Same as Linux (Termux is terminal)
            // - macOS: Terminal.app
            // - BSD variants: xterm
            // - Redox: Redox terminal (if available)
            //
            // # Process Flow
            //
            // 1. Validate message directory exists
            // 2. Get Uma executable path
            // 3. Try platform-specific terminal launcher
            // 4. If launch fails: Log error, inform user, return Ok(false)
            //
            // # Error Handling
            //
            // All errors handled gracefully:
            // - Directory not found: Print message, return Ok(false)
            // - Executable path error: Log and return Ok(false)
            // - Terminal launch fails: Log and return Ok(false)
            "mp" | "pm" | "message-passive" => {
                debug_log("mp selected - launching passive message view in new terminal");

                // ============================================================
                // PATH VALIDATION: Verify message directory exists
                // ============================================================
                let mut this_team_message_path = app.current_path.clone();
                this_team_message_path.push("message_posts_browser");

                debug_log!("mp: message_path {:?}", this_team_message_path);

                if !this_team_message_path.exists() {
                    println!("Message directory not found!");
                    debug_log!("mp: message directory does not exist: {:?}", this_team_message_path);
                    return Ok(false);
                }

                let message_path_str = this_team_message_path.to_string_lossy().into_owned();

                // ============================================================
                // EXECUTABLE PATH: Get path to current Uma binary
                // ============================================================
                let uma_path = match env::current_exe() {
                    Ok(path) => path,
                    Err(e) => {
                        debug_log!("mp: Failed to get current executable path: {}", e);
                        println!("Error: Cannot determine Uma executable path");
                        return Ok(false);
                    }
                };

                let uma_path_str = match uma_path.to_str() {
                    Some(path_str) => path_str,
                    None => {
                        debug_log!("mp: Failed to convert executable path to string");
                        println!("Error: Invalid executable path");
                        return Ok(false);
                    }
                };

                // ============================================================
                // PLATFORM-SPECIFIC TERMINAL LAUNCH
                // ============================================================

                // Linux and Android/Termux (same POSIX terminal approach)
                #[cfg(any(target_os = "linux", target_os = "android"))]
                {
                    debug_log!("mp: Linux/Android platform detected");

                    // Try gnome-terminal first (most common on Linux)
                    let result = StdCommand::new("gnome-terminal")
                        .arg("--")
                        .arg(uma_path_str)
                        .arg("--passive_message_mode")
                        .arg(&message_path_str)
                        .spawn();

                    if result.is_ok() {
                        debug_log!("mp: Successfully launched with gnome-terminal");
                    } else {
                        debug_log!("mp: gnome-terminal failed, trying xterm fallback");

                        // Fallback to xterm (more universal)
                        match StdCommand::new("xterm")
                            .arg("-e")
                            .arg(uma_path_str)
                            .arg("--passive_message_mode")
                            .arg(&message_path_str)
                            .spawn()
                        {
                            Ok(_) => {
                                debug_log!("mp: Successfully launched with xterm");
                            }
                            Err(e) => {
                                debug_log!("mp: Failed to launch terminal: {}", e);
                                println!("Error: Could not launch terminal. Please install gnome-terminal or xterm.");
                                return Ok(false);
                            }
                        }
                    }
                }

                // macOS (use Terminal.app)
                #[cfg(target_os = "macos")]
                {
                    debug_log!("mp: macOS platform detected");

                    // Use osascript to launch Terminal.app with command
                    // This is more reliable than `open -a Terminal`
                    let terminal_command = format!(
                        "tell application \"Terminal\" to do script \"{} --passive_message_mode {}\"",
                        uma_path_str,
                        message_path_str
                    );

                    match StdCommand::new("osascript")
                        .arg("-e")
                        .arg(&terminal_command)
                        .spawn()
                    {
                        Ok(_) => {
                            debug_log!("mp: Successfully launched with Terminal.app");
                        }
                        Err(e) => {
                            debug_log!("mp: Failed to launch Terminal.app: {}", e);
                            println!("Error: Could not launch Terminal.app");
                            return Ok(false);
                        }
                    }
                }

                // BSD variants (FreeBSD, OpenBSD, NetBSD - use xterm)
                #[cfg(any(
                    target_os = "freebsd",
                    target_os = "openbsd",
                    target_os = "netbsd",
                    target_os = "dragonfly"
                ))]
                {
                    debug_log!("mp: BSD platform detected");

                    match StdCommand::new("xterm")
                        .arg("-e")
                        .arg(uma_path_str)
                        .arg("--passive_message_mode")
                        .arg(&message_path_str)
                        .spawn()
                    {
                        Ok(_) => {
                            debug_log!("mp: Successfully launched with xterm");
                        }
                        Err(e) => {
                            debug_log!("mp: Failed to launch xterm: {}", e);
                            println!("Error: Could not launch xterm. Please install xterm.");
                            return Ok(false);
                        }
                    }
                }

                // Redox OS (use Redox terminal if available)
                #[cfg(target_os = "redox")]
                {
                    debug_log!("mp: Redox OS platform detected");

                    // Try Redox's terminal emulator
                    match StdCommand::new("terminal")
                        .arg(uma_path_str)
                        .arg("--passive_message_mode")
                        .arg(&message_path_str)
                        .spawn()
                    {
                        Ok(_) => {
                            debug_log!("mp: Successfully launched with Redox terminal");
                        }
                        Err(e) => {
                            debug_log!("mp: Failed to launch Redox terminal: {}", e);
                            println!("Error: Could not launch terminal on Redox");
                            return Ok(false);
                        }
                    }
                }

                // Catch-all for unsupported platforms
                #[cfg(not(any(
                    target_os = "linux",
                    target_os = "android",
                    target_os = "macos",
                    target_os = "freebsd",
                    target_os = "openbsd",
                    target_os = "netbsd",
                    target_os = "dragonfly",
                    target_os = "redox"
                )))]
                {
                    debug_log!("mp: Unsupported platform for terminal launch");
                    println!("Error: Terminal launch not supported on this platform");
                    println!("You can use tmux splits instead: 'mpv' or 'mph'");
                    return Ok(false);
                }

                debug_log!("mp: Command handler completed");
            }

            // "mp" | "pm" | "message-passive" => {
            //     debug_log("m selected");

            //     /////////////////
            //     // Passive View
            //     /////////////////
            //     let mut this_team_message_path = app.current_path.clone();
            //     this_team_message_path.push("message_posts_browser");

            //     debug_log!("message_path {:?}", this_team_message_path);

            //     // Check if directory exists
            //     if !this_team_message_path.exists() {
            //         println!("handle comand 'm', Message directory not found!");
            //         return Ok(false);  // Changed to match expected return type
            //     }

            //     let message_path_str = this_team_message_path.to_string_lossy().into_owned();

            //     #[cfg(target_os = "linux")]
            //     {
            //         if let Ok(uma_path) = env::current_exe() {
            //             if let Some(uma_path_str) = uma_path.to_str() {
            //                 StdCommand::new("gnome-terminal")
            //                     .arg("--")
            //                     .arg(uma_path_str)
            //                     .arg("--passive_message_mode")
            //                     .arg(&message_path_str)
            //                     .spawn()?;
            //             }
            //         }
            //     }


            //     debug_log(&format!("handle command 'mp'/'message-passive' app.current_path {:?}", app.current_path));
            // }

            "t" | "task" | "tasks" => {
                debug_log("t selected: task browser launching");

                // /////////////////
                // // Passive View
                // /////////////////
                // let mut task_path = app.current_path.clone();
                // task_path.push("task_browser");

                // // Check if directory exists
                // if !task_path.exists() {
                //     println!("Task directory not found!");
                //     return Ok(false);
                // }

                // let task_path_str = task_path.to_string_lossy().into_owned();

                // #[cfg(target_os = "linux")]
                // {
                //     if let Ok(uma_path) = env::current_exe() {
                //         if let Some(uma_path_str) = uma_path.to_str() {
                //             StdCommand::new("gnome-terminal")
                //                 .arg("--")
                //                 .arg(uma_path_str)
                //                 .arg("--passive_task_mode")
                //                 .arg(&task_path_str)
                //                 .spawn()?;
                //         }
                //     }
                // }


                debug_log(&format!("app.current_path {:?}", app.current_path));
                app.input_mode = InputMode::InsertText;

                // // TODO Assuming you have a way to get the current node's name:
                // let current_node_name = app.current_path.file_name().unwrap().to_string_lossy().to_string();

                app.current_path = app.current_path.join("task_browser");
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                debug_log!(
                    "app.current_path after joining 'task_browser': {:?}",
                    app.current_path
                );

                // Enter Browser of Tasks
                app.enter_task_browser();

            }


            "tp" | "pt" | "task-passive" | "tasks-passive" => {
                debug_log("t selected: task browser launching");

                /////////////////
                // Passive View
                /////////////////
                let mut task_path = app.current_path.clone();
                task_path.push("task_browser");

                // Check if directory exists
                if !task_path.exists() {
                    println!("Task directory not found!");
                    return Ok(false);
                }

                let task_path_str = task_path.to_string_lossy().into_owned();

                #[cfg(target_os = "linux")]
                {
                    if let Ok(uma_path) = env::current_exe() {
                        if let Some(uma_path_str) = uma_path.to_str() {
                            StdCommand::new("gnome-terminal")
                                .arg("--")
                                .arg(uma_path_str)
                                .arg("--passive_task_mode")
                                .arg(&task_path_str)
                                .spawn()?;
                        }
                    }
                }
                debug_log(&format!("'tp' 'task-passive' app.current_path {:?}", app.current_path));
            }

            // Tmux Vertical Split Task Passive View Handler
            //
            // Command aliases: "tpv" | "ptv" | "task-passive-vsplit"
            //
            // # Purpose
            //
            // Launches passive task board viewer in a new tmux vertical split pane.
            // Unlike the "tp" command (new terminal), this creates a split within
            // the current tmux session for side-by-side viewing of task board.
            //
            // # User Experience
            //
            // User types "tpv" in main Uma application:
            // - Current pane continues running Uma normally
            // - New vertical pane appears with passive task board view
            // - Task board auto-refreshes when changes detected
            // - User can switch between panes with tmux keybindings
            // - Passive view runs independently until manually closed
            //
            // # Tmux Split Behavior
            //
            // Creates vertical split with:
            // - Direction: Vertical (side-by-side panes)
            // - Command: uma --passive_vsplit_task_mode [path]
            // - Working directory: Inherited from current pane
            // - Size: Equal split (tmux default, user can resize)
            //
            // # Process Flow
            //
            // 1. Validate current path + task_board directory exists
            // 2. Get path to current Uma executable
            // 3. Build tmux command string
            // 4. Execute: tmux split-window -v "uma --passive_vsplit_task_mode [path]"
            // 5. Main Uma continues in original pane
            // 6. Passive task view starts in new split pane
            //
            // # Prerequisites
            //
            // - Must be running inside a tmux session
            // - tmux must be installed and available in PATH
            // - Uma executable must be accessible
            //
            // # Error Handling
            //
            // All errors log and return gracefully (never panic):
            // - Directory not found: Print error, return Ok(false)
            // - Cannot get Uma executable path: Log error, return Ok(false)
            // - tmux command fails: Log error, return Ok(false)
            //
            // If not in tmux session: Command fails with helpful message
            //
            // # Command Line Executed
            //
            // ```bash
            // tmux split-window -v "uma --passive_vsplit_task_mode /path/to/task_board"
            // ```
            //
            // # Related Commands
            //
            // - "tp" / "task-passive": Opens in new terminal window
            // - "tph" / "task-passive-hsplit": Opens in tmux horizontal split
            // - "t" / "task": Opens interactive task board
            //
            // # Related Functions
            //
            // - `optional_passive_mode()`: Handles --passive_vsplit_task_mode flag
            // - `run_passive_task_mode()`: Runs the passive task view loop
            // - `passive_display_tasks()`: Displays task board in passive view
            "tpv" | "ptv" | "task-passive-vsplit" => {
                debug_log("tpv command selected - launching passive task view in tmux vsplit");

                // ============================================================
                // PATH VALIDATION: Verify task board directory exists
                // ============================================================
                let mut this_team_task_board_path = app.current_path.clone();
                this_team_task_board_path.push("task_browser");

                debug_log!("tpv: task_board_path {:?}", this_team_task_board_path);

                // Check if directory exists
                if !this_team_task_board_path.exists() {
                    println!("Task board directory not found!");
                    debug_log!("tpv: task_board directory does not exist: {:?}", this_team_task_board_path);
                    return Ok(false);
                }

                // Convert path to string for command
                let task_board_path_str = this_team_task_board_path.to_string_lossy().into_owned();

                // ============================================================
                // EXECUTABLE PATH: Get path to current Uma binary
                // ============================================================
                let uma_path = match env::current_exe() {
                    Ok(path) => path,
                    Err(e) => {
                        debug_log!("tpv: Failed to get current executable path: {}", e);
                        println!("Error: Cannot determine Uma executable path");
                        return Ok(false);
                    }
                };

                let uma_path_str = match uma_path.to_str() {
                    Some(path_str) => path_str,
                    None => {
                        debug_log!("tpv: Failed to convert executable path to string");
                        println!("Error: Invalid executable path");
                        return Ok(false);
                    }
                };

                // ============================================================
                // TMUX COMMAND: Build and execute tmux split command
                // ============================================================
                // Build command string for tmux to execute in new pane
                let uma_command = format!(
                    "{} --passive_vsplit_task_mode {}",
                    uma_path_str,
                    task_board_path_str
                );

                debug_log!("tpv: Executing tmux command: split-window -v {}", uma_command);

                // Execute tmux split-window command
                match StdCommand::new("tmux")
                    .args(["split-window", "-v", &uma_command])
                    .spawn()
                {
                    Ok(_) => {
                        debug_log!("tpv: Successfully launched passive task view in tmux vsplit");
                    }
                    Err(e) => {
                        debug_log!("tpv: Failed to create tmux vsplit: {}", e);
                        println!("Error: Failed to create tmux split. Are you running inside tmux?");
                        return Ok(false);
                    }
                }

                debug_log!("tpv: Command handler completed successfully");
            }

            // Tmux Horizontal Split Task Passive View Handler
            //
            // Command aliases: "tph" | "pth" | "task-passive-hsplit"
            //
            // # Purpose
            //
            // Launches passive task board viewer in a new tmux horizontal split pane.
            // Unlike the "tp" command (new terminal), this creates a split within
            // the current tmux session for top-bottom viewing of task board.
            //
            // # User Experience
            //
            // User types "tph" in main Uma application:
            // - Current pane continues running Uma normally
            // - New horizontal pane appears with passive task board view
            // - Task board auto-refreshes when changes detected
            // - User can switch between panes with tmux keybindings
            // - Passive view runs independently until manually closed
            //
            // # Tmux Split Behavior
            //
            // Creates horizontal split with:
            // - Direction: Horizontal (top-bottom panes)
            // - Command: uma --passive_hsplit_task_mode [path]
            // - Working directory: Inherited from current pane
            // - Size: Equal split (tmux default, user can resize)
            //
            // # Process Flow
            //
            // 1. Validate current path + task_board directory exists
            // 2. Get path to current Uma executable
            // 3. Build tmux command string
            // 4. Execute: tmux split-window -h "uma --passive_hsplit_task_mode [path]"
            // 5. Main Uma continues in original pane
            // 6. Passive task view starts in new split pane
            //
            // # Prerequisites
            //
            // - Must be running inside a tmux session
            // - tmux must be installed and available in PATH
            // - Uma executable must be accessible
            //
            // # Error Handling
            //
            // All errors log and return gracefully (never panic):
            // - Directory not found: Print error, return Ok(false)
            // - Cannot get Uma executable path: Log error, return Ok(false)
            // - tmux command fails: Log error, return Ok(false)
            //
            // If not in tmux session: Command fails with helpful message
            //
            // # Command Line Executed
            //
            // ```bash
            // tmux split-window -h "uma --passive_hsplit_task_mode /path/to/task_board"
            // ```
            //
            // # Related Commands
            //
            // - "tp" / "task-passive": Opens in new terminal window
            // - "tpv" / "task-passive-vsplit": Opens in tmux vertical split
            // - "t" / "task": Opens interactive task board
            //
            // # Related Functions
            //
            // - `optional_passive_mode()`: Handles --passive_hsplit_task_mode flag
            // - `run_passive_task_mode()`: Runs the passive task view loop
            // - `passive_display_tasks()`: Displays task board in passive view
            "tph" | "pth" | "task-passive-hsplit" => {
                debug_log("tph command selected - launching passive task view in tmux hsplit");

                // ============================================================
                // PATH VALIDATION: Verify task board directory exists
                // ============================================================
                let mut this_team_task_board_path = app.current_path.clone();
                this_team_task_board_path.push("task_browser");

                debug_log!("tph: task_board_path {:?}", this_team_task_board_path);

                // Check if directory exists
                if !this_team_task_board_path.exists() {
                    println!("Task board directory not found!");
                    debug_log!("tph: task_board directory does not exist: {:?}", this_team_task_board_path);
                    return Ok(false);
                }

                // Convert path to string for command
                let task_board_path_str = this_team_task_board_path.to_string_lossy().into_owned();

                // ============================================================
                // EXECUTABLE PATH: Get path to current Uma binary
                // ============================================================
                let uma_path = match env::current_exe() {
                    Ok(path) => path,
                    Err(e) => {
                        debug_log!("tph: Failed to get current executable path: {}", e);
                        println!("Error: Cannot determine Uma executable path");
                        return Ok(false);
                    }
                };

                let uma_path_str = match uma_path.to_str() {
                    Some(path_str) => path_str,
                    None => {
                        debug_log!("tph: Failed to convert executable path to string");
                        println!("Error: Invalid executable path");
                        return Ok(false);
                    }
                };

                // ============================================================
                // TMUX COMMAND: Build and execute tmux split command
                // ============================================================
                // Build command string for tmux to execute in new pane
                let uma_command = format!(
                    "{} --passive_hsplit_task_mode {}",
                    uma_path_str,
                    task_board_path_str
                );

                debug_log!("tph: Executing tmux command: split-window -h {}", uma_command);

                // Execute tmux split-window command
                match StdCommand::new("tmux")
                    .args(["split-window", "-h", &uma_command])
                    .spawn()
                {
                    Ok(_) => {
                        debug_log!("tph: Successfully launched passive task view in tmux hsplit");
                    }
                    Err(e) => {
                        debug_log!("tph: Failed to create tmux hsplit: {}", e);
                        println!("Error: Failed to create tmux split. Are you running inside tmux?");
                        return Ok(false);
                    }
                }

                debug_log!("tph: Command handler completed successfully");
            }


            "q" | "quit" | "exit" => {
                debug_log("quit");
                let _ = no_restart_set_hard_reset_flag_to_false();
                let _ = quit_set_continue_uma_to_false();

                return Ok(true); // Signal to exit the loop
            }
            _ => {
                // Display error message (e.g., "Invalid command")
                debug_log(" 'other' commend? _ => {...");
                // if app.is_in_task_browser_directory() {
                if app.is_in_message_posts_browser_directory() {

                    if app.handle_task_action(input) { // Exit if handle_task_action returns true.
                        app.current_path.pop(); // Leave task browser directory
                    };
                // Stay within the task browser function and mode otherwise.
                } else {
                // ... Handle other command input as usual ...
                }
            }
            // ... (handle other commands)

        }
    }
    debug_log("end handle_command_main_mode()");
    return Ok(false); // Don't exit by default
}


fn task_mode_handle__commands(
    input: &str,
    app: &mut App,
    graph_navigation_instance_state: &GraphNavigationInstanceState
) -> Result<bool, io::Error> {
    /*
    For input command mode
    quit
    command-list/legend
    */

    debug_log(&format!("fn task_mode_handle__commands(), input->{:?}", input));

    let parts: Vec<&str> = input.trim().split_whitespace().collect();
    if let Some(command) = parts.first() {
        match command.to_lowercase().as_str() {
            "h" | "help" => {
                debug_log("Help!");
                // Display help information
            }

            "bigger" | "big" | "bg" => {
                app.tui_height = (app.tui_height + 1).max(1);  // Height cannot be less than 1
                app.tui_width = (app.tui_width + 1).max(1);  // Width cannot be less than 1
                // ... re-render
            }

            "smaller" | "small" | "sm" => {
                app.tui_height = (app.tui_height - 1).max(1);
                app.tui_width = (app.tui_width - 1).max(1);
                // ... re-render
            }

            "home" => {
                /*
                For a clean reset, 'home' quits and restarts,
                ensuring all processes are clean.
                */
                debug_log("Home command received.");
                let _ = quit_set_continue_uma_to_false();
            }

            "q" | "quit" | "exit" => {
                debug_log("quit");
                let _ = no_restart_set_hard_reset_flag_to_false();
                let _ = quit_set_continue_uma_to_false();

                return Ok(true); // Signal to exit the loop
            }
            _ => {
                // Display error message (e.g., "Invalid command")
                debug_log(" 'other' commend? _ => {...");

            }
            // ... (handle other commands)

        }
    }
    debug_log("end fn task_mode_handle__commands()");
    return Ok(false); // Don't exit by default
}


fn extract_last_path_section(current_path: &PathBuf) -> Option<String> {
    current_path.file_name().and_then(|os_str| os_str.to_str().map(|s| s.to_string()))
}

/// Determines the next available message file path.
///
/// Finds the highest existing message number in the given directory,
/// *ignoring usernames*, and returns a `PathBuf` for the next available file,
/// formatted as `{next_number}__{username}.toml`.
///
/// Handles empty directories and non-message files by starting from 1.
///
/// # Arguments
///
/// * `current_path`: The directory containing message files.
/// * `username`: The username for the *new* file.
///
/// # Returns
///
/// * `PathBuf`: Path to the next available message file.
fn get_next_message_file_path(current_path: &Path, username: &str) -> PathBuf {
    let mut max_number = 0;

    debug_log!(
        "get_next_message_file_path(): Starting. current_path: {:?}, username: {}",
        current_path, username
    );


    if let Ok(entries) = fs::read_dir(current_path) {
        for entry in entries.flatten() {
            if let Some(file_name) = entry.file_name().to_str() {
                if let Some((number_str, _rest)) = file_name.split_once("__") { // Ignore the rest of the filename
                    if let Ok(number) = number_str.parse::<u32>() {
                        max_number = max_number.max(number);
                    }
                }
            }
        }
    }

    let next_number = max_number + 1;
    let file_name = format!("{}__{}.toml", next_number, username);
    let file_path = current_path.join(file_name);


    debug_log!(
        "get_next_message_file_path(): Returning file_path: {:?}",
        file_path
    );
    file_path
}

// /// Loads collaborator data from a TOML file based on the username.
// ///
// /// This function uses `read_one_collaborator_addressbook_toml` to deserialize the collaborator data.
// ///
// /// # Arguments
// ///
// /// * `username` - The username of the collaborator whose data needs to be loaded.
// ///
// /// # Errors
// ///
// /// This function returns a `Result<CollaboratorTomlData, ThisProjectError>` to handle potential errors:
// ///  - `ThisProjectError::IoError`: If the collaborator file is not found or if there is an error reading the file.
// ///  - `ThisProjectError::TomlDeserializationError`: If there is an error parsing the TOML data.
// ///
// /// # Example
// ///
// /// ```
// /// let collaborator = get_addressbook_file_by_username("alice").unwrap(); // Assuming alice's data exists
// /// println!("Collaborator: {:?}", collaborator);
// /// ```
// fn get_addressbook_file_by_username(username: &str) -> Result<CollaboratorTomlData, ThisProjectError> {
//     debug_log!("Starting get_addressbook_file_by_username(username),  for -> '{}'", username);
//     // debug_log!("Starting get_addressbook_file_by_username(username),  for -> '{}'", username);

//     // Debug the directory structure
//     let base_dir = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR);
//     debug_log!("Base directory path: {:?}", base_dir);
//     debug_log!("Base directory exists: {}", base_dir.exists());

//     // Check current working directory
//     debug_log!("Current working directory: {:?}", std::env::current_dir()?);

//     // Construct and check the specific file path
//     let file_path = base_dir.join(format!("{}__collaborator.toml", username));
//     debug_log!("Looking for file at: {:?}", file_path);
//     debug_log!("File exists: {}", file_path.exists());

//     // Try to list files in the directory if it exists
//     if base_dir.exists() {
//         debug_log!("Contents of collaborator_files_address_book directory:");
//         match std::fs::read_dir(base_dir) {
//             Ok(entries) => {
//                 for entry in entries {
//                     if let Ok(entry) = entry {
//                         debug_log!("Found file: {:?}", entry.path());
//                     }
//                 }
//             },
//             Err(e) => debug_log!("Could not read directory contents: {}", e),
//         }
//     }
//     // Use read_one_collaborator_addressbook_toml to read and deserialize the data
//     match read_one_collaborator_addressbook_toml(username) {
//         Ok(loaded_collaborator) => {
//             debug_log!("Collaborator file found ok.");
//             Ok(loaded_collaborator)
//         }
//         Err(e) => {
//             debug_log!("Collaborator file not found: {:?}", e);
//             Err(e) // Propagate the error from read_one_collaborator_addressbook_toml
//         }
//     }
// }

// Version for clearsign toml only?
/// Loads collaborator data from a TOML file based on the username.
///
/// This function locates and loads a collaborator's data file using executable-relative
/// paths, ensuring consistent file access regardless of the current working directory.
/// The file is expected to be named "{username}__collaborator.toml" and located
/// in the project_graph_data/collaborator_files_address_book directory relative
/// to the executable's location.
///
/// # Arguments
///
/// * `username` - The username of the collaborator whose data needs to be loaded.
///
/// # Returns
///
/// * `Result<CollaboratorTomlData, ThisProjectError>` - The deserialized collaborator data
///   or an error detailing what went wrong.
///
/// # Errors
///
/// This function returns a `Result<CollaboratorTomlData, ThisProjectError>` to handle potential errors:
///  - `ThisProjectError::IoError`: If the collaborator file is not found or if there is an error reading the file.
///  - `ThisProjectError::TomlDeserializationError`: If there is an error parsing the TOML data.
///  - `ThisProjectError::PathResolutionError`: If the executable-relative path cannot be determined.
///
/// # Example
///
/// ```
/// let collaborator = get_addressbook_file_by_username("alice")?;
/// println!("Loaded collaborator data for: {}", collaborator.user_name);
/// ```
fn get_addressbook_file_by_username(
    username: &str,
    full_fingerprint_key_id_string: &str,
    ) -> Result<CollaboratorTomlData, ThisProjectError> {
    debug_log!("Starting GAFbU: get_addressbook_file_by_username for username -> '{}'", username);

    // Get the executable-relative base directory path
    let base_dir = match make_input_path_name_abs_executabledirectoryrelative_nocheck(
        COLLABORATOR_ADDRESSBOOK_PATH_STR
    ) {
        Ok(path) => path,
        Err(e) => {
            debug_log!("GAFbU: Failed to resolve collaborator directory path: {}", e);
            return Err(ThisProjectError::IoError(e));
        }
    };

    debug_log!("GAFbU: Base directory path (executable-relative): {:?}", base_dir);

    // Check if base directory exists
    let base_exists = base_dir.exists();
    debug_log!("GAFbU: Base directory exists: {}", base_exists);

    // Construct the specific file path
    let file_name = format!("{}__collaborator.toml", username);
    let file_path = base_dir.join(&file_name);
    debug_log!("GAFbU: Looking for collaborator file at: {:?}", file_path);

    // Check if file exists
    let file_exists = file_path.exists();
    debug_log!("GAFbU: Collaborator file exists: {}", file_exists);

    // If directory exists but file doesn't, list contents to help debugging
    if base_exists && !file_exists {
        debug_log!("GAFbU: Contents of collaborator_files_address_book directory:");
        match std::fs::read_dir(&base_dir) {
            Ok(entries) => {
                let mut found_files = false;
                for entry in entries {
                    if let Ok(entry) = entry {
                        debug_log!("- Found file: {:?}", entry.path().file_name().unwrap_or_default());
                        found_files = true;
                    }
                }
                if !found_files {
                    debug_log!("GAFbU: (directory is empty)");
                }
            },
            Err(e) => debug_log!("ERROR GAFbU: Could not read directory contents: {}", e),
        }
    }

    // Update the read_one_collaborator_addressbook_toml function to also use executable-relative paths
    // Since we don't see its implementation, we'll assume it's a function we need to call
    match read_one_collaborator_addressbook_toml(
        username,
        &full_fingerprint_key_id_string,
        ) {
        Ok(loaded_collaborator) => {
            debug_log!("GAFbU: Successfully loaded collaborator data for '{}'", username);
            Ok(loaded_collaborator)
        }
        Err(e) => {
            debug_log!("ERROR GAFbU: Failed to load collaborator file for '{}': {:?}", username, e);
            Err(e) // Propagate the error
        }
    }
}

/// Used to make a random hex string
/// to store the u128 salt for salted pearson hash
/// in the toml file as hex-string
fn generate_random_salt() -> String {
    let mut rng = rand::rng();
    let salt: u128 = rng.random(); // Generate a random u128
    format!("0x{:X}", salt) // Convert to hexadecimal string with "0x" prefix
}

/// Moves a task (node) from one column to another in the task browser.
/// Updates all relevant paths in node.toml files.
///
/// # Arguments
///
/// * `path_lookup_table` - HashMap containing path lookups by number
///
/// # Returns
///
/// * `Result<(), ThisProjectError>` - Success or error status
fn move_task(
    next_path_lookup_table: &HashMap<usize, PathBuf>
) -> Result<(), ThisProjectError> {
    debug_log("starting move_task()");
    // 1. Get source task number
    println!("Enter task number to move:");
    let task_num = get_user_input_number()?;

    // Get source path from lookup
    let source_path = match next_path_lookup_table.get(&task_num) {
        Some(path) => path.clone(),
        None => return Err(ThisProjectError::InvalidData(
            format!("Task number {} not found", task_num)
        )),
    };
    debug_log!("move_task(), Source path: {:?}", source_path);

    // 2. Get destination column number
    println!("Enter destination column number:");
    let dest_num = get_user_input_number()?;

    // Get destination path from lookup
    let dest_path = match next_path_lookup_table.get(&dest_num) {
        Some(path) => path.clone(),
        None => return Err(ThisProjectError::InvalidData(
            format!("Destination column {} not found", dest_num)
        )),
    };
    debug_log!("move_task(), Destination path: {:?}", dest_path);

    // 3. Perform the move operation
    move_node_directory(source_path, dest_path)?;
    debug_log!(
        "ending move_task()"
        );
    Ok(())
}

/// Helper function to get numeric input from user
fn get_user_input_number() -> Result<usize, ThisProjectError> {
    let mut input = String::new();
    io::stdin().read_line(&mut input)?;
    input.trim().parse::<usize>().map_err(|_|
        ThisProjectError::InvalidData("Invalid number".into())
    )
}

// /*
// This may be garbage:
// For Task Mode:
// 1. Link to tasks: view node 2nd layer deep using links in graph nav struct

// 2. Move task(node) to new directory
// Maybe use the lookup-number directory to get the path of the item to move.

// - command "move"
// - a Q&A interface:
// Q: Move what task?
// A: int
// (maybe get path from next-path lookup dict)

// Q: move to what column?
// A: int
// (this can also be from the lookup path dict)


// Moving a task involves:
// 1. move_from_path = (from next path lookup table)
// 2. move_to_directory_path = (from next path lookup table)
// 3. in move_from_path directory, change "directory_path" node.toml field to be move_to_directory_path
// 4. recursively move the whole directory to the new location...
// (note: internal nodes? local path? full path?)
// 5. resetting the file paths of all nested nodes (unless those are relative...)
// - iterate through new directory path recursively
// - look for node.toml files
// - set node_path to that absolute path

// why is this reading the file BEFORE the move?

// Why is the using path recorded IN the file,
// instead of the literal path to that file?

// Why is there no doc-string?
// */
// /// Moves a node directory and updates all internal paths
// fn move_node_directory(
//     source_path: PathBuf,
//     dest_path: PathBuf
// ) -> Result<(), ThisProjectError> {
//     debug_log("Starting move_node_directory()");

//     debug_log!("Moving node from {:?} to {:?}", source_path, dest_path);

//     // 1. Read the source node.toml
//     let node_toml_path = source_path.join("node.toml");
//     let mut node = load_core_node_from_toml_file(&node_toml_path)
//         .map_err(|e| ThisProjectError::InvalidData(e))?;

//     // 2. Update the node's directory path
//     node.directory_path = dest_path.clone();

//     // 3. Create the new directory
//     let new_node_path = dest_path.join(source_path.file_name().unwrap());
//     fs::create_dir_all(&new_node_path)?;

//     // 4. Move the directory contents
//     move_directory_contents(&source_path, &new_node_path)?;

//     // 5. Update paths in all nested node.toml files
//     update_nested_node_paths(&new_node_path)?;

//     // 6. Remove the old directory
//     fs::remove_dir_all(source_path)?;

//     Ok(())
// }

// /// Updates paths in all nested node.toml files
// fn update_nested_node_paths(
//     dir_path: &Path
// ) -> Result<(), ThisProjectError> {
//     debug_log("starting update_nested_node_paths()");
//     for entry in fs::read_dir(dir_path)? {
//         let entry = entry?;
//         let path = entry.path();

//         if path.is_dir() {
//             update_nested_node_paths(&path)?;
//         } else if path.file_name().unwrap() == "node.toml" {
//             let mut node = load_core_node_from_toml_file(&path)
//                 .map_err(|e| ThisProjectError::InvalidData(e))?;
//             node.directory_path = path.parent().unwrap().to_path_buf();
//             save_toml_to_file(&node, &path)?;
//         }
//     }
//     Ok(())
// }

// /// Recursively moves directory contents
// fn move_directory_contents(
//     from: &Path,
//     to: &Path
// ) -> Result<(), ThisProjectError> {
//     debug_log("starting move_directory_contents()");
//     for entry in fs::read_dir(from)? {
//         let entry = entry?;
//         let path = entry.path();
//         let destination = to.join(path.file_name().unwrap());

//         if path.is_dir() {
//             fs::create_dir_all(&destination)?;
//             move_directory_contents(&path, &destination)?;
//         } else {
//             fs::copy(&path, &destination)?;
//         }
//     }
//     Ok(())
// }

// /// Moves a node directory and updates its metadata.
// ///
// /// This function moves a node's directory from the `source_path` to the `dest_path`.
// /// It updates the `directory_path` field in the node's `node.toml` file to reflect
// /// the new location. The function uses the `source_path`, not path within the struct.
// /// It handles directory creation, moving, and file updates efficiently.
// ///
// /// # Arguments
// ///
// /// * `source_path`: The current path to the node's directory.
// /// * `dest_path`: The intended path for the moved node's directory.
// ///
// /// # Returns
// ///
// /// * `Result<(), ThisProjectError>`: `Ok(())` if the move is successful; otherwise, a `ThisProjectError` is returned.
// fn move_node_directory(
//     source_path: PathBuf,
//     dest_path: PathBuf,
// ) -> Result<(), ThisProjectError> {
//     debug_log!("Starting move_node_directory()");
//     debug_log!("Moving node from {:?} to {:?}", source_path, dest_path);

//     // 1. Construct the new node path (where the moved node will be located).
//     let new_node_path = dest_path.join(source_path.file_name().unwrap());
//     debug_log!("move_node_directory: new_node_path is: {:?}", new_node_path);

//     // 2. Create the new directory, including all parents.
//     fs::create_dir_all(&new_node_path)?;
//     debug_log!("move_node_directory: created new_node_path: {:?}", new_node_path);

//     // 3. Recursively move the source directory's contents to the new directory.
//     move_directory_contents(&source_path, &new_node_path)?;
//     debug_log!("move_node_directory: contents moved to: {:?}", new_node_path);

//     // 4. Update node.toml (use full path)
//     // (The old path is already deleted by move_directory_contents)
//     update_node_path_in_toml(&new_node_path)?;
//     debug_log!("move_node_directory: updated node.toml paths");

//     // 5. Remove the old directory.
//     fs::remove_dir_all(source_path.clone())?;
//     // fs::remove_dir_all(source_path)?;
//     debug_log!("move_node_directory: removed source_path at : {:?}", source_path);

//     Ok(())
// }


// /// Updates the directory_path in node.toml
// /// Does NOT attempt to move anything
// fn update_node_path_in_toml(new_node_path: &Path) -> Result<(), ThisProjectError> {
//     debug_log!("starting update_node_path_in_toml(), for path: {:?}", new_node_path);

//     let node_toml_path = new_node_path.join("node.toml");

//     // 1. Read node.toml file:
//     let mut node = load_core_node_from_toml_file(&node_toml_path)
//         .map_err(|e| ThisProjectError::InvalidData(e))?;

//     // 2. Check if directory path is already the new path:
//     if node.directory_path == new_node_path {
//         debug_log!(
//             "skipping: update_node_path_in_toml(): node_toml.directory_path is already = {:?}, so no change required",
//             node.directory_path
//         );
//         return Ok(());
//     }

//     debug_log!("update_node_path_in_toml: old-node.directory_path: {:?}", node.directory_path);

//     // 3. Set new node.directory_path:
//     node.directory_path = new_node_path.to_path_buf();
//     debug_log!("update_node_path_in_toml: new-node.directory_path: {:?}", node.directory_path);

//     // 4. Write node.toml file:
//     save_toml_to_file(&node, &node_toml_path)?; // No need to use new_node_path again

//     debug_log!("Successfully updated node.toml directory path.");
//     Ok(())
// }

// /// Recursively moves directory contents
// fn move_directory_contents(
//     from: &Path,
//     to: &Path
// ) -> Result<(), ThisProjectError> {
//     debug_log("starting move_directory_contents()");
//     for entry in fs::read_dir(from)? {
//         let entry = entry?;
//         let path = entry.path();
//         let destination = to.join(path.file_name().unwrap());

//         if path.is_dir() {
//             fs::create_dir_all(&destination)?;
//             move_directory_contents(&path, &destination)?;
//         } else {
//             fs::copy(&path, &destination)?;
//         }
//     }
//     Ok(())
// }

/// Moves a node directory and updates its metadata.
///
/// This function moves a node's directory from the `source_path` to the `dest_path`.
/// It updates the `directory_path` field in the node's `node.toml` file to reflect
/// the new location. The function uses the `source_path`, not path within the struct.
/// It handles directory creation, moving, and file updates efficiently.
///
/// # Arguments
///
/// * `source_path`: The current path to the node's directory.
/// * `dest_path`: The intended path for the moved node's directory.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` if the move is successful; otherwise, a `ThisProjectError` is returned.
fn move_node_directory(
    source_path: PathBuf,
    dest_path: PathBuf,
) -> Result<(), ThisProjectError> {
    debug_log!("Starting move_node_directory()");
    debug_log!("Moving node from {:?} to {:?}", source_path, dest_path);

    // 1. Construct the new node path (where the moved node will be located).
    let new_node_path = dest_path.join(source_path.file_name().unwrap());
    debug_log!("move_node_directory: new_node_path is: {:?}", new_node_path);

    // 2. Create the new directory, including all parents.
    fs::create_dir_all(&new_node_path)?;
    debug_log!("move_node_directory: created new_node_path: {:?}", new_node_path);


    // let original_node_toml_path = new_node_path.push("node.toml");
    let mut original_node_toml_path = source_path.clone();
    original_node_toml_path.push("node.toml");

    // 3. Update node.toml (use full path)
    // Option 1: Using to_string_lossy() (safest for paths that might contain non-UTF-8 characters)
    let new_node_path_string = dest_path.to_string_lossy().into_owned();

    debug_log!(
        "next: match safe_update_toml_field(\n{:?},\n{:?},\n{:?},\n)",
        &original_node_toml_path,   // path to .toml
        &new_node_path_string, // new value
        "directory_path",      // name of field
    );

    match safe_update_toml_field(
        &original_node_toml_path,        // path to .toml
        &new_node_path_string, // new value
        "directory_path",     // name of field
    ) {
        Ok(_) => println!("Successfully updated TOML file"),
        Err(e) => eprintln!("Error: {}", e)
    }


    // 4. Recursively move the source directory's contents to the new directory.
    move_directory_contents(&source_path, &new_node_path)?;
    debug_log!("move_node_directory: contents moved to: {:?}", new_node_path);




    debug_log!("move_node_directory: updated node.toml paths");

    // 5. Remove the old directory.
    fs::remove_dir_all(source_path.clone())?;
    debug_log!("move_node_directory: removed source_path at : {:?}", source_path);

    Ok(())
}

/// TODO update for clearsign...just load_core_node_from_toml_file?
/// Updates the directory_path in node.toml
/// Does NOT attempt to move anything
fn update_node_path_in_toml(new_node_path: &Path) -> Result<(), ThisProjectError> {
    debug_log!("starting update_node_path_in_toml(), for path: {:?}", new_node_path);

    let node_toml_path = new_node_path.join("node.toml");

    // 1. Read node.toml file:
    let mut node = load_core_node_from_toml_file(&node_toml_path)
        .map_err(|e| ThisProjectError::InvalidData(e))?;

    // 2. Check if directory path is already the new path:
    if node.directory_path == new_node_path {
        debug_log!(
            "skipping: update_node_path_in_toml(): node_toml.directory_path is already = {:?}, so no change required",
            node.directory_path
        );
        return Ok(());
    }

    debug_log!("update_node_path_in_toml: old-node.directory_path: {:?}", node.directory_path);

    // 3. Set new node.directory_path:
    node.directory_path = new_node_path.to_path_buf();
    debug_log!("update_node_path_in_toml: new-node.directory_path: {:?}", node.directory_path);

    // 4. Write node.toml file:
    save_toml_to_file(&node, &node_toml_path)?; // No need to use new_node_path again

    debug_log!("Successfully updated node.toml directory path.");
    Ok(())
}

/// Updates a specified field in a TOML file with a new value.
///
/// # Arguments
///
/// * `path` - A PathBuf containing the path to the TOML file
/// * `new_string` - A string slice containing the new value to be set
/// * `field` - A string slice containing the name of the field to update
///
/// # Returns
///
/// * `io::Result<()>` - Ok(()) on success, or an error if the operation fails
///
/// # Example
///
/// ```
/// # use std::fs;
/// # use std::path::PathBuf;
/// # fs::write("example.toml", "field = \"old_value\"").unwrap();
/// let path = PathBuf::from("example.toml");
/// let result = update_toml_field(&path, "new_value", "field");
/// # fs::remove_file("example.toml").unwrap();
/// ```
pub fn update_toml_field(
    path: &PathBuf,
    new_string: &str,
    field: &str
) -> io::Result<()> {
    // Read the entire file content using PathBuf's as_path() method
    let content = fs::read_to_string(path.as_path())?;

    // Create a temporary file with the same name plus .tmp
    let temp_path = path.with_extension("tmp");
    let mut temp_file = File::create(&temp_path)?;

    let mut field_found = false;

    // Process each line
    for line in content.lines() {
        let trimmed = line.trim();
        if trimmed.starts_with(field) && trimmed.contains('=') {
            // Write the new line for the matching field
            writeln!(temp_file, "{} = \"{}\"", field, new_string)?;
            field_found = true;
        } else {
            // Write the original line
            writeln!(temp_file, "{}", line)?;
        }
    }

    // If field wasn't found, append it
    if !field_found {
        writeln!(temp_file, "{} = \"{}\"", field, new_string)?;
    }

    // Ensure all data is written
    temp_file.flush()?;

    // Replace the original file with the temporary file
    fs::rename(temp_path, path)?;

    Ok(())
}

/// A safer wrapper function that includes additional error checking.
///
/// # Arguments
///
/// * `path` - A PathBuf containing the path to the TOML file
/// * `new_string` - A string slice containing the new value to be set
/// * `field` - A string slice containing the name of the field to update
///
/// # Returns
///
/// * `Result<(), String>` - Ok(()) on success, or an error message if the operation fails
///
/// Example Use:
/// ```
/// use std::path::PathBuf;
/// let config_path = PathBuf::from("config.toml");
/// match safe_update_toml_field(&config_path, "alice", "user_name") {
///     Ok(_) => println!("Successfully updated TOML file"),
///     Err(e) => eprintln!("Error: {}", e)
/// }
/// ```
pub fn safe_update_toml_field(
    path: &PathBuf,
    new_string: &str,
    field: &str
) -> Result<(), String> {

    debug_log("starting safe_update_toml_field()");

    debug_log!(
        "in safe_update_toml_field(\n{:?},\n{:?},\n{:?},\n)",
        &path,   // path to .toml
        &new_string, // new value
        "field",      // name of field
    );

    // Validate inputs
    if field.is_empty() {
        return Err("Error: safe_update_toml_field() Field name cannot be empty".to_string());
    }

    if !path.exists() {
        return Err(format!("Error: safe_update_toml_field() File not found: {}", path.display()));
    }

    update_toml_field(path, new_string, field)
        .map_err(|e| format!("Error: safe_update_toml_field() Failed to update TOML file: {}", e))
}

/// Recursively moves directory contents
fn move_directory_contents(
    from: &Path,
    to: &Path
) -> Result<(), ThisProjectError> {
    debug_log("starting move_directory_contents()");
    for entry in fs::read_dir(from)? {
        let entry = entry?;
        let path = entry.path();
        let destination = to.join(path.file_name().unwrap());

        if path.is_dir() {
            fs::create_dir_all(&destination)?;
            move_directory_contents(&path, &destination)?;
        } else {
            // Now, move the file instead of copying it
            fs::rename(&path, &destination)?;
        }
    }
    Ok(())
}

/// Loads connection data for members of the currently active team channel.
/// On success, returns a `HashSet` of `MeetingRoomSyncDataset` structs,
/// each containing connection
/// data for a collaborator in the current team channel (excluding the current user).
/// As a headline this makes an ip-whitelist or ip-allowlist but the overall process is bigger.
/// This should include 'yourself' so all connection data are there, so you know your ports
///
/// Note: this likely should also include the collabortor's last-received-timestamp (and the previous one)
/// this will also need a bootstrap where at first...there is no last timestamp.
///
/// Note: making the allow_lists requires information from more than one source:
/// =uma.toml
/// =project_graph_data/session_items/current_node_teamchannel_collaborators_with_access.toml
/// =/project_graph_data/collaborator_files_address_book/NAME__collaborator.toml
///
/// step 1: get team_channel list of (and data about) all possible team_channel_members
///     from externalized session state item doc @:
///     project_graph_data/session_items/current_node_teamchannel_collaborators_with_access.toml
///     The 6-port assignments come from this source.
///
/// step 2: get /collaborator_files_address_book data @:
///     .../project_graph_data/collaborator_files_address_book/ directory
///     as: NAME__collaborator.toml
///
/// step 3: Remove any collaborator from that 'possible list' whose information
///     is not in the .../project_graph_data/collaborator_files_address_book directory
///     as: NAME__collaborator.toml
///     The ipv4 and ipv6 lists come from this source.
///
/// step 4: make a session dataset for: teamchannel_connection_data
///     - allowlisted collaborators
///         - names
///         - ip lists
///         - ports
///
/// (note: members should have a list of ipv4, ipv6 addresses, not just one)
///
/// sample: project_graph_data/collaborator_files_address_book/alice__collaborator.toml
/// [[collaborator]]
/// user_name = "alice"
/// ipv4_addresses = ["24.0.189.112", "24.0.189.112"]
/// ipv6_addresses = ["2601:80:4803:9490::2e79","2601:80:4803:9490::2e79"]
/// gpg_key_public = "304A9A525A5D00D6AD269F765C3E7C56E5A3D0D8"
/// sync_interval = 5000
///
/// Do NOT read all data from all collaborators.
/// Ethical Data Access: The function only accesses the collaborator data that
/// is absolutely necessary for building the session_connection_allowlist for the current channel.
///
/// sample node.toml
/// node_name = "teamtest"
/// description_for_tui = "teamtest"
/// node_unique_id = 1728307130
/// directory_path = "project_graph_data/team_channels/teamtest"
/// order_number = 5
/// priority = "Medium"
/// owner = "initial_owner"
/// updated_at_timestamp = 1728307130
/// expires_at = 1728393530
/// children = []
/// teamchannel_collaborators_with_access = ["alice", "bob"]
///
/// # abstract_collaborator_port_assignments
/// [abstract_collaborator_port_assignments.alice_bob]
/// collaborator_ports = [
///     { name = "alice", ready_port = 50001, intray_port = 50002, gotit_port = 50003 },
///     { name = "bob", ready_port = 50004, intray_port = 50005, gotit_port = 50006 },
/// ]
///
/// [abstract_collaborator_port_assignments.alice_charlotte]
/// collaborator_ports = [
///     { name = "alice", ready_port = 50007, intray_port = 50008, gotit_port = 50009 },
///     { name = "charlotte", ready_port = 50010, intray_port = 50011, gotit_port = 50012 },
/// ]
///
/// [abstract_collaborator_port_assignments.bob_charlotte]
/// collaborator_ports = [
///     { name = "bob", ready_port = 50013, intray_port = 50014, gotit_port = 50015 },
///     { name = "charlotte", ready_port = 50016, intray_port = 50017, gotit_port = 50018 },
/// ]
///
/// maybe detects any port collisions,
/// excluding those who collide with senior members
/// or returning an error if found.
fn make_sync_meetingroomconfig_datasets(uma_local_owner_user: &str) -> Result<HashSet<MeetingRoomSyncDataset>, MyCustomError> {
    debug_log!("MSMD Entering the make_sync_meetingroomconfig_datasets() function...");

    // --- 1. find node.toml ---
    /*
    1. Find Path to team-channel node.toml,
    which contains the port assignments
    and the list of (all possible) team-members
    (collaborators with access to that channel,
    though perhaps not shared yet with you)
    */
    // get path, derive name from path
    // let channel_dir_path_str = read_state_string("current_node_directory_path.txt")?; // read as string first

    // get path, derive name from path
    let channel_dir_path_str = match read_state_string("current_node_directory_path.txt") {
        Ok(path) => {
            debug_log!("MSMD 1. Channel directory path (from session state): {:?}", path);
            path
        }
        Err(e) => {
            debug_log!(
                "MSMD ERROR: Failed to read 'current_node_directory_path.txt': {}. \
                 This may be due to missing file, permission issues, or malformed content.",
                e
            );
            return Err(MyCustomError::from(format!(
                "MSMD ERROR: Failed to read channel directory path: {}. \
                 Ensure the file exists and is accessible.",
                e
            )));
        }
    };


    debug_log!("MSMD 1. Channel directory path (from session state): {:?}", channel_dir_path_str);

    // use absolute file path
    let channel_dir_path = PathBuf::from(channel_dir_path_str);

    // A. Print the absolute path of the channel directory
    match channel_dir_path.canonicalize() {
        Ok(abs_path) => debug_log!("MSMD 1. Absolute channel directory path: {:?}", abs_path),
        Err(e) => debug_log!("MSMD Error 1. getting absolute path of channel directory: {}", e),
    }

    // todo: add either-or .toml .gpgtoml
    // A. Check for either node.toml or node.gpgtoml
    let node_toml_path = channel_dir_path.join("node.toml");
    let node_gpgtoml_path = channel_dir_path.join("node.gpgtoml");

    let raw_channelnodetoml_path = if node_toml_path.exists() {
        debug_log!("TCS: Found node.toml");
        node_toml_path
    } else if node_gpgtoml_path.exists() {
        debug_log!("TCS: Found node.gpgtoml");
        node_gpgtoml_path
    } else {
        return Err(MyCustomError::from(
            "TCS: Neither node.toml nor node.gpgtoml found in team channel directory".to_string()
        ));
    };

    // Get GPG fingerprint
    let gpg_fingerprint = LocalUserUma::read_gpg_fingerprint_from_file()
        .map_err(|e| MyCustomError::from(
            format!("TCS: Failed to read GPG fingerprint from uma.toml: {}", e)
        ))?;
        // .map_err(|e| Err(MyCustomError::from(
        //     format!("TCS: Failed to read GPG fingerprint from uma.toml: {}", e)
        // ))?;

    // Get temp directory
    let temp_dir = get_base_uma_temp_directory_path()
        .map_err(|e| MyCustomError::from(
            format!("TCS: Failed to get temp directory path: {}", e)
        ))?;
        // .map_err(|e| Err(MyCustomError::from(
        //     format!("TCS: Failed to get temp directory path: {}", e)
        // )))?;

    // Get readable copy
    let channel_node_tomlpath_string
        = get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
        &raw_channelnodetoml_path,
        &gpg_fingerprint,
        &temp_dir,
    ).map_err(|e| MyCustomError::from(
        format!("TCS: Failed to get readable copy of node file: {:?}", e)
    ))?;
    // ).map_err(|e| GpgError::PathError(
    //     format!("TCS: Failed to get readable copy of node file: {:?}", e)
    // ))?;

    debug_log!("TCS: channel_node_tomlpath_string
        : {}", channel_node_tomlpath_string
    );

    // Construct the path to node.toml
    // let channel_node_tomlpath_string
    //  = channel_dir_path.join("node.toml");

    debug_log!("MSMD 1. Channel node.toml path: {:?}", channel_node_tomlpath_string
    );

    let channel_node_toml_path = Path::new(
        &channel_node_tomlpath_string
    );

    // B. Print the absolute path of the node.toml file
    match channel_node_toml_path.canonicalize() {
        Ok(abs_path) => debug_log!("MSMD 1. Absolute channel_dir_path node.toml path: {:?}", abs_path),
        Err(e) => debug_log!("MSMD Error 1. getting absolute path of channel_dir_path node.toml: {}", e),
    }

    // --- 2. Load/Read node.toml ---
    // Read that (node toml) data into an organized 'struct' of variables
    // Read node.toml data with fn load_core_node_from_toml_file()
    // loading the fields into an organized struct with datatypes
    let teamchannel_nodetoml_data: CoreNode = match load_core_node_from_toml_file(&channel_node_toml_path) {
        Ok(node) => {
            debug_log!("MSMD 2. Successfully read channel node.toml");
            node // ???
        },
        Err(e) => {
            debug_log!("MSMD Error 2. reading channel node.toml: {:?}", channel_node_toml_path);
            debug_log!("MSMD Error 2. details: {}", e);
            return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e))); // Convert the error
        }
    };
    debug_log!("MSMD 2. teamchannel_nodetoml_data->{:?}", teamchannel_nodetoml_data);

    // --- 3. Empty Table for Later ---
    // Create an (empty) lookup-table (hash-set) to put all the meeting-room-data-sets in.
    // This will contain the local-port-assignments for each desk.
    let mut sync_config_data_set: HashSet<MeetingRoomSyncDataset> = HashSet::new();
    debug_log!("MSMD 3. sync_config_data_set->{:?} <should be empty, ok>", &sync_config_data_set);

    // --- 4. Team-Channel Memebers ---
    // Get team member names from team_channel node
    // (Example of derived-functional definitions:
    // compile this from the list of port-assignments,
    // rather than having multiple 'sources of truth' for members)
    // let collaborators_names_array = teamchannel_nodetoml_data.teamchannel_collaborators_with_access;
    // derive list functionally from port-assignemnt list
    let collaborators_names_array = match get_collaborator_names_from_node_toml(&channel_node_toml_path) {
        Ok(names) => names,
        Err(e) => {
            debug_log!("MSMD Error 4. getting collaborator names: {}", e);
            return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e)));
        }
    };
    debug_log!("MSMD 4. collaborators_names_array->{:?}", collaborators_names_array);

    // --- 5. raw-abstract port-assignments ---
    // Get the raw-abstract port-assignments
    // from the team_channel node
    // let abstract_collaborator_port_assignments = teamchannel_nodetoml_data.abstract_collaborator_port_assignments;
    // debug_log!(
    //     "5. abstract_collaborator_port_assignments->{:?}",
    //     &abstract_collaborator_port_assignments
    // );


    ////////////////////////////////
    // Extract Owner for Key Lookup
    ////////////////////////////////
    let owner_name_of_toml_field_key_to_read = "owner";
    debug_log!(
        "LCNFTF: Reading file owner from field '{}' for security validation",
        owner_name_of_toml_field_key_to_read
    );

    // get node_owners_public_gpg_key
    // Example: Read _ from the clearsigned TOML file
    let use_padnet = read_bool_field_from_toml(
        &channel_node_tomlpath_string,                // Target clearsigned file
        "use_padnet"                  // Field to read
    ).map_err(|e| {
        format!("LCNFTF: node_name Failed to read corenode_gpgtoml: {}", e)
    })?;

    let file_owner_username = match read_single_line_string_field_from_toml(
        &channel_node_tomlpath_string,  // TODO convert to string?
        owner_name_of_toml_field_key_to_read,
    ) {
        Ok(username) => {
            if username.is_empty() {
                // Convert to String error instead of GpgError
                return Err(MyCustomError::from(format!(
                    "MSMD: Field '{}' is empty in TOML file. File owner is required for security validation.",
                    owner_name_of_toml_field_key_to_read
                )));
            }
            username
        }
        Err(e) => {
            // Convert to String error instead of GpgError
            return Err(MyCustomError::from(format!(
                "MSMD: Failed to read file owner from field '{}': {}",
                owner_name_of_toml_field_key_to_read, e
            )));
        }
    };
    // println!("MSMD: File owner: '{}'", file_owner_username);
    debug_log!("MSMD: File owner: '{}'", file_owner_username);

    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            debug_log!("MSMD Error 5. getting abstract_collaborator_port_assignments: {}", e);
            return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e)));
        }
    };


    // Get the UME temp directory path with error handling
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| format!(
            "MSMD: Failed to get UME temp directory path: {:?}",
            io_err
        ))?;

    // Extract the addressbook path string with inline error conversion
    let addressbook_readcopy_path_string = get_addressbook_pathstring_to_temp_readcopy_of_toml_or_decrypted_gpgtoml(
        &file_owner_username,
        COLLABORATOR_ADDRESSBOOK_PATH_STR,
        &gpg_full_fingerprint_key_id_string,
        &base_uma_temp_directory_path,
    ).map_err(|e| format!(
        "MSMD: Failed to get addressbook path for user '{}': {:?}",
        file_owner_username,
        e
    ))?;

    // todo use where?
    // Define cleanup closure
    let cleanup_closure = || {
        let _ = cleanup_collaborator_temp_file(
            &channel_node_tomlpath_string,
            &base_uma_temp_directory_path,
            );
        let _ = cleanup_collaborator_temp_file(
            &addressbook_readcopy_path_string,
            &base_uma_temp_directory_path,
            );
    };

    /*
    pub fn read_abstract_ports_from_clearsigntoml_without_publicgpgkey(
        pathstr_to_config_file_that_contains_gpg_key: &str,
        pathstr_to_target_clearsigned_file: &str,
    ) -> Result<HashMap<String, Vec<ReadTeamchannelCollaboratorPortsToml>>, String> {
    */

    // let abstract_collaborator_port_assignments = match get_abstract_port_assignments_from_node_toml(&channel_node_toml_path) {
    //     Ok(names) => names,
    //     Err(e) => {
    //         debug_log!("MSMD Error 5. getting abstract_collaborator_port_assignments: {}", e);
    //         return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e)));
    //     }
    // };

    let abstract_collaborator_port_assignments = match read_abstract_ports_from_clearsigntoml_without_publicgpgkey(
        &addressbook_readcopy_path_string,
        &channel_node_tomlpath_string
    ) {
        Ok(names) => names,
        Err(e) => {
            debug_log!("MSMD Error 5. getting abstract_collaborator_port_assignments: {}", e);
            return Err(MyCustomError::from(io::Error::new(io::ErrorKind::Other, e)));
        }
    };

    debug_log!(
        "MSMD 5. abstract_collaborator_port_assignments->{:?}",
        &abstract_collaborator_port_assignments
    );

    // --- 6. filtered collaborators array ---
    // filter-pass: remove non-contacts from list
    //    - remove self
    //    - remove duplicates
    //    - remove names not in address-book
    let mut filtered_collaboratorsarray = collaborators_names_array.clone();

    // 6.1  Remove Self (don't try to call yourself on the phone)
    filtered_collaboratorsarray.retain(|name| name != &uma_local_owner_user);

    // 6.2  Remove Duplicates
    filtered_collaboratorsarray.sort();
    filtered_collaboratorsarray.dedup();

    // 6.3  Actual Meeting Contacts
    // Remove Names Not in your Address Book
    // the team-owner invites people to the team
    // each collaborator invites you to connect with them
    // filtered_collaboratorsarray.retain(|name| {
    //     let addressbook_toml_file_path = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
    //         .join(format!("{}__collaborator.toml", name));
    //     addressbook_toml_file_path.exists()
    // });


    filtered_collaboratorsarray.retain(|name| {
        let addressbook_dir = get_addressbook_directory_path().unwrap_or_else(|_| {
            // Handle error if needed, e.g., return an empty PathBuf or panic
            debug_log(
                "MSMD addressbook_dir not found..."
            );

            PathBuf::new()
        });
        let addressbook_toml_file_path = addressbook_dir.join(format!("{}__collaborator.toml", name));
        let addressbook_gpgtoml_file_path = addressbook_dir.join(format!("{}__collaborator.gpgtoml", name));
        addressbook_toml_file_path.exists() || addressbook_gpgtoml_file_path.exists()
    });



    debug_log!(
        "MSMD 6. filtered_collaboratorsarray->{:?}",
        &filtered_collaboratorsarray
    );

    // // TODO this perhaps shou be a parameter for this functions
    // // maybe in uma.toml
    // // Get armored public key, using key-id (full fingerprint in)
    // let mut full_fingerprint_key_id_string = String::new();
    // match q_and_a_user_selects_gpg_key_full_fingerprint() {
    //     Ok(temp_fullfingerprint_key_idstring) => {

    //         println!("Selected key id (full fingerprint in): {}", temp_fullfingerprint_key_idstring);
    //         full_fingerprint_key_id_string = temp_fullfingerprint_key_idstring;
    // }
    //     Err(e) => eprintln!("Error selecting full_fingerprint_key_id_string: {}", e.to_string()),
    // }


    // // Get armored public key, using key-id (full fingerprint in)
    // let mut full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
    //     Ok(fingerprint) => fingerprint,
    //     Err(e) => {
    //         eprintln!("Failed to read GPG fingerprint from uma.toml: {}", e);
    //         return Ok(false);
    //     }
    // };

    // Get armored public key, using key-id (full fingerprint in)
    let full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            eprintln!("MSMD Failed to read GPG fingerprint from uma.toml: {}", e);
            debug_log!("MSMD Failed to read GPG fingerprint from uma.toml: {}", e);
            return Err(MyCustomError::from(format!(
                "MSMD Failed to read GPG fingerprint from uma.toml: {}", e
            )));
        }
    };

    // --- Get local user's salt list ---
    let local_user_salt_list = match get_addressbook_file_by_username(
        uma_local_owner_user,
        &full_fingerprint_key_id_string,
        ) {
        Ok(data) => data.user_salt_list,
        Err(e) => {
            debug_log!("MSMD Error loading local user's salt list: {}", e);
            // return Err(e);
            return Err(e.into()); // Convert ThisProjectError to MyCustomError
        }
    };

    // --- 7. Iterate through the filtered address-book-name-list ---
    // Go through the list make a set of meeting room information for each team-member,
    // so that you (e.g. Alice) can sync with other team members.
    for collaborator_name in filtered_collaboratorsarray { // collaborator_data is now a String
        debug_log!("MSMD 7. Processing collaborator: {}", collaborator_name);

        // --- 8. get (that team member's) addressbook file by (their) username ---
        // using get_addressbook_file_by_username()
        // which loads the NAME__collaborator.toml from the collaborator_files_address_books directory
        // (owned by that collaborator, it is their own gpg signed data)
        let these_collaboratorfiles_toml_data = match get_addressbook_file_by_username(
            &collaborator_name,
            &full_fingerprint_key_id_string,
            ) {
            Ok(these_collaboratorfiles_toml_data) => these_collaboratorfiles_toml_data,
            Err(e) => {
                // This is where you'll most likely get the "No such file or directory" error
                debug_log!("MSMD Error 8. loading collaborator {}. File might be missing. Error: {}", collaborator_name, e);
                return Err(e.into()); // Convert ThisProjectError to MyCustomError
            }
        };
        debug_log!(
            "MSMD 8. Collaborator data these_collaboratorfiles_toml_data: {:?}",
            &these_collaboratorfiles_toml_data
        );

        // --- 9. extract data or drop collaborator from list ---
        // TODO addresses plural?
        /*
        what are all the fields of information to get?
        ipv6
        ipv4
        (is there some other type of address too?)
        gpg
        sync rate?
        */
        // IPvX...what else?
        // (If not available, drop this person from the list)
        let ipv6_address = match these_collaboratorfiles_toml_data
            .ipv6_addresses.clone()
            .and_then(|v| v.first().cloned())
        {
            Some(addr) => {
                debug_log!(
                    "MSMD 9. IPv6 address for {}: {}",
                    collaborator_name, addr
                );
                addr // ?
            },
            None => {
                debug_log!("MSMD WARNING: 9. No IPv6 address found for {}. Skipping this collaborator.", collaborator_name);
                continue; // Skip to the next collaborator in the loop
            }
        };
        debug_log!(
            "MSMD 9. ipv6_address {:?}->",
            &ipv6_address
        );

        // TODO Alpha under construction
        // --- 10. Translate abstract port assignments to local role-specific structs ---
        // let role_based_ports = translate_port_assignments()
        /*
        Make local port assignments: Translate abstract port assignments to local role-specific structs
        per real remote collaborator:

        Instance-Role-Specific Local-Meeting-Room-Struct
        This is no longer an abstract set of data that can be used
        in different ways in different instances,
        this is now one of those specific instances
        with local roles and one local way of using those data.
        The abstract port-assignments will be converted
        into a disambiguated and clarified specific local
        instance roles set of port assignments, namely,
        local_user_role, remote_collaborator_role
        */
        debug_log("MSMD 10. Starting translate_port_assignments()");
        let role_based_ports = translate_port_assignments(
            uma_local_owner_user,
            &collaborator_name,
            abstract_collaborator_port_assignments.clone(), // Clone to avoid ownership issues
        )?;
        debug_log!(
            "MSMD 10. role_based_ports {:?}->",
            &role_based_ports
        );
        /*
        abstract format is:
        # meeting rooms, abstract_collaborator_port_assignments
        [abstract_collaborator_port_assignments.alice_bob]
        collaborator_ports = [
            { name = "alice", ready_port = 50001, intray_port = 50002, gotit_port = 50003 },
            { name = "bob", ready_port = 50004, intray_port = 50005, gotit_port = 50006 },
        ]
        */

        // --- Get remote collaborator's salt list ---
        // let remote_collaborator_salt_list = match get_addressbook_file_by_username(collaborator_name.clone()) {
        let remote_collaborator_salt_list = match get_addressbook_file_by_username(
            &collaborator_name.clone(),
            &full_fingerprint_key_id_string,
            ) {
            Ok(data) => data.user_salt_list,
            Err(e) => {
                debug_log!("MSMD Error loading remote_collaborator_salt_list user's salt list: {}", e);
                // return Err(e);
                return Err(e.into()); // Convert ThisProjectError to MyCustomError
            }
        };

        // --- 11. Construct MeetingRoomSyncDataset (struct) ---
        // Assemble this one meeting room data-bundle from multiple sources
        // - from node.toml data
        // - from addressbook data
        // - from Instance-Role-Specific Local-Meeting-Room-Struct
        let meeting_room_sync_data = MeetingRoomSyncDataset {
            local_user_name: uma_local_owner_user.to_string(),  // TODO source?
            local_user_salt_list: local_user_salt_list.clone(), // Include the local salt list
            local_user_ipv6_addr_list: these_collaboratorfiles_toml_data.ipv6_addresses.clone().unwrap_or_default(), // Assuming you want to use the first IPv6 address for the local user
            // local_user_ipv6_addr_list: these_collaboratorfiles_toml_data.ipv6_addresses.expect("REASON"), // Assuming you want to use the first IPv6 address for the local user
            local_user_ipv4_addr_list: these_collaboratorfiles_toml_data.ipv4_addresses.clone().unwrap_or_default(), // Get IPv4 addresses or an empty vector
            // local_user_ipv4_addr_list: these_collaboratorfiles_toml_data.ipv4_addresses.expect("REASON"), // Assuming you want to use the first
            local_user_gpg_publickey_id: these_collaboratorfiles_toml_data.gpg_publickey_id.clone(),
            local_user_public_gpg: these_collaboratorfiles_toml_data.gpg_key_public.clone(),
            local_user_sync_interval: these_collaboratorfiles_toml_data.sync_interval,

            local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: role_based_ports.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,
            localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: role_based_ports.localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip,
            local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: role_based_ports.local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip,

            remote_collaborator_name: collaborator_name.clone(), // TODO source?
            remote_collaborator_salt_list: remote_collaborator_salt_list,
            remote_collaborator_ipv6_addr_list: these_collaboratorfiles_toml_data.ipv6_addresses.unwrap_or_default(), // Get ip addresses or empty vector
            remote_collaborator_ipv4_addr_list: these_collaboratorfiles_toml_data.ipv4_addresses.unwrap_or_default(), // Get IP addresses or empty vector
            // remote_collaborator_ipv6_addr_list: these_collaboratorfiles_toml_data.ipv6_addresses.expect("REASON"), // Get ip addresses or empty vector
            // remote_collaborator_ipv4_addr_list: these_collaboratorfiles_toml_data.ipv4_addresses.expect("REASON"), // Get IP addresses or empty vector
            remote_collaborator_gpg_publickey_id: these_collaboratorfiles_toml_data.gpg_publickey_id,
            remote_collaborator_public_gpg: these_collaboratorfiles_toml_data.gpg_key_public,
            remote_collaborator_sync_interval: these_collaboratorfiles_toml_data.sync_interval,

            remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: role_based_ports.remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip,
            remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: role_based_ports.remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip,
            remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: role_based_ports.remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip,
            use_padnet: use_padnet,
        };

        // --- 12. add meeting room to set-of-rooms-table ---
        // add this one meeting room data-bundle to the larger set
        sync_config_data_set.insert(meeting_room_sync_data.clone());
        debug_log!(
            "MSMD 12. Created MeetingRoomSyncDataset: {:?}",
            meeting_room_sync_data
        );

    } // End of collaborator loop

    debug_log!("MSMD Done: 12,13: sync_config_data_set created: {:?}", sync_config_data_set);

    // 13. after iterating, return full set of meeting-rooms
    Ok(sync_config_data_set)
}

/// Implementation of the Pearson hashing algorithm
///
/// This is a non-cryptographic hash function that produces an 8-bit hash value.
/// It's useful for:
/// - Hash tables
/// - Data integrity checks
/// - Fast execution on 8-bit processors
///
/// Features:
/// - Simple implementation
/// - Fast execution
/// - No simple class of inputs that produce collisions
/// - Two strings differing by one character never collide
///
/// Reference: Pearson, Peter K. (1990). "Fast Hashing of Variable-Length Text Strings"
///
/// Generate a permutation table using a non-linear transformation
/// This is done at compile time using const fn
const fn generate_pearson_permutation_table() -> [u8; 256] {
    let mut table = [0u8; 256];
    let mut i = 0;
    while i < 256 {
        // Non-linear transformation: multiply by prime number 167 and add 13
        // Then mask with 0xFF to keep it within u8 range
        table[i as usize] = ((i * 167 + 13) & 0xFF) as u8;
        i += 1;
    }
    table
}

// The permutation table is computed once at compile time
const PERMUTATION_TABLE: [u8; 256] = generate_pearson_permutation_table();

/// Computes the Pearson hash of the input bytes
///
/// # Arguments
///
/// * `input` - A slice of bytes to hash
///
/// # Returns
///
/// * An 8-bit hash value as u8
///
/// # Example
///
/// ```
/// let text = "Hello, World is the first onasei!";
/// let hash = pearson_hash6(text.as_bytes());
/// println!("Hash: {}", hash);
/// ```
pub fn pearson_hash_base(input: &[u8]) -> Result<u8, std::io::Error> {
    // Check if input is empty
    if input.is_empty() {
        return Err(std::io::Error::new(
            std::io::ErrorKind::InvalidInput,
            "Input cannot be empty"
        ));
    }

    // Initialize hash to 0
    let mut hash: u8 = 0;

    // For each byte in the input
    for &byte in input {
        // XOR the current byte with the hash, use result as index into permutation table
        hash = PERMUTATION_TABLE[(hash ^ byte) as usize];
    }

    Ok(hash)
}

/// Converts a Pearson hash (Vec<u8>) to a hexadecimal string.
///
/// # Arguments
///
/// * `hash`: The Pearson hash as a `Vec<u8>`.
///
/// # Returns
///
/// * `String`: The hexadecimal representation of the hash.
fn pearson_hash_to_hex_string(hash: &[u8]) -> String {
    hash.iter()
        .map(|&byte| format!("{:02x}", byte)) // Format each byte as two hex digits
        .collect()
}

/// Converts a hexadecimal string to a Pearson hash (Vec<u8>).
///
/// Returns an error if the input string is not a valid hexadecimal representation.
///
/// # Arguments
///
/// * `hex_string`: The hexadecimal string.
///
/// # Returns
///
/// * `Result<Vec<u8>, String>`: The Pearson hash as a `Vec<u8>`, or an error message.
fn hex_string_to_pearson_hash(hex_string: &str) -> Result<Vec<u8>, String> {
    debug_log("starting hex_string_to_pearson_hash()");

    if hex_string.len() % 2 != 0 {
        return Err("Invalid hex string: Length must be even".to_string());
    }

    let mut hash = Vec::with_capacity(hex_string.len() / 2);
    for i in (0..hex_string.len()).step_by(2) {
        let hex_byte = &hex_string[i..i + 2];
        match u8::from_str_radix(hex_byte, 16) {
            Ok(byte) => hash.push(byte),
            Err(_) => return Err(format!("Invalid hex string: Invalid byte: {}", hex_byte)),
        }
    }
    debug_log("end of hex_string_to_pearson_hash");
    Ok(hash)
}

/// Retrieves the salt list for a collaborator from their TOML configuration file.
///
/// This function reads the collaborator's TOML file located at
/// `project_graph_data/collaborator_files_address_book/{collaborator_name}__collaborator.toml`,
/// parses the TOML data, and extracts the `user_salt_list`.  It handles potential errors during file
/// reading, TOML parsing, and data extraction.
///
/// # Arguments
///
/// * `collaborator_name`: The name of the collaborator.
///
/// # Returns
///
/// * `Result<Vec<u128>, ThisProjectError>`:  A `Result` containing the collaborator's salt list (`Vec<u128>`) on success, or a `ThisProjectError` if any error occurs.
///
/// use with:let remote_collaborator_salt_list = get_saltlist_for_collaborator(NAME)?;
///
fn get_saltlist_for_collaborator(collaborator_name: &str) -> Result<Vec<u128>, ThisProjectError> {
    // 1. Construct File Path (using PathBuf)
    let file_path = Path::new(COLLABORATOR_ADDRESSBOOK_PATH_STR)
        .join(format!("{}__collaborator.toml", collaborator_name));

    // 2. Read File (handling potential errors)
    let toml_string = std::fs::read_to_string(&file_path)?;

    // 3. Parse TOML
    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = toml::from_str(&toml_string)?;

    // 4. Extract Salt List (handling missing/invalid data)
    let salt_list_result: Result<Vec<u128>, ThisProjectError> = match toml_value.get("user_salt_list") {
        Some(Value::Array(arr)) => {
            arr.iter()
                .map(|val| { // Iterate each item in the array
                    if let Value::String(hex_string) = val {
                        u128::from_str_radix(hex_string.trim_start_matches("0x"), 16)
                            .map_err(|_| ThisProjectError::InvalidData(format!("Invalid salt format in file for: {}", collaborator_name))) // clearer error message
                    } else {
                        Err(ThisProjectError::InvalidData(format!("Invalid salt format in file for: {}", collaborator_name))) // clearer error message
                    }
                }).collect() // Collect results
        },
        _ => Err(ThisProjectError::InvalidData(format!("Missing or invalid 'user_salt_list' in collaborator file for: {}", collaborator_name))), // Handle missing field or type mismatch
    };
    salt_list_result // Return the salt list Result
}

// TODO useful sometime, if not now
/// Calculates a list of Pearson hashes for a given input string using a provided salt list.
///
/// This function takes an input string, converts it to bytes, and calculates a Pearson hash for the
/// byte representation combined with each salt in the provided salt list. The resulting hashes are
/// returned as a `Vec<u8>`.
///
/// # Arguments
///
/// * `input_string`: The string to hash.
/// * `salt_list`: A slice of `u128` salt values.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`: A `Result` containing the list of calculated Pearson hashes on success,
///   or a `ThisProjectError` if an error occurs during hash calculation.
fn calculate_pearson_hashlist_for_string(
    input_string: &str,
    salt_list: &[u128],
) -> Result<Vec<u8>, ThisProjectError> {
    let input_bytes = input_string.as_bytes();
    let mut hash_list = Vec::new();

    for salt in salt_list {
        let mut salted_data = Vec::new();
        salted_data.extend_from_slice(input_bytes);
        salted_data.extend_from_slice(&salt.to_be_bytes());

        let hash = pearson_hash_base(&salted_data)?;
        hash_list.push(hash);
    }

    Ok(hash_list)
}

/// Verifies the Pearson hashes in a ReadySignal against a provided salt list.
///
/// This function calculates the expected hashes based on the `rt`, `rst`, and `re` fields of the `ReadySignal`
/// and the provided `salt_list`. It then compares the calculated hashes to the `rh` field of the `ReadySignal`.
///
/// # Arguments
///
/// * `ready_signal`: The ReadySignal to verify.
/// * `salt_list`: The list of salts to use for hash calculation.
///
/// # Returns
///
/// * `bool`: `true` if all hashes match, `false` otherwise.
/// Verifies the Pearson hashes in a ReadySignal against a provided salt list.
///
/// This function calculates the expected hashes based on the `rt`, `rst`, and `re` fields of the `ReadySignal`
/// and the provided `salt_list`. It then compares the calculated hashes to the `rh` field of the `ReadySignal`.
///
/// # Arguments
///
/// * `ready_signal`: The ReadySignal to verify.
/// * `salt_list`: The list of salts to use for hash calculation.
///
/// # Returns
///
/// * `bool`: `true` if all hashes match, `false` otherwise.
///
/// In this version of the function, the match expression for the
/// pearson_hash_base call returns false by default in the case
/// of an error. Additionally, the function checks if the index i
/// is within the bounds of the rh field before accessing it. If
/// the index is out-of-bounds, the function returns false.
///
/// By returning false by default in the case of any errors, the
/// function ensures that the caller can easily determine whether
/// the hashes are valid or not.
fn verify_readysignal_hashes(
    ready_signal: &ReadySignal,
    salt_list: &[u128]
) -> bool {
    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(&ready_signal.rt.to_be_bytes());
    data_to_hash.extend_from_slice(&ready_signal.rst.to_be_bytes());
    data_to_hash.extend_from_slice(&ready_signal.b.to_be_bytes());

    for (i, salt) in salt_list.iter().enumerate() {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());
        let calculated_hash = match pearson_hash_base(&salted_data) {
            Ok(hash) => hash,
            Err(e) => {
                debug_log!("verify_readysignal_hashes(), Error calculating Pearson hash: {}", e);
                return false; // Error during hash calculation
            }
        };

        if i >= ready_signal.rh.len() {
            debug_log!("verify_readysignal_hashes(),  Out-of-bounds index error when accessing rh field");
            return false; // Out-of-bounds index error
        }

        // comparing each index to each index: fail-checking step-wise
        if calculated_hash != ready_signal.rh[i] { // Compare with the received hash
            debug_log!(
                "failed in verify_readysignal_hashes(), hash != hash: ready_signal.rh->{:?} != calculated_hash->{:?}, all ready_signal.rh->{:?}",
                ready_signal.rh[i],
                calculated_hash,
                ready_signal.rh,
            );
            return false; // Hash mismatch
        }
    }

    // All hashes match
    true
}

// TODO maybe replace with simpler file-flag system: ~no stub-file no flag
/// Waits until either UMA should halt or synchronization is enabled.
///
/// This function implements a loop that checks two conditions:
/// 1. If UMA should halt (continue_uma.txt contains "0")
/// 2. If synchronization is enabled (ok_to_start_sync_flag.txt contains "1")
///
/// If UMA should halt, the function exits immediately.
/// If synchronization is enabled, the function exits to allow syncing to proceed.
/// Otherwise, it sleeps for the specified duration and checks again.
///
/// # Arguments
///
/// * `wait_this_many_seconds` - Number of seconds to wait between checks
fn sync_flag_ok_or_wait(wait_this_many_seconds: u64) {
    // check for quit
    loop {
        // // 1. Read the 'continue_uma.txt' file
        // let file_content = match fs::read_to_string(CONTINUE_UMA_PATH_STR) {
        //     Ok(content) => content,
        //     Err(_) => {
        //         debug_log("Error reading 'continue_uma.txt'. Continuing..."); // Handle the error (e.g., log it) but continue for now
        //         continue; // Skip to the next loop iteration
        //     }
        // };

        // // 2. break loop if continue=0
        // if file_content.trim() == "0" {
        //     debug_log("'continue_uma.txt' is 0. sync_flag_ok_or_wait Exiting loop.");
        //     break;
        // }

        // Read the 'continue_uma.txt' file and check if we should exit
        if should_halt_uma() {
            debug_log("wlpl 'continue_uma.txt' is 0. we_love_projects_loop() Exiting loop.");
            break;
        }

        // let is_sync_enabled = fs::read_to_string(SYNC_START_OK_FLAG_PATH_STR)
        //     .unwrap_or("0".to_string())
        //     .trim() == "1";

        // if is_sync_enabled {
        //     debug_log("Synchronization flag is '1'. Proceeding...");
        //     break; // Exit the loop
        // } else {
        //     // debug_log("Synchronization flag is '0'. Waiting...");
        //     thread::sleep(Duration::from_secs(wait_this_many_seconds)); // Wait for 3 seconds
        // }


        // Get the absolute path to the sync flag file
        let sync_flag_path = match get_sync_start_ok_flag_path() {
            Ok(path) => path,
            Err(e) => {
                debug_log!("Error resolving path to sync flag from get_sync_start_ok_flag_path(): {}", e);
                // Continue with the default value of "0" (assume syncing is disabled)
                thread::sleep(Duration::from_secs(wait_this_many_seconds));
                continue;
            }
        };

        // debug_log!(
        //     "sync_flag_ok_or_wait(), sync_flag_path -> {:?}",
        //     sync_flag_path,
        //     );

        // Read the sync flag file
        let is_sync_enabled = match fs::read_to_string(&sync_flag_path) {
            Ok(content) => content.trim() == "1",
            Err(e) => {
                debug_log!("Error reading sync flag file: {}", e);
                // Default to disabled (false) if we can't read the file
                false
            }
        };

        if is_sync_enabled {
            debug_log("Synchronization flag is '1'. Proceeding...");
            break; // Exit the loop
        } else {
            debug_log("Synchronization flag is '0'. Waiting...");
            thread::sleep(Duration::from_secs(wait_this_many_seconds)); // Wait for specified seconds
        }
    }
}

/// ### four byte array nearly 30 year timestamp v1
/// ## posix time scale notes
/// ```
/// (u1 to 1; u2 to 2; u4 to 8)
/// 1  1 			= 1 sec
/// 2  10			= 10 sec
/// (u8 to 256)
/// 3  100		= 1.67 min
/// (u16 to 65,536; 256^2)
/// 4  1000		= 16.7 minutes
/// 5  10000		= 2.7 hours
/// (u32 to 16,777,216; 256^3)
/// 6  100000		= 1.157 days / 0.165 weeks
/// 7  1000000 	= 0.381 months / 1.65 Weeks
/// 8  10000000	= 3.81 months / .317 years
/// (u64 to 4,294,967,296; 245^4)
/// 9  100000000	= 3.17 years
/// 10 1000000000	= 31.7 years
/// 11 10000000000	= 317 years
/// 12 100000000000	= 3171 years
/// ```
/// ## Compressed nonce-like timestamp freshness proxy
/// Use a four u8 byte array to get a nearly 31 year nonce timestamp
///
/// You need 8 digits: (skip the seconds digit)
/// ```
/// 10 (10sec) ->  100000000 (3.17 years)
/// +
/// some information about the 10th digit
/// ```
///
/// byte 1:
/// - digit 2 		(in the ones place)
/// - digit 3 		(in the tens place)
/// - fragment-1	(in the hundreds' place), not mod !%2
///
/// byte 2:
/// - digit 4 		(in the ones place)
/// - digit 5 		(in the tens place)
/// - fragment-2	(in the hundreds' place), not mod !%3
///
/// byte 3:
/// - digit 6 		(in the ones place)
/// - digit 7 		(in the tens place)
/// - fragment-3	(in the hundreds' place), not 0 or 4
///
/// byte 4:
/// - digit 8 		(in the ones place)
/// - digit 9 		(in the tens place)
/// - fragment-4	(in the hundreds' place), is prime
///
/// 10th digit fragments:
/// 1. not mod !%2
/// 2. not mod !%3
/// 3. not 0 or 4
/// 4. is prime
///
/// ## One Collision Case
/// The "5" value and "7" value from the compressed 10th-digit(31 year scale) collide, but at least most information from the 10th-digit could be expressed.
/// - The largest u32 number is: 16,777,216
/// - The largest u64 number is: 4,294,967,296 (Feb 7, year:2106)
/// - With the exception of 5 vs 7 in the last place, this system can mostly reflect posix time up to 9,999,999,999, (or Saturday, November 20, year:2286 5:46:39 PM) which is more than u64 can.
///
/// ### Without Bit Manipulation
/// This works without bitwise operations (fun though those are).
/// There are four u8 (unsigned 8-bit) values,
/// each of which can hold (in decimal terms)
/// up to 0-255
/// including 199
/// The hundres's place can safely be 1 or 0 (though it can be 2 also if we know the whole value is less than 255).
///
/// ## future research
/// For specified time ranges a smaller system should be possible.
/// e.g. if only months and not minutes are needed
fn generate_terse_timestamp_freshness_proxy_v4(posix_timestamp: u64) -> [u8; 4] {

    // 1. Extract relevant digits
    let digit_2 = ((posix_timestamp / 10) % 10) as u8;
    let digit_3 = ((posix_timestamp / 100) % 10) as u8;
    let digit_4 = ((posix_timestamp / 1000) % 10) as u8;
    let digit_5 = ((posix_timestamp / 10000) % 10) as u8;
    let digit_6 = ((posix_timestamp / 100000) % 10) as u8;
    let digit_7 = ((posix_timestamp / 1000000) % 10) as u8;
    let digit_8 = ((posix_timestamp / 10000000) % 10) as u8;
    let digit_9 = ((posix_timestamp / 100000000) % 10) as u8;
    let digit_10 = ((posix_timestamp / 1000000000) % 10) as u8;

    // 2. Determine 10th digit fragments
    let fragment_1 = (digit_10 % 2 != 0) as u8;
    let fragment_2 = (digit_10 % 3 != 0) as u8;
    let fragment_3 = (digit_10 != 0 && digit_10 != 4) as u8;
    let fragment_4 = (is_prime(digit_10)) as u8;

    // 3. Pack into u8 array (4 bytes, fragment in hundreds place)
    //let packed_timestamp = [
    //    (fragment_1 * 100) + (digit_2 * 10) + digit_3,
    //    (fragment_2 * 100) + (digit_4 * 10) + digit_5,
    //    (fragment_3 * 100) + (digit_6 * 10) + digit_7,
    //    (fragment_4 * 100) + (digit_8 * 10) + digit_9,
    //];

    // For readability, left to right
    let packed_timestamp = [
        (fragment_1 * 100) + (digit_9 * 10) + digit_8,
        (fragment_2 * 100) + (digit_7 * 10) + digit_6,
        (fragment_3 * 100) + (digit_5 * 10) + digit_4,
        (fragment_4 * 100) + (digit_3 * 10) + digit_2,
    ];

    packed_timestamp
}

fn is_prime(n: u8) -> bool {
    match n {
        2 | 3 | 5 | 7 => true,
        _ => false,
    }
}

/// Sends a byte slice over UDP to the specified address and port.
///
/// # Arguments
///
/// * `data`: The byte slice to send.
/// * `target_addr`: The target IP address.
/// * `port`: The target port.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`:  `Ok(())` if sending was successful, or a `ThisProjectError` if an error occurred.
fn send_data_via_udp(data: &[u8], target_addr: SocketAddr, port: u16) -> Result<(), ThisProjectError> {
    let socket = UdpSocket::bind(":::0")?; // Bind to any available port
    socket.send_to(data, SocketAddr::new(target_addr.ip(), port))?;
    debug_log!("Data sent to {}:{}", target_addr.ip(), port);
    Ok(())
}

/// Sends a `SendFile` struct to a remote collaborator's intray.
/// Now this function *only* handles sending; serialization is done elsewhere.
///
/// # Arguments
///
/// * `send_file`: The `SendFile` struct to send.
/// * `target_addr`: The target IP address.
/// * `port`: The target port.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` if the file was sent successfully, `Err(ThisProjectError)` otherwise.
fn sendfile_UDP_to_intray(
    send_file: &SendFile,
    target_addr: SocketAddr,
    port: u16,
) -> Result<(), ThisProjectError> {
    // 1. Serialize the SendFile struct.
    let serialized_data = serialize_send_file_struct(send_file)?;

    // 2. Send the serialized data using UDP.
    send_data_via_udp(&serialized_data, target_addr, port)?;

    Ok(())
}

/// Struct for sending file to in-tray (file sync)
/// Salted-Pearson-Hash-List system for quick verification that packet is intact and sent by owner at timestamp
// #[derive(Serialize, Deserialize, Debug)] // Add Serialize/Deserialize for sending/receiving
#[derive(Debug)] // Add Serialize/Deserialize for sending/receiving
struct SendFile {
    intray_send_time: Option<u64>, // send-time: generate_terse_timestamp_freshness_proxy(); for replay-attack protection
    gpg_encrypted_intray_file: Option<Vec<u8>>, // Holds the GPG-encrypted file contents
    intray_hash_list: Option<Vec<u8>>, // N hashes of intray_this_send_timestamp + gpg_encrypted_intray_file
    padnet_index_array: Option<PadIndex>, // New Field 4 bytes
}

/// ReadySignal struct
/// - Contents are 'Option<T>' so that assembly and inspection can occur in steps.
/// - Terse names to reduce network traffic, as an exceptional circumstance
/// - Ready-signals are the most commonly sent and most disposable
#[derive(Serialize, Deserialize, Debug)] // Add Serialize/Deserialize for sending/receiving
struct ReadySignal {
    rt: u64, // ready signal timestamp: last file obtained timestamp
    rst: u64, // send-time: generate_terse_timestamp_freshness_proxy(); for replay-attack protection
    b: u8, // Network Index (e.g. which ipv6 in the list)
    rh: Vec<u8>, // N hashes of rt + re // todo: fixed size?
}

/// Serializes a ReadySignal into a byte vector
/// Does NOT use serde.
fn serialize_ready_signal(ready_signal: &ReadySignal) -> Result<Vec<u8>, ThisProjectError> {
    let mut bytes = Vec::new();

    // Add timestamps (rt and rst)
    bytes.extend_from_slice(&ready_signal.rt.to_be_bytes());
    bytes.extend_from_slice(&ready_signal.rst.to_be_bytes());

    // Add Network band byte as u8 bytes
    bytes.extend_from_slice(&ready_signal.b.to_be_bytes());

    // Add hash list
    bytes.extend_from_slice(&ready_signal.rh);

    Ok(bytes)
}

// TODO max size check?
/// Calculates Pearson hashes for a ReadySignal's fields. Hashes `rt`, `rst`, `nt`, `ni`, and salts.
///
/// Args:
///     rt: The `rt` timestamp.
///     rst: The `rst` timestamp.
///     nt: The network type string.
///     ni: The network index.
///     local_user_salt_list: The list of salts for hashing.
///
/// Returns:
///     Result<Vec<u8>, ThisProjectError>: The calculated hash list, or an error if hashing fails.
fn calculate_ready_signal_hashes(
    rt: u64,
    rst: u64,
    band: u8,
    local_user_salt_list: &[u128],
) -> Result<Vec<u8>, ThisProjectError> {
    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(&rt.to_be_bytes());
    data_to_hash.extend_from_slice(&rst.to_be_bytes());
    data_to_hash.extend_from_slice(&band.to_be_bytes());

    let mut ready_signal_hash_list: Vec<u8> = Vec::new();
    for salt in local_user_salt_list {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());

        match pearson_hash_base(&salted_data) {
            Ok(hash) => ready_signal_hash_list.push(hash),
            Err(e) => return Err(ThisProjectError::IoError(e)), // Directly return the error
        }
    }

    Ok(ready_signal_hash_list)
}

// Define enums for each field you want to validate
#[derive(Debug, PartialEq)]
enum Timestamp {
    Valid(u64),
    Invalid,
}

#[derive(Debug, PartialEq)]
enum DocumentId {
    Valid(u64),
    Invalid,
}

// Proto struct with Option<T> for initial deserialization
#[derive(Debug)]
struct PrototGotitSignal {
    gst: Option<Timestamp>,
    di: Option<DocumentId>,
    gh: Option<Vec<u8>>,
}

/// GotItSignal struct
/// Terse names to reduce network traffic, as an esceptional circumstatnce
/// Probably does not need a nonce because repeat does nothing...
///
/// Final struct with validated data
/// use proto-struct PrototGotitSignal for loading possibly corrupted data
#[derive(Debug)]
struct GotItSignal {
    gst: u64,
    di: u64,
    gh: Vec<u8>,
}

// Converts a byte slice to a u64, handling potential errors.
fn bytes_to_u64(bytes: &[u8]) -> Result<u64, Error> {
    if bytes.len() != 8 {
        return Err(Error::new(ErrorKind::InvalidData, "Invalid byte length for u64"));
    }
    Ok(u64::from_be_bytes(bytes.try_into().unwrap()))
}

/// Calculates Pearson hash list for a GotItSignal.
/// Hashes the `gst` (send time), `di` (document ID/received timestamp), and salts.
///
/// # Arguments
///
/// * `gst`: The `gst` timestamp.
/// * `di`: The `di` timestamp (received file's timestamp).
/// * `local_user_salt_list`:  The list of salts for hashing.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`: The calculated hash list or an error.
fn calculate_gotitsignal_hashlist(
    timestamp_for_gst: u64,
    timestamp_for_di: u64,
    local_user_salt_list: &[u128],
) -> Result<Vec<u8>, ThisProjectError> {

    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(&timestamp_for_gst.to_be_bytes());
    data_to_hash.extend_from_slice(&timestamp_for_di.to_be_bytes());

    debug_log!(
        "calculate_gotitsignal_hashlist(): Data to hash: {:?}",
        &data_to_hash
    );

    let mut gotit_signal_hash_list: Vec<u8> = Vec::new();
    for salt in local_user_salt_list {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());

        match pearson_hash_base(&salted_data) {
            Ok(hash) => gotit_signal_hash_list.push(hash),
            Err(e) => {
                return Err(ThisProjectError::IoError(e));  // Return the error
            }
        }
    }
    debug_log!(
        "calculate_gotitsignal_hashlist(): Calculated Hashes: {:?}",
        &gotit_signal_hash_list
    );

    Ok(gotit_signal_hash_list)
}


/// Deserializes a byte slice into a `PrototGotitSignal`, manually handling the byte extraction.
///
/// Arguments:
///     bytes: The byte slice containing the serialized data.
///
/// Returns:
///     Result<PrototGotitSignal, Error>: A `Result` containing the `PrototGotitSignal` on success, or an `Error` if deserialization fails.
fn deserialize_proto_gotit_signal(bytes: &[u8]) -> Result<PrototGotitSignal, Error> {

    // Calculate expected lengths (assuming a u64 for both timestamp and ID)
    let timestamp_len = std::mem::size_of::<u64>();
    let id_len = std::mem::size_of::<u64>();
    let expected_min_length = timestamp_len + id_len; // Minimum length for timestamp and ID

    // Check if the byte array has enough data for at least the timestamp and document ID
    if bytes.len() < expected_min_length {
        return Err(Error::new(
            ErrorKind::InvalidData,
            "Invalid byte array length for PrototGotitSignal: too short",
        ));
    }

    // Extract timestamp
    let gst_bytes = &bytes[0..timestamp_len];
    let gst = match bytes_to_u64(gst_bytes) {
        Ok(ts) => Some(Timestamp::Valid(ts)),
        Err(_) => Some(Timestamp::Invalid),  // Or handle differently
    };

    // Extract document ID
    let di_bytes = &bytes[timestamp_len..expected_min_length];
    let di = match bytes_to_u64(di_bytes) {
        Ok(id) => Some(DocumentId::Valid(id)),
        Err(_) => Some(DocumentId::Invalid),
    };

    // Extract hash list (if any)
    let gh = if bytes.len() > expected_min_length {
        Some(bytes[expected_min_length..].to_vec())
    } else {
        None
    };

    Ok(PrototGotitSignal { gst, di, gh })
}


fn validate_and_convert_gotit_signal(proto_signal: PrototGotitSignal) -> Result<GotItSignal, String> {
    let gst = match proto_signal.gst {
        Some(Timestamp::Valid(ts)) => ts,
        _ => return Err("Invalid or missing gst".into()),
    };

    let di = match proto_signal.di {
        Some(DocumentId::Valid(id)) => id,
        _ => return Err("Invalid or missing di".into()),
    };

    // Default to an empty vector if the hash list is missing
    let gh = proto_signal.gh.unwrap_or_default();

    Ok(GotItSignal { gst, di, gh })
}

fn process_incoming_gotit_signal_bytes(bytes: &[u8]) -> Result<GotItSignal, String> {
    let proto_signal = deserialize_proto_gotit_signal(bytes)
        .map_err(|e| format!("Deserialization failed: {}", e))?; // Handle deserialization error

    validate_and_convert_gotit_signal(proto_signal)
}


#[derive(Debug, Clone)] // Add other necessary derives later
struct SendQueue {
    back_of_queue_timestamp: u64,
    // echo_send: bool, //
    items: Vec<PathBuf>,  // ordered list, filepaths
}
impl SendQueue {
    /// Adds a `PathBuf` to the *front* of the `items` vector in the `SendQueue`.
    ///
    /// # Arguments
    ///
    /// * `path`: The `PathBuf` to add to the queue.
    fn add_to_front_of_sendq(&mut self, path: PathBuf) {
        self.items.insert(0, path);
    }
}

// TODO
/// unpack new node
/// saves new node.toml file, ensuring path and feature directories
/// Unpacks and saves a new node from received data.
///
/// This function takes the raw bytes of a clearsigned and decrypted `node.toml` file
/// and saves it to the specified path. It also creates the standard UMA node
/// subdirectories: "message_posts_browser" and "task_browser".
///
/// This function is used during file synchronization to create or update nodes
/// on the local file system based on data received from a remote collaborator.
/// It assumes the `extracted_clearsigned_file_data` contains valid TOML data
/// for a `CoreNode` struct.
///
/// # Arguments
///
/// * `extracted_clearsigned_file_data`: The raw bytes of the decrypted and
///   clearsigned `node.toml` file.
/// * `new_full_abs_node_directory_path`: The *full absolute path* to the
///   directory where the node should be saved. This path should *include* the
///   node directory name itself (e.g.,
///   `"project_graph_data/team_channels/my_team/my_node"`).
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on success, or a
///   `ThisProjectError` if an error occurs during file or directory creation.
///
/// # Example
///
/// ```
/// // ... (assuming you have extracted_clearsigned_file_data and new_full_abs_node_directory_path)
///
/// match unpack_new_node_save_toml_and_create_dir(&extracted_clearsigned_file_data, &new_full_abs_node_directory_path) {
///     Ok(_) => println!("Node unpacked and saved successfully."),
///     Err(e) => eprintln!("Error unpacking node: {}", e),
/// }
/// ```
fn unpack_new_node_save_toml_and_create_dir(
    extracted_clearsigned_file_data: &Vec<u8>,
    new_full_abs_node_directory_path: &Path,
) -> Result<(), ThisProjectError> {

    // 1. Make full file path
    let new_node_toml_file_path = new_full_abs_node_directory_path.join("node.toml"); // Path to the new node.toml

    // 2. Create directory if it doesn't exist
    fs::create_dir_all(new_full_abs_node_directory_path)?;

    // 3. write file from GPG clearsign extracted data as node.toml
    if let Err(e) = fs::write(
        &new_node_toml_file_path,
        &extracted_clearsigned_file_data
    ) {
        debug_log!("HLOD-InTray: Unpack Node: Failed to write message file: {:?}", e);
        // Consider returning an error here instead of continuing the loop
        return Err(ThisProjectError::from(e));
    }

    // 4. Add IM-Browser directory
    let im_browser_path = new_full_abs_node_directory_path.join("message_posts_browser");  // Construct path correctly
    create_dir_all(&im_browser_path)?;

    // 5. Add Task-Browser directory
    let task_browser_path = new_full_abs_node_directory_path.join("task_browser");  // Construct path correctly
    create_dir_all(&task_browser_path)?;

    Ok(())
}

// /// unpack new node
// /// saves new node.toml file, ensuring path and IM directory
// fn unpack_new_node_save_toml_and_create_dir(
//     toml_string: &str,
//     path: &Path,
//     dir_name: &str,  // Now this is the general name
// ) -> Result<(), std::io::Error> {
//     // 1. Create parent directories.
//     create_dir_all(path)?;

//     // 2. Create and write to node.toml.
//     let toml_path = path.join("node.toml");
//     let mut toml_file = File::create(&toml_path)?;
//     toml_file.write_all(toml_string.as_bytes())?;

//     // 3. Create associated directory.  (This is the only change)
//     let dir_path = path.join(dir_name); // No longer specifically "message_posts_browser"
//     create_dir_all(&dir_path)?;


//     // Add this to create "message_posts_browser/" next to node.toml:
//     let im_browser_path = path.join("message_posts_browser");
//     create_dir_all(&im_browser_path)?;

//     Ok(())
// }

/// Retrieves the paths of all send queue update flags for a given collaborator in a team channel.
///
/// This function reads the contents of the directory `sync_data/{team_channel_name}/sendqueue_updates/{collaborator_name}`
/// and returns a vector of `PathBuf` representing the paths to the update flag files.  It also deletes the flag files
/// after reading their contents, ensuring that flags are processed only once.
///
/// Note: each potential participant must have a separate flag.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `collaborator_name`: The name of the collaborator.
///
/// # Returns
///
/// * `Result<Vec<PathBuf>, ThisProjectError>`:  A vector of paths to update flag files on success, or a `ThisProjectError` if an error occurs.
fn get_sendq_update_flag_paths(
    team_channel_name: &str,
    collaborator_name: &str,
) -> Result<Vec<PathBuf>, ThisProjectError> {

    // 1. Construct Directory Path (using PathBuf)
    let mut queue_dir = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;
    queue_dir.push(team_channel_name);
    queue_dir.push("sendqueue_updates");
    queue_dir.push(collaborator_name);

    let mut path_list: Vec<PathBuf> = Vec::new(); // Initialize path_list

    // 2. Read Directory and Collect Paths
    match read_dir(&queue_dir) {
        Ok(entries) => {
            for entry_result in entries {
                match entry_result {
                    Ok(entry) => {
                        let path = entry.path();
                        if path.is_file() {
                            // Read the file path from the queue file and delete.
                            let queue_file_path_str = match std::fs::read_to_string(&path) {
                                Ok(s) => s,
                                Err(e) => {
                                    debug_log!("Error reading queue file: {}", e);
                                    // Handle error appropriately, e.g., continue to the next file or return an error
                                    continue; // Skip this file and continue
                                }
                            };
                            let queue_file_path = PathBuf::from(queue_file_path_str);

                            debug_log!("HRCD: Removing update flag file: {:?}", path);
                            if let Err(e) = remove_file(&path) {
                                debug_log!("Error removing update flag file: {:?} - {}", path, e);
                                // Continue processing other files even if removal fails.
                                continue; // or choose to handle error
                            }

                            // Add the file path from *inside* the queue file to the path_list
                            path_list.push(queue_file_path);

                        }
                    },
                    Err(e) => {
                        debug_log!("Error reading directory entry: {}", e);
                        // Handle error as you see fit
                        return Err(ThisProjectError::IoError(e));
                    }
                }
            }
        }
        Err(e) if e.kind() == std::io::ErrorKind::NotFound => {
            // No queue files, return empty list
            debug_log!("get_sendq_update_flag_paths(): Send queue directory not found. Returning empty list.");
            return Ok(Vec::new());
        }
        Err(e) => return Err(ThisProjectError::IoError(e)),
    };


    Ok(path_list)
}

/// Converts a vector of u8 hash values into a hexadecimal string representation.
///
/// This function takes a slice of `u8` values (typically a hash) and converts it into a hexadecimal string,
/// with each byte represented by two hexadecimal characters.  The resulting string is suitable for use as a filename or identifier.
///
/// # Arguments
///
/// * `hash_array`: A slice of `u8` values representing the hash.
///
/// # Returns
///
/// * `String`: The hexadecimal string representation of the hash.
///
/// # Example
///
/// ```
/// let hash_array = [0x12, 0x34, 0x56, 0x78, 0x9a, 0xbc, 0xde, 0xf0];
/// let hex_string = hash_array_to_hex_string(&hash_array);
/// assert_eq!(hex_string, "123456789abcdef0");
/// ```
/// TODO Does this need error handling?
fn docid_hash_array_to_hex_string(hash_array: &[u8]) -> String {
    hash_array
        .iter()
        .map(|&h| format!("{:02x}", h))
        .collect::<String>()
}

fn hash_sendfile_struct_fields(
    salt_list: &[u128],
    intray_send_time: u64,
    gpg_encrypted_intray_file: &[u8], // Use a slice for efficiency
) -> Result<Vec<u8>, ThisProjectError> {
    let mut calculated_hashes = Vec::with_capacity(salt_list.len());
    let mut data_to_hash = Vec::new();
    data_to_hash.extend_from_slice(&intray_send_time.to_be_bytes());
    data_to_hash.extend_from_slice(gpg_encrypted_intray_file);
    for salt in salt_list {
        let mut salted_data = data_to_hash.clone();
        salted_data.extend_from_slice(&salt.to_be_bytes());
        match pearson_hash_base(&salted_data) {
            Ok(hash) => calculated_hashes.push(hash),
            Err(e) => {
                debug_log!("hash_sendfile_struct_fields(): Error calculating Pearson hash: {}", e);
                return Err(ThisProjectError::IoError(e));
            }
        }
    }
    Ok(calculated_hashes)
}

fn hash_checker_for_sendfile_struct(
    salt_list: &[u128],
    intray_send_time: u64,
    gpg_encrypted_intray_file: &[u8], // Use a slice
    compare_to_this_hashvec: &[u8], // Use a slice
) -> bool {
    // 1. Fail by default
    let mut all_hashes_match = false; // Initialize to false (Fail by default)

    debug_log!("HCFSS hash_checker_for_sendfile_struct(): Starting verification...");

    // 2. Calculate expected hashes
    let calculated_hashes_result = hash_sendfile_struct_fields(salt_list, intray_send_time, gpg_encrypted_intray_file);

    match calculated_hashes_result {
        Ok(calculated_hashes) => {
            // 3. Length Check
            if calculated_hashes.len() != compare_to_this_hashvec.len() {
                debug_log!("HCFSS hash_checker_for_sendfile_struct(): Hash list length mismatch. Expected: {}, Received: {}", calculated_hashes.len(), compare_to_this_hashvec.len());
            } else {
                // 4. Compare hashes one by one
                all_hashes_match = true; // Assume they match initially
                for (i, &calculated_hash) in calculated_hashes.iter().enumerate() {
                    if calculated_hash != compare_to_this_hashvec[i] {
                        debug_log!("HCFSS hash_checker_for_sendfile_struct(): Hash mismatch at index {}. Expected: {:02x}, Received: {:02x}", i, calculated_hash, compare_to_this_hashvec[i]);
                        all_hashes_match = false;
                        break;
                    }
                }
                if all_hashes_match {
                    debug_log!("HCFSS hash_checker_for_sendfile_struct(): All hashes match.");
                }
            }
        },
        Err(e) => {
             debug_log!("HCFSS error hash_checker_for_sendfile_struct():  Error calculating hashes: {:?}. Returning false.", e);
        },
    }
    debug_log!("HCFSS hash_checker_for_sendfile_struct(): Verification completed. Result: {}", all_hashes_match);

    all_hashes_match
}

/// Extracts the `updated_at_timestamp` field from a TOML file.
///
/// This function reads the TOML file at the specified path, parses it, and extracts the
/// `updated_at_timestamp` field.  It handles potential errors during file reading, TOML
/// parsing, and missing or invalid timestamp fields.
///
/// # Arguments
///
/// * `file_path`: The path to the TOML file.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`: The `updated_at_timestamp` value on success, or a
///   `ThisProjectError` if an error occurs.
fn get_updated_at_timestamp_from_toml_file(file_path: &Path) -> Result<u64, ThisProjectError> {
    // 1. Read the TOML file: Handle file read errors
    let toml_string = match std::fs::read_to_string(file_path) {
        Ok(content) => content,
        Err(e) => {
            debug_log!("Error reading TOML file {:?}: {}", file_path, e);
            return Err(ThisProjectError::from(e));
        }
    };
    debug_log!("GUATFTF Read TOML file: {:?}", file_path);


    // 2. Parse the TOML string: Handle TOML parsing errors
    // // TODO NO 'toml::from_str' !!!!!!!!!!!!!!!!!
    let toml_value: Value = match toml::from_str(&toml_string) {
        Ok(value) => value,
        Err(e) => {
            debug_log!("GUATFTF Error parsing TOML string: {}", e);
            return Err(ThisProjectError::from(e)); // Or handle error differently
        }
    };
    debug_log!("Parsed TOML value.");

    // 3. Extract updated_at_timestamp:  Handle missing/invalid timestamp
    let updated_at_timestamp = match toml_value.get("updated_at_timestamp") {
        Some(Value::Integer(ts)) => *ts as u64, // Convert to u64, handle overflow
        Some(_) => {
            debug_log!("'GUATFTF updated_at_timestamp' has invalid type");
            return Err(ThisProjectError::InvalidData(
                "GUATFTF 'updated_at_timestamp' has invalid type".into(),
            ));
        }
        None => {
            debug_log!("GUATFTF 'updated_at_timestamp' field not found in TOML file");
            return Err(ThisProjectError::InvalidData(
                "GUATFTF 'updated_at_timestamp' field not found in TOML file".into(),
            ));
        }
    };
    debug_log!("GUATFTF Extracted timestamp: {}", updated_at_timestamp);

    Ok(updated_at_timestamp) // Return the timestamp if successful
}

/// Retrieves the .rt timestamp from the oldest pre-fail flag file.
///
/// Iterates through the `fail_retry_flags` directory, finds the oldest file (based on filename, which is the `updated_at` timestamp),
/// reads the `.rt` timestamp (the file content) from that oldest file, and returns it.
/// Deletes all flag files after reading the oldest timestamp, ensuring flags are processed only once.
/// Returns 0 if no flags are found or if an error occurs during file operations.
///
/// Directory structure: `sync_data/{team_channel_name}/fail_retry_flags/{remote_collaborator_name}/{file_updated_at_timestamp}`
///
/// # Arguments
///
/// * `remote_collaborator_name`: The name of the remote collaborator.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`: The `.rt` timestamp from the oldest flag file (or 0) on success, or a `ThisProjectError`.
fn get_oldest_sendfile_prefailflag_rt_timestamp_or_0_w_cleanup(
    remote_collaborator_name: &str,
) -> Result<u64, ThisProjectError> {
    // #[cfg(debug_assertions)]
    debug_log("GOSPrtT: get_oldest prefail: starting get_oldest_sendfile_prefailflag_rt_timestamp_or_0_w_cleanup()");

    let mut oldest_timestamp = 0u64;
    let mut oldest_file_path: Option<PathBuf> = None; // Store path to the oldest file

    // #[cfg(debug_assertions)]
    debug_log("GOSPrtT: calling get_current_team_channel_name_from_nav_path...");

    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("get_oldest prefail... Unable to get team channel name".into()))?;

    let base_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;

    let prefail_directory = base_path
        .join(&team_channel_name)
        .join("fail_retry_flags")
        .join(remote_collaborator_name);

    if !prefail_directory.exists() {

        // #[cfg(debug_assertions)]
        debug_log!(
            "GOSPrtT: get_oldest...: Directory {:?} not found. Returning 0.",
            prefail_directory
        );
        return Ok(0);
    }

    // 1. Find the oldest file:
    for entry in fs::read_dir(&prefail_directory)? {
        let entry = entry?;
        let path = entry.path();

        // #[cfg(debug_assertions)]
        debug_log!(
            "GOSPrtT: get_oldest prefail... path -> {:?}",
            path
        );

        if path.is_file() {
            let file_name = path.file_name().and_then(|n| n.to_str()).ok_or(ThisProjectError::InvalidData("GOSPrtT error: Invalid flag file name".into()))?;
            let file_updated_at: u64 = file_name.parse().map_err(|_| ThisProjectError::InvalidData("GOSPrtT error: Invalid timestamp in flag file name".into()))?;

            if oldest_file_path.is_none() || file_updated_at < oldest_timestamp {
                oldest_timestamp = file_updated_at;
                oldest_file_path = Some(path.clone()); //Store the path
            }
        }
    }

    // 2. Read .rt timestamp from the oldest file (if found):
    if let Some(path) = oldest_file_path {
        match fs::read_to_string(&path) {
            Ok(content) => {
                oldest_timestamp = content.trim().parse()
                    .map_err(|_| ThisProjectError::InvalidData("Invalid .rt timestamp in flag file".into()))?;

                // #[cfg(debug_assertions)]
                debug_log!("GOSPrtT: get_oldest prefail: Oldest .rt timestamp found: {}", oldest_timestamp);
            },
            Err(e) => {
                // #[cfg(debug_assertions)]
                debug_log!("GOSPrtT error: get_oldest prefail: Error reading .rt timestamp from file {:?}: {}", path, e);
                return Err(ThisProjectError::from(e));
            }
        }

        // 3. Delete oldest flag - CORRECTED
        if let Err(e) = fs::remove_file(&path) {
            // #[cfg(debug_assertions)]
            debug_log!(
                "GOSPrtT error: get_oldest prefail: Error removing oldest_file_path flag file {:?}: {}",
                path,
                e);
            return Err(ThisProjectError::from(e));
        }
    }

    Ok(oldest_timestamp)
}


/// Sets a "pre-fail" flag file.  The filename is the file's `updated_at` timestamp.
/// The file content is the ReadySignal's `.rt` timestamp.
///
/// Directory structure: `sync_data/{team_channel_name}/fail_retry_flags/{remote_collaborator_name}/{file_updated_at_timestamp}`.
///
/// # Arguments
///
/// * `file_updated_at_time`: The file's `updated_at_timestamp`.
/// * `rt_timestamp`: The `.rt` timestamp from the ReadySignal.
/// * `remote_collaborator_name`: Remote collaborator's name.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on success, or a `ThisProjectError`.
fn set_prefail_flag_rt_timestamp__for_sendfile(
    file_updated_at_time: u64,
    mut rt_timestamp: u64,
    remote_collaborator_name: &str,
) -> Result<(), ThisProjectError> {

    /*
    edge case: if there are no files, the timestamp will be zero
    if the rt_timestamp is zero: set the flag for 1 (not zero)
    zero-return means there are no flags
    */
    if rt_timestamp == 0 {
        rt_timestamp = 1;
    }

    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

    let flagfile_basepath = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;

    let flag_file_path = flagfile_basepath
        .join(&team_channel_name)
        .join("fail_retry_flags")
        .join(remote_collaborator_name)
        .join(file_updated_at_time.to_string());  // Filename is the file's updated_at timestamp

    // Create directory structure if it doesn't exist
    if let Some(parent) = flag_file_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Write the .rt timestamp to the file
    fs::write(flag_file_path, rt_timestamp.to_string())?;

    debug_log!(
        "Set pre-fail flag for file updated at {} with ReadySignal timestamp {}.",
        file_updated_at_time, rt_timestamp
    );
    Ok(())
}

/// Removes all pre-fail flag files for a remote collaborator.
///
/// This function removes all files within the fail_retry_flags directory for the
/// given team channel and remote collaborator. The directory structure is as
/// follows:  `sync_data/{team_channel_name}/fail_retry_flags/{remote_collaborator_name}/`.
///
/// # Arguments
///
/// * `remote_collaborator_name`: The name of the remote collaborator.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` if all files were removed
///   successfully (or if the directory doesn't exist), or a
///   `ThisProjectError` if an error occurs during directory access or file
///   removal.
fn remove_prefail_flags__for_sendfile(
    remote_collaborator_name: &str,
) -> Result<(), ThisProjectError> {
    let team_channel_name = get_current_team_channel_name_from_nav_path()
        .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

    let directory_base = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;

    let directory_path = directory_base
        .join(&team_channel_name)
        .join("fail_retry_flags")
        .join(remote_collaborator_name);

    if !directory_path.exists() { // Check for existance
        return Ok(()); // Or log a message: debug_log!("Directory_path not found: {:?}", directory_path);
    }

    for entry in fs::read_dir(&directory_path)? {  // Iterate through directory_path contents
        let entry = entry?;
        let path = entry.path();
        if path.is_file() { // Only remove files
            match fs::remove_file(&path) { // Use remove_file, not remove_dir_all
                Ok(_) => debug_log!("Removed flag file: {:?}", path),
                Err(e) => {
                    debug_log!("Error removing flag file: {:?} - {}", path, e);
                    // Either continue or return the error if you want to stop on the first error.
                    return Err(ThisProjectError::IoError(e));
                }
            }
        }
    }
    Ok(())
}

/// Removes a specific pre-fail flag file based on its ID (timestamp).
/// currently gotit sign di (doc id) is the updated-at time of the file
///
/// This function attempts to remove the flag file located at:
/// `sync_data/{team_channel_name}/fail_retry_flags/{remote_collaborator_name}/{di_flag_id}`.
/// It returns an `Ok(())` if the file is successfully removed or if the file
/// doesn't exist (which isn't considered an error in this context, as the goal is
/// simply to ensure the flag is *not* present). It returns an error only if a file
/// operation other than `NotFound` occurs.
///
/// # Arguments
///
/// * `di_flag_id`: The document ID (timestamp) used as the flag file name.
/// * `remote_collaborator_name`: The remote collaborator's name.
/// * `team_channel_name`: The team channel name.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on successful removal or if the
/// file doesn't exist, or a `ThisProjectError` on other file operation errors.
fn remove_one_prefail_flag__for_sendfile(
    di_flag_id: u64,         // Use u64 directly, as the flag ID comes from a u64 timestamp.
    remote_collaborator_name: &str, // Use &str for efficiency
    team_channel_name: &str,   // Use &str for efficiency
) -> Result<(), ThisProjectError> {

    let flagbase = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;

    let mut flag_file_path = flagbase
        .join(team_channel_name)
        .join("fail_retry_flags")
        .join(remote_collaborator_name);

    if !flag_file_path.exists() { // Check for existance
        return Ok(()); //
    }

    flag_file_path.push(di_flag_id.to_string());  // Use di_flag_id directly

    match remove_file(flag_file_path) {
        Ok(_) => {
            debug_log!(
                "remove_one_prefail_flag__for_sendfile(): Successfully removed flag with id: {}",
                di_flag_id
            );
            Ok(())
        }
        Err(e) if e.kind() == ErrorKind::NotFound => {
            debug_log!("remove_one_prefail_flag__for_sendfile(): Flag file not found: {}", di_flag_id);
            Ok(()) // Not an error if the file isn't found.
        }
        Err(e) => {
            debug_log!("remove_one_prefail_flag__for_sendfile(): Error removing flag file: {}", e);
            Err(ThisProjectError::IoError(e))  // Return other errors
        }
    }
}

// let timestamp_request_port = // ... port for sending "ready to receive" to collaborator
// let file_receive_port = // ...  port for receiving files from collaborator
// let receipt_confirmation_port = // ... port for sending confirmations to collaborator
fn send_data(data: &[u8], target_addr: SocketAddr) -> Result<(), io::Error> {
    let socket = UdpSocket::bind(":::0")?;
    socket.send_to(data, target_addr)?;
    Ok(())
}

/// Gets the latest received file timestamp for a collaborator in a team channel, using a plain text file.
///
/// As another thread may be reading/writing the file, there
/// is a random-wait retry system
///
/// This function reads the timestamp from a plain text file at:
/// `sync_data/{team_channel_name}/latest_receivedfile_timestamps/
/// {collaborator_name}/latest_received_from_rc_filetimestamp.txt`
/// If the file or directory structure doesn't exist,
/// it creates them and initializes the timestamp to 0.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `collaborator_name`: The name of the collaborator.
///
/// # Returns
///
/// * `Result<u64, ThisProjectError>`:  The latest received timestamp on success, or a `ThisProjectError` if an error occurs.
///
/// This is one of those values and functions that can be confusing
/// because both you and your remote collaborator have quasi-mirror-image sync systems
/// with reversed roles. Both of you are making 'latest_received' timestamps
/// and both of you are using your and their 'latest_received' timestamps,
/// which are simultanously 'the same' abstract value but very different local-context-role-specific values
///
/// the complimentary function is: read_latestreceivedfromme_file_timestamp_plaintextstatefile()
///
/// example location of use:
/// Drone Loop to Send ReadySignals  (hlod)
/// 1.2 Refresh Timestamp
///
/// If the system is busy and needs to wait, just wait and retry
/// retry-wait must not be considered an 'error' to 'handled'
/// to collapse the entire system.
///
/// the complimentary function is: read_latestreceivedfromme_file_timestamp_plaintextstatefile()
fn read_rc_latest_received_from_rc_filetimestamp_plaintextstatefile(
    team_channel_name: &str,
    collaborator_name: &str,
) -> Result<u64, ThisProjectError> {

    let mut file_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;

    file_path.push(team_channel_name);
    file_path.push("latest_receivedfile_timestamps");
    file_path.push(collaborator_name);
    file_path.push("latest_received_from_rc_filetimestamp.txt");

    let mut retries = FILE_READWRITE_N_RETRIES;

    // Retry loop
    loop {
        // Generate a random pause duration within the specified range
        let pause_duration = Duration::from_secs(rand::rng().random_range(FILE_READWRITE_RETRY_SEC_PAUSE_MIN..=FILE_READWRITE_RETRY_SEC_PAUSE_MAX));

        match read_to_string(&file_path) {
            Ok(timestamp_str) => {
                match timestamp_str.trim().parse::<u64>() {
                    Ok(timestamp) => return Ok(timestamp), // Success!
                    Err(e) => {
                        debug_log!("Error parsing timestamp from file: {}. Retrying...", e);
                    }
                }
            }
            Err(e) if e.kind() == ErrorKind::NotFound => {
                // Create directories and file if not found (only on first attempt)
                if retries == FILE_READWRITE_N_RETRIES { // Only create on the first try:
                    if let Some(parent) = file_path.parent() {
                        create_dir_all(parent)?;
                    }
                    let mut file = File::create(&file_path)?;
                    file.write_all(b"0")?;
                    return Ok(0);
                } else {
                    debug_log!("File not found. Retrying...");
                }
            }
            Err(e) => {
                debug_log!("IO error reading timestamp file: {}. Retrying...", e);
            }
        }

        if retries == 0 {
            debug_log!("Failed to read timestamp after multiple retries. Using default value 0.");
            return Ok(0); // Or return an appropriate error
        }

        retries -= 1;
        thread::sleep(pause_duration);  // Pause before retrying
    }
}

/// Latest Received File Timestamp Finder: Directory Crawl for Maximum Timestamp
///
/// # Project Context
///
/// This function supports the UMA secure collaboration system's synchronization protocol
/// by determining when a remote collaborator last sent a file to the local user. The
/// returned timestamp is used as a reference point for deciding which files need to be
/// sent in the next transmission cycle.
///
/// ## Problem Being Solved
///
/// In bidirectional file synchronization:
/// - Each collaborator owns files in shared team channels
/// - Files are updated at different times
/// - The system needs to track "what has the other side already seen?"
/// - This timestamp represents the most recent file they sent to us
/// - It becomes the baseline for determining what we should send them next
///
/// ## Processing Logic
///
/// Scans all files in a team channel directory and:
/// 1. Filters for files owned by the specified collaborator
/// 2. Extracts the `updated_at_timestamp` from each qualifying file
/// 3. Returns the maximum (most recent) timestamp found
/// 4. Returns 0 if no qualifying files exist
///
/// ## Two-Tier Qualification System
///
/// ### Tier 1: Ownership Check
/// - Field: "owner"
/// - Type: Single-line string
/// - Logic: Must exactly match `collaborator_name` parameter
/// - Early exit: If owner doesn't match, don't read timestamp
///
/// ### Tier 2: Timestamp Extraction
/// - Field: "updated_at_timestamp"
/// - Type: u64 (milliseconds since epoch)
/// - Logic: Compare to current maximum, keep larger value
///
/// ## File Format Handling
///
/// Supports both plain and encrypted formats:
///
/// ### .toml (Plain Text)
/// - Read directly using custom field readers
/// - No preprocessing required
///
/// ### .gpgtoml (Encrypted)
/// - Decrypt to temporary directory first
/// - Read from temporary decrypted copy
/// - Original file remains encrypted
/// - Temporary cleanup handled by GPG infrastructure
///
/// ## Return Values
///
/// ### Ok(0)
/// Returned when:
/// - Directory is empty
/// - No files owned by the collaborator
/// - All qualifying files fail to parse
/// - This is NOT an error - it's valid to have no received files
///
/// ### Ok(timestamp)
/// Returned when:
/// - At least one qualifying file found
/// - Represents the maximum `updated_at_timestamp` among all qualifying files
///
/// ### Err(ThisProjectError)
/// Returned ONLY when:
/// - Team channel path construction fails
/// - GPG key fingerprint unavailable
/// - Temporary directory unavailable
/// - Directory is completely inaccessible (not just empty)
///
/// ## Error Handling Philosophy
///
/// Individual file failures do NOT cause function failure:
/// - File cannot be opened  skip, continue
/// - GPG decryption fails  skip, continue
/// - Owner field missing/malformed  skip, continue
/// - Timestamp field missing/malformed  skip, continue
///
/// Rationale: If 99 of 100 files are readable, we want the timestamp from those 99.
/// One corrupted file should not prevent the system from functioning.
///
/// ## Incremental Reading Strategy
///
/// Fields are read one at a time:
/// 1. Read "owner" field only
/// 2. If owner doesn't match  stop, skip file (never read timestamp)
/// 3. If owner matches  read "updated_at_timestamp"
/// 4. If timestamp valid  compare to current maximum
///
/// ### Performance Example
/// For a directory with 1000 files where:
/// - 50 owned by target collaborator
/// - 950 owned by others
///
/// Field reads: 1000 owner reads + 50 timestamp reads = 1050 total
/// vs. naive approach: 2000 reads (1000 files  2 fields)
///
/// Savings: 47.5% reduction in I/O operations
///
/// ## Operational Metrics
///
/// ### files_encountered
/// Total directory entries processed (including non-files)
/// - Use case: Verify directory walk is working
/// - Example: If 0, directory might be empty or inaccessible
///
/// ### files_skipped
/// Files that had errors during processing
/// - Includes: read errors, parse errors, decryption failures
/// - Excludes: files with non-matching owner (not an error)
/// - Use case: Monitor file corruption or encryption issues
///
/// ### files_processed
/// Files where owner field was successfully read and matched
/// - Use case: Verify collaborator has files in this channel
/// - Example: If 0, collaborator has never sent files here
///
/// ### timestamps_found
/// Files where both owner matched AND timestamp was extracted
/// - Use case: Track how many files contributed to result
/// - Note: Can be less than files_processed if some files lack timestamps
///
/// ## Security Considerations
///
/// ### Debug vs Production Logging
/// - Debug builds: Full file paths and detailed error messages
/// - Production builds: Only counters and result, no file paths
/// - Conditional compilation enforces separation
///
/// ### Error Message Content
/// Production messages contain:
/// - Function prefix: "GLRFRCFT"
/// - Error category: "read err", "gpg err", etc.
/// - Counters and result value
///
/// Production messages do NOT contain:
/// - File paths or names
/// - File contents
/// - User data
/// - System configuration details
///
/// ## Dependencies
///
/// ### External Functions (from codebase)
/// - `get_absolute_team_channel_path(name)`  Result<PathBuf, E>
/// - `LocalUserUma::read_gpg_fingerprint_from_file()`  Result<String, E>
/// - `get_base_uma_temp_directory_path()`  Result<PathBuf, E>
/// - `read_single_line_string_field_from_toml(path, field)`  Result<String, String>
/// - `read_u64_field_from_toml(path, field)`  Result<u64, String>
///
/// ### Helper Functions (defined below)
/// - `get_file_extension_safe(path)`  Option<&str>
/// - `prepare_readable_toml_path(...)`  Result<PathBuf, String>
///
/// ## Known Limitations and Edge Cases
///
/// ### Collaborator Has No Files
/// - Behavior: Returns Ok(0)
/// - Use case: New collaborator, or all their files were deleted
///
/// ### All Files Corrupted
/// - Behavior: Returns Ok(0), high files_skipped count
/// - Use case: Encryption key changed, filesystem corruption
///
/// ### Timestamp Field Missing
/// - Behavior: File is skipped for timestamp calculation
/// - Rationale: File schema may be outdated or incomplete
///
/// ### Concurrent File Modifications
/// - Behavior: Race conditions possible
/// - Mitigation: Result represents snapshot at scan time
///
/// ### Multiple Files Same Timestamp
/// - Behavior: Returns that timestamp (order doesn't matter)
/// - Logic: Uses max() which is stable for equal values
///
/// ## Performance Characteristics
///
/// ### Time Complexity
/// - Directory walk: O(N) where N = files in directory tree
/// - Per-file: O(1) to O(2) field reads depending on owner match
/// - Overall: O(N) with early exit optimization
///
/// ### I/O Operations
/// - Directory traversal: 1 system call per entry
/// - Plain .toml: 1-2 partial file reads per file
/// - Encrypted .gpgtoml: 1 GPG decryption + 1-2 partial file reads
///
/// ### Memory Usage
/// - Constant: O(1) - only tracks one u64 and counters
/// - No queue building, no path storage
/// - Minimal temporary storage per file
///
/// ## Usage Example
///
/// ```rust
/// match get_latest_received_from_rc_file_timestamp("team_alpha", "bob") {
///     Ok(0) => println!("Bob has never sent files to this channel"),
///     Ok(ts) => println!("Bob's most recent file was at timestamp: {}", ts),
///     Err(e) => eprintln!("Cannot access team channel: {}", e),
/// }
/// ```
///
/// ## Maintenance Notes
///
/// ### Debugging No Results (Ok(0))
/// 1. Check files_encountered: Is directory empty?
/// 2. Check files_skipped: Are files corrupted?
/// 3. Check files_processed: Does collaborator own any files?
/// 4. Check timestamps_found: Are timestamp fields missing?
///
/// ### Modifying Qualification Criteria
/// To add additional filters (e.g., file type, size):
/// - Add check after owner match, before timestamp read
/// - Maintain early-exit pattern for performance
/// - Update documentation with new tier
///
/// ### Handling Schema Changes
/// If TOML file schema changes:
/// - Timestamp field renamed: Update field name in read call
/// - Multiple timestamp fields: Choose which to use (created vs. updated)
/// - Timestamp format changes: Update parsing logic
///
/// # Arguments
///
/// * `team_channel_name` - Name of team channel to scan
/// * `collaborator_name` - Name of collaborator who owns files
///
/// # Returns
///
/// * `Ok(u64)` - Maximum timestamp found, or 0 if no qualifying files
/// * `Err(ThisProjectError)` - Only if directory/infrastructure unavailable
fn get_latest_received_from_rc_file_timestamp(
    team_channel_name: &str,
    collaborator_name: &str,
) -> Result<u64, ThisProjectError> {

    // =================================================
    // Setup: Get required paths and configuration
    // =================================================

    // Get absolute team channel path
    let team_channel_path = get_absolute_team_channel_path(team_channel_name)
        .map_err(|e| {
            #[cfg(debug_assertions)]
            debug_log!(
                "GLRFRCFT: Failed to get team channel path for '{}': {}",
                team_channel_name,
                e
            );
            ThisProjectError::from(format!("GLRFRCFT: path err"))
        })?;

    // Get GPG fingerprint for decrypting .gpgtoml files
    let gpg_full_fingerprint_key_id_string = LocalUserUma::read_gpg_fingerprint_from_file()
        .map_err(|e| {
            #[cfg(debug_assertions)]
            debug_log!(
                "GLRFRCFT: Failed to read GPG fingerprint: {}",
                e
            );
            ThisProjectError::from(format!("GLRFRCFT: gpg key err"))
        })?;

    // Get temporary directory for decrypted files
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|e| {
            #[cfg(debug_assertions)]
            debug_log!(
                "GLRFRCFT: Failed to get temp directory: {}",
                e
            );
            ThisProjectError::from(format!("GLRFRCFT: temp dir err"))
        })?;

    #[cfg(debug_assertions)]
    debug_log!(
        "GLRFRCFT: Starting scan - team_channel_path: {:?}, collaborator: {}",
        team_channel_path,
        collaborator_name
    );

    // =================================================
    // Initialize tracking variables
    // =================================================

    let mut latest_timestamp: u64 = 0;
    let mut files_encountered: usize = 0;
    let mut files_skipped: usize = 0;
    let mut files_processed: usize = 0; // Successfully read owner and matched
    let mut timestamps_found: usize = 0; // Successfully extracted timestamp

    // =================================================
    // Walk directory and process each file
    // =================================================

    for entry in WalkDir::new(&team_channel_path) {
        files_encountered += 1;

        // Get directory entry, skip on any error
        let entry = match entry {
            Ok(e) => e,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "GLRFRCFT: WalkDir entry error (skipping): {}",
                    e
                );
                files_skipped += 1;
                continue;
            }
        };

        // Only process regular files
        if !entry.file_type().is_file() {
            continue;
        }

        // Get file extension safely
        let extension = match get_file_extension_safe(entry.path()) {
            Some(ext) if ext == "toml" || ext == "gpgtoml" => ext,
            _ => {
                // Not a TOML file, skip silently (not an error)
                continue;
            }
        };

        #[cfg(debug_assertions)]
        debug_log!(
            "GLRFRCFT: Processing file: {:?}, extension: {}",
            entry.path(),
            extension
        );

        // Prepare readable TOML path (decrypt .gpgtoml if needed)
        let readable_path = match prepare_readable_toml_path(
            entry.path(),
            extension,
            &gpg_full_fingerprint_key_id_string,
            &base_uma_temp_directory_path,
        ) {
            Ok(p) => p,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "GLRFRCFT: Failed to prepare readable path for {:?}: {} (skipping)",
                    entry.path(),
                    e
                );
                files_skipped += 1;
                continue;
            }
        };

        // Convert PathBuf to &str for TOML reading functions
        let toml_path_str = match readable_path.to_str() {
            Some(s) => s,
            None => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "GLRFRCFT: Path conversion failed for {:?} (skipping)",
                    readable_path
                );
                files_skipped += 1;
                continue;
            }
        };

        // =================================================
        // Tier 1: Check if file is owned by collaborator
        // =================================================

        let owner = match read_single_line_string_field_from_toml(toml_path_str, "owner") {
            Ok(o) => o,
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "GLRFRCFT: Failed to read owner field from {:?}: {} (skipping)",
                    entry.path(),
                    e
                );
                files_skipped += 1;
                continue;
            }
        };

        // If owner doesn't match, skip (not an error, just not relevant)
        if owner != collaborator_name {
            #[cfg(debug_assertions)]
            debug_log!(
                "GLRFRCFT: File {:?} owned by '{}', not '{}'",
                entry.path(),
                owner,
                collaborator_name
            );
            continue;
        }

        // Owner matches - this file is relevant
        files_processed += 1;

        #[cfg(debug_assertions)]
        debug_log!(
            "GLRFRCFT: File {:?} owned by collaborator, reading timestamp",
            entry.path()
        );

        // =================================================
        // Tier 2: Extract timestamp and compare to maximum
        // =================================================

        match read_u64_field_from_toml(toml_path_str, "updated_at_timestamp") {
            Ok(timestamp) => {
                timestamps_found += 1;

                #[cfg(debug_assertions)]
                debug_log!(
                    "GLRFRCFT: Found timestamp {} in {:?}",
                    timestamp,
                    entry.path()
                );

                // Update latest_timestamp if this one is newer
                if timestamp > latest_timestamp {
                    latest_timestamp = timestamp;

                    #[cfg(debug_assertions)]
                    debug_log!(
                        "GLRFRCFT: New maximum timestamp: {}",
                        latest_timestamp
                    );
                }
            }
            Err(e) => {
                #[cfg(debug_assertions)]
                debug_log!(
                    "GLRFRCFT: Failed to read timestamp from {:?}: {} (skipping)",
                    entry.path(),
                    e
                );
                files_skipped += 1;
            }
        }
    }

    // =================================================
    // Log operational metrics and return result
    // =================================================

    #[cfg(debug_assertions)]
    debug_log!(
        "GLRFRCFT: Scan complete - encountered: {}, skipped: {}, processed: {}, timestamps: {}, result: {}",
        files_encountered,
        files_skipped,
        files_processed,
        timestamps_found,
        latest_timestamp
    );

    // Production logging (minimal, no file paths)
    #[cfg(not(debug_assertions))]
    {
        // Log to production system if needed
        // Format: "GLRFRCFT: encountered=N skipped=N processed=N result=N"
    }

    Ok(latest_timestamp)
}

// =================================================
// Helper Functions
// =================================================
// Note: If these already exist from send queue builder, skip duplicates

/// Safely extracts file extension as a string slice.
///
/// # Project Context
/// Distinguishes between .toml (plain) and .gpgtoml (encrypted) files
/// to determine if decryption preprocessing is needed.
///
/// # Arguments
/// - `path` - File path to extract extension from
///
/// # Returns
/// - `Some(&str)` - Extension as string slice (e.g., "toml", "gpgtoml")
/// - `None` - No extension or invalid UTF-8
///
/// # Safety
/// Returns None instead of panicking on invalid paths or non-UTF-8 extensions.
fn get_file_extension_safe(path: &std::path::Path) -> Option<&str> {
    path.extension()
        .and_then(std::ffi::OsStr::to_str)
}

/// Prepares a readable TOML path from either .toml or .gpgtoml file.
///
/// # Project Context
/// In the UMA secure collaboration system, files may be stored as:
/// - Plain .toml files (readable directly)
/// - Encrypted .gpgtoml files (must be decrypted to temp directory first)
///
/// This function abstracts that difference, always returning a path to a
/// readable .toml file (either the original or a temporary decrypted copy).
/// The caller can then use standard TOML reading functions on the result.
///
/// # Arguments
/// - `file_path` - Original file path (may be .toml or .gpgtoml)
/// - `extension` - File extension ("toml" or "gpgtoml")
/// - `gpg_fingerprint` - GPG key fingerprint for decryption
/// - `temp_dir` - Base temp directory for decrypted files
///
/// # Returns
/// - `Ok(PathBuf)` - Path to readable .toml file
/// - `Err(String)` - Decryption failed or invalid extension
///
/// # Error Handling
/// Caller should skip the file and continue processing if Err is returned.
/// This is not a fatal error - just means this particular file cannot be
/// processed in this pass.
///
/// # Security Notes
/// - Temporary decrypted files are managed by the GPG infrastructure
/// - Cleanup of temp files is handled by that infrastructure
/// - This function does not validate cleanup
fn prepare_readable_toml_path(
    file_path: &std::path::Path,
    extension: &str,
    gpg_fingerprint: &str,
    temp_dir: &PathBuf,
) -> Result<PathBuf, String> {
    match extension {
        "toml" => {
            // Plain TOML file - use directly
            Ok(file_path.to_path_buf())
        }
        "gpgtoml" => {
            // Encrypted file - decrypt to temp directory
            // Returns Result<String, _>, convert to PathBuf
            let temp_path_string = get_pathstring_to_temp_plaintoml_verified_extracted(
                file_path,
                gpg_fingerprint,
                temp_dir,
            )
            .map_err(|e| format!("PRTEP: GPG decryption failed: {:?}", e))?;

            // Convert String to PathBuf
            Ok(PathBuf::from(temp_path_string))
        }
        _ => {
            // Invalid extension (should not reach here due to earlier filtering)
            Err(format!("PRTEP: Invalid extension: {}", extension))
        }
    }
}

// =================================================
// Unit Tests
// =================================================

#[cfg(test)]
mod get_latest_received_from_rc_file_timestamp_tests {
    use super::*;

    #[test]
    fn test_get_file_extension_safe_with_toml() {
        let path = std::path::Path::new("/path/to/file.toml");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some("toml"));
    }

    #[test]
    fn test_get_file_extension_safe_with_gpgtoml() {
        let path = std::path::Path::new("/path/to/file.gpgtoml");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some("gpgtoml"));
    }

    #[test]
    fn test_get_file_extension_safe_no_extension() {
        let path = std::path::Path::new("/path/to/file");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, None);
    }

    #[test]
    fn test_get_file_extension_safe_empty_extension() {
        let path = std::path::Path::new("/path/to/file.");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some(""));
    }

    // Note: Full integration tests would require:
    // - Mock directory structure with .toml and .gpgtoml files
    // - Mock GPG infrastructure
    // - Mock TOML field readers
    // These should be added based on your testing infrastructure
}

/// Sets the latest received file timestamp for a collaborator in a team channel, using a plain text file.
///
/// As another thread may be reading/writing the file, there
/// is a random-wait retry system
///
/// This function writes the `timestamp` to a file at the specified path, creating the directory structure if needed.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `remote_collaborator_name`: The name of the collaborator.
/// * `timestamp`: The timestamp to set.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` on success, or a `ThisProjectError` if an error occurs.
fn write_save_latest_received_from_rc_file_timestamp_plaintext(
    team_channel_name: &str,
    remote_collaborator_name: &str,
    timestamp: u64,
) -> Result<(), ThisProjectError> {

    let mut file_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;
    file_path.push(team_channel_name);
    file_path.push("latest_receivedfile_timestamps");
    file_path.push(remote_collaborator_name);
    file_path.push("latest_received_from_rc_filetimestamp.txt");

    // Create directory structure if it doesn't exist
    if let Some(parent) = file_path.parent() {
        create_dir_all(parent)?;
    }

    let mut retries = FILE_READWRITE_N_RETRIES;

    loop {
        // Random pause duration
        let pause_duration = Duration::from_secs(rand::rng().random_range(FILE_READWRITE_RETRY_SEC_PAUSE_MIN..=FILE_READWRITE_RETRY_SEC_PAUSE_MAX));

        // Attempt to write to the file
        match std::fs::write(&file_path, timestamp.to_string()) { // Note the &
            Ok(_) => return Ok(()), // Success! Exit the loop.
            Err(e) => {
                // Check if the directory structure exists and create it if it doesn't.
                // Create the directory *only* if the file write fails *and* it's due to a missing directory:
                if e.kind() == ErrorKind::NotFound && retries == FILE_READWRITE_N_RETRIES {
                    if let Some(parent) = file_path.parent() {
                        if let Err(dir_err) = create_dir_all(parent) {
                            debug_log!(
                                "Error creating directory: {}",
                                dir_err
                            ); // Log and return the error if the directory can't be created.
                            return Err(ThisProjectError::IoError(dir_err)); // Return appropriate error
                        }
                    }

                }

                // Log the error before retrying
                debug_log!(
                    "Error writing timestamp to file: {}. Retrying... in write_save_latest_received_from_rc_file_timestamp_plaintext()",
                    e
                );
            }
        }


        if retries == 0 { // Maximum retries reached. Return an error or use a default value as needed.
            debug_log!("Failed to write timestamp to file after multiple retries.");
            return Err(ThisProjectError::NetworkError("Failed to write timestamp after retries".into())); // Or return a more appropriate error
        }

        retries -= 1;
        thread::sleep(pause_duration); // Pause before the next retry
    }
}

#[derive(Debug)]
enum CompressionError {
    InvalidNetworkType,
    NetworkIndexOutOfRange,
}

/// Compresses network type and index into a single u8, strictly using 3 digits.
/// Hundreds digit: 0 for IPv4, 1 for IPv6.
/// Remaining digits (0-99): Network index.
///
/// # Arguments
///
/// * `network_type`: "ipv4" or "ipv6".
/// * `network_index`: The network index (0-99).
///
/// # Returns
///
/// * `Result<u8, CompressionError>`: The compressed byte (0-199), or an error if input is invalid.
fn compress_band_data_byte(
    network_type: &str,
    network_index: u8,
) -> Result<u8, CompressionError> {

    if network_index > 99 {
        return Err(CompressionError::NetworkIndexOutOfRange);
    }

    let hundreds_digit = match network_type {
        "ipv4" => 0,
        "ipv6" => 1,
        _ => return Err(CompressionError::InvalidNetworkType),
    };

    let band_byte = (hundreds_digit * 100) + network_index; // Combine using decimal places, not bitwise

    debug_log!("compress_band_data_byte(), band_byte: {}, (network_type, network_index) ({}, {})", band_byte, network_type, network_index);
    Ok(band_byte)
}

#[derive(Debug)]
enum DecompressionError {
    InvalidBandByte,
    InvalidIndex,
}

// Implement Display for DecompressionError to improve debug output:
impl std::fmt::Display for DecompressionError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            DecompressionError::InvalidBandByte => write!(f, "Invalid band byte value (must be 0-199)"),
            DecompressionError::InvalidIndex => write!(f, "Invalid network index (must be 0-99)"),
        }
    }
}
// Implement Error for DecompressionError for compatibility:
impl std::error::Error for DecompressionError {}

/// Decompresses network type and index from a u8 byte.
///
/// Hundreds digit: 0 for IPv4, 1 for IPv6.
/// Remaining digits (0-99):  Network index.
/// Returns an error for invalid input.  Handles errors explicitly with Result.
///
/// # Arguments
///
/// * `band_byte`: The compressed byte.
///
/// # Returns
///
/// * `Result<(String, u8), DecompressionError>`:  The network type and index, or a DecompressionError.
fn decompress_banddata_byte(band_byte: u8) -> Result<(String, u8), DecompressionError> {
    if band_byte >= 200 {
        debug_log!("decompress_banddata_byte(): Invalid band_byte: {} (must be 0-199).", band_byte);
        return Err(DecompressionError::InvalidBandByte);
    }

    let hundreds_digit = band_byte / 100;
    let network_index = band_byte % 100;

    if network_index > 99 { // Strict check as per the specification.
        debug_log!("decompress_banddata_byte(): Invalid index: {} (must be from 0-99).", network_index);
        return Err(DecompressionError::InvalidIndex); // Specific error for easier handling
    }

    let network_type = if hundreds_digit == 1 {
        "ipv6".to_string()
    } else {
        "ipv4".to_string()
    };

    debug_log!("decompress_banddata_byte(), band_byte: {}: (network_type, network_index) ({}, {})", band_byte, network_type, network_index);
    Ok((network_type, network_index)) // Valid data: return Ok(data)
}

/// Sends a ReadySignal to the specified target address, selecting the IP address based on the network type.
/// goes to: their_rmtclb_ip
///     i.e. local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
///
/// Handles hash calculation, serialization, and sending the signal via UDP.
///
/// Args:
///     local_user_salt_list: A slice of `u128` salt values for hash calculation.
///     local_user_ipv4_address: The local user's IPv4 address.
///     local_user_ipv6_address: The local user's IPv6 address.
///     target_port: The target port on the remote machine.
///     last_received_timestamp: The timestamp of the last received file.
///     network_type: A string slice representing the network type ("ipv6" or "ipv4").
///     network_index: The index of the valid IP address in the local user's IP list (included in ReadySignal, but not used for IP selection).
///
/// Returns:
///     Result<(), ThisProjectError>: `Ok(())` on success, or a `ThisProjectError` if an error occurred.
fn send_ready_signal(
    local_user_salt_list: &[u128], // to make hash
    rc_network_type_string: String, // Remote collaborator's network type (ipv4, ipv6, etc.)
    rc_ip_addr_string: String, // Remote collaborator's IP string
    target_port: u16, // local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip
    last_received_timestamp: u64, // last_received_timestamp
    local_user_network_type: &str, // LOU needed for .b section
    local_user_network_index: u8,  // LOU needed for .b section
) -> Result<(), ThisProjectError> {
    debug_log!("send_ready_signal()1: Starting...");

    // for ready_signal.b
    let b_band_data = match compress_band_data_byte(
        local_user_network_type,
        local_user_network_index,
    ) {
        Ok(data) => data,
        Err(e) => {
            // Handle the error here. You could print an error message, return from the function,
            // or do something else depending on your specific needs.
            eprintln!("send_ready_signal()2: Error compressing band data: {:?}", e);
            return Ok(());
        }
    };

    // 1. Calculate hashes
    let current_timestamp = get_current_unix_timestamp();
    let hashes_result = calculate_ready_signal_hashes(
        last_received_timestamp,
        current_timestamp,
        b_band_data,
        local_user_salt_list,
    );
    let hashes = match hashes_result {
        Ok(h) => h,
        Err(e) => return Err(e),
    };

    // 2. Create ReadySignal
    let ready_signal = ReadySignal {
        rt: last_received_timestamp,
        rst: current_timestamp,
        b: b_band_data,
        rh: hashes,
    };
    debug_log!("send_ready_signal()3: ReadySignal created: {:?}", ready_signal);

    // 3. Serialize
    let serialized_signal = serialize_ready_signal(&ready_signal)?;
    debug_log!("send_ready_signal()4: ReadySignal serialized.");

    // 4. Determine target IP based on network_type:
    let send_readysignal_ip_addr = match rc_network_type_string {
        value if value == "ipv6".to_string() => {
            let ipv6_addr: Ipv6Addr = rc_ip_addr_string.parse().map_err(|_| ThisProjectError::NetworkError("Invalid IPv6 address".into()))?; // Corrected: .parse()
            IpAddr::V6(ipv6_addr)
        },
        value if value == "ipv4".to_string() => {
            let ipv4_addr: Ipv4Addr = rc_ip_addr_string.parse().map_err(|_| ThisProjectError::NetworkError("Invalid IPv4 address".into()))?; // Corrected: .parse()
            IpAddr::V4(ipv4_addr)
        },
        _ => return Err(ThisProjectError::NetworkError("send_ready_signal() error Invalid network type".into())),
    };

    let target_addr = SocketAddr::new(send_readysignal_ip_addr, target_port);

    // 5. Send the signal
    debug_log!("send_ready_signal()4: Sending ReadySignal to: {:?}", target_addr);
    send_data(&serialized_signal, target_addr)?;
    debug_log!("send_ready_signal()5: ReadySignal sent successfully.");

    Ok(())
}

// draft based on 'send ready signal' function
/// Sends a Gotit to the specified target address.
fn send_gotit_signal(
    local_user_salt_list: &[u128],
    local_user_ipv4_address: &Ipv4Addr,
    local_user_ipv6_address: &Ipv6Addr,
    network_type: &str,  // Add network type
    local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: u16,
    received_file_updatedat_timestamp: u64,
) -> Result<(), ThisProjectError> {
    /*
    struct GotItSignal {
        gst: Option<u64>, // send-time:
            generate_terse_timestamp_freshness_proxy(); for replay-attack protection
        di: Option<u64>, // the 'id' is updated_at file timestamp
            (because context= filesync timeline ID)
        gh: Option<Vec<u8>>, // N hashes of rt + re
    */

    let timestamp_for_gst = get_current_unix_timestamp();

    // Make hashes of gotit_signal fields:
    let gh_hashes = calculate_gotitsignal_hashlist(
        timestamp_for_gst,
        received_file_updatedat_timestamp, // as di
        local_user_salt_list,
    );

    // Create the GotItSignal struct:
    let gotit_struct = GotItSignal {
        gst: timestamp_for_gst,
        di: received_file_updatedat_timestamp,
        gh: gh_hashes?, // Include calculated hashes
    };

    // 5. Serialize the ReadySignal
    let serialized_gotitsignal_data = serialize_gotit_signal(
        &gotit_struct
    ).expect("inHLOD send_gotit_signal() err Failed to serialize ReadySignal, gotit_signal_to_send_from_this_loop");

    // --- Inspect Serialized Data ---
    debug_log!("inHLOD send_gotit_signal() serialized_gotitsignal_data: {:?}", serialized_gotitsignal_data);

    // Determine target IP based on network_type
    let detected_lou_ip_addr = match network_type {
        "ipv6" => IpAddr::V6(*local_user_ipv6_address),
        "ipv4" => IpAddr::V4(*local_user_ipv4_address),
        _ => return Err(ThisProjectError::NetworkError("Invalid network type in send_gotit_signal".into())),
    };

    let target_addr = SocketAddr::new(
        detected_lou_ip_addr,
        local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip,
    );

    // Log before sending
    debug_log!(
        "inHLOD send_gotit_signal() Attempting to send ReadySignal to {}: {:?}",
        target_addr,
        local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip
    );

    // // If sending to the first address succeeds, no need to iterate further

    if send_data(&serialized_gotitsignal_data, target_addr).is_ok() {
        debug_log("inHLOD send_gotit_signal() 6. Successfully sent GotIt to {} (first address)");
        return Ok(()); // Exit the thread
    } else {
        debug_log("inHLOD send_gotit_signal() err 6. Failed to send GotIt to {} (first address)");
        return Err(ThisProjectError::NetworkError("Failed to send ReadySignal".to_string())); // Return an error
    }

    Ok(())
}

/// Set up the local owner users in-tray desk
/// requests to recieve are sent from here
/// other people's owned docs are received here
/// gpg confirmed
/// save .toml (handle the type: content, node, etc.)
/// and 'gotit' signal sent out from here
///
/// echo_send: if any document comes in
/// automatically send out an echo-type request
/// if you get a file: auto-send an echo-request
/// a thread per 'sync-event'
///     after entering loop
///     Alice follows these steps...
///     1. Check for halt/quit uma signal
///     2. Make a sync-event thread, enter thread
///     3. set sync_event_id to be unique thread id
///     4. Creates a ReadySignal instance to be the ready signal
///     5. Serialize the ReadySignal
///     6. Send the signal @ local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip (exact ip choice pending...)
fn handle_local_owner_desk(
    local_owner_desk_setup_data: ForLocalOwnerDeskThread,
) -> Result<(), ThisProjectError> {
    /*
    TODO:
    I think there is supposed to be a thread per 'sync-event'
    Alice makes an event thread:
    Alice says ready: in the thread
    Alice waits N-miliseconds
    If no reply, kill thread.
    if there is a reply to that event unqiue ID,
    - gpg verify input (if not, kill thread)
    - save .toml etc if ok (if not, kill thread)
    - make another echo-thread (repeat)
    - if ok: send 'gotit!!' signal
    - kill thread
    */

    // TODO maybe a flag here to exit the function?
    // let mut exit_hlod = false;

    debug_log("HLOD Starting the handle_local_owner_desk()");

    let localowner_gotit_port = local_owner_desk_setup_data.local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip.clone();

    let remote_collaborator_name = local_owner_desk_setup_data.remote_collaborator_name.clone();

    debug_log("HLOD setup: cloned values.");

    /////////////////////////////////////////
    // Band: Load Network Band Configuration
    /////////////////////////////////////////
    /*
    Load from sync state files:
    - network_type
    - network_index
    - this_ipv4
    - this_ipv6

    nt/ni (typd/index) will be used for making and sending ReadySignal structs
    network Type + ipv6/ipv4 will be used to listen for files
    */
    // Load local owner band configuration data
    let (
        band_local_network_type,
        band_local_network_index,
        band_local_user_ipv4_address,
        band_local_user_ipv6_address,
    ) = match read_band__network_config_type_index_specs() {
        Ok(data) => data,
        Err(e) => {
            // Handle the error (e.g., log and return or use default values)
            debug_log!("Error reading band configuration: error -> e'{}'e ", e);
            return Err(e); // Or handle differently
        }
    };
    debug_log("HLOD setup: read_band__network_config_type_index_specs() run");

    /////////////
    // Bootstrap
    /////////////
    /*
    HLOD needs is the (ip string, type string) to use with two actions:
        their_rmtclb_ip -> local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: local_ports.ready_port,
                           localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: local_ports.intray_port,
        their_rmtclb_ip -> local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: local_ports.gotit_port,

    ready and gotit are aimed at the RC ip.
    */
    let Ok((rc_network_type_string, rc_ip_addr_string)) = hlod_udp_handshake__rc_network_type_rc_ip_addr(
        &local_owner_desk_setup_data, //: &ForLocalOwnerDeskThread,
        &band_local_network_type, //: &str,
        &band_local_user_ipv4_address, //: &Ipv4Addr,
        &band_local_user_ipv6_address, //: &Ipv6Addr,
        band_local_network_index, //: u8,
    ) else {
        // TODO, handled another way?
        return Err(ThisProjectError::NetworkError("Handshake failed".into()));
        };
    debug_log("HLOD setup: hlod_udp_handshake__rc_network_type_rc_ip_addr() run");

    loop { // 1. start overall loop to (re)start whole desk
        debug_log("HLOD 1. start overall loop to (re)start whole desk");


        // 1. Create lookup table:
        let channel_dir_path_str = read_state_string("current_node_directory_path.txt")?; // read as string first
        debug_log!("HLOD 1. Channel directory path (from session state): {}", channel_dir_path_str);

        // use absolute file path
        let team_channel_path = PathBuf::from(channel_dir_path_str);
        let hashtable_node_id_to_path = create_node_id_to_path_lookup(&team_channel_path)?;

        let remote_collaborator_name_for_thread_1 = remote_collaborator_name.clone();
        let remote_collaborator_name_for_thread_2 = remote_collaborator_name.clone();
        // let salt_list_1_drone_clone = salt_list_1.clone();

        // 1.1 check for halt/quit uma signal
        if should_halt_uma() {
            debug_log!("should_halt_uma(), exiting Uma in handle_local_owner_desk()");
            break Ok(());

        }

        debug_log("HLOD calling get_current_team_channel_name_from_nav_path");
        // --- Get team channel name ---
        let team_channel_name = match get_current_team_channel_name_from_nav_path() {
            Some(name) => name,
            None => {
                debug_log!("Error: Could not get current channel name. Skipping.");
                continue; // Skip to the next loop iteration
            }
        };

        // wait, if only for testing, so thread debug prints do not ~overlap
        thread::sleep(Duration::from_millis(1000)); // Avoid busy-waiting

        debug_log!("\n (re)Start HLOD handle_local_owner_desk()");
        // Print all sync data for the desk
        debug_log!("
            HLOD handle_local_owner_desk: local_owner_desk_setup_data -> {:?}",
            &local_owner_desk_setup_data
        );

        /*
        internal "echo":
        To avoid a prolonged delay if there is a backlog of files to recieve,
        but still allow a 3-5 sec pause when there is no backlog,
        each file-recept will turn off the echo
        */
        // let mut echo_flag = false;

        // Drone Loop in a thread? TODO

        /*
        Balancing Accuracy and efficiency:
        the first time in a session the drone loop will use the full search
        to find the most recent file timestamp,
        but thereafter
        the value is saved in a quasi-state or state.
        */

        // initialization
        let mut latest_received_from_rc_file_timestamp = match get_latest_received_from_rc_file_timestamp(
            &team_channel_name, // Correct argument order.
            &remote_collaborator_name_for_thread_1,
        ) {
            Ok(temp_extractor) => temp_extractor,
            Err(e) => {
                debug_log!("HLOD Error getting timestamp via get_latest_received_from_rc_file_timestamp: e'{}'e. Using 0.", e);
                0 // Use a default timestamp (0) if an error occurs.
            }
        };
        debug_log!(
            "HLOD: latest_received_from_rc_file_timestamp -> {:?}",
            latest_received_from_rc_file_timestamp,
        );

        // initialization
        // update state: latest received timestamp
        let _ = write_save_latest_received_from_rc_file_timestamp_plaintext(
            &team_channel_name, // for team_channel_name
            &remote_collaborator_name.clone(), // for collaborator_name
            latest_received_from_rc_file_timestamp, // for timestamp
        );

        // clone to avoid closure issues:
        let band_local_network_type_clone = band_local_network_type.clone();
        let salty_the_clone_list = local_owner_desk_setup_data.local_user_salt_list.clone();

        let rc_ip_addr_string_1 = rc_ip_addr_string.clone();
        let rc_network_type_string_1 = rc_network_type_string.clone();

        // --- 1.5 Drone Loop to Send ReadySignals ---
        let _ = thread::spawn(move || {
            ////////////////////////////////////
            // Drone Loop to Send ReadySignals  (hlod)
            //////////////////////////////////
            loop {

                // 1.1 Wait (and check for exit Uma)  this waits and checks N times: for i in 0..N {
                for _ in 0..10 {
                    // break for loop ?
                    if should_halt_uma() {
                        debug_log!("should_halt_uma(), exiting Uma in handle_local_owner_desk()");
                        break;
                    }
                    thread::sleep(Duration::from_millis(1000));
                }
                // break loop loop?
                if should_halt_uma() {
                    debug_log!("HLOD should_halt_uma(), exiting Uma in handle_local_owner_desk()");
                    break;
                }

                debug_log!("\nHLOD Drone Loop Start...thanks for coming around!");

                // 1.2 Refresh Timestamp
                // get timestamp of the file you (local owner user) recieved most recently from the RC
                // remote collaborator in this team-channel.
                /*
                @
                sync_data/{team_channel}/latest_receivedfile_timestamps/bob/latest_receivedfromme_file_timestamp
                */

                latest_received_from_rc_file_timestamp = match read_rc_latest_received_from_rc_filetimestamp_plaintextstatefile(
                    &team_channel_name,
                    &remote_collaborator_name_for_thread_2,
                ) {
                    Ok(temp_extractor) => temp_extractor,
                    Err(e) => {
                        debug_log!("HLOD GotItSignal Error getting timestamp via get_latest_received_from_rc_in_teamchannel_file_timestamp_filecrawl: e'{}'e. Using 0.", e);
                        0 // Use a default timestamp (0) if an error occurs.
                    }
                };
                debug_log!(
                    "HLOD drone loop (ready-signals) latest_received_from_rc_file_timestamp -> {:?}",
                    latest_received_from_rc_file_timestamp,
                );

                // 1.3 Send Ready Signal (using a function)
                let _ = send_ready_signal(
                    &salty_the_clone_list, // local_user_salt_list: &[u128],
                    rc_network_type_string_1.clone(), // local_user_ipv4_address: &Ipv4Addr,
                    rc_ip_addr_string_1.clone(), // local_user_ipv6_address: &Ipv6Addr,
                    local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,
                    latest_received_from_rc_file_timestamp, // last_received_timestamp: u64, // for rst
                    &band_local_network_type_clone, // network_type: String, // for nt
                    band_local_network_index, //network_index: u8, // for ni
                );

                debug_log!("\n");
            } // end drone loop (ready-signals)
        }); // end ready_thread

        //////////////////////////////
        // 3. InTrayListerLoop Start
        ////////////////////////////

        // 3.1 intrystruct_hash_set_session_nonce = HashSet::new() as protection against replay attacks Create a HashSet to store received hashes
        let mut intrystruct_hash_set_session_nonce = HashSet::new();  // Create a HashSet to store received hashes

        // to discard duplicate files already saved
        // TODO: to scale this should be perhaps a stub-file flag
        let mut file_hash_set_session_nonce = HashSet::new();  // Create a HashSet to store received hashes

        // --- 2. Enter In-Try-loop ---
        // restarts if crashes
        // enter main loop (to handle in-tray Send-File, gotit signl sending, 'echo' ready-signal sending)
        loop { // 3.2 In-Try-loop

            // --- 3.3 Check for 'should_halt_uma' Signal ---
            if should_halt_uma() {
                debug_log!(
                    "HLOD-InTray 3.3 main loop Check for halt signal. Halting handle_local_owner_desk() for {}",
                    local_owner_desk_setup_data.remote_collaborator_name
                );
                break;
            }

            // --- 3.4 Create UDP intray socket ---
            /*
            band_local_network_type,
            band_local_user_ipv4_address,
            band_local_user_ipv6_address,
            */
            debug_log("HLOD Creating intray socket listening UDP...");
            let intray_socket = create_local_udp_socket(
                &band_local_network_type,
                &band_local_user_ipv4_address,
                &band_local_user_ipv6_address,
                local_owner_desk_setup_data.localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip,
            )?;
            debug_log!("HLOD: Intray socket created.");

            // --- 3.5 in-tray Send-File Event ---
            // "Listener"?
            // 3.5.1 Receive in-tray Send-File packet
            let mut buf = [0; 65536]; // Maximum UDP datagram size
            loop { // In-Tray-Loop
                // Check for halt signal at the beginning of the loop
                if should_halt_uma() {
                    debug_log!("HLOD-InTray: Halt signal received. Exiting.");
                    break;
                }

                match intray_socket.recv_from(&mut buf) {
                    Ok((amt, src)) => {
                    debug_log!(
                        "HLOD-InTray match intray_socket.recv_from(&mut buf) Ok((amt, src)) {:?} {:?}",
                        amt,
                        src
                    );

                    // Check for exit-signal:
                    if should_halt_uma() {
                        debug_log!(
                            "HLOD-InTray 3.5.2 main loop Check for halt signal. Halting handle_local_owner_desk() for {}",
                            local_owner_desk_setup_data.remote_collaborator_name
                        );
                        break;
                    }

                    debug_log!(
                        "HLOD-InTray 3.5.2.1 Ok((amt, src)) ready_port Signal Received {} bytes from {}",
                        amt,
                        src
                    );

                    // --- Inspect Raw Bytes ---
                    debug_log!(
                        "HLOD-InTray 3.5.2.2 Ready Signal Raw bytes received: {:?}",
                        &buf[..amt]
                    );

                    // --- Inspect Bytes as Hex ---
                    let hex_string = buf[..amt].iter()
                        .map(|b| format!("{:02X}", b))
                        .collect::<String>();
                    debug_log!(
                        "HLOD-InTray 3.5.2.3 Ready Signal Raw bytes as hex: {}",
                        hex_string
                    );

                    // --- 3.5.3 Deserialize the SendFile signal ---
                    let use_padnet_flag = &local_owner_desk_setup_data.use_padnet;

                    // If Padnet
                    let incoming_intray_file_struct: SendFile = if *use_padnet_flag {

                        // Padnet
                        // let incoming_intray_file_struct: SendFile = match padnet_deserialize_intray_sendfile_struct(
                        match padnet_deserialize_intray_sendfile_struct(

                            &buf[..amt],
                        ) {
                            Ok(incoming_intray_file_struct) => {
                                debug_log("HLOD-InTray 2.3 SendFile listener: Receive File Data...do you copy, gold leader... >*<");

                                debug_log!("HLOD-InTray 2.3 Deserialize Ok(incoming_intray_file_struct) {}: Received SendFile: {:?}",
                                    local_owner_desk_setup_data.remote_collaborator_name,
                                    incoming_intray_file_struct
                                ); // Log the signal
                                incoming_intray_file_struct
                            },
                            Err(e) => {
                                debug_log!("HLOD-InTray 2.3 Deserialize Err Receive data Failed to parse ready signal: {}", e);
                                continue; // Continue to the next iteration of the loop
                            }
                        } // no semicolon, to pass value

                    } else {

                        // TODO PADNET
                        // let incoming_intray_file_struct: SendFile = match deserialize_intray_send_file_struct(
                       match deserialize_intray_send_file_struct(

                            &buf[..amt],
                        ) {
                            Ok(incoming_intray_file_struct) => {
                                debug_log("HLOD-InTray 2.3 SendFile listener: Receive File Data...do you copy, gold leader... >*<");

                                debug_log!("HLOD-InTray 2.3 Deserialize Ok(incoming_intray_file_struct) {}: Received SendFile: {:?}",
                                    local_owner_desk_setup_data.remote_collaborator_name,
                                    incoming_intray_file_struct
                                ); // Log the signal
                                incoming_intray_file_struct
                            },
                            Err(e) => {
                                debug_log!("HLOD-InTray 2.3 Deserialize Err Receive data Failed to parse ready signal: {}", e);
                                continue; // Continue to the next iteration of the loop
                            }
                        } // no semicolon, to pass value

                    };

                    debug_log("##HLOD-InTray## starting checks(hound's tooth, they say) 2.4");

                    // --- 3.2 timestamp freshness checks ---
                    let current_timestamp = get_current_unix_timestamp();

                    debug_log!(
                        "HLOD 2.4.1 check timestamp freshness checks: current_timestamp -> {:?}",
                        current_timestamp
                    );

                    // 3.2.1 No Future Dated Requests
                    if incoming_intray_file_struct.intray_send_time > Some(current_timestamp + 5) { // Allow for some clock skew (5 seconds)
                        debug_log!("HLOD 2.4.2 check: Received future-dated timestamp. Discarding.");
                        continue;
                    }

                    // 3.2.2 No Requests Older Than ~10 sec
                    if current_timestamp - 10 > incoming_intray_file_struct.intray_send_time.expect("REASON") {
                        debug_log!("HLOD 2.4.3 check: Received outdated timestamp (older than 10 seconds). Discarding.");
                        continue;
                    }

                    // 3.2.3 Check .intray_hash_list hash
                    if incoming_intray_file_struct.intray_hash_list.is_none() {
                        debug_log("HLOD 2.4.4 Check: intray_hash_list hash field is empty. Drop packet and keep going.");
                        continue; // Drop packet: Restart the loop to listen for the next signal
                    }

                    // 3.2.4 Check .intray_send_time timestamp
                    if incoming_intray_file_struct.intray_send_time.is_none() {
                        debug_log("HLOD 2.4.5 Check: intray_send_time ready signal sent-at timestamp field is empty. Drop packet and keep going.");
                        continue; // Drop packet: Restart the loop to listen for the next signal
                    }

                    // --- 4 Check / Add Hash-Nonce for per-session ready-signals ---
                    // ...e.g. guarding against the few seconds of expiration-gap
                    // HLOD 4.1 Hashes
                    let incoming_intray_file_struct_hash_vec = incoming_intray_file_struct.intray_hash_list.clone().expect("intray_hash_list is none");

                    // 4.2
                    if !incoming_intray_file_struct_hash_vec.is_empty() {
                        if intrystruct_hash_set_session_nonce.contains(&incoming_intray_file_struct_hash_vec) {
                            debug_log!("HLOD 4.2 quasi nonce check: Duplicate SendFile received (hash match). Discarding.");
                            continue; // Discard the duplicate signal
                        }
                        intrystruct_hash_set_session_nonce.insert(incoming_intray_file_struct_hash_vec); // Add hash to the set
                    } else {
                        debug_log!("HLOD 4.2 quasi nonce check: SendFile received without hashes. Discarding."); // Or handle differently
                        continue;
                    }

                    // --- 5.0 Hash-Check for SendFile Struct ---
                    // HLOD 5.0 Drop packet when fail check
                    // Check the hash of the incoming file against the provided list of salts
                    if !hash_checker_for_sendfile_struct(
                        &local_owner_desk_setup_data.remote_collaborator_salt_list, // Use remote collaborator's salts
                        incoming_intray_file_struct.intray_send_time.expect("Missing intray_send_time"), // Safe unwrap, checked earlier
                        incoming_intray_file_struct.gpg_encrypted_intray_file.as_deref().expect("Missing encrypted file"), // Safe unwrap, checked earlier
                        incoming_intray_file_struct.intray_hash_list.as_deref().expect("Missing hash list")  //Safe unwrap, checked earlier

                    ) {
                        debug_log!("failed HLOD 5.0: SendFile Struct hash verification failed. Discarding signal.");
                        continue; // Discard the signal and continue listening
                    }

                    debug_log!("Passed HLOD 5.0: SendFile Struct hash verified.");

                    /*
                    TODO?

                    If message file:
                    look in Navigation-State for Messages requires gpg-encrypted
                    if not: look in file for flag

                    if node-file
                    look in file for flag

                    add steps to

                    (if not a message file or no mssage-file nav-state:  Messages requires gpg-encrypted)
                    A. save as a temp file (no os-temp, uma-data temp)
                    B. make read-copy
                    C. look for flag
                    */


                    // --- 6. HLOD decypt ---
                    /*
                    For padnet:
                    - get blob
                    - get array
                    - run read
                    - turn file into new blob

                    /// # Returns
                    /// * `Ok(usize)` - Number of bytes processed
                    /// * `Err(PadnetError)` - Operation failed, no output created
                    pub fn padnet_reader_xor_file(
                        path_to_target_file: &Path, // `path_to_target_file` - Absolute path to file to XOR
                        result_path: &Path,         // `result_path` - Absolute path for output file
                        path_to_padset: &Path,      // `path_to_padset` - Absolute path to padset root
                        pad_index: &PadIndex,       // `pad_index` - Starting line index for XOR operation
                    ) -> Result<usize, PadnetError> {
                    */

                    // 6.1  Handle the Option<Vec<u8>> for gpg_encrypted_intray_file
                    let still_encrypted_file_blob = match &incoming_intray_file_struct.gpg_encrypted_intray_file {

                        Some(data) => data,  // Extract the Vec<u8> if Some
                        None => {
                            debug_log!("HLOD 6.1: gpg_encrypted_intray_file is None. Skipping.");
                            continue; // Or handle the None case differently (e.g., return an error)
                        }
                    };

                    debug_log!(
                        "HLOD 6.1 still_encrypted_file_blob -> {:?}",
                        still_encrypted_file_blob
                    );

                    // let padnet_index_array = match &incoming_intray_file_struct.padnet_index_array {
                    //     Some(data) => data,  // Extract the Vec<u8> if Some
                    //     None => {
                    //         debug_log!("HLOD 6.1: padnet_index_array is None. Skipping.");

                    //         TODO continue; // Or handle the None case differently (e.g., return an error)
                    //     }
                    // };

                    let decrypted_clearsignfile_data = if *use_padnet_flag {
                        /*
                        return: vec<u8> bytes

                        1. still OTP layer, get blob
                        2. make paths; 1. to write OTP blob to, 2. to write gpg blob to
                        3. write OTP blob
                        4. get padnet_directory_path
                        5. read OTP file, make gpg file
                        6. get bytes from file
                        */

                        // 1. still OTP layer, get blob
                        let still_otp_encrypted_file_blob = match &incoming_intray_file_struct.gpg_encrypted_intray_file {
                            Some(data) => data,  // Extract the Vec<u8> if Some
                            None => {
                                debug_log!("HLOD: if *use_padnet_flag:  6.1: gpg_encrypted_intray_file is None. Skipping.");
                                continue; // Or handle the None case differently (e.g., return an error)
                            }
                        };

                        // 2. make paths; 1. to write OTP blob to, 2. to write gpg blob to
                        let otp_blob_file_path = create_unique_temp_filepathbuf(
                            &std::env::temp_dir(),
                            "uma_xor_result",
                            TEMP_FILE_CREATION_RETRY_ATTEMPTS,
                            TEMP_FILE_RETRY_DELAY_MS,
                        ).map_err(|e| {
                            ThisProjectError::IoError(std::io::Error::new(
                                e.kind(),
                                format!("HLOD: if *use_padnet_flag: failed to create temp file #2: {}", e),
                            ))
                        })?;

                        let gpg_blob_file_path = create_unique_temp_filepathbuf(
                            &std::env::temp_dir(),
                            "uma_xor_result",
                            TEMP_FILE_CREATION_RETRY_ATTEMPTS,
                            TEMP_FILE_RETRY_DELAY_MS,
                        ).map_err(|e| {
                            ThisProjectError::IoError(std::io::Error::new(
                                e.kind(),
                                format!("HLOD: if *use_padnet_flag: failed to create temp file #2: {}", e),
                            ))
                        })?;


                        // 3. write OTP blob to file
                        // set blob to blob_as_file_path;
                        /*
                        fn write_bytes_to_file_atomic(
                            data: &[u8],
                            file_path: &Path,
                        ) -> Result<(), ThisProjectError> {
                        */
                        let _ = write_bytes_to_file_atomic(
                            still_otp_encrypted_file_blob, // data: &[u8],
                            &gpg_blob_file_path, // file_path: &Path,
                        )?;

                        // 4. get padnet_directory_path, read-pad path (with id and channel name)
                        let team_channel_name = match get_current_team_channel_name_from_nav_path() {
                            Some(name) => name,
                            None => {
                                debug_log!("HLOD: if *use_padnet_flag: Error: Could not get current channel name. Skipping set_as_active.");
                                return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
                            },
                        };
                        let rc_key_id = &local_owner_desk_setup_data.remote_collaborator_gpg_publickey_id;

                        // make name
                        //  -- /padnet/to/{team_channel}/{RC key-id}
                        let mut padnet_directory_path = get_reader_from_padnet_directory_path()?;
                        padnet_directory_path.push(&team_channel_name);
                        padnet_directory_path.push(rc_key_id);

                        // 5. read OTP file, make gpg file
                        /*

                        /// # Arguments
                        /// * `path_to_target_file` - Absolute path to file to XOR
                        /// * `result_path` - Absolute path for output file
                        /// * `path_to_padset` - Absolute path to padset root
                        /// * `pad_index` - Starting line index for XOR operation
                        ///
                        /// # Returns
                        /// * `Ok(usize)` - Number of bytes processed
                        /// * `Err(PadnetError)` - Operation failed, no output created
                        pub fn padnet_reader_xor_file(
                            path_to_target_file: &Path, // `path_to_target_file` - Absolute path to file to XOR
                            result_path: &Path,         // `result_path` - Absolute path for output file
                            path_to_padset: &Path,      // `path_to_padset` - Absolute path to padset root
                            pad_index: &PadIndex,       // `pad_index` - Starting line index for XOR operation
                        ) -> Result<usize, PadnetError> {
                        */

                        let padnet_index_array = match &incoming_intray_file_struct.padnet_index_array {
                            Some(data) => data,  // Extract the Vec<u8> if Some
                            None => {
                                debug_log!("HLOD: if *use_padnet_flag:  6.1: padnet_index_array is None. Skipping.");

                                continue; // Or handle the None case differently (e.g., return an error)
                            }
                        };


                        let _ = padnet_reader_xor_file(
                            &otp_blob_file_path,  // path_to_target_file: &Path, // `path_to_target_file` - Absolute path to file to XOR
                            &gpg_blob_file_path,         // `result_path` - Absolute path for output file
                            &padnet_directory_path,      // `path_to_padset` - Absolute path to padset root
                            padnet_index_array, // pad_index: &PadIndex,       // `pad_index` - Starting line index for XOR operation
                        );

                        // 6. get bytes from file
                        /*
                        fn read_file_to_bytes(
                            file_path: &Path,
                        ) -> Result<Vec<u8>, ThisProjectError> {
                        */
                        // 6. get bytes from file
                        match read_file_to_bytes(&gpg_blob_file_path) {
                            Ok(bytes) => {
                                #[cfg(debug_assertions)]
                                println!("HLOD: if *use_padnet_flag:  6.6: Read {} bytes from GPG file", bytes.len());

                                bytes  //  Return the Vec<u8> (no semicolon!)
                            },
                            Err(e) => {
                                debug_log!("HLOD: if *use_padnet_flag:  6.6: Read failed: {}. Skipping.", e);
                                continue; // Skip to next packet
                            }
                        }
                    } else {



                        // 6.2 *Now* decrypt the data
                        // let decrypted_clearsignfile_data = match gpg_decrypt_from_bytes(
                        match gpg_decrypt_from_bytes(
                            still_encrypted_file_blob,
                            &local_owner_desk_setup_data.local_user_gpg_publickey_id
                        ) { // Pass the extracted data
                            Ok(data) => data,
                            Err(e) => {
                                debug_log!("HLOD NOT*use_padnet_flag: 6.2: GPG decryption failed: {}. Skipping.", e);
                                continue; // Skip to the next packet if decryption fails
                            }
                        }

                     };

                    debug_log!(
                        "HLOD 6.2 decrypt the data decrypted_clearsignfile_data -> {:?}",
                        decrypted_clearsignfile_data
                    );

                    /*
                    // 6.3 Extract the clearsigned data
                    let extracted_clearsigned_file_data = match extract_clearsign_data(&decrypted_clearsignfile_data) {
                        Ok(data) => data,
                        Err(e) => {
                            debug_log!("HLOD 6.3: Clearsign extraction failed: {}. Skipping.", e);
                            continue;
                        }
                    };
                    debug_log!(
                        "HLOD 6.3 extracted_clearsigned_file_data -> {:?}",
                        extracted_clearsigned_file_data
                    );

                    */

                    let extracted_clearsigned_file_data = if *use_padnet_flag {

                        /*
                        // 1. flag for padnet-mode where?
                        // 2. get team-channel-name
                        // 3. get RC key-id (state)
                        // 4. get read-pad path (with id, team-channel)
                        //  -- /padnet/to/{team_channel}/{RC key-id}
                        */

                        let team_channel_name = match get_current_team_channel_name_from_nav_path() {
                            Some(name) => name,
                            None => {
                                debug_log!("Error: Could not get current channel name. Skipping set_as_active.");
                                return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
                            },
                        };
                        let rc_key_id = &local_owner_desk_setup_data.remote_collaborator_gpg_publickey_id;

                        ();
                        // 3. get read-pad path (with id)
                        //  -- /padnet/to/{team_channel}/{RC key-id}
                        let mut padnet_directory_path = get_reader_from_padnet_directory_path()?;
                        padnet_directory_path.push(&team_channel_name);
                        padnet_directory_path.push(rc_key_id);


                        // 6.3 Extract the clearsigned data
                        match extract_clearsign_data(&decrypted_clearsignfile_data) {
                            Ok(data) => data,
                            Err(e) => {
                                debug_log!("HLOD 6.3: Clearsign extraction failed: {}. Skipping.", e);
                                continue;
                            }
                        }

                    } else {
                    // Normal Mode, No Padnet OTP Network Layer

                        // 6.3 Extract the clearsigned data
                        match extract_clearsign_data(&decrypted_clearsignfile_data) {
                            Ok(data) => data,
                            Err(e) => {
                                debug_log!("HLOD 6.3: Clearsign extraction failed: {}. Skipping.", e);
                                continue;
                            }
                        }


                    };

                    debug_log!(
                        "HLOD 6.3 extracted_clearsigned_file_data -> {:?}",
                        extracted_clearsigned_file_data
                    );

                    // Section 6.4 - Extract flag - for clearsigned .toml / .gpgtoml
                    let file_str = std::str::from_utf8(&extracted_clearsigned_file_data)
                        .map_err(|_| ThisProjectError::InvalidData("Invalid UTF-8 in file content".into()))?;

                    // todo?
                    let save_as_gpgtoml = file_str.contains("\nmessagepost_gpgtoml = true\n")
                        || file_str.contains("\ncorenode_gpgtoml = true\n");

                    debug_log!("HLOD 6.4: save_as_gpgtoml flag = {}", save_as_gpgtoml);

                    // 7 Save File into Uma Folder Structure
                    // let received_toml: Value = toml::from_slice(&extracted_clearsigned_file_data)?;
                    /*
                    1. if X then save in A place
                    2. if Y then save in B place
                    for a message file,
                    filepath_in_node = "/message_posts_browser"
                    for MVP: just add it the same way you add any message, next available number.

                    current_path = project_graph_data/team_channels/{}/message_posts_browser/

                    let incoming_file_path = get_next_message_file_path(current_path, local_owner_user);
                    */
                    // 7.1 1. Identifying Instant Message Files
                    let file_str = std::str::from_utf8(&extracted_clearsigned_file_data).map_err(|_| {
                        ThisProjectError::InvalidData("Invalid UTF-8 in file content".into())
                    })?;


                    debug_log!(
                        "HLOD 7.1 found message file, file_str -> {:?}",
                        file_str
                    );

                    // let mut incoming_file_path: PathBuf = PathBuf::from("project_graph_data/team_channels");
                    let mut incoming_file_path: PathBuf; // = PathBuf::new();

                    let team_channel_name = get_current_team_channel_name_from_nav_path()
                        .ok_or(ThisProjectError::InvalidData(
                            "Unable to get team channel name".into())
                        )?;

                    // ======================
                    // File Type Processing 1. message Posts
                    // ======================

                    // TODO handling:
                    // 1. message Posts <-
                    // 2. 0toml config for message posts
                    // 3. Nodes
                    // future
                    // 4. Uma Data
                    if file_str.contains("filepath_in_node = \"/message_posts_browser\"") {
                        debug_log!("HLOD-InTray: an instant message file.");

                        // 7.2
                        // 2. Generating File Path

                        // let mut current_path = PathBuf::from("project_graph_data/team_channels");
                        let mut current_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
                            "project_graph_data/team_channels"
                        )?;

                        current_path.push(&team_channel_name);
                        current_path.push("message_posts_browser");

                        incoming_file_path = get_next_message_file_path(
                            &current_path,
                            &local_owner_desk_setup_data.remote_collaborator_name // local user name
                        );

                        // NEW: Adjust extension based on flag
                        if save_as_gpgtoml {
                            incoming_file_path.set_extension("gpgtoml");
                        }

                        debug_log!(
                            "HLOD 7.2 got-made incoming_file_path -> {:?}",
                            incoming_file_path
                        );

                        // check: see if this same file was already saved
                        // 1. Calculate the hash of the received file content using the *local* user's salts and the *raw bytes*:
                        let received_file_hash_result = calculate_pearson_hashlist_for_string( // Use a byte-oriented hash function
                            &file_str,  // Hash the raw bytes
                            &local_owner_desk_setup_data.local_user_salt_list, // Use *local* user's salts
                        );

                        let received_file_hash = match received_file_hash_result {
                            Ok(hash) => hash,
                            Err(e) => {
                                debug_log!("Error calculating hash for received file: {}", e);
                                continue; // Skip to next file if hashing fails
                            }
                        };

                        // 2. Check for duplicates and insert the hash (as before)
                        if file_hash_set_session_nonce.contains(&received_file_hash) {
                            debug_log!("Duplicate file received (hash match). Discarding.");
                            continue; // Discard the duplicate file
                        }
                        file_hash_set_session_nonce.insert(received_file_hash); // Insert BEFORE saving

                        // 3. Saving the File
                        // MODIFIED: Choose what to save
                        let data_to_save = if save_as_gpgtoml {
                            still_encrypted_file_blob  // Save encrypted version
                        } else {
                            &decrypted_clearsignfile_data  // Save clearsigned version
                        };

                        // 3. Saving the File
                        // if let Err(e) = fs::write(&incoming_file_path, data_to_save) {
                        //     debug_log!("HLOD-InTray: Failed to write message file: {:?}", e);
                        //     return Err(ThisProjectError::from(e));
                        // }

                        // Create parent directories if they don't exist
                        if let Some(parent) = Path::new(&incoming_file_path).parent() {
                            if let Err(e) = fs::create_dir_all(parent) {
                                debug_log!("HLOD-InTray: Failed to create directories: {:?}", e);
                                return Err(ThisProjectError::from(e));
                            }
                        }

                        // 3. Saving the File
                        if let Err(e) = fs::write(&incoming_file_path, data_to_save) {
                            debug_log!("HLOD-InTray: Failed to write message file: {:?}", e);
                            return Err(ThisProjectError::from(e));
                        }

                        debug_log!("7.3 HLOD-InTray: IM message file saved to: {:?}", incoming_file_path);
                        // if let Err(e) = fs::write(&incoming_file_path, &extracted_clearsigned_file_data) {
                        //     debug_log!("HLOD-InTray: Failed to write message file: {:?}", e);
                        //     // Consider returning an error here instead of continuing the loop
                        //     return Err(ThisProjectError::from(e));
                        // }

                        // debug_log!("7.3 HLOD-InTray: IM message file saved to: {:?}", incoming_file_path);


                    }


                    // ======================
                    // File Type Processing 2: 0toml config for message posts
                    // ======================

                    // TODO handling:
                    // 1. message Posts
                    // 2. 0toml config for message posts <-
                    // 3. Nodes
                    // future
                    // 4. Uma Data
                    if file_str.contains("messageposts_expire_after_n_min =") {
                        debug_log!("HLOD-InTray: an instant message file.");

                        // 7.2
                        // 2. Generating File Path

                        // let mut current_path = PathBuf::from("project_graph_data/team_channels");
                        let mut current_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
                            "project_graph_data/team_channels"
                        )?;

                        current_path.push(&team_channel_name);
                        current_path.push("message_posts_browser");

                        // "Always"
                        current_path.push("0.toml");

                        // incoming_file_path = get_next_message_file_path(
                        //     &current_path,
                        //     &local_owner_desk_setup_data.remote_collaborator_name // local user name
                        // );


                        // NEW: Adjust extension based on flag
                        if save_as_gpgtoml {
                            current_path.set_extension("gpgtoml");
                        }

                        debug_log!(
                            "HLOD 7.2 got-made incoming_file_path -> {:?}",
                            current_path
                        );

                        // check: see if this same file was already saved
                        // 1. Calculate the hash of the received file content using the *local* user's salts and the *raw bytes*:
                        let received_file_hash_result = calculate_pearson_hashlist_for_string( // Use a byte-oriented hash function
                            &file_str,  // Hash the raw bytes
                            &local_owner_desk_setup_data.local_user_salt_list, // Use *local* user's salts
                        );

                        let received_file_hash = match received_file_hash_result {
                            Ok(hash) => hash,
                            Err(e) => {
                                debug_log!("Error calculating hash for received file: {}", e);
                                continue; // Skip to next file if hashing fails
                            }
                        };

                        // 2. Check for duplicates and insert the hash (as before)
                        if file_hash_set_session_nonce.contains(&received_file_hash) {
                            debug_log!("Duplicate file received (hash match). Discarding.");
                            continue; // Discard the duplicate file
                        }
                        file_hash_set_session_nonce.insert(received_file_hash); // Insert BEFORE saving

                        // 3. Saving the File
                        // MODIFIED: Choose what to save
                        let data_to_save = if save_as_gpgtoml {
                            still_encrypted_file_blob  // Save encrypted version
                        } else {
                            &decrypted_clearsignfile_data  // Save clearsigned version
                        };

                        // 3. Saving the File

                        // Create parent directories if they don't exist
                        if let Some(parent) = Path::new(&current_path).parent() {
                            if let Err(e) = fs::create_dir_all(parent) {
                                debug_log!("HLOD-InTray: Failed to create directories: {:?}", e);
                                return Err(ThisProjectError::from(e));
                            }
                        }

                        // 3. Saving the File
                        if let Err(e) = fs::write(&current_path, data_to_save) {
                            debug_log!("HLOD-InTray: Failed to write message file: {:?}", e);
                            return Err(ThisProjectError::from(e));
                        }

                        debug_log!("7.3 HLOD-InTray: IM message file saved to: {:?}", current_path);

                    }


                    // // TODO?
                    // // if message file
                    // // if nav-state fule
                    // // if contains gpg "\ngpgtoml = true\n"
                    // if file_str.contains("\nmessagepost_gpgtoml = true\n") || file_str.contains("\ncorenode_gpgtoml = true\n"){

                    //     // save .gpg version as .gpgtoml
                    //     // ...file name if message...

                    // }

                    // ======================
                    // File Type Processing 3. Node files
                    // ======================

                    // For now only handling:
                    // 1. message-post files
                    // 2. 0toml message-post config files
                    // 3. Node files <-
                    // Future:
                    // 4. Uma Data
                    // TODO, don't load whole file...
                    if file_str.contains("node_unique_id = \"") {
                        debug_log!("HLOD-InTray: an Ode file. (Grecian Urn...you know.)");

                        // 7.2
                        // 2. Generating File Path
                        // attach to absolute path: TODO

                        // Extract directory_path:
                        let new_node_directory_path_result = file_str
                            .lines()  // Iterate over lines
                            .find_map(|line| { // Use find_map to extract and parse in one step
                                if line.starts_with("directory_path = \"") && line.ends_with("\"") {
                                    let path_str = &line["directory_path = \"".len()..line.len() - 1];
                                    Some(PathBuf::from(path_str))
                                } else {
                                    None
                                }
                            });

                        let node_file_path = match new_node_directory_path_result {
                            Some(path) => path,
                            None => {
                                debug_log!("'directory_path' not found or invalid format in node.toml");
                                continue; // Or handle error as you see fit
                            }
                        };

                        // get absolute path
                        let new_full_abs_node_directory_path = PathBuf::from(node_file_path);

                        // make sure path exists
                        fs::create_dir_all(&new_full_abs_node_directory_path)?;

                        debug_log!(
                            "HLOD 7.2 got-made new_full_abs_node_directory_path -> {:?}",
                            &new_full_abs_node_directory_path
                        );

                        let new_node_toml_file_path = new_full_abs_node_directory_path.join("node.toml"); // Path to the new node.toml

                        debug_log!(
                            "HLOD 7.2 got-made new_node_toml_file_path -> {:?}",
                            &new_node_toml_file_path
                        );

                        // check: see if this same file was already saved
                        // 1. Calculate the hash of the received file content using the *local* user's salts and the *raw bytes*:
                        let received_file_hash_result = calculate_pearson_hashlist_for_string( // Use a byte-oriented hash function
                            &file_str,  // Hash the raw bytes
                            &local_owner_desk_setup_data.local_user_salt_list, // Use *local* user's salts
                        );

                        let received_file_hash = match received_file_hash_result {
                            Ok(hash) => hash,
                            Err(e) => {
                                debug_log!("Error calculating hash for received file: {}", e);
                                continue; // Skip to next file if hashing fails
                            }
                        };

                        // 2. Check for duplicates and insert the hash (as before)
                        if file_hash_set_session_nonce.contains(&received_file_hash) {
                            debug_log!("Duplicate file received (hash match). Discarding.");
                            continue; // Discard the duplicate file
                        }
                        file_hash_set_session_nonce.insert(received_file_hash); // Insert BEFORE saving


                        /////////////////
                        // Move or Save
                        ////////////////
                        /*
                        1. Make a hash-table of node files' unique ID in session/team-channel: id: path lookup
                        2. check this node uniqeu ID
                        3. if this node is an existing node:
                        4. remove the old path
                        5. (re)save at the new path
                        */

                        // 2. Access node data (must match `node_unique_id_str` from `create_node_id_to_path_lookup`):
                        let node_unique_id_str_result = extract_string_from_toml_bytes(&extracted_clearsigned_file_data, "node_unique_id");
                        // ?
                        // let new_node_dir_path_str = match extract_string_from_toml_bytes(received_file_bytes, "directory_path") {
                        //     Ok(s) => s,
                        //     Err(_) => return Err(ThisProjectError::InvalidData("directory_path field missing from node file".into())),
                        // };

                        match node_unique_id_str_result {
                            Ok(node_unique_id_str) => { // Node exists, handle move/replace:
                                /*
                                Establish Variables
                                1. new node directory path (get) - Done Above
                                    new_full_abs_node_directory_path

                                2. new node file path (matke) - Done Above
                                    new_node_toml_file_path

                                Look for (opposite make/get order from above):
                                3. Old node file path (get)
                                4. old node directory path (make)

                                If no old path:
                                5A. make new directory,
                                6A. save new file

                                If old path exists:
                                5B. remove OLD node FILE (just the file, not the directory)
                                6B. save (relace) new node file in old directory
                                7. recoursively move the old directory to the NEW directory path

                                */
                                // Use the node_unique_id_str

                                // let new_node_dir_path = PathBuf::from(new_node_dir_path_str);
                                // let new_node_toml_path = new_node_dir_path.join("node.toml"); // Path to the new node.toml

                                // Get old node.toml file path (if exists)
                                if let Some(olddir_existing_node_directory_path) = hashtable_node_id_to_path.get(&node_unique_id_str) {

                                    // make old directory path
                                    let olddir_abs_node_directory_path = PathBuf::from(olddir_existing_node_directory_path);

                                    debug_log!(
                                        "HLOD 7.2 got-made olddir_abs_node_directory_path -> {:?}",
                                        &olddir_abs_node_directory_path
                                    );

                                    // for clearsigned .toml and .gpgtoml
                                    // Determine filename based on flag
                                    let node_filename = if save_as_gpgtoml {
                                        "node.gpgtoml"
                                    } else {
                                        "node.toml"
                                    };

                                    let oldfile_node_file_path = olddir_abs_node_directory_path.join(node_filename);

                                    // Choose what to save
                                    let data_to_save = if save_as_gpgtoml {
                                        still_encrypted_file_blob  // Save encrypted version
                                    } else {
                                        &decrypted_clearsignfile_data  // Save clearsigned version
                                    };

                                    // 3.2 replace (delete the old) node file
                                    if let Err(e) = fs::write(&oldfile_node_file_path, data_to_save) {
                                        debug_log!("Error writing node file: {:?} - {}", &oldfile_node_file_path, e);
                                        return Err(ThisProjectError::from(e));
                                    }


                                    // let oldfile_node_toml_file_path = olddir_abs_node_directory_path.join("node.toml"); // Path to the new node.toml

                                    // debug_log!(
                                    //     "HLOD 7.2 got-made oldfile_node_toml_file_path -> {:?}",
                                    //     &oldfile_node_toml_file_path
                                    // );

                                    // // 3.2 replace (delete the old) node.toml file (file, not directory)
                                    // // Write the received data to the OLD node.toml location, replacing it:
                                    // if let Err(e) = fs::write(&oldfile_node_toml_file_path, &extracted_clearsigned_file_data) {
                                    //     debug_log!("Error writing node.toml: {:?} - {}", &oldfile_node_toml_file_path, e);
                                    //     return Err(ThisProjectError::from(e));
                                    // }

                                    // 3.3 Move old node directory (not remove/delete) (directory, not file)
                                    // TODO HERE HERE
                                    // from olddir_abs_node_directory_path to new_full_abs_node_directory_path
                                    if let Err(error) = move_directory_from_path_to_path(&olddir_abs_node_directory_path, &new_full_abs_node_directory_path) {
                                        debug_log!("An error occurred: {}", error);
                                    }

                                    debug_log!("7.3 HLOD-InTray: moved file moved from: {:?}", &olddir_abs_node_directory_path);
                                    debug_log!("7.3 HLOD-InTray: moved-new file saved to: {:?}", &new_full_abs_node_directory_path);

                                } else if file_str.contains("messageposts_expire_after_n_min =") {



                                } else {
                                    // 3. saving node as clearsigned .toml or .gpgtoml

                                    // Determine filename based on flag
                                    let node_filename = if save_as_gpgtoml {
                                        "node.gpgtoml"
                                    } else {
                                        "node.toml"
                                    };

                                    let new_node_file_path = new_full_abs_node_directory_path.join(node_filename);

                                    // Choose what to save
                                    let data_to_save = if save_as_gpgtoml {
                                        still_encrypted_file_blob  // Save encrypted version
                                    } else {
                                        &decrypted_clearsignfile_data  // Save clearsigned version
                                    };

                                    // Create directory
                                    fs::create_dir_all(&new_full_abs_node_directory_path)?;

                                    // Save file
                                    if let Err(e) = fs::write(&new_node_file_path, data_to_save) {
                                        debug_log!("Error writing node file: {:?} - {}", &new_node_file_path, e);
                                        return Err(ThisProjectError::from(e));
                                    }

                                    debug_log!("7.3 HLOD-InTray: new file saved to: {:?}", new_node_file_path);


                                    // Node is new, save it:
                                    // 3. Unpacking/Saving the File as node.toml file

                                    // match unpack_new_node_save_toml_and_create_dir(
                                    //     &extracted_clearsigned_file_data,
                                    //     &new_full_abs_node_directory_path
                                    // ) {
                                    //     Ok(_) => debug_log("Node unpacked and saved successfully."),
                                    //     Err(e) => debug_log!("Error unpacking node: {}", e),
                                    // }

                                    // debug_log!("7.3 HLOD-InTray: new file saved to: {:?}", new_full_abs_node_directory_path);

                                    // unpack_new_node_save_toml_and_create_dir(
                                    //     &extracted_clearsigned_file_data,
                                    //     &new_full_abs_node_directory_path,
                                    // );

                                    // if let Err(e) = fs::write(
                                    //     &new_node_toml_file_path,
                                    //     &extracted_clearsigned_file_data
                                    // ) {
                                    //     debug_log!("HLOD-InTray: Failed to write message file: {:?}", e);
                                    //     // Consider returning an error here instead of continuing the loop
                                    //     return Err(ThisProjectError::from(e));
                                    // }
                                }
                            }
                            Err(e) => {
                                // Handle error
                                continue;
                            }
                        }
                    }

                      /////////////
                     // Echo Base
                    /////////////
                    /*
                    After a file is received and saved
                    a miniature ReadySignal is sent out
                    using the timestamp of the 'current file' as the latest file
                    and saving that in state
                    so that the drone-loop (above) sending ready signals will also know
                    there is a new latest-date
                    */

                    // Extract timestamp
                    let received_file_updatedat_timestamp = match extract_updated_at_timestamp(
                        &extracted_clearsigned_file_data
                    ) {
                        Ok(temp_extraction_timestamp) => temp_extraction_timestamp,
                        Err(e) => {
                            debug_log!("HLOD-InTray: Error extracting timestamp: {}. Skipping.", e);
                            continue;
                        }
                    };

                    // update state: latest received timestamp
                    let _ = write_save_latest_received_from_rc_file_timestamp_plaintext(
                        &team_channel_name, // for team_channel_name
                        &local_owner_desk_setup_data.remote_collaborator_name, // for collaborator_name
                        received_file_updatedat_timestamp, // for timestamp
                    );

                    // Now you have the received_file_updatedat_timestamp timestamp
                    debug_log!("7.3 HLOD-InTray: Received file was updated_at: {}", received_file_updatedat_timestamp);
                    // println!("Received file updated at: {}", received_file_updatedat_timestamp);

                    // 1.4 Send Echo Ready Signal (using a function)
                    /*
                    struct GotItSignal {
                        gst: Option<u64>, // send-time:
                            generate_terse_timestamp_freshness_proxy(); for replay-attack protection
                        di: Option<u64>, // the 'id' is updated_at file timestamp
                            (because context= filesync timeline ID)
                        gh: Option<Vec<u8>>, // N hashes of rt + re
                    */

                    debug_log("7.3 HLOD-InTray: send_gotit_signal ");
                    let _ = send_gotit_signal(
                        &local_owner_desk_setup_data.local_user_salt_list,
                        &band_local_user_ipv4_address, // local_user_ipv4_address: &Ipv4Addr,
                        &band_local_user_ipv6_address, // local_user_ipv6_address: &Ipv6Addr,
                        &band_local_network_type, // network_type: String, // for nt
                        localowner_gotit_port,
                        received_file_updatedat_timestamp, // as di
                    );


                    // 1.4 Send Echo Ready Signal (using a function)
                    // 2nd copy for other threads
                    let rc_network_type_string_2 = rc_network_type_string.clone();
                    let rc_ip_addr_string_2 = rc_ip_addr_string.clone();

                    // TODO: how long?
                    // This lets last item run
                    thread::sleep(Duration::from_secs(5));
                    thread::sleep(Duration::from_secs(3));

                    send_ready_signal(
                        &local_owner_desk_setup_data.local_user_salt_list, // local_user_salt_list: &[u128],
                        rc_network_type_string_2, // Remote collaborator's network type (ipv4, ipv6
                        rc_ip_addr_string_2,  // Remote collaborator's IP string
                        local_owner_desk_setup_data.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,
                        received_file_updatedat_timestamp, // last_received_timestamp: u64, // for rst
                        &band_local_network_type, // network_type: String, // for nt
                        band_local_network_index, //network_index: u8, // for ni
                    )?;

                }
                Err(e) if e.kind() == std::io::ErrorKind::WouldBlock => {
                    // No data available yet.  Don't treat this as an error.
                    debug_log!("HLOD-InTray: No data available yet...WouldBlock");
                    std::thread::sleep(std::time::Duration::from_millis(100));
                    continue; // Continue to the next loop iteration
                }
                Err(e) => {
                    // A real error occurred. Log and handle it.
                    debug_log!("HLOD-InTray: Error receiving data: {}", e);
                    return Err(ThisProjectError::NetworkError(format!(
                        "Error receiving data: {}",
                        e
                    )));  // Or choose another way to handle this
                }
                }
            } // end match ready_socket.recv_from(&mut buf) {
        } // end In-Tray-Loop
        ////////////////////////
        // InTrayListerLoop End
        ////////////////////////


        // TESTING ONLY wait, if only for testing, so thread debug prints do not ~overlap
        thread::sleep(Duration::from_millis(100)); // Avoid busy-waiting

        debug_log!(
            "HLOD Exiting handle_local_owner_desk() for {}",
            local_owner_desk_setup_data.local_user_name
        ); // Add collaborator name
        debug_log(">*< Halt signal received. Exiting The Uma. Closing... handle_local_owner_desk() |o|");
    }
}

/// Calculates Pearson hashes for a vector of byte slices.
///
/// This function iterates through the input `data_sets` and calculates the Pearson hash for each slice,
/// returning a vector of the calculated hashes.
///
/// # Arguments
///
/// * `data_sets`: A vector of byte slices to hash.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`: A `Result` containing a vector of the calculated Pearson hashes,
///   or a `ThisProjectError` if an error occurs during hash calculation.
fn calculate_pearson_hashes(data_sets: &[&[u8]]) -> Result<Vec<u8>, ThisProjectError> {
    let mut hashes = Vec::new();
    for data in data_sets {
        let hash = pearson_hash_base(data)?;
        hashes.push(hash);
    }
    Ok(hashes)
}

/// Vanilla Deserilize json signal
/// The idea of the salt-hash or salt-checksum
/// is that it is a faster and more anonymous way
/// to target the goals of packet-soundness checking
/// and spoof-protection
/// while keeping the computer and network load lite
///
///  "Data length" refers to verifying that the received byte slice
/// has enough bytes to successfully extract all the fields of the
/// ReadySignal struct. If the byte slice is too short,
///  attempting to access elements outside its bounds will lead to a "panic".
///
/// Do not attempt to use Serde crate with this function!!!
fn deserialize_ready_signal(bytes: &[u8], salt_list: &[u128]) -> Result<ReadySignal, ThisProjectError> {
    // 1. Calculate the expected minimum length, *including* the hash list.
    /*
    rt: u64, // ready signal timestamp: last file obtained timestamp
    rst: u64, // send-time: generate_terse_timestamp_freshness_proxy(); for replay-attack protection
    b: u8, // Network Index (e.g. which ipv6 in the list)
    rh: Vec<u8>, // N hashes of rt + re
    */
    // debug_log("DRS Starting deserialize_ready_signal");

    let timestamp_len = std::mem::size_of::<u64>();         // Length of a u64 (8 bytes)
    let band_index_len = std::mem::size_of::<u8>();           // Length of the band index (1 byte)
    let hash_list_len = salt_list.len() * std::mem::size_of::<u8>(); // Length of the hash list (4 bytes in current design: 4 salts * 1 byte/hash)
    let expected_len = timestamp_len * 2 + band_index_len + hash_list_len; // Total expected length

    // 2. Full Length Check
    if bytes.len() != expected_len {  // Note: Now a strict equality check
        return Err(ThisProjectError::InvalidData(format!("DRS error: Invalid byte array length for ReadySignal. Expected: {}, Received: {}", expected_len, bytes.len())));
    }

    // 3. Extract rt (receive timestamp)
    let rt = u64::from_be_bytes(bytes[0..timestamp_len].try_into().map_err(|_| ThisProjectError::InvalidData("Failed to convert rst bytes to u64".into()))?);


    // 4. Extract rst (send timestamp)
    let rst_start = timestamp_len;
    let rst_end = rst_start + timestamp_len;
    if bytes.len() < rst_end {
        return Err(ThisProjectError::InvalidData("DRS error: Data too short for rst".into()));
    }
    let rst_bytes = &bytes[rst_start..rst_end];
    let rst = u64::from_be_bytes(rst_bytes.try_into().map_err(|_| ThisProjectError::InvalidData("Failed to convert rst bytes to u64".into()))?);


    // 6. Extract b (network index) -- u8
    let b_start = rst_start + timestamp_len;
    if bytes.len() <= b_start {  // Check length *before* access
        return Err(ThisProjectError::InvalidData("DRS error: Data too short for b".into()));
    }
    let b = bytes[b_start];  // Directly access as u8

    // 7. Extract rh (hash list)  Length Check
    let rh_start = b_start + 1;  // one byte for b
    let rh_end = rh_start + hash_list_len;
    if bytes.len() < rh_end {
        return Err(ThisProjectError::InvalidData("DRS error: Data too short for rh".into()));
    }
    let rh = bytes[rh_start..rh_end].to_vec();

    Ok(ReadySignal { rt, rst, b, rh })
}

/// Deserializes a byte slice into a SendFile struct.
///
/// This function performs the reverse operation of serializing a SendFile struct.
/// It takes a byte slice as input and extracts the fields to construct a SendFile struct instance.
/// It includes error handling for invalid data lengths and returns a Result to indicate success or failure.
///
/// # Arguments
/// * `bytes`: The byte slice containing the serialized SendFile data.
///
/// # Returns
///
/// * `Result<SendFile, ThisProjectError>`:  A Result containing the deserialized SendFile on success, or a ThisProjectError on failure.
fn deserialize_intray_send_file_struct(
    bytes: &[u8],
) -> Result<SendFile, ThisProjectError> {
    // 1. Check Minimum Length
    let timestamp_len = std::mem::size_of::<u64>();
    let min_length = timestamp_len; // Minimum length for just the timestamp

    debug_log!(
        "DISFS Starting deserialize_intray_send_file_struct() bytes {:?}",
        bytes
    );

    if bytes.len() < min_length {
        debug_log!("DISFS bytes.len() < min_length -> returning: Err(ThisProjectError::InvalidData(\"Invalid byte array length for SendFile\".into()))");
        return Err(ThisProjectError::InvalidData("Invalid byte array length for SendFile".into()));
    }

    debug_log!("DISFS bytes.len() >= min_length");


    // 2. Extract intray_send_time (as before)
    // // TODO: NO UNWRAP!!!!
    let intray_send_time = u64::from_be_bytes(bytes[0..timestamp_len].try_into().unwrap());

    // 3. Extract intray_hash_list  (Corrected)
    let hash_list_start = timestamp_len;
    let hash_list_end = hash_list_start + 4; // 4 u8 hashes = 4 bytes

    let intray_hash_list = if bytes.len() >= hash_list_end {
        Some(bytes[hash_list_start..hash_list_end].to_vec()) // Extract and wrap in Some()
    } else {
        None // No hash list present (handle as you see fit)
    };

    // 4. Extract gpg_encrypted_intray_file (Corrected)
    let gpg_encrypted_file_start = hash_list_end;
    let gpg_encrypted_intray_file = if bytes.len() > gpg_encrypted_file_start {
        Some(bytes[gpg_encrypted_file_start..].to_vec()) // Extract and wrap in Some()
    } else {
        None // Or handle the empty case appropriately
    };

    // ... [Construction of SendFile as before, but use Some() wrappers]
    Ok(SendFile {
        intray_send_time: Some(intray_send_time),
        gpg_encrypted_intray_file, // No need for clone, the value is already owned
        intray_hash_list,  // Use the corrected Option<Vec<u8>>
        padnet_index_array: None,
    })
}

/// Serializes a `SendFile` struct into a byte vector.
///
/// # Arguments
/// * `send_file`: The `SendFile` instance to serialize.
///
/// # Returns
///
/// * `Result<Vec<u8>, ThisProjectError>`:  The serialized `SendFile` data as a `Vec<u8>` on success, or a
///   `ThisProjectError` if serialization fails.
fn serialize_send_file_struct(send_file: &SendFile) -> Result<Vec<u8>, ThisProjectError> {
    let mut serialized_data: Vec<u8> = Vec::new();

    // Add intray_send_time
    serialized_data.extend_from_slice(&send_file.intray_send_time.ok_or(ThisProjectError::InvalidData("Missing intray_send_time".into()))?.to_be_bytes());

    // Add intray_hash_list (handle Option)
    if let Some(hash_list) = &send_file.intray_hash_list {
        serialized_data.extend_from_slice(hash_list);
    } else {
        // Handle the None case. Perhaps return an error or use a default/empty hash list.
        return Err(ThisProjectError::InvalidData("intray_hash_list is None".into()));
    }

    // Add gpg_encrypted_file_contents (handle Option)
    if let Some(encrypted_file) = &send_file.gpg_encrypted_intray_file {
        serialized_data.extend_from_slice(encrypted_file);
    } else {
        return Err(ThisProjectError::InvalidData("gpg_encrypted_intray_file is None".into()));
    }

    Ok(serialized_data)
}

fn serialize_gotit_signal(signal: &GotItSignal) -> std::io::Result<Vec<u8>> {
    let mut bytes = Vec::new();

    bytes.extend_from_slice(&signal.gst.to_be_bytes()); // gst is now u64, no expect needed
    bytes.extend_from_slice(&signal.di.to_be_bytes());  // di is now u64, no expect needed
    bytes.extend_from_slice(&signal.gh);             // gh is now Vec<u8>, no Option

    Ok(bytes)
}

/// Serializes a `SendFile` struct with padnet index into a byte vector.
///
/// ## Project Context
/// This function creates a wire-format message for padnet-enabled file synchronization.
/// The padnet index array is placed at the start of the message to identify the destination
/// location in the one-time-pad filesystem hierarchy before any other data is processed.
/// This allows early routing decisions without deserializing the entire payload.
///
/// ## Wire Format (Total: 16+ bytes)
/// ```
/// [padnet_index: 4 bytes]      Destination in OTP filesystem (Standard variant only)
/// [timestamp: 8 bytes]          Replay attack protection
/// [hash_list: 4 bytes]          Salted Pearson hash verification
/// [encrypted_file: variable]    GPG-encrypted file contents
/// ```
///
/// ## Current Limitation
/// Only supports `PadIndex::Standard` (4-byte) variant. The `Extended` (8-byte) variant
/// will return an error. This design is modular to allow future 8-byte support by
/// changing the constant `PADNET_WIRE_FORMAT_SIZE` and updating the match arm.
///
/// ## Error Conditions
/// - Missing `padnet_index_array` (None)
/// - Extended variant provided (not yet supported)
/// - Missing `intray_send_time` (None)
/// - Missing `intray_hash_list` (None)
/// - Missing `gpg_encrypted_intray_file` (None)
///
/// # Arguments
/// * `send_file`: The `SendFile` instance to serialize with padnet index.
///
/// # Returns
/// * `Result<Vec<u8>, ThisProjectError>`: The serialized data as `Vec<u8>` on success,
///   or a `ThisProjectError` with "PSS error: " prefix if serialization fails.
///
/// # Example Error Messages
/// - "PSS error: padnet_index_array is None"
/// - "PSS error: Extended variant not supported in wire format"
/// - "PSS error: Missing intray_send_time"
fn padnet_serialize_sendfile_struct(send_file: &SendFile) -> Result<Vec<u8>, ThisProjectError> {
    // Future-proofing: Change this constant to 8 when Extended variant is supported
    const PADNET_WIRE_FORMAT_SIZE: usize = 4;

    let mut serialized_data: Vec<u8> = Vec::new();

    // ========================================
    // 1. Extract and Add Padnet Index (4 bytes at START)
    // ========================================
    // Project Context: The padnet index must be first in the wire format to allow
    // receiving systems to route the message to the correct OTP location before
    // decrypting or verifying the payload.

    let padnet_index_bytes: [u8; PADNET_WIRE_FORMAT_SIZE] = match &send_file.padnet_index_array {
        Some(PadIndex::Standard(bytes)) => {
            // Extract the 4-byte array from Standard variant
            *bytes
        }
        Some(PadIndex::Extended(_)) => {
            // Extended (8-byte) variant not yet supported in wire format
            // Future work: Add discriminator byte and handle 8-byte serialization
            return Err(ThisProjectError::InvalidData(
                "PSS error: Extended variant not supported in wire format".into()
            ));
        }
        None => {
            // Padnet index is required for padnet-enabled serialization
            return Err(ThisProjectError::InvalidData(
                "PSS error: padnet_index_array is None".into()
            ));
        }
    };

    // Add the 4-byte padnet index to the beginning of serialized data
    serialized_data.extend_from_slice(&padnet_index_bytes);

    // ========================================
    // 2. Add Timestamp (8 bytes)
    // ========================================
    // Project Context: Timestamp provides replay attack protection by ensuring
    // messages can be identified as stale if received outside acceptable time window.

    let timestamp = send_file.intray_send_time
        .ok_or(ThisProjectError::InvalidData("PSS error: Missing intray_send_time".into()))?;

    serialized_data.extend_from_slice(&timestamp.to_be_bytes());

    // ========================================
    // 3. Add Hash List (4 bytes)
    // ========================================
    // Project Context: Salted Pearson hash list allows quick verification that the
    // packet is intact and was sent by the owner at the specified timestamp.
    // This provides integrity checking without full decryption.

    let hash_list = send_file.intray_hash_list
        .as_ref()
        .ok_or(ThisProjectError::InvalidData("PSS error: intray_hash_list is None".into()))?;

    serialized_data.extend_from_slice(hash_list);

    // ========================================
    // 4. Add GPG Encrypted File Contents (variable length)
    // ========================================
    // Project Context: The actual file payload, encrypted with GPG. This is the
    // final component and can be any length, which is why all fixed-size metadata
    // comes before it in the wire format.

    let encrypted_file = send_file.gpg_encrypted_intray_file
        .as_ref()
        .ok_or(ThisProjectError::InvalidData("PSS error: gpg_encrypted_intray_file is None".into()))?;

    serialized_data.extend_from_slice(encrypted_file);

    // Return the complete serialized byte vector
    Ok(serialized_data)
}


/// Deserializes a byte slice into a SendFile struct with padnet index.
///
/// ## Project Context
/// This function reconstructs a `SendFile` from the padnet wire format. It performs
/// the reverse operation of `padnet_serialize_sendfile_struct()`, extracting the
/// destination padnet index, timestamp, verification hashes, and encrypted payload
/// from a received message.
///
/// ## Wire Format Expected (Total: 16+ bytes minimum)
/// ```
/// [padnet_index: 4 bytes]      Destination in OTP filesystem
/// [timestamp: 8 bytes]          Replay attack protection
/// [hash_list: 4 bytes]          Salted Pearson hash verification
/// [encrypted_file: variable]    GPG-encrypted file contents (may be empty)
/// ```
///
/// ## Current Limitation
/// Only constructs `PadIndex::Standard` (4-byte) variant. Future 8-byte support
/// requires updating `PADNET_WIRE_FORMAT_SIZE` and extraction logic.
///
/// ## Defensive Programming
/// - Validates minimum length before any extraction
/// - Uses `try_into()` with proper error handling (no unwrap)
/// - Returns specific error messages with "PDISFS error: " prefix
/// - Handles variable-length encrypted file (may be empty after fixed fields)
///
/// ## Error Conditions
/// - Byte slice too short (< 16 bytes)
/// - Invalid array conversion during extraction
///
/// # Arguments
/// * `bytes`: The byte slice containing the serialized SendFile data with padnet index.
///
/// # Returns
/// * `Result<SendFile, ThisProjectError>`: A Result containing the deserialized SendFile
///   on success, or a ThisProjectError with "PDISFS error: " prefix on failure.
///
/// # Example Error Messages
/// - "PDISFS error: Invalid byte array length, minimum 16 bytes required"
/// - "PDISFS error: Failed to extract padnet_index_array"
/// - "PDISFS error: Failed to extract intray_send_time"
fn padnet_deserialize_intray_sendfile_struct(
    bytes: &[u8],
) -> Result<SendFile, ThisProjectError> {
    // Future-proofing: Change this constant to 8 when Extended variant is supported
    const PADNET_WIRE_FORMAT_SIZE: usize = 4;
    const TIMESTAMP_SIZE: usize = std::mem::size_of::<u64>(); // 8 bytes
    const HASH_LIST_SIZE: usize = 4; // 4 bytes for hash list

    // Minimum length: padnet_index + timestamp + hash_list = 4 + 8 + 4 = 16 bytes
    const MIN_LENGTH: usize = PADNET_WIRE_FORMAT_SIZE + TIMESTAMP_SIZE + HASH_LIST_SIZE;

    debug_log!(
        "PDISFS Starting padnet_deserialize_intray_sendfile_struct() with {} bytes",
        bytes.len()
    );

    // ========================================
    // 1. Validate Minimum Length
    // ========================================
    // Project Context: We must have at least the fixed-size fields present.
    // The encrypted file may be empty (0 bytes) but all metadata must be present.

    if bytes.len() < MIN_LENGTH {
        debug_log!(
            "PDISFS bytes.len() {} < MIN_LENGTH {} -> returning error",
            bytes.len(),
            MIN_LENGTH
        );
        return Err(ThisProjectError::InvalidData(
            "PDISFS error: Invalid byte array length, minimum 16 bytes required".into()
        ));
    }

    debug_log!("PDISFS bytes.len() >= MIN_LENGTH, proceeding with extraction");

    // ========================================
    // 2. Extract Padnet Index (4 bytes from START)
    // ========================================
    // Project Context: The padnet index indicates where in the OTP filesystem
    // hierarchy this file should be stored/retrieved. It maps directly to
    // directory structure: padnest_0/pad/page/line

    let padnet_index_end = PADNET_WIRE_FORMAT_SIZE;

    let padnet_index_array_bytes: [u8; PADNET_WIRE_FORMAT_SIZE] =
        bytes[0..padnet_index_end]
            .try_into()
            .map_err(|_| ThisProjectError::InvalidData(
                "PDISFS error: Failed to extract padnet_index_array".into()
            ))?;

    let padnet_index_array = Some(PadIndex::Standard(padnet_index_array_bytes));

    debug_log!(
        "PDISFS Extracted padnet_index_array: {:?}",
        padnet_index_array_bytes
    );

    // ========================================
    // 3. Extract Timestamp (8 bytes)
    // ========================================
    // Project Context: Timestamp for replay attack protection. Receiving system
    // can reject messages that are too old or from the future.

    let timestamp_start = padnet_index_end;
    let timestamp_end = timestamp_start + TIMESTAMP_SIZE;

    let timestamp_bytes: [u8; TIMESTAMP_SIZE] =
        bytes[timestamp_start..timestamp_end]
            .try_into()
            .map_err(|_| ThisProjectError::InvalidData(
                "PDISFS error: Failed to extract intray_send_time".into()
            ))?;

    let intray_send_time = Some(u64::from_be_bytes(timestamp_bytes));

    debug_log!("PDISFS Extracted intray_send_time: {:?}", intray_send_time);

    // ========================================
    // 4. Extract Hash List (4 bytes)
    // ========================================
    // Project Context: Salted Pearson hash list for integrity verification.
    // This allows quick validation that the message hasn't been corrupted
    // or tampered with, without requiring full GPG decryption.

    let hash_list_start = timestamp_end;
    let hash_list_end = hash_list_start + HASH_LIST_SIZE;

    let intray_hash_list = Some(bytes[hash_list_start..hash_list_end].to_vec());

    debug_log!("PDISFS Extracted intray_hash_list (4 bytes)");

    // ========================================
    // 5. Extract GPG Encrypted File Contents (remaining bytes)
    // ========================================
    // Project Context: The actual encrypted payload. This may be empty (0 bytes)
    // in some cases (e.g., deletion markers, control messages), so we handle
    // that case by creating an empty Vec rather than None.

    let gpg_encrypted_file_start = hash_list_end;

    let gpg_encrypted_intray_file = if bytes.len() > gpg_encrypted_file_start {
        Some(bytes[gpg_encrypted_file_start..].to_vec())
    } else {
        // No encrypted file content present (empty payload)
        Some(Vec::new())
    };

    debug_log!(
        "PDISFS Extracted gpg_encrypted_intray_file ({} bytes)",
        bytes.len().saturating_sub(gpg_encrypted_file_start)
    );

    // ========================================
    // 6. Construct and Return SendFile
    // ========================================
    debug_log!("PDISFS Successfully deserialized SendFile with padnet index");

    Ok(SendFile {
        intray_send_time,
        gpg_encrypted_intray_file,
        intray_hash_list,
        padnet_index_array,
    })
}


// ========================================
// TESTS for Padnet Serialization/Deserialization
// ========================================

#[cfg(test)]
mod padnet_sds_tests {
    use super::*;

    /// Test: Successful round-trip serialization/deserialization with Standard variant
    ///
    /// Project Context: This verifies that a SendFile with all fields populated
    /// can be serialized and then deserialized back to an equivalent struct.
    #[test]
    fn test_padnet_roundtrip_standard_variant() {
        // Create a test SendFile with Standard padnet index
        let original = SendFile {
            intray_send_time: Some(1234567890u64),
            gpg_encrypted_intray_file: Some(vec![0xDE, 0xAD, 0xBE, 0xEF]),
            intray_hash_list: Some(vec![0x01, 0x02, 0x03, 0x04]),
            padnet_index_array: Some(PadIndex::Standard([0xAA, 0xBB, 0xCC, 0xDD])),
        };

        // Serialize
        let serialized = padnet_serialize_sendfile_struct(&original)
            .expect("Serialization should succeed");

        // Verify length: 4 (padnet) + 8 (timestamp) + 4 (hash) + 4 (file) = 20 bytes
        assert_eq!(serialized.len(), 20);

        // Verify padnet index is at the start
        assert_eq!(&serialized[0..4], &[0xAA, 0xBB, 0xCC, 0xDD]);

        // Deserialize
        let deserialized = padnet_deserialize_intray_sendfile_struct(&serialized)
            .expect("Deserialization should succeed");

        // Verify all fields match
        assert_eq!(deserialized.intray_send_time, original.intray_send_time);
        assert_eq!(deserialized.gpg_encrypted_intray_file, original.gpg_encrypted_intray_file);
        assert_eq!(deserialized.intray_hash_list, original.intray_hash_list);
        assert_eq!(deserialized.padnet_index_array, original.padnet_index_array);
    }

    /// Test: Serialization fails with None padnet_index_array
    ///
    /// Project Context: Padnet serialization requires a valid destination index.
    /// This test ensures we properly reject messages without routing information.
    #[test]
    fn test_padnet_serialize_missing_padnet_index() {
        let send_file = SendFile {
            intray_send_time: Some(1234567890u64),
            gpg_encrypted_intray_file: Some(vec![0xDE, 0xAD, 0xBE, 0xEF]),
            intray_hash_list: Some(vec![0x01, 0x02, 0x03, 0x04]),
            padnet_index_array: None, // Missing!
        };

        let result = padnet_serialize_sendfile_struct(&send_file);

        assert!(result.is_err());
        if let Err(ThisProjectError::InvalidData(msg)) = result {
            assert!(msg.contains("PSS error: padnet_index_array is None"));
        } else {
            panic!("Expected InvalidData error");
        }
    }

    /// Test: Serialization fails with Extended variant (not yet supported)
    ///
    /// Project Context: Current wire format only supports 4-byte Standard variant.
    /// Extended (8-byte) support is planned but not implemented.
    #[test]
    fn test_padnet_serialize_extended_variant_not_supported() {
        let send_file = SendFile {
            intray_send_time: Some(1234567890u64),
            gpg_encrypted_intray_file: Some(vec![0xDE, 0xAD, 0xBE, 0xEF]),
            intray_hash_list: Some(vec![0x01, 0x02, 0x03, 0x04]),
            padnet_index_array: Some(PadIndex::Extended([0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF, 0x00, 0x11])),
        };

        let result = padnet_serialize_sendfile_struct(&send_file);

        assert!(result.is_err());
        if let Err(ThisProjectError::InvalidData(msg)) = result {
            assert!(msg.contains("PSS error: Extended variant not supported"));
        } else {
            panic!("Expected InvalidData error");
        }
    }

    /// Test: Deserialization fails with insufficient bytes
    ///
    /// Project Context: Wire format requires minimum 16 bytes of metadata.
    /// This test ensures we reject malformed or truncated messages.
    #[test]
    fn test_padnet_deserialize_insufficient_bytes() {
        let short_bytes = vec![0x01, 0x02, 0x03]; // Only 3 bytes, need 16

        let result = padnet_deserialize_intray_sendfile_struct(&short_bytes);

        assert!(result.is_err());
        if let Err(ThisProjectError::InvalidData(msg)) = result {
            assert!(msg.contains("PDISFS error: Invalid byte array length"));
        } else {
            panic!("Expected InvalidData error");
        }
    }

    /// Test: Deserialization with exactly minimum length (no encrypted file)
    ///
    /// Project Context: Some messages (e.g., control messages, deletion markers)
    /// may not have an encrypted file payload, only metadata.
    #[test]
    fn test_padnet_deserialize_minimum_length_no_payload() {
        let mut bytes = Vec::new();

        // Padnet index: 4 bytes
        bytes.extend_from_slice(&[0x11, 0x22, 0x33, 0x44]);

        // Timestamp: 8 bytes
        bytes.extend_from_slice(&9876543210u64.to_be_bytes());

        // Hash list: 4 bytes
        bytes.extend_from_slice(&[0xAA, 0xBB, 0xCC, 0xDD]);

        // No encrypted file (total: exactly 16 bytes)

        let deserialized = padnet_deserialize_intray_sendfile_struct(&bytes)
            .expect("Should deserialize minimum length message");

        assert_eq!(deserialized.padnet_index_array, Some(PadIndex::Standard([0x11, 0x22, 0x33, 0x44])));
        assert_eq!(deserialized.intray_send_time, Some(9876543210u64));
        assert_eq!(deserialized.intray_hash_list, Some(vec![0xAA, 0xBB, 0xCC, 0xDD]));
        assert_eq!(deserialized.gpg_encrypted_intray_file, Some(Vec::new())); // Empty but Some
    }

    /// Test: Verify wire format byte positions
    ///
    /// Project Context: This test documents and verifies the exact byte layout
    /// of the wire format, which is critical for interoperability and debugging.
    #[test]
    fn test_padnet_wire_format_byte_positions() {
        let send_file = SendFile {
            intray_send_time: Some(0x0102030405060708u64),
            gpg_encrypted_intray_file: Some(vec![0xFF, 0xEE]),
            intray_hash_list: Some(vec![0x10, 0x20, 0x30, 0x40]),
            padnet_index_array: Some(PadIndex::Standard([0xA0, 0xB0, 0xC0, 0xD0])),
        };

        let serialized = padnet_serialize_sendfile_struct(&send_file)
            .expect("Serialization should succeed");

        // Verify padnet index at bytes 0-3
        assert_eq!(&serialized[0..4], &[0xA0, 0xB0, 0xC0, 0xD0]);

        // Verify timestamp at bytes 4-11
        assert_eq!(&serialized[4..12], &[0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08]);

        // Verify hash list at bytes 12-15
        assert_eq!(&serialized[12..16], &[0x10, 0x20, 0x30, 0x40]);

        // Verify encrypted file at bytes 16+
        assert_eq!(&serialized[16..], &[0xFF, 0xEE]);
    }
}

fn get_absolute_team_channel_path(team_channel_name: &str) -> io::Result<PathBuf> {

    // let team_channels_dir = Path::new("project_graph_data/team_channels");

    let team_channels_dir = match get_team_channels_homebase_directory_path() {
        Ok(path) => path,
        Err(e) => {
            debug_log!("in get_team_channels_homebase_directory_path()-> Failed to get absolute path: {}", e);
            return Err(e);
        }
    };

    let channel_path = team_channels_dir.join(team_channel_name);

    channel_path.canonicalize() // Get the absolute path
}

#[cfg(test)]
mod get_sendq_tests {
    use super::*;

    #[test]
    fn test_get_file_extension_safe_with_toml() {
        let path = Path::new("/path/to/file.toml");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some("toml"));
    }

    #[test]
    fn test_get_file_extension_safe_with_gpgtoml() {
        let path = Path::new("/path/to/file.gpgtoml");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some("gpgtoml"));
    }

    #[test]
    fn test_get_file_extension_safe_no_extension() {
        let path = Path::new("/path/to/file");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, None);
    }

    #[test]
    fn test_get_file_extension_safe_empty_extension() {
        let path = Path::new("/path/to/file.");
        let ext = get_file_extension_safe(path);
        assert_eq!(ext, Some(""));
    }

    // Note: Additional integration tests would require:
    // - Mock TOML files
    // - Mock GPG decryption infrastructure
    // - Mock directory structure
    // These should be added based on your testing infrastructure
}

/// Checks if a file qualifies for the send queue using incremental field reads.
///
/// # Project Context
/// In the UMA send-queue system, files are sent to collaborators based on
/// a three-tier qualification system:
///
/// 1. **Ownership**: File must be owned by the local user (security boundary)
/// 2. **Access Control**: Remote collaborator must be in the access list (permissions)
/// 3. **Freshness**: File must be newer than last successful send (efficiency)
///
/// This function implements these checks in order, stopping as soon as any
/// check fails (defensive programming + efficiency). We never read more data
/// from a file than necessary to make the qualification decision.
///
/// # Read Order (stops on first failure)
/// 1. Read "owner" field only  if no match, stop (don't read more)
/// 2. Read "teamchannel_collaborators_with_access"  if not in list, stop
/// 3. Read "updated_at_timestamp"  if too old, stop
/// 4. If all pass  return Ok(true)
///
/// # Arguments
/// - `readable_toml_path` - Path to readable .toml file (plain or decrypted)
/// - `localowneruser_name` - Expected owner name
/// - `remote_collaborator_name` - Collaborator to check access for
/// - `timestamp_threshold` - Minimum timestamp for inclusion
///
/// # Returns
/// - `Ok(true)` - File qualifies, should be added to queue
/// - `Ok(false)` - File doesn't qualify (not an error, just doesn't match criteria)
/// - `Err(String)` - File is malformed/unreadable (caller should skip file)
///
/// # Error Handling
/// A return of `Ok(false)` is not an error - it simply means the file doesn't
/// meet the criteria (e.g., owned by different user, collaborator not on list).
/// Only `Err` indicates the file itself has a problem (missing fields, parse errors).
///
/// # Performance
/// Incremental reading means:
/// - If owner doesn't match, we never read the collaborators array
/// - If collaborator not in list, we never read the timestamp
/// - Minimum I/O for disqualified files
fn check_file_qualifications(
    readable_toml_path: &PathBuf,
    localowneruser_name: &str,
    remote_collaborator_name: &str,
    timestamp_threshold: u64,
) -> Result<bool, String> {
    // Convert PathBuf to &str for TOML reading functions
    let toml_path_str = readable_toml_path
        .to_str()
        .ok_or_else(|| "CFQUAL: Path conversion to string failed".to_string())?;

    // =================================================
    // Check 1: Owner must match local user
    // =================================================

    let owner = read_single_line_string_field_from_toml(toml_path_str, "owner")
        .map_err(|e| format!("CFQUAL: Failed to read owner field: {}", e))?;

    if owner != localowneruser_name {
        // Not owned by local user - doesn't qualify (not an error)
        return Ok(false);
    }

    // =================================================
    // Check 2: Remote collaborator must have access
    // =================================================

    let collaborators = read_string_array_field_from_toml(
        toml_path_str,
        "teamchannel_collaborators_with_access",
    )
    .map_err(|e| format!("CFQUAL: Failed to read collaborators field: {}", e))?;

    if !collaborators.contains(&remote_collaborator_name.to_string()) {
        // Collaborator not in access list - doesn't qualify (not an error)
        return Ok(false);
    }

    // =================================================
    // Check 3: File must be newer than threshold
    // =================================================

    let timestamp = read_u64_field_from_toml(toml_path_str, "updated_at_timestamp")
        .map_err(|e| format!("CFQUAL: Failed to read timestamp field: {}", e))?;

    if timestamp <= timestamp_threshold {
        // File is not newer than threshold - doesn't qualify (not an error)
        return Ok(false);
    }

    // =================================================
    // All checks passed - file qualifies
    // =================================================

    Ok(true)
}


/// Gets existing send-Queue or makes a new one: to send out locally owned files: a queue of paths to those files
/// if back_of_queue_timestamp != 0 and
/// if request-time-stamp = send-q back_of_queue_timestamp -> just return timestamp
/// else: make a new timestamp
///
/// can Creates a new send queue based on the provided timestamp and collaborator name.
///
/// This function crawls through the team channel directory tree, looking for TOML files owned by the specified local_owner_user(collaborator).
/// So that the local-owner-user can send their owned files to other collaborators.
/// This function adds file paths to the send queue if the file's `updated_at_timestamp` is greater than the provided `back_of_queue_timestamp`.
///
/// # Arguments
///
/// * `team_channel_name`: The name of the team channel.
/// * `localowneruser_name`: The name of the local-owner-usercollaborator.
/// * `back_of_queue_timestamp`: The timestamp to use as the starting point for the queue. If 0, all files are added to the queue.
///
/// # Returns
///
/// * `Result<SendQueue, ThisProjectError>`: A `Result` containing the new `SendQueue` on success, or a `ThisProjectError` on failure.
/// Send Queue Building: Directory Crawl with Incremental Qualification Checks
///
/// # Project Context
///
/// This code section implements the "heavy lifting" operation of the UMA secure
/// collaboration system's send-queue builder. It scans a team channel directory
/// to identify which files need to be transmitted to a specific remote collaborator.
///
/// ## Problem Being Solved
///
/// In a multi-user secure collaboration environment:
/// - Multiple users own different files in shared team channels
/// - Each file has an access control list of collaborators
/// - Files are updated at different times
/// - Some files are encrypted (.gpgtoml), others are plain text (.toml)
/// - Network transmission must only send files that:
///   1. Are owned by the local user (security boundary)
///   2. Grant access to the specific remote collaborator (permissions)
///   3. Have been modified since the last successful transmission (efficiency)
///
/// ## Three-Tier Qualification System
///
/// Files are checked in this specific order (with early exit optimization):
///
/// ### Tier 1: Ownership Check
/// - Field: "owner"
/// - Type: Single-line string
/// - Logic: Must exactly match `localowneruser_name`
/// - Rationale: Security boundary - users can only send their own files
/// - Early exit: If owner doesn't match, skip remaining checks
///
/// ### Tier 2: Access Control Check
/// - Field: "teamchannel_collaborators_with_access"
/// - Type: String array
/// - Logic: Must contain `remote_collaborator_name`
/// - Rationale: Permissions - collaborator must be explicitly granted access
/// - Early exit: If collaborator not in list, skip timestamp check
///
/// ### Tier 3: Freshness Check
/// - Field: "updated_at_timestamp"
/// - Type: u64 (milliseconds since epoch)
/// - Logic: Must be > `session_send_queue.back_of_queue_timestamp`
/// - Rationale: Efficiency - only send files modified since last successful transmission
/// - Note: `back_of_queue_timestamp` represents the `updated_at` timestamp of the
///   last file successfully received by the remote collaborator (from the ready-signal),
///   NOT the time the ready-signal was sent
///
/// ## File Format Handling
///
/// Files in team channels may exist in two formats:
///
/// ### .toml (Plain Text)
/// - Readable directly
/// - No preprocessing required
/// - Path used as-is for field reading
///
/// ### .gpgtoml (Encrypted)
/// - Cannot be read directly
/// - Must be decrypted to temporary directory first
/// - Uses `get_pathstring_to_temp_plaintoml_verified_extracted()`
/// - Returns path to temporary decrypted copy
/// - Temporary file cleanup handled by GPG infrastructure (not validated here)
/// - Original .gpgtoml path stored in queue (not temp path)
///
/// ## Incremental Reading Strategy
///
/// Fields are read one at a time in qualification order. If any field causes
/// disqualification, no further fields are read from that file.
///
/// ### Example: Owner Mismatch
/// ```text
/// File: example.toml
/// 1. Read "owner"  value is "alice", expected "bob"
/// 2. Disqualified, stop reading
/// 3. Never read "teamchannel_collaborators_with_access"
/// 4. Never read "updated_at_timestamp"
/// 5. Skip to next file
/// ```
///
/// ### Performance Benefit
/// For a directory with 1000 files where:
/// - 800 are owned by other users
/// - 150 don't grant access to this collaborator
/// - 50 qualify for transmission
///
/// Total field reads: ~1150 fields (800 owner + 150 owner + 150 access + 50 full)
/// vs. naive approach: 3000 fields (1000 files  3 fields each)
///
/// ## Error Handling Philosophy
///
/// ### Per-File Failures (Skip and Continue)
/// The loop NEVER stops processing due to individual file issues:
/// - File cannot be opened (permissions, corruption, concurrent deletion)
/// - GPG decryption fails (wrong key, corrupted encryption, missing key)
/// - TOML field missing (file schema mismatch, incomplete write)
/// - TOML field malformed (encoding error, truncated data)
/// - Path conversion fails (invalid UTF-8, filesystem issues)
///
/// Rationale: Partial queue building (e.g., 99 of 100 files) is preferable to
/// complete failure (0 files) due to one corrupted file. The system can function
/// with reduced data and retry failed files later.
///
/// ### Operation Metrics
/// Three counters track processing:
/// - `files_encountered`: Total entries processed (including directories)
/// - `files_skipped`: Files that failed to process (errors only, not disqualified)
/// - `files_added_to_queue`: Files that passed all three qualification tiers
///
/// Note: Files that don't qualify (wrong owner, no access, timestamp too old)
/// are not counted as "skipped" - they are successfully processed but don't
/// meet criteria.
///
/// ## Security Considerations
///
/// ### Debug vs Production Logging
/// - Debug builds: Log full file paths and error details for diagnostics
/// - Production builds: Log only counters, no file paths or sensitive data
/// - Conditional compilation: `#[cfg(debug_assertions)]` enforces separation
///
/// ### Path Storage
/// Original file paths are stored in the send queue, preserving encryption state:
/// - .gpgtoml files remain as .gpgtoml paths in queue
/// - Decrypted temporary paths are NOT stored
/// - Sender can re-encrypt or process as needed for transmission
///
/// ### Information Disclosure Prevention
/// Production error messages use function prefixes (e.g., "CFQUAL: ...") but
/// do not include:
/// - File contents
/// - Full file paths
/// - User data
/// - System configuration details
///
/// ## Dependencies and Assumptions
///
/// ### Required Functions (from codebase)
/// - `read_single_line_string_field_from_toml(path, field)`  Result<String, String>
/// - `read_string_array_field_from_toml(path, field)`  Result<Vec<String>, String>
/// - `read_u64_field_from_toml(path, field)`  Result<u64, String>
/// - `get_pathstring_to_temp_plaintoml_verified_extracted(path, key, tempdir)`  Result<String, E>
///
/// ### Required Variables (from surrounding context)
/// - `team_channel_path: &PathBuf` - Absolute path to team channel directory
/// - `localowneruser_name: &str` - Name of local user (file owner filter)
/// - `remote_collaborator_name: &str` - Name of remote collaborator (access filter)
/// - `session_send_queue.back_of_queue_timestamp: u64` - Timestamp threshold (freshness filter)
/// - `gpg_full_fingerprint_key_id_string: &str` - GPG key for .gpgtoml decryption
/// - `base_uma_temp_directory_path: &PathBuf` - Base directory for temporary decrypted files
///
/// ### Struct Mutation
/// - `session_send_queue.items: Vec<PathBuf>` - Modified in place, qualified paths appended
///
/// ## Known Limitations and Edge Cases
///
/// ### Empty Directory
/// - Behavior: Loop completes normally, no files added
/// - Result: `files_encountered = 0`, `files_added_to_queue = 0`
///
/// ### All Files Disqualified
/// - Behavior: Loop completes normally, no files added
/// - Result: `files_encountered = N`, `files_added_to_queue = 0`
///
/// ### All Files Fail to Read
/// - Behavior: Loop completes normally, no files added
/// - Result: `files_encountered = N`, `files_skipped = N`, `files_added_to_queue = 0`
///
/// ### Mixed .toml and .gpgtoml
/// - Behavior: Both types processed uniformly after decryption step
/// - Performance: .gpgtoml files incur decryption overhead
///
/// ### Concurrent File Modifications
/// - Behavior: Race conditions possible if files modified during crawl
/// - Mitigation: Individual file errors are skipped, not fatal
/// - Note: Queue represents snapshot at time of crawl
///
/// ### Timestamp Equality
/// - Logic: Uses `>` not `>=`
/// - Rationale: File with timestamp equal to threshold was already sent
/// - Edge case: If file modified in same millisecond as last send, will be skipped
///
/// ## Performance Characteristics
///
/// ### Time Complexity
/// - Directory walk: O(N) where N = total files in directory tree
/// - Per-file processing: O(1) to O(3) field reads depending on early exit
/// - Overall: O(N) with early exit optimization
///
/// ### I/O Operations
/// - Directory traversal: 1 system call per entry
/// - Plain .toml: 1-3 partial file reads per qualifying file
/// - Encrypted .gpgtoml: 1 GPG decryption + 1-3 partial file reads
///
/// ### Memory Usage
/// - Queue growth: O(M) where M = qualifying files
/// - Temporary storage: Minimal, per-file processing only
/// - No whole-file loading, incremental field reading
///
/// ## Maintenance Notes
///
/// ### Adding New Qualification Criteria
/// To add a fourth qualification tier:
/// 1. Add field read after timestamp check in `check_file_qualifications()`
/// 2. Update "Three-Tier" documentation to "Four-Tier"
/// 3. Add performance impact notes
/// 4. Update example calculations
///
/// ### Modifying Qualification Order
/// Current order (owner  access  timestamp) is optimized for:
/// - Owner check: Fastest, most likely to filter files
/// - Access check: Medium complexity, filters remaining files
/// - Timestamp check: Least likely to filter (most files will be newer)
///
/// If file distribution changes (e.g., most files fail timestamp check),
/// consider reordering for performance.
///
/// ### Debugging Queue Building Issues
/// 1. Enable debug build to see file-level diagnostics
/// 2. Check counter values: ratio of skipped/added indicates issue type
/// 3. High skipped count: File format or encryption issues
/// 4. Low added count with low skipped: Qualification criteria too strict
/// 5. Zero encountered: Directory path incorrect or inaccessible
///
/// ### Testing Considerations
/// This code section cannot be easily unit tested in isolation because:
/// - Requires real filesystem structure
/// - Requires GPG infrastructure
/// - Requires mutable SessionSendQueue struct
/// - Embedded in larger function with surrounding context
///
/// For testing, consider:
/// - Integration tests with mock directory structure
/// - Separate helper functions have unit tests
/// - End-to-end tests of parent function
///
/// ## Design Rationale Summary
///
/// ### Why Not Use TOML Crate?
/// - Avoid third-party dependencies (security policy)
/// - Incremental reading not well-supported by TOML crates
/// - Custom field readers provide early-exit optimization
///
/// ### Why Store Original Paths?
/// - Preserve encryption state (.gpgtoml vs .toml)
/// - Temporary paths may be cleaned up before transmission
/// - Sender needs original path for re-processing/re-encryption
///
/// ### Why Skip Instead of Fail?
/// - Robustness: One bad file shouldn't break entire sync
/// - Partial data delivery better than no data
/// - Errors logged for later diagnosis/retry
///
/// ### Why Check Owner First?
/// - Security boundary: Most fundamental check
/// - Likely to filter majority of files (in multi-user environment)
/// - Cheapest check: Single string comparison
///
/// ### Why Count All Three Metrics?
/// - `files_encountered`: Verify directory walk working
/// - `files_skipped`: Identify error rates for monitoring
/// - `files_added_to_queue`: Verify qualification logic working
fn get_or_create_send_queue(
    team_channel_name: &str,
    localowneruser_name: &str,
    remote_collaborator_name: &str,
    mut session_send_queue: SendQueue,
    ready_signal_rt_timestamp: u64,
    bootstrap_sendqueue: bool,
) -> Result<SendQueue, ThisProjectError> {
    /*

    TODO is this checking for fail-flag dates...or is the done before calling this?

    #[derive(Debug, Clone)]
    struct SendQueue {
        back_of_queue_timestamp: u64,
        // echo_send: bool, //
        items: Vec<PathBuf>,  // ordered list, filepaths
    }
    */
    // let mut back_of_queue_timestamp = session_send_queue.back_of_queue_timestamp.clone();
    debug_log!(
        "inHRCD->get_or_create_send_queue 1: start;  ready_signal_rt_timestamp -> {:?}",
        ready_signal_rt_timestamp
    );

    /*
    Conditions for making a new send_queue

    1. First Time Bootstrap

    2. Backtrack Order: If the ready_signal_rt_timestamp is older
       than session_send_queue.back_of_queue_timestamp
       indicating that the user is requesting a back-track.

    3. Prefail Flag Check: If there is a fail flag,
       remake the queue with that timestamp

    'normally' only one queue is ever made,
    and that queue most-times remains empty with nothing sent
    unless and until a new local-owned-filed is made and added to the queue
    which should be checked for ~last.
    */
    let mut make_a_new_queue_flag = false;
    if bootstrap_sendqueue {
        make_a_new_queue_flag = true;
    }
    debug_log!(
        "inHRCD->get_or_create_send_queue: bootstrap_sendqueue={:?}, make_a_new_queue_flag={:?}",
        bootstrap_sendqueue,
        make_a_new_queue_flag
    );
    /*
    It is not clear that this comparison needs to be done:
    ready_signal_rt_timestamp == session_send_queue.back_of_queue_timestamp

    because preset-fail-flags are set, moving ahead cannot be done
    unless a confirmed gotit recept (of a confirmed file recept) happens.
    changing the back_of_queue_timestamp date may have no advanstage
    (or maybe some use will be discovered, likely it is not harmful)
    */

    debug_log("inHRCD->get_or_create_send_queue  checking: ready_signal_rt_timestamp < back_of_queue_timestamp");
    // Backtrack Order
    // if remote collaborator requests a reset to an older time (ah, those were the days...)
    // set the back_of_queue_timestamp to be sent .rt time ... if the .rt is older
    if ready_signal_rt_timestamp < session_send_queue.back_of_queue_timestamp {
        session_send_queue.back_of_queue_timestamp = ready_signal_rt_timestamp;
        make_a_new_queue_flag = true;
        debug_log("inHRCD->get_or_create_send_queue: found: ready_signal_rt_timestamp < back_of_queue_timestamp, make_a_new_queue_flag = true");
    }

    ///////////////////////////////////
    // Prefail Flag Check on Isle Five
    ///////////////////////////////////
    match get_oldest_sendfile_prefailflag_rt_timestamp_or_0_w_cleanup(&remote_collaborator_name) {
        Ok(oldest_prefail_flag_rt_timestamp) => {
            // 2. Now you can compare: (zero means no timestamps exist)
            if oldest_prefail_flag_rt_timestamp != 0 {
                // 3. Reset the send queue:
                session_send_queue = SendQueue {
                    back_of_queue_timestamp: oldest_prefail_flag_rt_timestamp,
                    items: Vec::new(),
                };
                debug_log!("inHRCD->get_or_create_send_queue  Resetting send queue using timestamp from flag: {}", oldest_prefail_flag_rt_timestamp);
                debug_log("inHRCD->get_or_create_send_queue: found: prefailflag(s), make_a_new_queue_flag = true");
                make_a_new_queue_flag = true
            } else {
                debug_log("inHRCD->get_or_create_send_queue  No retry flags found. Using ReadySignal timestamp.");
                // Handle the case where no pre-fail flags were found. Perhaps use the timestamp from the ready signal?
                session_send_queue.back_of_queue_timestamp = ready_signal_rt_timestamp
            }
        }
        Err(e) => {
            // 4. Handle the error:
            debug_log!("inHRCD->get_or_create_send_queue  Error getting oldest retry timestamp: {}", e);
            // Decide how to handle the error. You might:
            // - continue; // Skip to the next iteration
            // - return Err(e); // Or wrap the error: return Err(ThisProjectError::from(e));
            // - use a default timestamp: back_of_queue_timestamp = 0;

            debug_log("inHRCD->get_or_create_send_queue: error, so: make_a_new_queue_flag = true");
            make_a_new_queue_flag = true
        }
    }

    // 1. Get the path RESULT
    let team_channel_path_result = get_absolute_team_channel_path(team_channel_name);


    // 2. HANDLE the Result from get_absolute_team_channel_path()
    let team_channel_path = match team_channel_path_result {
        Ok(path) => path,
        Err(e) => {
            debug_log!("inHRCD->get_or_create_send_queue 4: Error getting absolute team channel path: {}", e);
            return Err(e.into());  // Or handle the error differently
        }
    };


    // Get armored public key, using key-id (full fingerprint in)
    let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
        Ok(fingerprint) => fingerprint,
        Err(e) => {
            // Since the function returns Result<CoreNode, String>, we need to return a String error
            return Err(format!(
                "implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                e
            ).into());
        }
    };

    // code from load_core_node...()
    // Get the UME temp directory path with proper GpgError conversion
    let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
        .map_err(|io_err| GpgError::ValidationError(
            format!("Failed to get UME temp directory path: {}", io_err)
        ))?;



    // --- 3. Make a new Queue ---
    debug_log!("inHRCD->get_or_create_send_queue 5: no crawl if false, make_a_new_queue_flag -> {:?}", make_a_new_queue_flag);

    if make_a_new_queue_flag {
        debug_log!("inHRCD->get_or_create_send_queue 5: Starting crawl of directory: {:?}", team_channel_path);

        // Operational metrics
        let mut files_encountered: usize = 0;
        let mut files_skipped: usize = 0;
        let mut files_added_to_queue: usize = 0;

        // Walk directory and process each file
        for entry in WalkDir::new(&team_channel_path) {
            files_encountered += 1;

            // Get directory entry, skip on any error
            let entry = match entry {
                Ok(e) => e,
                Err(e) => {
                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue: WalkDir entry error (skipping): {}",
                        e
                    );
                    files_skipped += 1;
                    continue;
                }
            };

            // Only process regular files
            if !entry.file_type().is_file() {
                continue;
            }

            // Get file extension safely
            let extension = match get_file_extension_safe(entry.path()) {
                Some(ext) if ext == "toml" || ext == "gpgtoml" => ext,
                _ => {
                    // Not a TOML file, skip silently
                    continue;
                }
            };

            #[cfg(debug_assertions)]
            debug_log!(
                "inHRCD->get_or_create_send_queue 6: Processing file: {:?}, extension: {}",
                entry.path(),
                extension
            );

            // Prepare readable TOML path (decrypt .gpgtoml if needed)
            let readable_path = match prepare_readable_toml_path(
                entry.path(),
                extension,
                &gpg_full_fingerprint_key_id_string,
                &base_uma_temp_directory_path,
            ) {
                Ok(p) => p,
                Err(e) => {
                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue: Failed to prepare readable path for {:?}: {} (skipping)",
                        entry.path(),
                        e
                    );
                    files_skipped += 1;
                    continue;
                }
            };

            // Check if file qualifies for send queue (incremental checks)
            match check_file_qualifications(
                &readable_path,
                localowneruser_name,
                remote_collaborator_name,
                session_send_queue.back_of_queue_timestamp,
            ) {
                Ok(true) => {
                    // File qualifies - add ORIGINAL path to queue
                    session_send_queue.items.push(entry.path().to_path_buf());
                    files_added_to_queue += 1;

                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue 10: Added to queue: {:?}",
                        entry.path()
                    );
                }
                Ok(false) => {
                    // File doesn't qualify (not an error)
                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue: File doesn't qualify: {:?}",
                        entry.path()
                    );
                }
                Err(e) => {
                    // File is malformed or unreadable
                    #[cfg(debug_assertions)]
                    debug_log!(
                        "inHRCD->get_or_create_send_queue: File read/parse error for {:?}: {} (skipping)",
                        entry.path(),
                        e
                    );
                    files_skipped += 1;
                }
            }
        }

        // Log metrics
        #[cfg(debug_assertions)]
        debug_log!(
            "inHRCD->get_or_create_send_queue: Crawl complete - encountered: {}, skipped: {}, added: {}",
            files_encountered,
            files_skipped,
            files_added_to_queue
        );
    }

    debug_log("inHRCD-> get_or_create_send_queue 11: calling, get_toml_file_updated_at_timestamp(), Hello?");

    // Get update flag paths
    let newpath_list = match get_sendq_update_flag_paths(
        team_channel_name, // No & needed now
        localowneruser_name, // Correct collaborator name
    ) {
        Ok(paths) => paths,
        Err(e) => {
            debug_log!("inHRCD->get_or_create_send_queue 2: Error getting update flag paths: {}", e);
            return Err(e); // Or handle as needed
        }
    };

    // Add new paths to the front of the queue
    for this_iter_newpath in newpath_list {
        session_send_queue.add_to_front_of_sendq(this_iter_newpath); // Use the new method
    }

    //////////////
    // New Files
    //////////////
    // Check for new-file flags, add those to the queue
    // this needs to be done ~last (before sorting is ok)

    // // --- Get new file paths and add them to the send queue ---
    // let new_file_paths_result = read_all_newfile_sendq_flags_w_cleanup(
    //     remote_collaborator_name,
    //     &team_channel_name,
    // );

    // // add to sendqueue
    // match new_file_paths_result {
    //     Ok(new_file_paths) => {
    //         session_send_queue.items.extend(new_file_paths); // Extend the items Vec directly
    //     },
    //     Err(e) => {
    //         debug_log!("Error reading new file flags: {}", e);
    //         // Handle error as needed
    //     }
    // };

    // Sort the files in the queue based on their modification time
    debug_log("Sequence of queue should be yougnest last, oldest first");
    session_send_queue.items.sort_by_key(|path| {
        get_toml_file_updated_at_timestamp(path).unwrap_or(0) // Handle potential errors in timestamp retrieval
        // std::cmp::Reverse(get_toml_file_updated_at_timestamp(path).unwrap_or(0)) // puts older items' first in queue
    });

    // reverse order so oldest are at the front
    session_send_queue.items.reverse();

    debug_log!(
        "session_send_queue.items -> {:?}",
        session_send_queue.items
    );

    // remove duplicates
    session_send_queue.items = remove_duplicates_from_path_array(session_send_queue.items);

    // Remove duplicates?

    // TODO(remove this later) extra Inspection here:
    debug_log("|| Extra Insepction || get_or_create_send_queue: end: Q");
    debug_log!(
        "inHRCD->get_or_create_send_queue 12: start;  ready_signal_rt_timestamp -> {:?}",
        ready_signal_rt_timestamp
    );
    debug_log!("inHRCD->get_or_create_send_queue 13: end: Q -> {:?}", session_send_queue);

    // Testing?
    // 1.5.6 Sleep for a duration (e.g., 100ms)
    // thread::sleep(Duration::from_millis(100000));

    Ok(session_send_queue)
}

/// Waits and checks indefintely until either a legitimate ready signal or exit uma
/// Retrieves SocketAddrs for the remote collaborator's ready and "got it" ports.
/// and saves remote collaborator IP band info
///
/// Continually, as when a remote collaborator may be never or belatedly online:
/// Iterates through the ipv6 and ipv4 addresses, listening for a ReadySignal. Returns SocketAddrs
/// for the ready and "got it" ports on the first valid IP. Directly uses UdpSocket::bind for
/// improved simplicity and efficiency. Does One Thing Well.
///
/// # Arguments
///
/// * `room_sync_input`: The collaborator's connection data.
///
/// # Returns
///
/// * `Result<(SocketAddr, SocketAddr), ThisProjectError>`:
/// Tuple of SocketAddrs (ready, gotit), or an error.
///
fn get_rc_band_ready_gotit_socketaddrses_hrcd(
    room_sync_input: &ForRemoteCollaboratorDeskThread,
) -> Result<(SocketAddr, SocketAddr), ThisProjectError> {
    let timeout_duration = Duration::from_secs(15);
    let mut buf = [0; 1024];

    // --- 1. Load Local Band Information (as before) ---
    debug_log("get_rc_band...HRCD: 1. load local band");
    let (
        local_network_type,
        _, // local_network_index is not used here
        local_ipv4,
        local_ipv6,
    ) = read_band__network_config_type_index_specs()?;


    // --- 2. Determine Local IP Address (as before) ---
    debug_log("get_rc_band...HRCD: 2. load local band");
    let local_ip = match local_network_type.as_str() {
        "ipv6" => IpAddr::V6(local_ipv6),
        "ipv4" => IpAddr::V4(local_ipv4),
        _ => return Err(ThisProjectError::NetworkError("get_rc_band_..._hrcd Invalid local network type".into())),
    };


    // 3. Create SocketAddr for Listening (as before)
    debug_log("get_rc_band...HRCD: 3. SocketAddr for Listening");
    let ready_socket_addr = SocketAddr::new(
        local_ip,
        room_sync_input.remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip,
    );


    // --- 4. Bind Socket (outside the loop) ---
    debug_log("get_rc_band...HRCD: 4. create_rc_udp_socket(ready_socket_addr)");
    let socket = create_rc_udp_socket(ready_socket_addr)?;

    // --- 5. Enter Loop to Continuously Listen ---
    debug_log("get_rc_band...HRCD: 5. loop");
    loop { // Main listening loop
        // 5.1 Check for UMA shutdown
        if should_halt_uma() {
            return Err(ThisProjectError::NetworkError("get_rc_band_..._hrcd UMA halt signal received during band handshake".into()));
        }

        debug_log!("get_rc_band...HRCD: 5.1 Listening for ReadySignal on: {:?}", ready_socket_addr);

        // 5.2 Set Timeout (inside loop, in case it's reset by recv)
        socket.set_read_timeout(Some(timeout_duration))?;

        // 5.3 Receive and Process
        match receive_ready_signal_with_timeout(&socket, &mut buf, &room_sync_input.remote_collaborator_salt_list) {
            Ok(Some((_, ready_signal))) => {
                debug_log("get_rc_band...HRCD: 5.3 Receive and Process");
                // Note: this Hash Verification  is already performed inside receive_ready_signal_with_timeout()
                // 5.3.1 Hash and Timestamp Verification (Perform checks *inside* the Ok case)
                // if !verify_readysignal_hashes(&ready_signal, &room_sync_input.remote_collaborator_salt_list) {
                //     debug_log!("get_rc_band_..._hrcd ReadySignal hash verification failed. Discarding and continuing to listen.");
                //     continue; // Continue to listen for a valid signal
                // }

                let current_timestamp = get_current_unix_timestamp();
                if ready_signal.rst > current_timestamp + 5 || current_timestamp - 10 > ready_signal.rst {
                    debug_log!("get_rc_band_..._hrcd Received outdated or future-dated ReadySignal. Discarding and continuing to listen.");
                    continue; // Continue listening
                }

                // --- 5.3.2 Extract and Save Remote Band Information ---
                debug_log("get_rc_band...HRCD: 5.3.2 Extract and Save Remote");
                // let (rc_network_type, rc_network_index) = decompress_banddata_byte(ready_signal.b);
                let (rc_network_type, rc_network_index) = { // Create a new inner scope here
                    let band_result = decompress_banddata_byte(ready_signal.b);
                    debug_log!(
                        "get_rc_band...HRCD: 5.3.2 Extract and Save -> band_result: {:?}",
                        band_result,
                        );

                    match band_result {
                        Ok((tempnetworktype, tempnetworkindex)) => (tempnetworktype, tempnetworkindex), // Assign values.
                        Err(e) => {
                            debug_log!("Error decompressing band data: {}. Skipping.", e);
                            continue;  // Skip to next iteration if an error occurs during decompression.
                        }
                    }
                };

                // --- Select IP for "got it" signal ---
                let rc_ip = match get_ip_from_index_and_type(
                    &room_sync_input.remote_collaborator_ipv4_addr_list,
                    &room_sync_input.remote_collaborator_ipv6_addr_list,
                    &rc_network_type,
                    rc_network_index,
                ) {
                    Some(ip) => ip,
                    None => {
                        debug_log!("get_rc_band_..._hrcd Failed to get remote collaborator IP address from received network index and type. Continuing to listen.");
                        continue; // Continue listening for valid signal
                    }
                };
                let gotit_socket_addr = SocketAddr::new(rc_ip, room_sync_input.remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip);  // Correct port from room_sync_input

                // --- Write/Save Received Band Data ---
                let team_channel_name = match get_current_team_channel_name_from_nav_path() {
                    Some(name) => name,
                    None => {
                        debug_log!("Error: get_rc_band_ Could not get current channel name. Skipping set_as_active.");
                        return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
                    },
                };

                debug_log("get_rc_band...HRCD: next: write_save_rc_bandnetwork_type_index");
                write_save_rc_bandnetwork_type_index(
                    room_sync_input.remote_collaborator_name.clone(),
                    team_channel_name,
                    rc_network_type,
                    rc_network_index,
                    local_ipv4,
                    local_ipv6,
                )?;

                // --- 5.4 Return Socket Addresses (Valid Signal Received) ---
                return Ok((ready_socket_addr, gotit_socket_addr)); // Return SocketAddrs on success
            }
            Ok(None) => {
                // 5.5 Handle timeout (Ok(None) from receive_ready_signal_with_timeout) - Just continue listening
                debug_log!("get_rc_band_..._hrcd Timeout waiting for ReadySignal. Continuing to listen.");
                continue; // Continue listening. The loop handles the timeout. No explicit error.
            },
            Err(e) => {
                debug_log!("get_rc_band_ready_gotit_socketaddrses_hrcd: Error receiving ReadySignal: {}", e);
                return Err(e); // Return any other errors
            }
        }
    } // End of main listening loop
}

/// Gets the IP address from combined IPv4/IPv6 lists based on index and type.
///
/// # Arguments
///
/// * `ipv4_list`: A slice of IPv4 addresses.
/// * `ipv6_list`: A slice of IPv6 addresses.
/// * `network_type`: The network type string.
/// * `network_index`: The index into the appropriate list.
///
/// # Returns
///
/// * `Option<IpAddr>`: The `IpAddr` at the given index and type, or `None` if the index is out of bounds or the network type is invalid.
fn get_ip_from_index_and_type(
    ipv4_list: &[Ipv4Addr],
    ipv6_list: &[Ipv6Addr],
    network_type: &str,
    network_index: u8
) -> Option<IpAddr> {
    match network_type {
        "ipv4" => ipv4_list.get(network_index as usize).map(|&ip| IpAddr::V4(ip)),
        "ipv6" => ipv6_list.get(network_index as usize).map(|&ip| IpAddr::V6(ip)),
        _ => None, // Or handle an invalid network type in another way
    }
}

/// Receives a ReadySignal with a timeout, performing hash and timestamp verification.
/// Goal purpose and scope: screening valid packets to verify a live-ip
///
/// This function now includes both hash verification and timestamp freshness checks.
///
/// # Arguments
///
/// * `socket`: The UDP socket to receive data on.
/// * `buf`: A mutable buffer to store the received data.
/// * `salt_list`: The salt list for hash verification.
///
/// # Returns
///
/// * `Result<Option<SocketAddr>, ThisProjectError>`: The sender's `SocketAddr` on success, an error, or `Ok(None)` on timeout.
fn receive_ready_signal_with_timeout( // Hash and timestamp checks moved HERE!
    socket: &UdpSocket,
    buf: &mut [u8],
    senders_salt_list: &[u128],
) -> Result<Option<(SocketAddr, ReadySignal)>, ThisProjectError> { // Changed to return the signal
    debug_log!("receive_ready_signal_with_timeout(): Starting...");

    let timeout_duration = Duration::from_secs(15);

    socket.set_read_timeout(Some(timeout_duration))?;

    match socket.recv_from(buf) {
        Ok((amt, src)) => {
            debug_log!("receive_ready_signal_with_timeout(): Received {} bytes from {}", amt, src);

            // 1. Deserialize
            let ready_signal = match deserialize_ready_signal(&buf[..amt], senders_salt_list) { // Deserialize first.  Use the passed-in senders_salt_list
                Ok(signal) => signal,
                Err(e) => {
                    debug_log!("receive_ready_signal_with_timeout():  Failed to deserialize ReadySignal: {}", e);
                    return Err(e);  // Or continue to listen for the next signal
                },
            };

            // 2. Hash Verification: PERFORM HASH CHECK HERE!
            if !verify_readysignal_hashes(&ready_signal, senders_salt_list) { // Hash verification alongside timestamp check
                debug_log!("receive_ready_signal_with_timeout(): ReadySignal hash verification failed. Discarding.");
                return Ok(None); // Or continue to listen, but return nothing.
            };
            debug_log!("receive_ready_signal_with_timeout(): ReadySignal hashes verified.");

            // 3. Timestamp Freshness Check: PERFORM TIMESTAMP CHECK HERE!
            let current_timestamp = get_current_unix_timestamp();
            if ready_signal.rst > current_timestamp + 5 || current_timestamp - 10 > ready_signal.rst {  // Freshness check, combined
                debug_log!("receive_ready_signal_with_timeout(): Received outdated or future-dated ReadySignal.  Discarding.");
                return Ok(None); // Indicate invalid signal without returning an Error.
            };
            debug_log!("receive_ready_signal_with_timeout():  ReadySignal timestamp verified.");

            // 4. Return the source address and ReadySignal if all checks pass.
            Ok(Some((src, ready_signal))) // Include ReadySignal
        },

        Err(e) if e.kind() == ErrorKind::WouldBlock => {
            debug_log!("receive_ready_signal_with_timeout(): Timeout");
            Ok(None) // Correct handling of timeout, not returning an error!
        }
        Err(e) => {
            debug_log!("receive_ready_signal_with_timeout(): Error receiving data: {}", e);
            Err(ThisProjectError::NetworkError(e.to_string()))
        },
    }
}

/// TODO: What on earth is this thing???
///
/// Gets the latest `updated_at_timestamp` from the current team channel's files.
///
/// This function crawls through the current team channel's directory and retrieves
/// the most recent `updated_at_timestamp` from the TOML files it finds.
///
/// # Returns
///
/// `Result<u64, ThisProjectError>`:  The latest timestamp, or an error if the directory read fails, a TOML file cannot be parsed, or the updated_at_timestamp is invalid.
fn get_latest_timestamp_from_team_channel_dir() -> Result<u64, ThisProjectError> {
    let mut latest_timestamp = 0u64; // Initialize to zero

    let channel_dir_path_str = match read_state_string("current_node_directory_path.txt") {
        Ok(s) => s,
        Err(e) => {
            debug_log!("Error reading channel directory path: {}", e);
            return Err(e.into()); // Or handle error differently
        }
    };

    //  Crawl through the team channel directory
    for entry in WalkDir::new(channel_dir_path_str) {
        let entry = entry?; // Check for WalkDir errors
        let path = entry.path();
        if path.is_file() && path.extension() == Some(OsStr::new("toml")) {
            match get_toml_file_updated_at_timestamp(path) {
                Ok(timestamp) => {
                    if timestamp > latest_timestamp {
                        latest_timestamp = timestamp;
                    }
                },
                Err(e) => {
                    debug_log!("Error reading or parsing TOML file: {:?} - {}", path, e);
                    // Handle the error as you see fit. Perhaps continue or return the error.
                    continue; // Skip to the next file
                },
            };
        }
    }
    Ok(latest_timestamp)
}

/// handle_remote_collaborator_meetingroom_desk (send files here)
/// very brief overview:
/// 1. listen for got-it signals and remove fail-flags (yes, their 'last' 3rd step is actually done first)
/// 2. listen for 'ready' signal
/// 3. send one send-queue item at at time & update send-queue (pop item and update back_of_queue_timestamp)
///
/// delete/rewrite:
/// ```path
/// sync_data/team_channel/collaborator_name/back_of_queue_timestamp
/// ```
///
/// Error Handling:
/// 1. Distinguish Between Error Types: Not all errors are equal. Some errors might be transient (e.g., WouldBlock indicating no data is available yet), while others might be fatal (e.g., a socket error).
/// 2. Handle Transient Errors: For transient errors, we can simply continue the loop and try to receive data again.
/// 3. Handle Fatal Errors: For fatal errors, we should log the error, potentially notify the user, and consider exiting the function or the entire sync process.
///
/// TODO add  "workflow" steps: handle_remote_collaborator_meetingroom_desk()
fn handle_remote_collaborator_meetingroom_desk(
    room_sync_input: &ForRemoteCollaboratorDeskThread,
) -> Result<(), ThisProjectError> {
    /*


    */
    loop { // 1. start overall loop to restart whole desk
        // --- 1. overall loop to restard handler in case of failure ---
        //  1.1 Check for halt signal.
        if should_halt_uma() {
            debug_log!(
                "HRCD 1.1 Check for halt signal. Halting handle_remote_collaborator_meetingroom_desk() for {}",
                room_sync_input.remote_collaborator_name
            );
            break;
        }

        debug_log!(
            "\n Started HRCD the handle_remote_collaborator_meetingroom_desk() for->{}",
            room_sync_input.remote_collaborator_name
        );
        debug_log!(
            "HRCD room_sync_input -> {:?}",
            room_sync_input
        );

        /////////////
        // Bootstrap
        /////////////

        debug_log("HRCD calling get_current_team_channel_name_from_nav_path");

        // TODO
        // setup: Get Team Channel Name
        let team_channel_name = get_current_team_channel_name_from_nav_path()
            .ok_or(ThisProjectError::InvalidData("Unable to get team channel name".into()))?;

        // 1.2 Get Remote Collaborator's IP and Network Type
        debug_log("HRCD starting search for Remote Collaborator's IP");

        let (ready_socket_addr, gotit_socket_addr) =
            match get_rc_band_ready_gotit_socketaddrses_hrcd(room_sync_input) {
                Ok(addrs) => addrs,
                Err(e) => {
                    debug_log!("HRCD: Error getting SocketAddrs: {}", e);
                    return Err(e);
                }
            };

        debug_log!(
            "HRCD get_rc_band_ready_gotit_socketaddrses_hrcd: RC -> {:?} || ready_socket_addr -> {:?} || gotit_socket_addr -> {:?}",
            room_sync_input.remote_collaborator_name,
            ready_socket_addr,
            gotit_socket_addr
        );




        // 1. UPD Handshake
        // hrcd_udp_handshake(&room_sync_input);



        // --- 1.3 Create two UDP Sockets for Ready and GotIt Signals ---`
        debug_log("HRCD 1.3 Making ready_port listening UDP socket...");
        let ready_socket = create_rc_udp_socket(ready_socket_addr)?;

        debug_log("HRCD 1.3 Making gotit_port listening UDP socket...");
        let gotit_socket = create_rc_udp_socket(gotit_socket_addr)?;

        // --- 1.4 Initialize (empty for starting) Send Queue ---
        // let mut session_send_queue: Option<SendQueue> = None;
        // 1.4 Initialize Send Queue (empty, with zero timestamp)
        let mut session_send_queue = SendQueue {
            back_of_queue_timestamp: 0,
            items: Vec::new(),
        };

        debug_log!(
            // this does require &
            "HRCD 1.5.2 check: new session_send_queue.items -> {:?} (Should be empty...)",
            session_send_queue.items
        );

        let remote_collaborator_name_clone = room_sync_input.remote_collaborator_name.clone();

        // --- HRCD 1.5 Spawn a thread to handle recieving GotItSignal(s) and SendFile prefail-flag removal ---
        // let gotit_thread
        let _ = thread::spawn(move || {
            //////////////////////////////////////
            // Listen for 'I got it' GotItSignal
            ////////////////////////////////////

            loop { // gotit loop
                debug_log(
                    "HRCD Got it loop starting. GotItloop"
                );
                // 1.5.1 Check for halt-uma signal
                if should_halt_uma() {
                    debug_log!("HRCD 1.5.1 GotItloop Got It loop: Halt signal received. Exiting. in handle_remote_collaborator_meetingroom_desk");
                    break; // Exit the loop
                }

                // 1.5.2 Receive and handle "Got It" signals // under construction TODO
                let mut buf = [0; 1024];
                match gotit_socket.recv_from(&mut buf) {
                    Ok((amt, src)) => {

                        // Check for exit-signal:
                        if should_halt_uma() {
                            debug_log(
                                "HRCD 1.5.2 should_halt_uma() Halting handle_remote_collaborator_meetingroom_desk",
                            );
                            break;
                        }

                        debug_log!("HRCD 1.5.2 GotItloop Ok((amt, src)) Received {} bytes from {} on gotit port", amt, src);

                        // --- Inspect Raw Bytes ---
                        debug_log!(
                            // this does require &
                            "HRCD 1.5.2 GotItloop Raw bytes received: {:?}",
                            &buf[..amt]
                        );

                        // --- Inspect Bytes as Hex ---
                        let hex_string = buf[..amt].iter()
                            .map(|b| format!("{:02X}", b))
                            .collect::<String>();
                        debug_log!("HRCD 1.5.2 GotItloop Raw bytes as hex: {}", hex_string);

                        // Clone the values you need from room_sync_input
                        // let remote_collaborator_name = room_sync_input.remote_collaborator_name.clone();

                        // 1.5.3 Deserialize the GotItSignal
                        let gotit_signal: GotItSignal = match process_incoming_gotit_signal_bytes(&buf[..amt]) {
                            Ok(gotit_signal) => {
                                debug_log!("HRCD 1.5.3 GotItloop Ok(gotit_signal) : Received GotItSignal: {:?}",
                                    // remote_collaborator_name,
                                    gotit_signal
                                ); // Log the signal
                                gotit_signal
                            },
                            Err(e) => {
                                debug_log!("HRCD 1.5.3 GotItloop Err Receive data Failed to parse ready signal: {}", e);
                                continue; // Continue to the next iteration of the loop
                            }
                        };

                        // 1.5.4  get document_id from signal
                        let document_id = gotit_signal.di;

                        debug_log(
                            "HRCD: Done event of got-it listener."
                        );

                        // 1.5.5 check and remove filestubs with name==document_id
                        /*
                        If match
                        Remove From:
                        ```path
                        sync_data/team_channel/fail_flags/NAME-of-COLLABORATOR/DOC-ID
                        ```
                        */

                        let _ = remove_one_prefail_flag__for_sendfile(
                            document_id, // di_flag_id: String,
                            &remote_collaborator_name_clone, // remote_collaborator_name: String,
                            &team_channel_name, // team_channel_name: String,
                        );
                        // 1.5.6 update ~timestamp_of_latest_received_file_that_i_sent

                    // // 1.5.7 Sleep for a short duration (e.g., 100ms)
                    // thread::sleep(Duration::from_millis(1000));

                    },
                    Err(e) => {
                        debug_log!("HRCD 1.5 GotItloop Error receiving data on gotit_port: {}", e);
                        // You might want to handle the error more specifically here (e.g., retry, break the loop, etc.)
                        // For now, we'll just log the error and continue listening.
                        continue;
                    }
                }
            }
        }); // End of GotIt Loooooop

        // 1.6.1 zero_timestamp_counter = 0 for ready signal send-at timestamps
        let mut zero_timestamp_counter = 0;

        // 1.6.2 intrystruct_hash_set_session_nonce = HashSet::new() as protection against replay attacks Create a HashSet to store received hashes
        let mut intrystruct_hash_set_session_nonce = HashSet::new();  // Create a HashSet to store received hashes

        let mut rc_set_as_active = false;

        // For first-time bootstrap
        let mut bootstrap_sendqueue = true;


        // --- 2. Enter Main Loop ---
        // enter main loop (to handling signals, sending)
        loop {
            debug_log(
                "HRCD  2.: Starting, restarting Main loop"
            );

            // --- 2.1 Check for 'should_halt_uma' Signal ---
            if should_halt_uma() {
                debug_log!(
                    "HRCD 2.1 main loop Check for halt signal. Halting handle_remote_collaborator_meetingroom_desk() for {}",
                    room_sync_input.remote_collaborator_name
                );
                break;
            }

            // --- 2.2. Handle Ready Signal:  ---
            // "Listener"?
            // 2.2.1 Receive Ready Signal
            let mut buf = [0; 1024]; // TODO size?
            match ready_socket.recv_from(&mut buf) {
                Ok((amt, src)) => {
                    debug_log!(
                        "HRCD 2.2.1 Ok((amt, src)) ready_port Signal Received {} bytes from {}",
                        amt,
                        src
                    );

                    debug_log!(
                        "HRCD 2.2.1 check queue {:?}",
                        session_send_queue.items,
                    );

                    if should_halt_uma() {
                        debug_log!(
                            "HRCD Halting handle_local_owner_desk() for {}",
                            room_sync_input.remote_collaborator_name
                        );
                        break;
                    }

                    if !rc_set_as_active {
                        if let Err(e) = set_as_active(&room_sync_input.remote_collaborator_name) {
                            debug_log!("Error setting collaborator as active: {}", e);
                            // Handle the error appropriately (e.g., continue or return)
                            continue; // Example: skip to the next iteration
                        }

                        rc_set_as_active = true;
                        debug_log("HRCD rc_set_as_active = true")
                    }



                    // --- Inspect Raw Bytes ---
                    debug_log!(
                        "HRCD 2.2.1 Ready Signal Raw bytes received: {:?}",
                        &buf[..amt]
                    );
                                        // --- Inspect Raw Bytes ---
                    debug_log!(
                        "HRCD thread::sleep(Duration::from_secs(3));",
                    );

                    // TODO: how long?
                    // this lets last item run
                    // thread::sleep(Duration::from_secs(5));

                    // --- Inspect Bytes as Hex ---
                    let hex_string = buf[..amt].iter()
                        .map(|b| format!("{:02X}", b))
                        .collect::<String>();
                    debug_log!(
                        "HRCD 2.2.1 Ready Signal Raw bytes as hex: {}",
                        hex_string
                    );

                    // --- 2.3 Deserialize the ReadySignal ---
                    // TODO add size check to deserialize function
                    let ready_signal: ReadySignal = match deserialize_ready_signal(&buf[..amt], &room_sync_input.remote_collaborator_salt_list) {
                        Ok(ready_signal) => {
                            // println!("HRCD 2.3 Deserialize Ok(ready_signal) {}: Received ReadySignal: {:?}",
                            //     room_sync_input.remote_collaborator_name, ready_signal
                            // ); // Print to console
                            debug_log!("HRCD 2.3 Deserialize Ok(ready_signal) {}: Received ReadySignal: {:?}",
                                room_sync_input.remote_collaborator_name,
                                ready_signal
                            ); // Log the signal
                            ready_signal
                        },
                        Err(e) => {
                            debug_log!("HRCD 2.3 Deserialize Err Receive data Failed to parse ready signal: {}", e);
                            continue; // Continue to the next iteration of the loop
                        }
                    };

                    // --- 2.4 Inspect & edge cases ---
                    // - look for missing required fields e.g. timestamp
                    // - only re(is_echo_send_boolean) can be empty, all other cases must drop packet
                    // - handle edge cases such as valid echo-request...with no queue
                    // or maybe there is a queue but empty so just let it do nothing?
                    // maybe ok, make sure this works
                    /*
                        struct ReadySignal {
                            rt: Option<u64>, // ready signal timestamp: last file obtained timestamp
                            rst: Option<u64>, // send-time
                            re: Option<bool>, // echo_send
                            rh: Option<Vec<u8>>, // N hashes of rt + re [can be empty]

                        no echo signal, then re = false
                    */

                    debug_log("\n##HRCD## starting checks(plaid) 2.4");

                    // --- 2.5 Hash-Check for ReadySignal ---
                    // Drop packet when fail check
                    if !verify_readysignal_hashes(
                        &ready_signal,
                        &room_sync_input.remote_collaborator_salt_list,
                    ) {
                        debug_log("HRCD 2.5: ReadySignal hash verification failed. Discarding signal.");
                        continue; // Discard the signal and continue listening
                    }

                    // --- 2.6 Check / Add Hash-Nonce for per-session ready-signals ---
                    // ...e.g. guarding against the few seconds of expiration-gap
                    // After you deserialize the ReadySignal and before the other checks:
                    let ready_signal_hash_vec = ready_signal.rh.clone();

                    if !ready_signal_hash_vec.is_empty() {
                        if intrystruct_hash_set_session_nonce.contains(&ready_signal_hash_vec) {
                            debug_log!("HRCD 2.6 quasi nonce check: Duplicate ReadySignal received (hash match). Discarding.");
                            continue; // Discard the duplicate signal
                        }
                        intrystruct_hash_set_session_nonce.insert(ready_signal_hash_vec); // Add hash to the set
                    } else {
                        debug_log!("HRCD 2.6 quasi nonce check: ReadySignal received without hashes. Discarding."); // Or handle differently
                        continue;
                    }

                    // --- 3. Get or Create Send Queue ---

                    // 3.1 ready_signal_timestamp for send-queue
                    let rst_sent_ready_signal_timestamp = ready_signal.rst; // Unwrap the timestamp outside the match, as it's always required.

                    debug_log!(
                        "HRCD 3.1 check rst_sent_ready_signal_timestamp for send-queue: rst_sent_ready_signal_timestamp -> {:?}",
                        rst_sent_ready_signal_timestamp
                    );

                    debug_log!(
                        "HRCD 3.1 check rt: rc's last-file-received-from-you timestamp received in a readysignal. ready_signal.rt -> {:?}",
                        ready_signal.rt,
                    );

                    // --- 3.2 timestamp freshness checks ---
                    let current_timestamp = get_current_unix_timestamp();

                    debug_log!(
                        "HRCD 3.2 check timestamp freshness checks: current_timestamp -> {:?}",
                        current_timestamp,
                    );

                    // 3.2.1 No Future Dated Requests
                    if rst_sent_ready_signal_timestamp > current_timestamp + 5 { // Allow for some clock skew (5 seconds)
                        debug_log!("HRCD 3.2.1 check: Received future-dated timestamp. Discarding.");
                        continue;
                    }

                    // 3.2.2 No Requests Older Than ~10 sec
                    if current_timestamp - 10 > rst_sent_ready_signal_timestamp {
                        debug_log!("HRCD 3.2.2 check: Received outdated timestamp (older than 10 seconds). Discarding.");
                        continue;
                    }

                    // 3.2.3 only 3 0=timstamp requests per session (count them!)
                    if rst_sent_ready_signal_timestamp == 0 {
                        if zero_timestamp_counter >= 5 {
                            debug_log("HRCD 3.2.3 check: Too many zero-timestamp requests. Discarding.");
                            continue;
                        }
                        zero_timestamp_counter += 1;
                    }

                    debug_log("##HRCD## [Done] checks(plaid) 3.2.3\n");

                    // 3.2.4 look for fail-flags:

                    ////////////////////////////////
                    // Set back_of_queue_timestamp
                    //////////////////////////////

                    // --- 3.3 Get / Make Send-Queue ---
                    let this_team_channelname = match get_current_team_channel_name_from_nav_path() {
                        Some(name) => name,
                        None => {
                            debug_log("HRCD 3.3: Error: Could not get current channel name. Skipping send queue creation.");
                            continue; // Skip to the next iteration of the loop
                        }
                    };
                    debug_log!("HRCD 3.3 this_team_channelname -> {:?}", this_team_channelname);

                    // TODO currently set to always run... ok?
                    debug_log("HRCD 3.3 get_or_create_send_queue");

                    session_send_queue = get_or_create_send_queue(
                        &this_team_channelname, // for team_channel_name
                        &room_sync_input.local_user_name, // local owner user name
                        &room_sync_input.remote_collaborator_name, // remote_collaborator_name
                        session_send_queue, // for session_send_queue
                        ready_signal.rt, // for ready_signal_rt_timestamp
                        bootstrap_sendqueue,
                    )?;

                    bootstrap_sendqueue = false;

                    debug_log!(
                        "HRCD ->[]<- 3.3 Get / Make session_send_queue {:?}",
                        session_send_queue
                    );

                    /*
                    send_file_toml_to_rc_intray(
                        file_path: &PathBuf,
                        target_addr: SocketAddr,
                        port: u16,
                        collaborator_salt_list: &[u128], // Pass the salt list here
                    )

                    # Explaining:
                    ```
                    if let Some(ref mut queue) = session_send_queue {
                        while let Some(file_path) = queue.items.pop() {
                    ```

                    That code snippet represents a common pattern in Rust for
                    iterating over and processing items in a Vec (vector) while
                     also potentially modifying the vector itself (in this case,
                         by removing elements). Let's break down the logic:

                    if let Some(ref mut queue) = session_send_queue: This is a
                    conditional statement that uses pattern matching with if
                    let. session_send_queue is an Option<SendQueue>, meaning
                    it can either contain a SendQueue or be None.

                    Some(ref mut queue): This part of the pattern attempts
                     to match the Some variant of the Option. If session_send_queue
                     contains a SendQueue, the code inside the if block will
                     be executed. The ref mut creates a mutable reference to the
                      inner SendQueue, allowing you to modify it.

                    If session_send_queue is None, the if block is skipped entirely.

                    while let Some(file_path) = queue.items.pop(): This is a
                    while let loop, another form of pattern matching. queue.items
                    is a Vec<PathBuf>. pop() removes and returns
                    the last element of the vector.

                    Some(file_path): This part of the pattern attempts to match
                     the Some variant of the Option returned by pop().
                     If queue.items is not empty, pop() will return Some(PathBuf)
                     where PathBuf is the removed element. The code inside the
                     while loop will be executed, and file_path will be assigned
                     the value of the removed PathBuf.

                    Empty Vector: When queue.items becomes empty, pop() will
                    return None. This will cause the while let loop to terminate.

                    In Summary:

                    The combined if let and while let structure ensures the following:

                    The code inside the while loop only executes
                    if session_send_queue contains a SendQueue (it's not None).

                    The loop iterates over the items in the SendQueue
                    from the last element to the first,
                    removing each item as it's processed.
                    */

                    debug_log!(
                        "HRCD ->[cue]<- 4.1 Send One File from Queue, session_send_queue -> {:?}",
                        session_send_queue
                    );

                    // 4. while: Send File: Send One File from Queue
                    // if let ref mut queue = session_send_queue {
                    if let ref mut queue = session_send_queue {

                        debug_log!(
                            "HRCD 4 before le pop, queue.items -> {:?}",
                            queue.items
                        );

                        while let Some(file_path) = queue.items.pop() {

                            debug_log!(
                                "HRCD 4 after le pop, queue.items -> {:?}",
                                queue.items
                            );

                            debug_log!(
                                "HRCD 4.2 Send File: if/while let Some(file_path) = queue.items.pop()  file_path {:?}",
                                file_path
                            );

                            /*
                            Probably from raw path to file
                            get path to readcopy of toml (checked and 'unpackaged' from clearsign and gpg encrypt)
                            */
                            // Using Debug trait for more detailed error information
                            // this is in clearsigntoml module
                            /*
                            pub fn get_pathstring_to_tmp_clearsigned_readcopy_of_toml_or_decrypted_gpgtoml(
                                input_toml_absolute_path: &Path,
                                gpg_full_fingerprint_key_id_string: &str, // COLLABORATOR_ADDRESSBOOK_PATH_STR
                                base_uma_temp_directory_path: &Path,
                            ) -> Result<String, GpgError> {
                             */
                             // Get armored public key, using key-id (full fingerprint in)
                             let gpg_full_fingerprint_key_id_string = match LocalUserUma::read_gpg_fingerprint_from_file() {
                                 Ok(fingerprint) => fingerprint,
                                 // Err(e) => {
                                 //     // Since the function returns Result<CoreNode, String>, we need to return a String error
                                 //     return Err(format!(
                                 //         "LCNFTF: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}",
                                 //         e
                                 //     ));
                                 // }
                                 Err(e) => {
                                     debug_log!( "LCNFTF: implCoreNode save node to file: Failed to read GPG fingerprint from uma.toml: {}", e);
                                     continue; // Skip to the next file if hashing fails
                                 }
                             };

                             // 1. Paths & Reading-Copies Part 1: node.toml path and read-copy


                             // Get the UME temp directory path with explicit String conversion
                             let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
                                 .map_err(|io_err| {
                                     let gpg_error = GpgError::ValidationError(
                                         format!("LCNFTF: Failed to get UME temp directory path: {}", io_err)
                                     );
                                     // Convert GpgError to String for the function's return type
                                     format!("LCNFTF: {:?}", gpg_error)
                                 })?;

                            // base file to send is clearsigned
                            let sendfile_readcopy_pathstring = get_pathstring_to_temp_plaintoml_verified_extracted(
                                &file_path,
                                &gpg_full_fingerprint_key_id_string,
                                &base_uma_temp_directory_path,
                            ).map_err(|e| format!("LCNFTF: Failed to get temporary read copy of TOML file: {:?}", e))?;

                            // converst from path-string to path-type path
                            let path_sendfile_readcopy_path = Path::new(&sendfile_readcopy_pathstring);


                            /*
                            /// ## Error Handling
                            /// - On ANY error: delete temp file, return error
                            /// - Lines already deleted stay deleted (cannot retry from same position)
                            /// - Caller must restart from new first-available line
                            ///
                            /// # Arguments
                            /// * `path_to_target_file` - Absolute path to file to XOR
                            /// * `result_path` - Absolute path for output file
                            /// * `path_to_padset` - Absolute path to padset root
                            ///
                            /// # Returns
                            /// * `Ok((PadIndex, usize))` - Starting index used and bytes processed
                            /// * `Err(PadnetError)` - Operation failed, no output created
                            pub fn padnet_writer_strict_cleanup_continuous_xor_file(
                                path_to_target_file: &Path,
                                result_path: &Path,
                                path_to_padset: &Path,
                            ) -> Result<(PadIndex, usize), PadnetError> {
                            */

                            // 4.2.1 Get File Send Time
                            let intray_send_time = get_current_unix_timestamp();

                            let use_padnet_flag = &room_sync_input.use_padnet;

                            // let mut padnet_index_array: PadIndex;

                            let sendfile_struct: SendFile = if *use_padnet_flag {

                                // - check file for flag, if *use_padnet_flag
                                // 1. flag for padnet-mode where?
                                // 2. get team-channel-name
                                // 3. get RC key-id (state)
                                // 4. get write-pad path (with id, team-channel)
                                //  -- /padnet/to/{team_channel}/{RC key-id}
                                // 5. use padnet_wrapper_path_to_clearsign_to_gpgencrypt_to_otp_to_send_bytes
                                // - clearsign
                                // - gpg
                                // - otp
                                // - to bytes, get array-index
                                // 5. use bytes for file_bytes2send
                                // 6. use arry index in struct


                                let team_channel_name = match get_current_team_channel_name_from_nav_path() {
                                    Some(name) => name,
                                    None => {
                                        debug_log!("Error: Could not get current channel name. Skipping set_as_active.");
                                        return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
                                    },
                                };
                                let rc_key_id = &room_sync_input.remote_collaborator_gpg_publickey_id;

                                // 3. get write-pad path (with id)
                                //  -- /padnet/to/{team_channel}/{RC key-id}
                                let mut padnet_directory_path = get_writer_to_padnet_directory_path()?;
                                padnet_directory_path.push(&team_channel_name);
                                padnet_directory_path.push(rc_key_id);

                                // Get temp directory path with explicit String conversion
                                let base_uma_temp_directory_path = get_base_uma_temp_directory_path()
                                    .map_err(|io_err| {
                                        let gpg_error = GpgError::ValidationError(
                                            format!("HRCMD: Failed to get UME temp directory path: {}", io_err)
                                        );
                                        // Convert GpgError to String for the function's return type
                                        format!("HRCMD: {:?}", gpg_error)
                                    })?;

                                let temp_filepath_padnet = create_unique_temp_filepathbuf(
                                &base_uma_temp_directory_path,    // base_path: &Path,
                                "padnet",    // prefix: &str,
                                5,    // number_of_attempts: u32,
                                16,    // retry_delay_ms: u64,
                                )?;

                                // calls padnet_writer_strict_cleanup_continuous_xor_file
                                let (file_bytes2send, padnet_index_array) = padnet_wrapper_path_to_clearsign_to_gpgencrypt_to_otp_to_send_bytes(
                                    &temp_filepath_padnet, // padnes path?
                                    &room_sync_input.remote_collaborator_public_gpg,
                                    &padnet_directory_path, // path_to_padset
                                )?;

                                // // 4.5. Calculate SendFile Struct Hashes (Using Collaborator's Salts)
                                // 4.5 calculate hashes: HRCD
                                let calculated_hrcd_sendfile_hashes_result = hash_sendfile_struct_fields(
                                    &room_sync_input.local_user_salt_list,
                                    intray_send_time,
                                    &file_bytes2send,
                                );

                                // Handle the Result from hash_sendfile_struct_fields
                                let calculated_hashes = match calculated_hrcd_sendfile_hashes_result {
                                    Ok(hashes) => hashes,
                                    Err(e) => {
                                        debug_log!("HRCD 4.5 Error calculating hashes: {}", e);
                                        continue; // Skip to the next file if hashing fails
                                    }
                                };

                                debug_log!(
                                    "HRCD 4.5 calculated_hashes {:?}",
                                    calculated_hashes
                                );

                                // 4.6. Create SendFile Struct
                                SendFile {
                                    intray_send_time: Some(intray_send_time),
                                    gpg_encrypted_intray_file: Some(file_bytes2send), // Clone needed here if file_bytes2send is used later
                                    intray_hash_list: Some(calculated_hashes),  // Clone here as well
                                    padnet_index_array: Some(padnet_index_array),
                                }

                            } else {

                                // Wrapper of bytes to bytes:
                                // 4.2.2 Read File Contents
                                // 4.3.1 GPG Clearsign the File (with your private key)
                                // 4.3.2 GPG Encrypt File (with their public key)
                                let file_bytes2send = wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes(
                                    &path_sendfile_readcopy_path,
                                    &room_sync_input.remote_collaborator_public_gpg,
                                )?;

                                debug_log(
                                    "HRCD 4.2, 4.3.1, 4.3.2 done gpg wrapper"
                                );

                                // // 4.5. Calculate SendFile Struct Hashes (Using Collaborator's Salts)
                                // 4.5 calculate hashes: HRCD
                                let calculated_hrcd_sendfile_hashes = hash_sendfile_struct_fields(
                                    &room_sync_input.local_user_salt_list,
                                    intray_send_time,
                                    &file_bytes2send,
                                );

                                // Handle the Result from hash_sendfile_struct_fields
                                let calculated_hashes = match calculated_hrcd_sendfile_hashes {
                                    Ok(hashes) => hashes,
                                    Err(e) => {
                                        debug_log!("HRCD 4.5 Error calculating hashes: {}", e);
                                        continue; // Skip to the next file if hashing fails
                                    }
                                };

                                debug_log!(
                                    "HRCD 4.5 calculated_hashes {:?}",
                                    calculated_hashes
                                );

                                // 4.6. Create SendFile Struct (no padnet)
                                SendFile {
                                    intray_send_time: Some(intray_send_time),
                                    gpg_encrypted_intray_file: Some(file_bytes2send), // Clone needed here if file_bytes2send is used later
                                    intray_hash_list: Some(calculated_hashes),  // Clone here as well
                                    padnet_index_array: None,
                                }

                            };

                            // TODO
                            // 1. get &room_sync_input.remote_collaborator_gpg_publickey_id,
                            // 2. look at bool field from file if there: padnet_opt: true
                            // TODO, maybe this gets OPT array etc

                            /*


                            // Wrapper of bytes to bytes:
                            // 4.2.2 Read File Contents
                            // 4.3.1 GPG Clearsign the File (with your private key)
                            // 4.3.2 GPG Encrypt File (with their public key)
                            let file_bytes2send = wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes(
                                &path_sendfile_readcopy_path,
                                &room_sync_input.remote_collaborator_public_gpg,
                            )?;

                            debug_log(
                                "HRCD 4.2, 4.3.1, 4.3.2 done gpg wrapper"
                            );

                            // remove file... clean function
                            let _ = cleanup_collaborator_temp_file(
                                &node_readcopy_path,
                                &base_uma_temp_directory_path,
                                );

                            // }

                            // // 4.5. Calculate SendFile Struct Hashes (Using Collaborator's Salts)
                            // 4.5 calculate hashes: HRCD
                            let calculated_hrcd_sendfile_hashes = hash_sendfile_struct_fields(
                                &room_sync_input.local_user_salt_list,
                                intray_send_time,
                                &file_bytes2send,
                            );

                            // Handle the Result from hash_sendfile_struct_fields
                            let calculated_hashes = match calculated_hrcd_sendfile_hashes {
                                Ok(hashes) => hashes,
                                Err(e) => {
                                    debug_log!("HRCD 4.5 Error calculating hashes: {}", e);
                                    continue; // Skip to the next file if hashing fails
                                }
                            };

                            debug_log!(
                                "HRCD 4.5 calculated_hashes {:?}",
                                calculated_hashes
                            );

                            // 4.6. Create SendFile Struct
                            let sendfile_struct = SendFile {
                                intray_send_time: Some(intray_send_time),
                                gpg_encrypted_intray_file: Some(file_bytes2send), // Clone needed here if file_bytes2send is used later
                                intray_hash_list: Some(calculated_hashes),  // Clone here as well
                                padnet_index_array: None,

                            };

                            make novel path with timestamp



                            if any issues: continue;
                             */


                            // // } else {

                            // // Wrapper of bytes to bytes:
                            // // 4.2.2 Read File Contents
                            // // 4.3.1 GPG Clearsign the File (with your private key)
                            // // 4.3.2 GPG Encrypt File (with their public key)
                            // let file_bytes2send = wrapper__path_to_clearsign_to_gpgencrypt_to_send_bytes(
                            //     &path_sendfile_readcopy_path,
                            //     &room_sync_input.remote_collaborator_public_gpg,
                            // )?;

                            // debug_log(
                            //     "HRCD 4.2, 4.3.1, 4.3.2 done gpg wrapper"
                            // );

                            // // }
                            // //

                            // // // 4.5. Calculate SendFile Struct Hashes (Using Collaborator's Salts)
                            // // 4.5 calculate hashes: HRCD
                            // let calculated_hrcd_sendfile_hashes = hash_sendfile_struct_fields(
                            //     &room_sync_input.local_user_salt_list,
                            //     intray_send_time,
                            //     &file_bytes2send,
                            // );

                            // // Handle the Result from hash_sendfile_struct_fields
                            // let calculated_hashes = match calculated_hrcd_sendfile_hashes {
                            //     Ok(hashes) => hashes,
                            //     Err(e) => {
                            //         debug_log!("HRCD 4.5 Error calculating hashes: {}", e);
                            //         continue; // Skip to the next file if hashing fails
                            //     }
                            // };

                            // debug_log!(
                            //     "HRCD 4.5 calculated_hashes {:?}",
                            //     calculated_hashes
                            // );

                            // // 4.6. Create SendFile Struct
                            // let sendfile_struct = SendFile {
                            //     intray_send_time: Some(intray_send_time),
                            //     gpg_encrypted_intray_file: Some(file_bytes2send), // Clone needed here if file_bytes2send is used later
                            //     intray_hash_list: Some(calculated_hashes),  // Clone here as well
                            //     padnet_index_array: None,

                            // };

                            // end padnet if?

                            debug_log!(
                                "HRCD 4.6 Create sendfile_struct {:?}",
                                sendfile_struct
                            );

                            debug_log!("HRCD 4.7.2 ready_signal.rt for set_prefail_flag_rt_timestamp__for_sendfile {:?}", ready_signal.rt);


                            // get updatedat value of .toml
                            let file_last_updatedat_time: u64 = get_updated_at_timestamp_from_toml_file(&path_sendfile_readcopy_path)?;


                            // 4.7.2 HRCD set_prefail_flag_rt_timestamp__for_sendfile
                            if let Err(e) = set_prefail_flag_rt_timestamp__for_sendfile(
                                file_last_updatedat_time, // for fail flag file name
                                ready_signal.rt, // for fail flag file value
                                &room_sync_input.remote_collaborator_name,
                            ) {
                                debug_log!("HRCD 4.7.2.e Error setting pre-fail flag: {}", e);
                                continue; // Handle error as you see fit
                            }
                            debug_log!("HRCD 4.7.2 prefail flag set using timestamp {:?}", &ready_signal.rt);

                            debug_log!(
                                "HRCD 4.6-7 Create sendfile_struct {:?}",
                                sendfile_struct
                            );


                            if *use_padnet_flag {

                                // Padnet Netowrk Layer
                                let serialized_file_struct_to_send = padnet_serialize_sendfile_struct(&sendfile_struct);

                                // --- 4.7 Send serializd-file: send UDP to intray ---
                                // 4.7.1 Send file
                                // 4.7 Send serializd-file Send if serialization was successful (handle Result)
                                match serialized_file_struct_to_send {
                                    Ok(extracted_serialized_data) => {  // Serialization OK
                                        match send_data_via_udp(
                                            &extracted_serialized_data,
                                            src,
                                            room_sync_input.remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip,
                                            ) {
                                            Ok(_) => {
                                                debug_log!("HRCD 4.7 File sent successfully");
                                                // ... (Handle successful send, e.g., update timestamp log)

                                                // --- 4.7.3 Get Timestamp ---
                                                //  Timestamp Log is depricated (most likely)
                                                debug_log("HRCD calling calling get_toml_file_updated_at_timestamp(), yes...");
                                                // if let Ok(timestamp) = get_toml_file_updated_at_timestamp(&file_path) {
                                                // //     update_collaborator_sendqueue_timestamp_log(
                                                // //         // TODO: Replace with the actual team channel name
                                                // //         &this_team_channelname,
                                                // //         &room_sync_input.remote_collaborator_name,
                                                // //     )?;
                                                //     // debug_log!("HRCD 4.7.3  Updated timestamp log for {}", room_sync_input.remote_collaborator_name);
                                                // }
                                            }
                                            Err(e) => {
                                                debug_log!("Error sending data: {}", e);
                                                // Handle the send error (e.g., log, retry, etc.)
                                            }
                                        }
                                    }
                                    Err(e) => { // Serialization error
                                        debug_log!("Serialization error: {}", e);
                                        // Handle the serialization error (e.g., log, skip file)
                                    }
                                }


                            } else {

                                let serialized_file_struct_to_send = serialize_send_file_struct(&sendfile_struct);

                                // --- 4.7 Send serializd-file: send UDP to intray ---
                                // 4.7.1 Send file
                                // 4.7 Send serializd-file Send if serialization was successful (handle Result)
                                match serialized_file_struct_to_send {
                                    Ok(extracted_serialized_data) => {  // Serialization OK
                                        match send_data_via_udp(
                                            &extracted_serialized_data,
                                            src,
                                            room_sync_input.remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip,
                                            ) {
                                            Ok(_) => {
                                                debug_log!("HRCD 4.7 File sent successfully");
                                                // ... (Handle successful send, e.g., update timestamp log)

                                                // --- 4.7.3 Get Timestamp ---
                                                //  Timestamp Log is depricated (most likely)
                                                debug_log("HRCD calling calling get_toml_file_updated_at_timestamp(), yes...");
                                                // if let Ok(timestamp) = get_toml_file_updated_at_timestamp(&file_path) {
                                                // //     update_collaborator_sendqueue_timestamp_log(
                                                // //         // TODO: Replace with the actual team channel name
                                                // //         &this_team_channelname,
                                                // //         &room_sync_input.remote_collaborator_name,
                                                // //     )?;
                                                //     // debug_log!("HRCD 4.7.3  Updated timestamp log for {}", room_sync_input.remote_collaborator_name);
                                                // }
                                            }
                                            Err(e) => {
                                                debug_log!("Error sending data: {}", e);
                                                // Handle the send error (e.g., log, retry, etc.)
                                            }
                                        }
                                    }
                                    Err(e) => { // Serialization error
                                        debug_log!("Serialization error: {}", e);
                                        // Handle the serialization error (e.g., log, skip file)
                                    }
                                }


                            }

                            // debugpause(30);
                            debug_log!("\nHRCD: bottom of ready_signal listener. (maybe)\n");




                        } // end of while
                    } // end of 4.4: if let Some(ref mut queue) = session_send_queue {
                    debug_log!("\nHRCD: end of inner match.\n");
                }, // end of the Ok inside the match: Ok((amt, src)) => {
                Err(e) if e.kind() == ErrorKind::WouldBlock => {
                    // TODO What is all this then?
                    // // --- 3.6 No Ready Signal, Log Periodically ---
                    // terrible idea: most people are simply not online most of the time
                    // this is not an error!!
                    // if last_debug_log_time.elapsed() >= Duration::from_secs(5) {
                    //     debug_log!("HRCD 3.6 {}: Listening for ReadySignal on port {}",
                    //                room_sync_input.remote_collaborator_name,
                    //                room_sync_input.remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip);
                    //     last_debug_log_time = Instant::now();
                    // }
                    debug_log!("HRCD Err(e) if e.kind() == ErrorKind::WouldBlock =>");
                },
                Err(e) => {
                    // --- 3.7 Handle Other Errors ---
                    debug_log!("HRCD #? {}: Error receiving data on ready_port: {} ({:?})",
                            room_sync_input.remote_collaborator_name, e, e.kind());
                    return Err(ThisProjectError::NetworkError(e.to_string()));
                }
            // thread::sleep(Duration::from_millis(100));
            } // match ready_socket.recv_from(&mut buf) {
        } // closes main loop
        debug_log!("\nHRCD: bottom of main loop.\n");
    }
    debug_log!("\nending HRCD\n");
    Ok(())
}

/// Creates a UDP socket bound to the specified address and port.
///
/// Simplifies socket creation by taking a SocketAddr directly.
/// Does one thing well.
///
/// # Arguments
///
/// * `socket_addr`: The address and port to bind to.
///
/// # Returns
///
/// * `Result<UdpSocket, ThisProjectError>`: The bound socket or an error if binding fails.
fn create_rc_udp_socket(socket_addr: SocketAddr) -> Result<UdpSocket, ThisProjectError> {
    UdpSocket::bind(socket_addr).map_err(|e| {
        ThisProjectError::NetworkError(format!("Failed to bind to UDP socket: {}", e))
    })
}

/// Creates a UDP socket bound to a locally chosen IP address and port based on the network band configuration.
///
/// This function uses the provided `band_local_network_type`, `band_local_user_ipv4_address`, and `band_local_user_ipv6_address`
/// to determine the appropriate IP address to bind to.
/// if type says ivp6 or ipv4, this function then attempts to bind
/// a UDP socket to that ip address and the specified port.
///
/// # Arguments
///
/// * `band_local_network_type`: A string slice indicating the network type ("ipv4" or "ipv6").
/// * `band_local_user_ipv4_address`: The local user's IPv4 address (used if `band_local_network_type` is "ipv4").
/// * `band_local_user_ipv6_address`: The local user's IPv6 address (used if `band_local_network_type` is "ipv6").
/// * `port`: The port number.
///
/// # Returns
///
/// * `Result<UdpSocket, ThisProjectError>`:  The created and bound UDP socket on success, or a `ThisProjectError` on failure (invalid IP, binding error, unsupported network type).
fn create_local_udp_socket(
    band_local_network_type: &str,
    band_local_user_ipv4_address: &Ipv4Addr,
    band_local_user_ipv6_address: &Ipv6Addr,
    port: u16,
) -> Result<UdpSocket, ThisProjectError> {
    let socket_addr = match band_local_network_type {
        "ipv6" => SocketAddr::new(IpAddr::V6(*band_local_user_ipv6_address), port),
        "ipv4" => SocketAddr::new(IpAddr::V4(*band_local_user_ipv4_address), port),
        _ => return Err(ThisProjectError::NetworkError("Unsupported network type".into())),
    };

    UdpSocket::bind(socket_addr).map_err(|e| {
        ThisProjectError::NetworkError(format!("Failed to bind to {} address: {}", band_local_network_type, e))
    })
}

// Result enum for the sync operation, allowing communication between threads
enum SyncResult {
    Success(u64), // Contains the new timestamp after successful sync
    Failure(ThisProjectError), // Contains an error if sync failed
}

// TODO likely need to be updated to abs-exe-parent-relative paths
/// Extracts the team channel name from the current working directory path.
///
/// Looks for the pattern "project_graph_data/team_channels/[CHANNEL_NAME]" in the absolute path
/// and returns the CHANNEL_NAME if found.
///
/// # Returns
/// * `Some(String)` - The team channel name if found
/// * `None` - If no channel name could be extracted (invalid path, missing markers, etc.)
///
/// # Example
/// ```
/// match get_current_team_channel_name_from_nav_path() {
///     Some(channel) => println!("Found channel: {}", channel),
///     None => println!("No channel found"),
/// }
/// ```
/// or:
/// let team_channel_name = match get_current_team_channel_name_from_nav_path() {
///     Some(name) => name,
///     None => {
///         debug_log!("Error: Could not get current channel name. Skipping set_as_active.");
///         return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
///     },
/// };
fn get_current_team_channel_name_from_nav_path() -> Option<String> {
    debug_log!("\nGCTCNFNP Starting: get_current_team_channel_name_from_nav_path()");

    // // Get absolute path from current directory
    // let absolute_path = match PathBuf::from(".").canonicalize() {
    //     Ok(path) => path,
    //     Err(e) => {
    //         debug_log!("Failed to get absolute path: {}", e);
    //         return None;
    //     }
    // };

    let absolute_path_string = match read_state_string("current_node_directory_path.txt") {
        Ok(path) => path,
        Err(e) => {
            debug_log!("GCTCNFNP Failed to get absolute path: {}", e);
            return None;
        }
    };

    debug_log!("GCTCNFNP Absolute path: {}", absolute_path_string);

    // Convert path to string
    // let path_str = absolute_path.to_string_lossy();

    // Define the marker we're looking for
    let marker = "project_graph_data/team_channels/";

    // Find marker position
    let position = match absolute_path_string.find(marker) {
        Some(pos) => pos,
        None => {
            debug_log!("GCTCNFNP Marker '{}' not found in path", marker);
            return None;
        }
    };

    // Extract everything after the marker
    let after_marker = &absolute_path_string[position + marker.len()..];
    debug_log!("GCTCNFNP Path after marker: {:?}", after_marker);

    // Get the first component after the marker
    let team_channel = after_marker
        .split(std::path::MAIN_SEPARATOR)
        .next()
        .map(String::from);

    // Validate and return
    match team_channel {
        Some(channel) if !channel.is_empty() => {
            debug_log!("GCTCNFNP Found team channel: {}", channel);
            Some(channel)
        }
        _ => {
            debug_log!("GCTCNFNP No valid team channel found");
            None
        }
    }
}

/// for normal mode, updates graph-navigation location and graph-state for both
/// 1. the struct
/// 2. the file-set version in .../project_graph_data/session_state_items
/// in both enter-new-node cases, in new-channel, cases, and in other cases
///
/// node.toml toml tables! store the ports: (check they are unique)
/// { collaborator_name = "bob", ready_port = 50001,
///     intray_port = 50002, gotit_port = 50003,
///     self_ready_port = 50004,
///     self_intray_port = 50005,
///     self_gotit_port = 50006 },
///
/// /// ... other imports ...
/// use std::sync::mpsc; /// For message passing between threads (if needed)
///
/// Version 2:
/// as set by node.toml in the team_channel node
///
/// for every other collaborator, you make:
/// two threds:
///     - your in-tray desk
///     - their in-tray desk
///
/// Each thred has six ports:
///     - three for each 'in-tray desk'
///
/// For each this-session-active-collaborator you keep a send-queue.
/// For one who never requested a file (who isn't online): no need to make a send-queue
///
///  Note current node members are not the same as channel members
///  a node may have narrower scope, but not broader.
///  this may especially apply to tasks only shared with relevant members
fn you_love_the_sync_team_office() -> Result<(), Box<dyn std::error::Error>> {
    /*
    "It's all fun and games until someone syncs a file."

    TODO:
    there needs to be a signal to wait to start
    the home_square_one flag may work
    */
    // --- WAIT FOR CHANNEL SELECTION ---
    sync_flag_ok_or_wait(5); // Wait for the sync flag to become "1"

    // 1.5.1 Check for halt-uma signal
    if should_halt_uma() {
        debug_log(">*< Halt signal received. Exiting The Uma. Closing... you_love_the_sync_team_office() |o|");
        return Ok(()); // Exit the function
    }

    debug_log("starting YLTSTO! UMA Sync Team Office...you_love_the_sync_team_office()");

    // // Read uma_local_owner_user from uma.toml
    // // maybe add gpg and make this a separate function TODO
    // let uma_toml_path = Path::new("uma.toml");
    // let user_metadata = toml::from_str::<toml::Value>(&fs::read_to_string(uma_toml_path)?)?;
    // let uma_local_owner_user = user_metadata["uma_local_owner_user"].as_str().unwrap().to_string();



    debug_log!(
        "YLTSTO Step 1: Reading LOCAL OWNER USER's name from {}",
        UMA_TOML_CONFIGFILE_PATH_STR,
    );

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("YLTSTO Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "YLTSTO Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            GpgError::PathError(error_msg)
        })?;

    // Read LOCAL OWNER USER's name from uma.toml
    let uma_local_owner_user = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("YLTSTO Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        GpgError::ValidationError(error_msg)
    })?;

    debug_log!("YLTSTO LOCAL OWNER USER's name is, uma_local_owner_user: {}", uma_local_owner_user);



    debug_log!("\n\nStarting UMA Sync Team Office for (local owner) -> {}", &uma_local_owner_user);

    // let session_connection_allowlists = make_sync_meetingroomconfig_datasets(&uma_local_owner_user)?;
    // debug_log!("session_connection_allowlists -> {:?}", &session_connection_allowlists);

    // 1. get sync_meetingroom_config_datasets
    let sync_meetingroom_config_datasets = match make_sync_meetingroomconfig_datasets(&uma_local_owner_user) {

        Ok(room_config_datasets) => {
            debug_log!(
                "Successfully generated room_config_datasets: {:?}",
                room_config_datasets
            );
            room_config_datasets
        },
        Err(e) => {
            debug_log!("YLTSTO Error creating room_config_datasets: {}", e);
            return Err(Box::new(e)); // Return the error early
        }
    };

    // 2. Create a list for threads for each collaborator on the room_config_datasets:
    /*
    TODO explain why/how a list:
    to gather for shutdown?
    */
    let mut collaborator_threads = Vec::new();

    // 3. get sync_meetingroom_config_dataset
    // with MeetingRoomSyncDataset, ForLocalOwnerDeskThread, ForRemoteCollaboratorDeskThread

    for this_meetingroom_iter in sync_meetingroom_config_datasets {
        // Extract data from this_meetingroom_iter
        // and place each pile in a nice baggy for each desk.
        debug_log!(
            "Configuring Connection: Setting up proverbial meetingroom and desk for/with: {}",
            this_meetingroom_iter.remote_collaborator_name,
        );

        // Create sub-structs
        let data_baggy_for_owner_desk = ForLocalOwnerDeskThread {
            local_user_name: this_meetingroom_iter.local_user_name.clone(),
            remote_collaborator_name: this_meetingroom_iter.remote_collaborator_name.clone(),
            local_user_salt_list: this_meetingroom_iter.local_user_salt_list.clone(),
            remote_collaborator_salt_list: this_meetingroom_iter.remote_collaborator_salt_list.clone(),
            local_user_ipv6_addr_list: this_meetingroom_iter.local_user_ipv6_addr_list.clone(),
            local_user_ipv4_addr_list: this_meetingroom_iter.local_user_ipv4_addr_list.clone(),
            remote_collaborator_ipv6_addr_list: this_meetingroom_iter.remote_collaborator_ipv6_addr_list.clone(),
            remote_collaborator_ipv4_addr_list: this_meetingroom_iter.remote_collaborator_ipv4_addr_list.clone(),
            local_user_gpg_publickey_id: this_meetingroom_iter.local_user_gpg_publickey_id.clone(),
            remote_collaborator_gpg_publickey_id: this_meetingroom_iter.remote_collaborator_gpg_publickey_id.clone(),
            local_user_public_gpg: this_meetingroom_iter.local_user_public_gpg.clone(),
            local_user_sync_interval: this_meetingroom_iter.local_user_sync_interval,
            // ready! (local)
            local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip: this_meetingroom_iter.local_user_ready_port__yourdesk_yousend__aimat_their_rmtclb_ip,
            // in-tray (local)
            localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip: this_meetingroom_iter.localuser_intray_port__yourdesk_youlisten__bind_yourlocal_ip,
            // got-it! (local)
            local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip: this_meetingroom_iter.local_user_gotit_port__yourdesk_yousend__aimat_their_rmtclb_ip,
            use_padnet: this_meetingroom_iter.use_padnet.clone(),
        };
        let data_baggy_for_collaborator_desk = ForRemoteCollaboratorDeskThread {
            remote_collaborator_name: this_meetingroom_iter.remote_collaborator_name.clone(),
            local_user_name: this_meetingroom_iter.local_user_name.clone(),
            remote_collaborator_salt_list: this_meetingroom_iter.remote_collaborator_salt_list.clone(),
            local_user_salt_list: this_meetingroom_iter.local_user_salt_list.clone(),
            remote_collaborator_ipv6_addr_list: this_meetingroom_iter.remote_collaborator_ipv6_addr_list,
            remote_collaborator_ipv4_addr_list: this_meetingroom_iter.remote_collaborator_ipv4_addr_list,
            local_user_ipv6_addr_list: this_meetingroom_iter.local_user_ipv6_addr_list,
            local_user_ipv4_addr_list: this_meetingroom_iter.local_user_ipv4_addr_list,
            remote_collaborator_gpg_publickey_id: this_meetingroom_iter.remote_collaborator_gpg_publickey_id.clone(),
            remote_collaborator_public_gpg: this_meetingroom_iter.remote_collaborator_public_gpg.clone(),
            remote_collaborator_sync_interval: this_meetingroom_iter.remote_collaborator_sync_interval,
            // ready! (remote)
            remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip: this_meetingroom_iter.remote_collab_ready_port__theirdesk_youlisten__bind_yourlocal_ip,
            // in-tray (remote)
            remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip: this_meetingroom_iter.remote_collab_intray_port__theirdesk_yousend__aimat_their_rmtclb_ip,
            // got-it! (remote)
            remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip: this_meetingroom_iter.remote_collab_gotit_port__theirdesk_youlisten__bind_yourlocal_ip,
            use_padnet: this_meetingroom_iter.use_padnet.clone(),
        };

        // Create the two "meeting room desks" for each collaborator pair:
        // Your Desk
        let owner_desk_thread = thread::spawn(move || {
            let _ = handle_local_owner_desk(data_baggy_for_owner_desk);

        });
        // Their Desk
        let collaborator_desk_thread = thread::spawn(move || {
            let _ = handle_remote_collaborator_meetingroom_desk(&data_baggy_for_collaborator_desk);
        });
        collaborator_threads.push(owner_desk_thread);
        collaborator_threads.push(collaborator_desk_thread);
    }

    // ... Handle join logic for your threads...
    for thread in collaborator_threads {
        thread.join().expect("Failed to join thread.");
    }
    debug_log!("UMA Sync Team Office closed");
    println!("UMA Sync Team Office closed");
    Ok(())
}

// TODO doc string needed, massive, huge.
/// Proverbial Main()
fn we_love_projects_loop() -> Result<(), io::Error> {
    /*

    setup and bootstrap
    - load data
    - start Graph Navigation Struct instance
    - do first bootstrap TUI display of team-channel choices

    Command Loop
    1. Get input
    2. process input/command
    3. show updated state
    */

    // TODO abs exe-parent path needed
    // Load UMA configuration from uma.toml
    // let uma_toml_path = Path::new("uma.toml");

   // TUI Setup, TODO
    /*
    If there is an umi.toml,
    and it has tui_height/tui_height that are not 80/24
    use those new values (from umi.toml) for
    tui_height =
    tui_width =

    or maybe this gets done in the project-manager-thread (not the sink thread)
    */


    // Step 1: Get the absolute path to the executable's parent directory
    let executable_parent_directory = match get_absolute_path_to_executable_parentdirectory() {
        Ok(path) => path,
        Err(e) => {
            debug_log(&format!("Error getting executable directory: {}", e));
            return Err(io::Error::new(
                io::ErrorKind::NotFound,
                format!("Failed to determine executable directory: {}", e)
            ));
        }
    };

    debug_log!("executable_parent_directory: {:?}", executable_parent_directory);

    // Step 2: Join the target path to the executable directory
    let target_path = executable_parent_directory.join("project_graph_data/team_channels");

    // Step 3: Verify the path exists
    let path_exists = match abs_executable_directory_relative_exists(&target_path) {
        Ok(exists) => exists,
        Err(e) => {
            debug_log(&format!("Error checking if path exists: {}", e));
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("Failed to check if path exists: {}", e)
            ));
        }
    };

    // Step 4: Canonicalize the path if it exists, otherwise error
    let current_exe_dir_relative_abs_path_canonicalized = if path_exists {
        match target_path.canonicalize() {
            Ok(canonical_path) => canonical_path,
            Err(e) => {
                debug_log(&format!("Error canonicalizing path: {}", e));
                return Err(io::Error::new(
                    io::ErrorKind::Other,
                    format!("Failed to canonicalize path: {}", e)
                ));
            }
        }
    } else {
        debug_log(&format!("Path does not exist: {:?}", target_path));
        return Err(io::Error::new(
            io::ErrorKind::NotFound,
            format!("Path does not exist: {:?}", target_path)
        ));
    };

    debug_log!("Current executable-relative absolute path: {:?}", current_exe_dir_relative_abs_path_canonicalized);

    debug_log!("Using project path: {:?}", current_exe_dir_relative_abs_path_canonicalized);

    debug_log!(" {:?}", current_exe_dir_relative_abs_path_canonicalized);

    // getting data from uma.toml
    /*
    requires new functions:
    simple read / clearsign-read
    u8 int
    u64 int
    or... how to do?
    int out?
    */

    // Get absolute path to uma.toml configuration file
    let relative_uma_toml_path = UMA_TOML_CONFIGFILE_PATH_STR;
    let absolute_uma_toml_path = make_file_path_abs_executabledirectoryrelative_canonicalized_or_error(relative_uma_toml_path)
        .map_err(|e| {
            let error_msg = format!("___ Failed to locate uma.toml configuration file: {}", e);
            println!("Error: {}", error_msg);
            io::Error::new(io::ErrorKind::InvalidData, error_msg)
        })?;

    // Convert PathBuf to string for TOML reading
    let absolute_uma_toml_path_str = absolute_uma_toml_path
        .to_str()
        .ok_or_else(|| {
            let error_msg = "__ Unable to convert UMA TOML path to string".to_string();
            println!("Error: {}", error_msg);
            io::Error::new(io::ErrorKind::InvalidData, error_msg)
        })?;


    // Read LOCAL OWNER USER's name from uma.toml
    let uma_local_owner_user = read_single_line_string_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_local_owner_user"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // u64
    let default_im_messages_expiration_days = read_u64_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_default_im_messages_expiration_days"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read default_im_messages_expiration_days: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // u64
    let default_task_nodes_expiration_days = read_u64_field_from_toml(
        absolute_uma_toml_path_str,
        "uma_default_task_nodes_expiration_days"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read default_task_nodes_expiration_days: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // u8
    let tui_height = read_u8_field_from_toml(
        absolute_uma_toml_path_str,
        "tui_height"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read tui_height: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // u8
    let tui_width = read_u8_field_from_toml(
        absolute_uma_toml_path_str,
        "tui_width"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read tui_width: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // Read use_padnet from uma.toml
    let use_padnet = read_bool_field_from_toml(
        absolute_uma_toml_path_str,
        "use_padnet"
    ).map_err(|e| {
        let error_msg = format!("WLPL Failed to read LOCAL OWNER USER's name: {}", e);
        println!("Error: {}", error_msg);
        io::Error::new(io::ErrorKind::InvalidData, error_msg)
    })?;

    // node-graph navigation 'state' initial setup
    let graph_navigation_instance_state = GraphNavigationInstanceState {
        // local_owner_user: user_metadata["uma_local_owner_user"].as_str().unwrap().to_string(),
        // active_team_channel: String::new(), // or perhaps "None", or "Default"
        // default_im_messages_expiration_days: user_metadata["uma_default_im_messages_expiration_days"].as_integer().unwrap() as u64,
        // default_task_nodes_expiration_days: user_metadata["uma_default_task_nodes_expiration_days"].as_integer().unwrap() as u64,

        // // look into making these smaller for memory use...unless there is a reason
        // // this is not pixels, but character-lines on a single screen
        // // tui_height: user_metadata["tui_height"].as_integer().unwrap() as u8,
        // // tui_width: user_metadata["tui_width"].as_integer().unwrap() as u8,

        // // Handle missing or invalid values for tui_height and tui_width:
        // tui_height: user_metadata.get("tui_height")
        //     .and_then(Value::as_integer)
        //     .map(|height| height as u8) // Convert to u8 if valid
        //     .unwrap_or(24),  // Default to 24 if missing or invalid

        // tui_width: user_metadata.get("tui_width")
        //     .and_then(Value::as_integer)
        //     .map(|width| width as u8) // Convert to u8 if valid
        //     .unwrap_or(80), // Default to 80 if missing or invalid

        local_owner_user: uma_local_owner_user,
        active_team_channel: String::new(), // or perhaps "None", or "Default"
        default_im_messages_expiration_days: default_im_messages_expiration_days,
        default_task_nodes_expiration_days: default_task_nodes_expiration_days,

        // look into making these smaller for memory use...unless there is a reason
        // this is not pixels, but character-lines on a single screen
        // tui_height: user_metadata["tui_height"].as_integer().unwrap() as u8,
        // tui_width: user_metadata["tui_width"].as_integer().unwrap() as u8,

        // Handle missing or invalid values for tui_height and tui_width:
        tui_height: tui_height,  // Default to 24 if missing or invalid
        tui_width: tui_width, // Default to 80 if missing or invalid

        current_full_file_path: current_exe_dir_relative_abs_path_canonicalized, // Set initial absolute path
        // Initialize other fields of GraphNavigationInstanceState
        current_node_teamchannel_collaborators_with_access: Vec::new(),
        current_node_name: String::new(),
        current_node_owner: String::new(),
        current_node_description_for_tui: String::new(),
        current_node_directory_path: PathBuf::new(),
        current_node_unique_id: Vec::new(),
        current_node_members: Vec::new(),
        home_square_one: true,
        // Project Areas,
        pa1_process: String::new(),
        pa2_schedule: Vec::new(), // Vec<u64>,?
        pa3_users: String::new(),
        pa4_features: String::new(),
        pa5_mvp: String::new(),
        pa6_feedback: String::new(),
        // message-post

        // message_post_gpgtoml_required bool option
        message_post_gpgtoml_required: None,

        // Integer validation ranges as tuples (min, max) - inclusive bounds
        message_post_data_format_specs_integer_ranges_from_to_tuple_array: None,

        // Integer-string validation ranges as tuples (min, max) for the integer part
        message_post_data_format_specs_int_string_ranges_from_to_tuple_array: None,

        // Maximum string length
        message_post_max_string_length_int: None,

        // Whether posts are public or private
        message_post_is_public_bool: None,

        // Whether user confirmation is required before posting
        message_post_user_confirms_bool: None,

        // Start time for accepting posts (UTC POSIX timestamp)
        message_post_start_date_utc_posix: None,

        // End time for accepting posts (UTC POSIX timestamp)
        message_post_end_date_utc_posix: None,

        // Use OTP network layer (bool)
        use_padnet: use_padnet,
    };

    // if !verify_gpg_signature(&local_user) {
    //     println!("GPG key verification failed (placeholder)");
    //     return Err(io::Error::new(io::ErrorKind::Other, "GPG Verification Failed"));
    // }

    // // Create App instance
    // let mut app = App::new(graph_navigation_instance_state.clone()); // Pass graph_navigation_instance_state

    // Create App instance
    let mut app = match App::new(graph_navigation_instance_state.clone()) {
        Ok(app) => app,
        Err(e) => {
            debug_log(&format!("Failed to initialize App: {}", e));
            return Err(e); // Or handle the error in another appropriate way
        }
    };

    // -- bootstrap: Start in MainCommand Mode ---
    app.input_mode = InputMode::MainCommand; // Initialize app in command mode

    // bootstrap: load team-channels
    app.update_directory_list()?;

    // bootstrap: TUI display:
    print!("\x1B[2J\x1B[1;1H"); // Clear the screen
    let _ = write_formatted_navigation_legend_to_tui();

    tiny_tui::simple_render_list(
        &app.tui_directory_list,
        &app.current_path,
    );


    // Start
    loop {
        // // Read the 'continue_uma.txt' file
        // let file_content = match fs::read_to_string(CONTINUE_UMA_PATH_STR) {
        //     Ok(content) => content,
        //     Err(_) => {
        //         debug_log!("Error reading 'continue_uma.txt'. Continuing..."); // Handle the error (e.g., log it) but continue for now
        //         continue; // Skip to the next loop iteration
        //     }
        // };
        // // break loop if continue=0
        // if file_content.trim() == "0" {
        //     debug_log("wlpl 'continue_uma.txt' is 0. we_love_projects_loop() Exiting loop.");
        //     break;
        // }

        // Read the 'continue_uma.txt' file and check if we should exit
        if should_halt_uma() {
            debug_log("wlpl 'continue_uma.txt' is 0. we_love_projects_loop() Exiting loop.");
            break;
        }

        // Update GraphNavigationInstanceState based on the current path
        debug_log("start loop: we_love_projects_loop()");
        debug_log!(
            "wlpl &app.current_path -> {:?}",
            &app.current_path,
        );

        debug_log!("wlpl app.input_mode {:?}", &app.input_mode);

        debug_log!(
            "wlpl &app.next_path_lookup_table -> {:?}",
            &app.next_path_lookup_table
        );

        debug_log!(
            "wlpl &app.task_display_table -> {:?}",
            &app.task_display_table
        );

        app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();

        debug_log!(
            "wlpl app.current_path.clone(); -> {:?}",
            &app.current_path.clone(),
        );

        debug_log!(
            "wlpl &app.graph_navigation_instance_state.current_full_file_path -> {:?}",
            &app.graph_navigation_instance_state.current_full_file_path,
        );

        // -- Here: this function reads state and adds current graph-node-location data
        app.graph_navigation_instance_state.nav_graph_look_read_node_toml();

        // --- this is or maybe should be part of the TUI (no state record)

        //  Check for exit signal
        if should_halt_uma() {
            debug_log("Exiting we_love_projects_loop");
            break;
        }

        /*
        Command Loop
        1. Get input
        2. process input/command
        3. show updated state


        # Main Command Loop
        1. input: getting a command from the user
	       - Q: for refresh, is there a way to separate input (input buffer?)
	       to display current user typing along with refreshed other items etc?

        2. process the command

        If int:
        - move to the path
        - check if new place is a node
        - load new path into Nav state
        - load basic display info:
        -- name
        -- description
        -- scope n schedule (user feature:, subfeatures:, days:}

        Handle commands such as T, M, etc.

        Handle change of Mode:
        (maybe all input-mode is handled not in this loop)

        3. Tui: showing the user where they are
        (loop)

        */

        // 1. get input/command
        let input = tiny_tui::get_input()?;

        // 2. handle input/command
        // If in main command mode, handle main commands:
        // ?. Update directory list (only in MainCommand mode) - MOVE THIS
        if app.input_mode == InputMode::MainCommand {
            if handle_command_main_mode(&input, &mut app)? {
                return Ok(());
            }
            app.update_directory_list()?;

        }

        // // 2. handle input/command
        // if handle_command_main_mode(&input, &mut app, &graph_navigation_instance_state)? {
        //     return Ok(());
        // } else if app.input_mode == InputMode::MainCommand {
        //     handle_numeric_input(&input, &mut app, &graph_navigation_instance_state)?;
        // }



        // 3. Render TUI *before* input:
        if app.input_mode == InputMode::InsertText {

            debug_log("we love projects: handle_insert_text_input");

            if input == "m" {
                // pass

            } else if input == "back" {
                debug_log("escape toggled");
                // app.input_mode = InputMode::MainCommand; // Access input_mode using self
                // app.current_path.pop(); // Go back to the parent directory
                // app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone(); // Update full path after popping.
                // app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                // app.update_directory_list()?;

                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone(); // Update full path after popping.
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                tiny_tui::render_list(
                    &app.tui_directory_list,
                    &app.current_path,
                    // Project Areas
                    &app.graph_navigation_instance_state.pa1_process,
                    &app.graph_navigation_instance_state.pa2_schedule,  // str? vec<u64>?
                    &app.graph_navigation_instance_state.pa3_users,
                    &app.graph_navigation_instance_state.pa4_features,
                    &app.graph_navigation_instance_state.pa5_mvp,
                    &app.graph_navigation_instance_state.pa6_feedback,
                );
                app.update_directory_list()?;  // refresh to current cwd display items

            } else if input == "b" {
                debug_log("escape toggled");
                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                app.update_directory_list()?;  // refresh to current cwd display items
            } else if input == "q" {
                debug_log("escape toggled");
                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                app.update_directory_list()?;  // refresh to current cwd display items
            } else if !input.is_empty() {
                debug_log("!input.is_empty()");

                let local_owner_user = &app.graph_navigation_instance_state.local_owner_user; // Access using self

                // 1. final path name (.toml)
                let message_path = get_next_message_file_path(&app.current_path, local_owner_user);
                debug_log(&format!("Next message path: {:?}", message_path)); // Log the calculated message path

                // 2. make message file
                add_new_messagepost_message(
                    &message_path,
                    local_owner_user,
                    input.trim(),
                    &app.graph_navigation_instance_state, // Pass using self
                ).expect("handle_insert_text_input: Failed to add message");

                app.load_messagepost_messages(); // Access using self
            }
        }

        // 3. Render TUI *before* input:
        if app.input_mode == InputMode::TaskCommand {

            debug_log("we love projects: task mode");

            // First, try to handle numeric input
            if let Ok(index) = input.trim().parse::<usize>() {
                // Check if the index exists in the path lookup table
                if let Some(target_path) = app.next_path_lookup_table.get(&index) {
                    debug_log(&format!("Selected path from lookup table: {:?}", target_path));
                    // Regular directory navigation
                    app.current_path = target_path.clone();
                    app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone();
                    app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                    app.input_mode = InputMode::MainCommand; // Access input_mode using self

                } else {
                    debug_log(&format!("Invalid index: {} not found in path lookup table", index));
                }
            }

            // // app.update_task_display()?;
            // let (headers, data) = app.update_task_display()?;
            // debug_log!(
            //     "headers -> {:?} data -> {:?}",
            //      headers,
            //      data,
            // );
            // tiny_tui::display_table(&headers, &data);

            // app.handle_tui_action(); // Remove the extra argument here

            debug_log!(
                "we_love_projects_loop() app.next_path_lookup_table {:?}",
                 app.next_path_lookup_table,
            );

            debug_log("handle_tui_action() started in we_love_projects_loop()");

            if input == "t" {

                // pass (no additional action if task mode entered)

            } else if input == "move" {
                let _ = move_task(
                    &app.next_path_lookup_table,
                );

            } else if input == "back" {
                debug_log("escape toggled");
                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                app.graph_navigation_instance_state.current_full_file_path = app.current_path.clone(); // Update full path after popping.
                app.graph_navigation_instance_state.nav_graph_look_read_node_toml(); // ???

                tiny_tui::render_list(
                    &app.tui_directory_list,
                    &app.current_path,
                    // Project Areas
                    &app.graph_navigation_instance_state.pa1_process,
                    &app.graph_navigation_instance_state.pa2_schedule,
                    &app.graph_navigation_instance_state.pa3_users,
                    &app.graph_navigation_instance_state.pa4_features,
                    &app.graph_navigation_instance_state.pa5_mvp,
                    &app.graph_navigation_instance_state.pa6_feedback,
                );
                app.update_directory_list()?;  // refresh to current cwd display items

            } else if input == "q" {
                debug_log("escape toggled");
                app.input_mode = InputMode::MainCommand; // Access input_mode using self
                app.current_path.pop(); // Go back to the parent directory
                tiny_tui::render_list(
                    &app.tui_directory_list,
                    &app.current_path,
                    // Project Areas
                    &app.graph_navigation_instance_state.pa1_process,
                    &app.graph_navigation_instance_state.pa2_schedule,
                    &app.graph_navigation_instance_state.pa3_users,
                    &app.graph_navigation_instance_state.pa4_features,
                    &app.graph_navigation_instance_state.pa5_mvp,
                    &app.graph_navigation_instance_state.pa6_feedback,
                );
                app.update_directory_list()?;  // refresh to current cwd display items

            } else if !input.is_empty() {
                debug_log("!input.is_empty()");

                // let local_owner_user = &app.graph_navigation_instance_state.local_owner_user; // Access using self

                // // 1. final path name (.toml)
                // let message_path = get_next_message_file_path(&app.current_path, local_owner_user);
                // debug_log(&format!("Next message path: {:?}", message_path)); // Log the calculated message path

                // // 2. make message file
                // add_new_messagepost_message(
                //     &message_path,
                //     local_owner_user,
                //     input.trim(),
                //     None,
                //     &app.graph_navigation_instance_state, // Pass using self
                // ).expect("handle_insert_text_input: Failed to add message");

                // app.load_messagepost_messages(); // Access using self
            }
        }


        ///////////
        // Display
        ///////////

        // boostrap


        // Clear the screen
        print!("\x1B[2J\x1B[1;1H");

        // bootstrap: simple TUI display when at home screen
        debug_log!("app.current_path.to_string_lossy() -> {:?}", app.current_path.to_string_lossy());

        if app.current_path.to_string_lossy() == "project_graph_data/team_channels" {
            let _ = write_formatted_navigation_legend_to_tui();
            println!("Select a Team-Channel (by number):");
            tiny_tui::simple_render_list(
                &app.tui_directory_list,
                &app.current_path);

        } else {

            match app.input_mode {
                InputMode::MainCommand => tiny_tui::render_list(
                    &app.tui_directory_list,
                    &app.current_path,
                    // Project Areas
                    &app.graph_navigation_instance_state.pa1_process,
                    &app.graph_navigation_instance_state.pa2_schedule,
                    &app.graph_navigation_instance_state.pa3_users,
                    &app.graph_navigation_instance_state.pa4_features,
                    &app.graph_navigation_instance_state.pa5_mvp,
                    &app.graph_navigation_instance_state.pa6_feedback,
                ),
                InputMode::TaskCommand => { /* Task list rendering logic */ },
                InputMode::InsertText => tiny_tui::simple_render_list(
                    &app.tui_textmessage_list,
                    &app.current_path,
                    // &app.graph_navigation_instance_state.agenda_process,
                    // &app.graph_navigation_instance_state.goals_features_subfeatures_tools_targets,
                    // &app.graph_navigation_instance_state.scope,
                    // &app.graph_navigation_instance_state.pa2_schedule,
                ),
            };
        }

    } // end of main loop
    debug_log("Finish: we love project loop.");
    debug_log(">*< Halt signal received. Exiting The Uma. Closing... we_love_projects_loop() |o|");

    Ok(())
}

/// Helper function to set the sync flag to a specific value
/// for set_sync_start_ok_flag_to_true()
/// for initialize_ok_to_start_sync_flag_to_false()
///
/// # Arguments
///
/// * `value` - The byte value to write to the flag file ("0" for false, "1" for true)
/// * `operation_name` - A description of the operation for logging purposes
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or failure with detailed error information
fn set_sync_flag(value: &[u8], operation_name: &str) -> Result<(), io::Error> {

    debug_log!("starting: set_sync_flag(), operation_name->{}", operation_name);

    // Get the absolute path to the flag file relative to the executable
    // let flag_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
    //     "data/flags/ok_to_start_sync_flag.txt"
    // )?;

    // // Get the absolute path to the sync flag file
    // let flag_path = match get_sync_start_ok_flag_path() {
    //     Ok(path) => path,
    //     Err(e) => {
    //         debug_log!("Error resolving path to sync flag from get_sync_start_ok_flag_path(): {}", e);
    //         PathBuf::new()
    //     }
    // };

    let mut flag_path = PathBuf::new(); // Default value if the function errors

    // TODO How to handle error in get_sync_start_ok_flag_path?
    if let Ok(path) = get_sync_start_ok_flag_path() {
        flag_path = path; // Only set if the function returns Ok
    } else {
        debug_log!("Error resolving path to sync flag from get_sync_start_ok_flag_path()");
    }


    // Ensure parent directories exist
    if let Some(parent_dir) = flag_path.parent() {
        fs::create_dir_all(parent_dir)?;
    }

    // Remove existing file if it exists
    match fs::remove_file(&flag_path) {
        Ok(_) => debug_log!("Old 'ok_to_start_sync_flag.txt' file deleted."),
        Err(e) if e.kind() == io::ErrorKind::NotFound => {
            // File doesn't exist, that's fine
        },
        Err(e) => {
            // Other errors might be important (permissions, etc.)
            debug_log!("Warning: couldn't remove old flag file: {}", e);
        }
    }

    // Create the file
    let mut file = File::create(&flag_path)
        .map_err(|e| {
            debug_log!("Failed to create 'ok_to_start_sync_flag.txt' file: {}", e);
            e
        })?;

    // Write the value
    file.write_all(value)
        .map_err(|e| {
            debug_log!("Failed to write to 'ok_to_start_sync_flag.txt' file: {}", e);
            e
        })?;

    debug_log!("Successfully {} at: {:?}", operation_name, flag_path);
    Ok(())
}

/// Sets the synchronization start flag to true ("1"), allowing synchronization to proceed.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or failure with detailed error information
///
/// # Errors
///
/// This function can fail if:
/// * Path resolution fails
/// * File creation fails (e.g., insufficient permissions)
/// * Writing to the file fails
pub fn set_sync_start_ok_flag_to_true() -> Result<(), io::Error> {
    set_sync_flag(b"1", "set sync flag to true")
}

/// Initializes the synchronization start flag to false ("0"), indicating that
/// synchronization should wait.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or failure with detailed error information
///
/// # Errors
///
/// This function can fail if:
/// * Path resolution fails
/// * File creation fails (e.g., insufficient permissions)
/// * Writing to the file fails
pub fn initialize_ok_to_start_sync_flag_to_false() -> Result<(), io::Error> {
    set_sync_flag(b"0", "initialized sync flag to false")
}

/// Creates a unique temporary file in the specified base directory with configurable retry logic.
///
/// # Project Context
/// This function generates temporary file names for intermediate processing
/// in our application where we cannot use third-party dependencies. The file
/// is created atomically to prevent race conditions where multiple processes
/// or threads might generate the same name. This version allows the caller
/// to configure retry behavior based on their specific use case (e.g., high
/// contention environments may need more retries, low-priority operations
/// may want fewer retries to fail fast).
///
/// # Implementation Strategy
/// - Uses process ID, thread ID, and nanosecond timestamp for uniqueness
/// - Attempts atomic file creation with `create_new(true)` flag
/// - Retries up to `number_of_attempts` times with configurable delay
/// - Different timestamps on each retry provide additional uniqueness
/// - Parameterized retry logic allows tuning for different deployment scenarios
///
/// # Arguments
/// * `base_path` - The directory where the temporary file will be created (must exist)
/// * `prefix` - A prefix for the filename to identify the file's purpose (e.g., "cache", "upload")
/// * `number_of_attempts` - Maximum number of creation attempts (recommended: 3-10)
/// * `retry_delay_ms` - Milliseconds to wait between retry attempts (recommended: 1-100)
///
/// # Returns
/// * `Ok(PathBuf)` - Absolute path to the newly created unique temporary file
/// * `Err(io::Error)` - If file creation fails after all retry attempts or other I/O error
///
/// # Error Conditions
/// - `CUTF: system time unavailable` - System clock error (rare, catastrophic)
/// - `CUTF: max retry attempts exceeded` - Could not create unique file after all attempts
/// - `CUTF: unexpected loop exit` - Internal logic error (should never occur)
/// - Standard I/O errors: permission denied, disk full, path not found, etc.
///
/// # Safety & Reliability
/// - No panic: all error cases return Result
/// - No heap allocation in error messages (uses static strings with CUTF prefix)
/// - Bounded retry loop (caller-specified maximum attempts)
/// - Atomic file creation prevents race conditions
/// - Thread-safe: uses thread-local IDs
/// - Handles system clock errors gracefully
///
/// # Configuration Guidelines
/// - **Low contention** (single-threaded, low frequency): `number_of_attempts = 3`, `retry_delay_ms = 1`
/// - **Medium contention** (multi-threaded application): `number_of_attempts = 5`, `retry_delay_ms = 1-5`
/// - **High contention** (distributed system, many processes): `number_of_attempts = 10`, `retry_delay_ms = 10-50`
/// - **Fast-fail scenarios** (can afford to fail): `number_of_attempts = 1`, `retry_delay_ms = 0`
///
/// # Edge Cases Handled
/// - Zero attempts: Function will try once (loop runs 0..0 means 0 iterations, caught by unreachable error)
/// - System time moves backwards: Handled gracefully with retry
/// - Concurrent file creation: Atomic `create_new` prevents race conditions
/// - Disk full or permission errors: Immediate return without retries
///
/// # Example
/// ```
/// use std::path::Path;
///
/// let base = Path::new("/tmp");
///
/// // Standard usage
/// match create_unique_temp_filepathbuf(base, "myapp", 5, 1) {
///     Ok(path) => {
///         println!("Created: {:?}", path);
///         // Use the file...
///         // Remember to delete it when done!
///         let _ = std::fs::remove_file(path);
///     },
///     Err(e) => {
///         eprintln!("Failed to create temp file: {}", e);
///         // Handle error - application continues
///     }
/// }
///
/// // High-contention scenario
/// match create_unique_temp_filepathbuf(base, "distributed", 10, 10) {
///     Ok(path) => { /* use file */ },
///     Err(e) => { /* handle gracefully */ }
/// }
/// ```
///
/// # Security Considerations
/// - File names are predictable (not cryptographically random)
/// - Suitable for temporary storage, not for security-critical scenarios
/// - Consider file permissions on created files (inherits from OpenOptions defaults)
/// - Caller must ensure base_path is in a secure location
///
/// # Performance Considerations
/// - Each retry costs `retry_delay_ms` milliseconds
/// - Maximum possible delay: `number_of_attempts * retry_delay_ms`
/// - Nanosecond timestamp provides ~1 billion unique values per second per thread
/// - Thread ID formatting allocates small string (unavoidable with std::thread API)
pub fn create_unique_temp_filepathbuf(
    base_path: &Path,
    prefix: &str,
    number_of_attempts: u32,
    retry_delay_ms: u64,
) -> Result<PathBuf, io::Error> {
    use std::process;
    use std::thread;
    use std::time::{SystemTime, UNIX_EPOCH, Duration};
    use std::fs::OpenOptions;
    use std::io;

    // Production catch: validate number_of_attempts is non-zero
    // Zero attempts would make function always fail
    if number_of_attempts == 0 {
        return Err(io::Error::new(
            io::ErrorKind::InvalidInput,
            "CUTF: number_of_attempts must be greater than zero",
        ));
    }

    // Get process ID once (constant for this process)
    let pid = process::id();

    // Get thread ID and format it for filename use
    let thread_id = thread::current().id();
    let thread_id_string = format!("{:?}", thread_id);

    // Clean thread ID: remove "ThreadId(" prefix and ")" suffix
    // This converts "ThreadId(123)" to "123"
    let thread_id_clean = thread_id_string
        .trim_start_matches("ThreadId(")
        .trim_end_matches(')');

    // Attempt to create unique file with retry logic
    for attempt in 0..number_of_attempts {
        // Get current timestamp with nanosecond precision
        // This provides uniqueness across time
        let timestamp_result = SystemTime::now().duration_since(UNIX_EPOCH);

        let timestamp_nanos = match timestamp_result {
            Ok(duration) => duration.as_nanos(),
            Err(_) => {
                // System time error (e.g., clock moved backwards)
                // In production, we handle this gracefully and continue
                if attempt == number_of_attempts - 1 {
                    return Err(io::Error::new(
                        io::ErrorKind::Other,
                        "CUTF: system time unavailable",
                    ));
                }
                // Try again with next attempt
                thread::sleep(Duration::from_millis(retry_delay_ms));
                continue;
            }
        };

        // Construct filename: prefix_pid_threadid_timestamp.tmp
        // Example: myapp_12345_67_1234567890123456789.tmp
        let filename = format!(
            "{}_{}_{}_{}.tmp",
            prefix, pid, thread_id_clean, timestamp_nanos
        );

        // Build absolute path
        let file_path = base_path.join(&filename);

        // Attempt to create file atomically
        // create_new(true) ensures the operation fails if file exists
        // This prevents race conditions with other processes/threads
        match OpenOptions::new()
            .write(true)
            .create_new(true)  // Critical: fails if file already exists
            .open(&file_path)
        {
            Ok(_file) => {
                // Success: file created exclusively
                // File handle is dropped here, closing the file
                // Caller is responsible for file cleanup
                return Ok(file_path);
            }
            Err(e) if e.kind() == io::ErrorKind::AlreadyExists => {
                // File name collision detected
                // This is expected in high-concurrency scenarios

                // Production catch: check if we've exhausted retries
                if attempt == number_of_attempts - 1 {
                    // Final attempt failed - return descriptive error
                    return Err(io::Error::new(
                        io::ErrorKind::AlreadyExists,
                        "CUTF: max retry attempts exceeded",
                    ));
                }

                // Wait briefly before retry
                // This allows timestamp to change and reduces contention
                thread::sleep(Duration::from_millis(retry_delay_ms));

                // Continue to next attempt
                continue;
            }
            Err(e) => {
                // Other error occurred (permissions, disk full, etc.)
                // Return immediately - retrying won't help
                return Err(e);
            }
        }
    }

    // Should be unreachable due to loop logic, but rust requires this
    // Production safety: return error rather than panic
    Err(io::Error::new(
        io::ErrorKind::Other,
        "CUTF: unexpected loop exit",
    ))
}

// =============================================================================
// Tests
// =============================================================================

#[cfg(test)]
mod tempname_tests {
    use super::*;
    use std::fs;

    /// Test basic functionality: can we create a temp file with standard parameters?
    #[test]
    fn test_create_temp_file_basic() {
        let temp_dir = std::env::temp_dir();

        let result = create_unique_temp_filepathbuf(&temp_dir, "test", 5, 1);

        assert!(result.is_ok(), "Should successfully create temp file");

        let path = result.unwrap();
        assert!(path.exists(), "Created file should exist");
        assert!(path.starts_with(&temp_dir), "File should be in temp directory");

        // Cleanup
        let _ = fs::remove_file(path);
    }

    /// Test that multiple files created rapidly are unique
    #[test]
    fn test_create_multiple_unique_files() {
        let temp_dir = std::env::temp_dir();
        let mut paths = Vec::new();

        // Create 5 temp files in rapid succession
        for _ in 0..5 {
            let result = create_unique_temp_filepathbuf(&temp_dir, "multi", 5, 1);
            assert!(result.is_ok(), "Should create file");
            paths.push(result.unwrap());
        }

        // Verify all paths are unique
        for i in 0..paths.len() {
            for j in (i + 1)..paths.len() {
                assert_ne!(paths[i], paths[j], "Paths should be unique");
            }
        }

        // Verify all files exist
        for path in &paths {
            assert!(path.exists(), "File should exist");
        }

        // Cleanup
        for path in paths {
            let _ = fs::remove_file(path);
        }
    }

    /// Test that function returns error for non-existent directory
    #[test]
    fn test_nonexistent_directory() {
        let bad_path = Path::new("/this/path/definitely/does/not/exist/nowhere/12345");

        let result = create_unique_temp_filepathbuf(bad_path, "test", 3, 1);

        assert!(result.is_err(), "Should fail for non-existent directory");
    }

    /// Test filename format contains expected components
    #[test]
    fn test_filename_format() {
        let temp_dir = std::env::temp_dir();

        let result = create_unique_temp_filepathbuf(&temp_dir, "prefix", 5, 1);
        assert!(result.is_ok(), "Should create file");

        let path = result.unwrap();
        let filename = path.file_name().unwrap().to_str().unwrap();

        // Verify filename contains prefix
        assert!(filename.starts_with("prefix_"), "Filename should start with prefix");

        // Verify filename ends with .tmp
        assert!(filename.ends_with(".tmp"), "Filename should end with .tmp");

        // Verify filename contains underscores (pid_threadid_timestamp structure)
        assert!(filename.matches('_').count() >= 3, "Filename should have at least 3 underscores");

        // Cleanup
        let _ = fs::remove_file(path);
    }

    /// Test with zero attempts parameter (should return error immediately)
    #[test]
    fn test_zero_attempts() {
        let temp_dir = std::env::temp_dir();

        let result = create_unique_temp_filepathbuf(&temp_dir, "zero", 0, 1);

        assert!(result.is_err(), "Should fail with zero attempts");

        if let Err(e) = result {
            let error_msg = format!("{}", e);
            assert!(error_msg.contains("CUTF"), "Error should have CUTF prefix");
            assert!(
                error_msg.contains("greater than zero") || error_msg.contains("number_of_attempts"),
                "Error should mention invalid attempt count"
            );
        }
    }

    /// Test with single attempt (should work in low-contention)
    #[test]
    fn test_single_attempt() {
        let temp_dir = std::env::temp_dir();

        let result = create_unique_temp_filepathbuf(&temp_dir, "single", 1, 1);

        assert!(result.is_ok(), "Should succeed with single attempt in low contention");

        if let Ok(path) = result {
            assert!(path.exists(), "File should exist");
            let _ = fs::remove_file(path);
        }
    }

    /// Test with different delay values (ensures parameter is used)
    #[test]
    fn test_different_delays() {
        let temp_dir = std::env::temp_dir();

        // Test with zero delay
        let result1 = create_unique_temp_filepathbuf(&temp_dir, "delay0", 3, 0);
        assert!(result1.is_ok(), "Should work with zero delay");
        if let Ok(path) = result1 {
            let _ = fs::remove_file(path);
        }

        // Test with larger delay
        let result2 = create_unique_temp_filepathbuf(&temp_dir, "delay100", 3, 100);
        assert!(result2.is_ok(), "Should work with 100ms delay");
        if let Ok(path) = result2 {
            let _ = fs::remove_file(path);
        }
    }

    /// Test with high number of attempts (stress test)
    #[test]
    fn test_many_attempts() {
        let temp_dir = std::env::temp_dir();

        let result = create_unique_temp_filepathbuf(&temp_dir, "many", 20, 1);

        assert!(result.is_ok(), "Should work with many attempts");

        if let Ok(path) = result {
            assert!(path.exists(), "File should exist");
            let _ = fs::remove_file(path);
        }
    }

    /// Test prefix with special characters (edge case)
    #[test]
    fn test_prefix_with_special_chars() {
        let temp_dir = std::env::temp_dir();

        // Test with prefix containing hyphens and underscores
        let result = create_unique_temp_filepathbuf(&temp_dir, "my-app_v2", 5, 1);

        assert!(result.is_ok(), "Should handle prefix with special chars");

        if let Ok(path) = result {
            let filename = path.file_name().unwrap().to_str().unwrap();
            assert!(filename.starts_with("my-app_v2_"), "Filename should preserve prefix");
            let _ = fs::remove_file(path);
        }
    }

    /// Test that created file is actually writable
    #[test]
    fn test_file_is_writable() {
        let temp_dir = std::env::temp_dir();

        let result = create_unique_temp_filepathbuf(&temp_dir, "writable", 5, 1);
        assert!(result.is_ok(), "Should create file");

        let path = result.unwrap();

        // Try to open and write to the file
        let write_result = OpenOptions::new()
            .write(true)
            .open(&path);

        assert!(write_result.is_ok(), "Should be able to open file for writing");

        // Cleanup
        let _ = fs::remove_file(path);
    }

    /// Test concurrent creation from multiple threads
    #[test]
    fn test_concurrent_creation() {
        use std::sync::Arc;

        let temp_dir = Arc::new(std::env::temp_dir());
        let mut handles = vec![];

        // Spawn 5 threads that each create 2 files
        for thread_num in 0..5 {
            let temp_dir_clone = Arc::clone(&temp_dir);

            let handle = thread::spawn(move || {
                let mut created_paths = Vec::new();

                for file_num in 0..2 {
                    let prefix = format!("concurrent_t{}_f{}", thread_num, file_num);
                    let result = create_unique_temp_filepathbuf(&temp_dir_clone, &prefix, 10, 5);

                    assert!(result.is_ok(), "Should create file from thread");
                    created_paths.push(result.unwrap());
                }

                created_paths
            });

            handles.push(handle);
        }

        // Collect all created paths
        let mut all_paths = Vec::new();
        for handle in handles {
            let paths = handle.join().expect("Thread should complete");
            all_paths.extend(paths);
        }

        // Verify all paths are unique
        for i in 0..all_paths.len() {
            for j in (i + 1)..all_paths.len() {
                assert_ne!(all_paths[i], all_paths[j], "All paths from all threads should be unique");
            }
        }

        // Verify all files exist
        for path in &all_paths {
            assert!(path.exists(), "All created files should exist");
        }

        // Cleanup
        for path in all_paths {
            let _ = fs::remove_file(path);
        }
    }

    /// Test error message format for debugging
    #[test]
    fn test_error_messages_have_cutf_prefix() {
        let temp_dir = std::env::temp_dir();

        // Test zero attempts error
        let result = create_unique_temp_filepathbuf(&temp_dir, "test", 0, 1);
        if let Err(e) = result {
            assert!(format!("{}", e).contains("CUTF"), "Error should have CUTF prefix");
        }
    }
}

/// Sets a collaborator as "active" by creating a stub file in the sync_data directory.
///
/// This function creates an empty file (a "stub" file) in the directory:
/// `sync_data/{team_channel_name}/is_active/{collaborator_name}`. The presence of this file marks the collaborator as active
/// in the current session for the specified team channel.  The function handles directory creation and any potential errors during
/// file creation.
///
/// This flag signals to other threads and parts of uma that
/// this (remote collaborator) user is acive.
///
/// # Arguments
///
/// * `collaborator_name`: The name of the collaborator to set as active.
///
/// # Returns
///
/// * `Result<(), ThisProjectError>`: `Ok(())` if the stub file was successfully created, or a `ThisProjectError` if an error occurred.
///
/// uses:
/// use std::fs::{create_dir_all, File};
/// use std::path::PathBuf;
fn set_as_active(collaborator_name: &str) -> Result<(), ThisProjectError> {
    // 1. Get team channel name (replace with your actual implementation)
    let team_channel_name = match get_current_team_channel_name_from_nav_path() {
        Some(name) => name,
        None => {
            debug_log!("Error: Could not get current channel name. Skipping set_as_active.");
            return Err(ThisProjectError::InvalidData("Could not get team channel name".into()));
        },
    };

    // 2. Construct the directory path using PathBuf
    let mut directory_path = make_input_path_name_abs_executabledirectoryrelative_nocheck(
        "sync_data"
    )?;
    directory_path.push(&team_channel_name);
    directory_path.push("is_active");
    directory_path.push(collaborator_name);

    // 3. Create the directory if it doesn't exist
    create_dir_all(directory_path.parent().unwrap())?;

    // 4. Create the stub file
    // The mere existence of the file (even empty) acts as the flag
    match File::create(&directory_path) {
        Ok(_) => {
            debug_log!("Collaborator '{}' set as active in channel '{}'.", collaborator_name, team_channel_name);
            Ok(())
        },
        Err(e) => {
            debug_log!("Error setting collaborator '{}' as active: {}", collaborator_name, e);
            Err(ThisProjectError::IoError(e))
        },
    }
}


// /// signal for continuing or for stoping whole Uma program with all threads
// /// Initializes the UMA continue/halt signal by creating or resetting the
// /// `continue_uma.txt` file and setting its value to "1" (continue).
// /// set to halt by `quit_set_continue_uma_to_false()`
// fn initialize_continue_uma_signal() {
//     // 1. Ensure the directory exists
//     let directory_path = Path::new(CONTINUE_UMA_PATH_STR).parent().unwrap(); // Get the parent directory
//     fs::create_dir_all(directory_path).expect("Failed to create directory for continue_uma.txt");

//     // 2. Create or overwrite the file
//     if fs::remove_file(CONTINUE_UMA_PATH_STR).is_ok() {
//         debug_log("Old 'continue_uma.txt' file deleted."); // Optional log.
//     }

//     let mut file = fs::File::create(CONTINUE_UMA_PATH_STR)
//         .expect("Failed to create 'continue_uma.txt' file.");

//     file.write_all(b"1")
//         .expect("Failed to write to 'continue_uma.txt' file.");
// }

// /// signal for continuing or for stoping whole Uma program with all threads
// fn initialize_hard_restart_signal() {
//     // 1. Ensure the directory exists
//     let directory_path = Path::new(HARD_RESTART_FLAG_PATH_STR).parent().unwrap(); // Get the parent directory
//     fs::create_dir_all(directory_path).expect("Failed to create directory for yes_hard_restart_flag.txt");

//     // 2. Create or overwrite the file
//     if fs::remove_file(HARD_RESTART_FLAG_PATH_STR).is_ok() {
//         debug_log("Old 'yes_hard_restart_flag.txt' file deleted."); // Optional log.
//     }

//     let mut file = fs::File::create(HARD_RESTART_FLAG_PATH_STR)
//         .expect("Failed to create 'yes_hard_restart_flag.txt' file.");

//     file.write_all(b"1")
//         .expect("Failed to write to 'yes_hard_restart_flag.txt' file.");
// }

// use std::fs::{self, File};
// use std::io::{self, Write};
// use std::path::PathBuf;

/// Initializes the UMA continue/halt signal by creating or resetting the
/// `continue_uma.txt` file and setting its value to "1" (continue).
///
/// This function sets up the continue/halt mechanism by writing a "1" to the
/// continue_uma.txt file, indicating that UMA should continue running.
/// It follows these steps:
///
/// 1. Resolves the absolute path to the file relative to the executable location
/// 2. Creates any necessary parent directories
/// 3. Removes any existing file (if present)
/// 4. Creates a new file with the content "1"
///
/// To halt UMA, the file can be set to "0" using `quit_set_continue_uma_to_false()`.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or an I/O error if the operation failed
///
/// # Errors
///
/// This function can fail if:
/// * The path cannot be resolved
/// * Parent directories cannot be created
/// * The file cannot be created or written to
pub fn initialize_continue_uma_signal() -> Result<(), io::Error> {
    // Get the executable-relative absolute path
    let abs_path = get_continue_uma_path()?;

    debug_log!("Initializing continue_uma signal to true (1) at: {:?}", abs_path);

    // Ensure parent directories exist
    if let Some(parent) = abs_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Try to delete the existing file if it exists
    match fs::remove_file(&abs_path) {
        Ok(_) => debug_log!("Old 'continue_uma.txt' file deleted."),
        Err(e) => {
            if e.kind() != io::ErrorKind::NotFound {
                // Log warning but continue - it's not fatal if we can't delete
                debug_log!("Warning: Could not delete old continue_uma.txt file: {}", e);
            }
        }
    }

    // Create and write to the file
    let mut file = File::create(&abs_path)?;
    file.write_all(b"1")?;

    debug_log!("Successfully initialized continue_uma signal to true (1)");
    Ok(())
}

/// Initializes the hard restart signal by creating or resetting the
/// `yes_hard_restart_flag.txt` file and setting its value to "1".
///
/// This function sets up the hard restart mechanism by writing a "1" to the
/// yes_hard_restart_flag.txt file, indicating that a hard restart is required.
/// It follows these steps:
///
/// 1. Resolves the absolute path to the file relative to the executable location
/// 2. Creates any necessary parent directories
/// 3. Removes any existing file (if present)
/// 4. Creates a new file with the content "1"
///
/// To cancel a hard restart, the file can be set to "0" using
/// `no_restart_set_hard_reset_flag_to_false()`.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or an I/O error if the operation failed
///
/// # Errors
///
/// This function can fail if:
/// * The path cannot be resolved
/// * Parent directories cannot be created
/// * The file cannot be created or written to
pub fn initialize_hard_restart_signal() -> Result<(), io::Error> {
    // Get the executable-relative absolute path
    let abs_path = get_hard_restart_flag_path()?;

    debug_log!("Initializing hard restart signal to true (1) at: {:?}", abs_path);

    // Ensure parent directories exist
    if let Some(parent) = abs_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Try to delete the existing file if it exists
    match fs::remove_file(&abs_path) {
        Ok(_) => debug_log!("Old 'yes_hard_restart_flag.txt' file deleted."),
        Err(e) => {
            if e.kind() != io::ErrorKind::NotFound {
                // Log warning but continue - it's not fatal if we can't delete
                debug_log!("Warning: Could not delete old yes_hard_restart_flag.txt file: {}", e);
            }
        }
    }

    // Create and write to the file
    let mut file = File::create(&abs_path)?;
    file.write_all(b"1")?;

    debug_log!("Successfully initialized hard restart signal to true (1)");
    Ok(())
}

// use std::fs::{self, File};
// use std::io::{self, Write};
// use std::path::PathBuf;

/// Sets a signal to stop the entire Uma program with all threads.
///
/// This function writes a "0" to the continue_uma.txt file, which is used
/// as a signal to stop the Uma program. It follows these steps:
///
/// 1. Resolves the absolute path to the continue_uma.txt file relative to the executable
/// 2. Attempts to delete any existing file (ignoring if it doesn't exist)
/// 3. Creates parent directories if they don't exist
/// 4. Creates a new file with the content "0"
///
/// The function uses a replace-not-modify workflow to avoid potential
/// file locking or partial write issues.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or an I/O error if the operation failed
///
/// # Errors
///
/// This function can fail if:
/// * The path cannot be resolved
/// * The parent directories cannot be created
/// * The file cannot be created or written to
pub fn quit_set_continue_uma_to_false() -> Result<(), io::Error> {
    // Get the executable-relative absolute path
    let abs_path = get_continue_uma_path()?;

    debug_log!("Setting continue_uma flag to false (0) at: {:?}", abs_path);

    // Try to delete the existing file if it exists
    match fs::remove_file(&abs_path) {
        Ok(_) => debug_log!("Old 'continue_uma.txt' file deleted."),
        Err(e) => {
            if e.kind() != io::ErrorKind::NotFound {
                // Log error but continue - it's not fatal if we can't delete
                debug_log!("Warning: Could not delete old continue_uma.txt file: {}", e);
            }
        }
    }

    // Ensure parent directories exist
    if let Some(parent) = abs_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Create and write to the file
    let mut file = File::create(&abs_path)?;
    file.write_all(b"0")?;

    debug_log!("Successfully set continue_uma flag to false (0)");
    Ok(())
}

/// Sets the hard restart flag to false, indicating no restart is needed.
///
/// This function writes a "0" to the yes_hard_restart_flag.txt file, which is used
/// to control program restart behavior. It follows these steps:
///
/// 1. Resolves the absolute path to the flag file relative to the executable
/// 2. Attempts to delete any existing file (ignoring if it doesn't exist)
/// 3. Creates parent directories if they don't exist
/// 4. Creates a new file with the content "0"
///
/// The function uses a replace-not-modify workflow to avoid potential
/// file locking or partial write issues.
///
/// # Returns
///
/// * `Result<(), io::Error>` - Success or an I/O error if the operation failed
///
/// # Errors
///
/// This function can fail if:
/// * The path cannot be resolved
/// * The parent directories cannot be created
/// * The file cannot be created or written to
pub fn no_restart_set_hard_reset_flag_to_false() -> Result<(), io::Error> {
    // Get the executable-relative absolute path
    let abs_path = get_hard_restart_flag_path()?;

    debug_log!("Setting hard restart flag to false (0) at: {:?}", abs_path);

    // Try to delete the existing file if it exists
    match fs::remove_file(&abs_path) {
        Ok(_) => debug_log!("Old 'yes_hard_restart_flag.txt' file deleted."),
        Err(e) => {
            if e.kind() != io::ErrorKind::NotFound {
                // Log error but continue - it's not fatal if we can't delete
                debug_log!("Warning: Could not delete old yes_hard_restart_flag.txt file: {}", e);
            }
        }
    }

    // Ensure parent directories exist
    if let Some(parent) = abs_path.parent() {
        fs::create_dir_all(parent)?;
    }

    // Create and write to the file
    let mut file = File::create(&abs_path)?;
    file.write_all(b"0")?;

    debug_log!("Successfully set hard restart flag to false (0)");
    Ok(())
}

// // TODO spin these two off into a function optional_passive_mode();
// // if return true, return?
// // Get command line arguments
// let args: Vec<String> = env::args().collect();
// // Check for passive message mode
// if args.len() >= 3 && args[1] == "--passive_message_mode" {
//     let path = Path::new(&args[2]);
//     if let Err(e) = run_passive_message_mode(path) {
//         eprintln!("Error in passive message mode: {}", e);
//         process::exit(1);
//     }
//     return;
// }
// // Check for passive message mode
// if args.len() >= 3 && args[1] == "--passive_task_mode" {
//     let path = Path::new(&args[2]);
//     if let Err(e) = run_passive_task_mode(path) {
//         eprintln!("Error in passive message mode: {}", e);
//         process::exit(1);
//     }
//     return;
// }

// /// Check for user input argument flag to launch int passive mode
// /// - message mode passsive
// /// or
// /// - task mode passive
// /// if so, return True (after running that mode)
// /// else: return false
// ///
// /// use in main with:
// /// ```
// /// if optional_passive_mode() {
// ///     return;
// /// };
// /// ```
// ///
// fn optional_passive_mode() -> bool {
//     // TODO spin these two off into a function optional_passive_mode();
//     // if return true, return?
//     // Get command line arguments
//     let args: Vec<String> = env::args().collect();
//     // Check for passive message mode
//     if args.len() >= 3 && args[1] == "--passive_message_mode" {
//         let path = Path::new(&args[2]);
//         if let Err(e) = run_passive_message_mode(path) {
//             eprintln!("Error in passive message mode: {}", e);
//             process::exit(1);
//         }
//         return true;
//     }
//     // Check for passive message mode
//     if args.len() >= 3 && args[1] == "--passive_task_mode" {
//         let path = Path::new(&args[2]);
//         if let Err(e) = run_passive_task_mode(path) {
//             eprintln!("Error in passive message mode: {}", e);
//             process::exit(1);
//         }
//         return true;
//     }

//     return false;
// }

/// Check for Command-Line Flags to Launch Passive Mode
///
/// # Purpose
///
/// Detects if Uma was launched with a passive mode flag and, if so, runs
/// the appropriate passive viewer instead of the main interactive application.
/// This allows Uma to act as both an interactive application and a passive
/// viewer depending on command-line arguments.
///
/// # Supported Passive Modes
///
/// 1. **Message Passive Mode** (new terminal window)
///    - Flag: `--passive_message_mode [path]`
///    - Launched by: "mp" / "pm" / "message-passive" commands
///    - Creates: New terminal window with passive message viewer
///
/// 2. **Message Passive Vsplit Mode** (tmux vertical split)
///    - Flag: `--passive_vsplit_message_mode [path]`
///    - Launched by: "mpv" / "pmv" / "message-passive-vsplit" commands
///    - Creates: Tmux vertical split pane with passive message viewer
///
/// 3. **Message Passive Hsplit Mode** (tmux horizontal split)
///    - Flag: `--passive_hsplit_message_mode [path]`
///    - Launched by: "mph" / "pmh" / "message-passive-hsplit" commands
///    - Creates: Tmux horizontal split pane with passive message viewer
///
/// 4. **Task Passive Mode** (existing, for tasks)
///    - Flag: `--passive_task_mode [path]`
///    - Launched by: Task-related commands
///    - Creates: Passive task viewer
///
/// # Usage in main()
///
/// This function should be called at the very start of main():
///
/// ```rust
/// fn main() {
///     // Check if launched in passive mode
///     if optional_passive_mode() {
///         return; // Exit main - passive mode handles everything
///     }
///
///     // Otherwise, continue with normal interactive Uma startup
///     // ...
/// }
/// ```
///
/// # Process Flow
///
/// 1. Parse command-line arguments via `env::args()`
/// 2. Check if first argument matches a passive mode flag
/// 3. If match found:
///    - Extract path from second argument
///    - Run appropriate passive mode function
///    - Return true (signaling main should exit)
/// 4. If no match:
///    - Return false (signaling main should continue normally)
///
/// # Passive Mode Execution
///
/// When a passive mode flag is detected:
/// - The corresponding passive viewer function is called
/// - That function enters an infinite refresh loop
/// - Main() returns after the loop exits (user closes viewer)
/// - Interactive Uma never starts
///
/// # Command-Line Format
///
/// All passive mode invocations follow this pattern:
/// ```bash
/// uma --[passive_mode_flag] /path/to/target/directory
/// ```
///
/// Examples:
/// ```bash
/// # New terminal window
/// uma --passive_message_mode /tmp/uma_team1/channel1/message_posts_browser
///
/// # Tmux vertical split
/// uma --passive_vsplit_message_mode /tmp/uma_team1/channel1/message_posts_browser
///
/// # Tmux horizontal split
/// uma --passive_hsplit_message_mode /tmp/uma_team1/channel1/message_posts_browser
/// ```
///
/// # Error Handling
///
/// - If passive mode function returns error: Print to stderr and exit(1)
/// - This ensures viewer failures don't leave zombie processes
/// - Main Uma process is unaffected (different process)
///
/// # Return Value
///
/// * `true` - Passive mode was detected and executed (main should return)
/// * `false` - No passive mode flag found (main should continue normally)
///
/// # Design Rationale
///
/// **Why check in main instead of during command handling?**
/// - Passive viewers run in separate processes
/// - They need to skip entire Uma initialization
/// - Checking at main entry is most efficient
///
/// **Why same function for all passive modes?**
/// - Single point of truth for passive mode detection
/// - Easier to maintain and extend
/// - Consistent error handling across all modes
///
/// **Why exit(1) on error instead of returning error?**
/// - Passive viewers are spawned processes, not library calls
/// - Need definitive termination signal for parent process
/// - Stderr message already printed for debugging
///
/// # Related Functions
///
/// - `run_passive_message_mode()`: Message viewer refresh loop
/// - `run_passive_task_mode()`: Task viewer refresh loop
/// - Command handlers: "mp", "mpv", "mph" that spawn with these flags
///
/// # Future Extensions
///
/// To add new passive modes:
/// 1. Add new flag check in this function
/// 2. Create corresponding `run_passive_*_mode()` function
/// 3. Add command handler that spawns with new flag
fn optional_passive_mode() -> bool {
    debug_log("OPM: Checking for passive mode command-line flags");

    // Get command line arguments
    let args: Vec<String> = env::args().collect();

    // Log arguments for debugging
    debug_log!("OPM: Command-line args: {:?}", args);

    // ============================================================
    // MESSAGE PASSIVE MODE: New terminal window
    // ============================================================
    if args.len() >= 3 && args[1] == "--passive_message_mode" {
        debug_log!("OPM: Detected --passive_message_mode flag");

        let path = Path::new(&args[2]);
        debug_log!("OPM: Message path: {:?}", path);

        if let Err(e) = run_passive_message_mode(path) {
            eprintln!("Error in passive message mode: {}", e);
            debug_log!("OPM: Passive message mode failed: {}", e);
            process::exit(1);
        }

        debug_log!("OPM: Passive message mode completed");
        return true;
    }

    // ============================================================
    // MESSAGE PASSIVE VSPLIT MODE: Tmux vertical split
    // ============================================================
    if args.len() >= 3 && args[1] == "--passive_vsplit_message_mode" {
        debug_log!("OPM: Detected --passive_vsplit_message_mode flag");

        let path = Path::new(&args[2]);
        debug_log!("OPM: Message path (vsplit): {:?}", path);

        if let Err(e) = run_passive_message_mode(path) {
            eprintln!("Error in passive message vsplit mode: {}", e);
            debug_log!("OPM: Passive message vsplit mode failed: {}", e);
            process::exit(1);
        }

        debug_log!("OPM: Passive message vsplit mode completed");
        return true;
    }

    // ============================================================
    // MESSAGE PASSIVE HSPLIT MODE: Tmux horizontal split
    // ============================================================
    if args.len() >= 3 && args[1] == "--passive_hsplit_message_mode" {
        debug_log!("OPM: Detected --passive_hsplit_message_mode flag");

        let path = Path::new(&args[2]);
        debug_log!("OPM: Message path (hsplit): {:?}", path);

        if let Err(e) = run_passive_message_mode(path) {
            eprintln!("Error in passive message hsplit mode: {}", e);
            debug_log!("OPM: Passive message hsplit mode failed: {}", e);
            process::exit(1);
        }

        debug_log!("OPM: Passive message hsplit mode completed");
        return true;
    }

    // ============================================================
    // TASK PASSIVE MODE: Existing task viewer
    // ============================================================
    if args.len() >= 3 && args[1] == "--passive_task_mode" {
        debug_log!("OPM: Detected --passive_task_mode flag");

        let path = Path::new(&args[2]);
        debug_log!("OPM: Task path: {:?}", path);

        if let Err(e) = run_passive_task_mode(path) {
            eprintln!("Error in passive task mode: {}", e);
            debug_log!("OPM: Passive task mode failed: {}", e);
            process::exit(1);
        }

        debug_log!("OPM: Passive task mode completed");
        return true;
    }

    // ============================================================
    // TASK PASSIVE VSPLIT MODE: Tmux vertical split
    // ============================================================
    if args.len() >= 3 && args[1] == "--passive_vsplit_task_mode" {
        debug_log!("OPM: Detected --passive_vsplit_task_mode flag");

        let path = Path::new(&args[2]);
        debug_log!("OPM: Task board path (vsplit): {:?}", path);

        if let Err(e) = run_passive_task_mode(path) {
            eprintln!("Error in passive task vsplit mode: {}", e);
            debug_log!("OPM: Passive task vsplit mode failed: {}", e);
            process::exit(1);
        }

        debug_log!("OPM: Passive task vsplit mode completed");
        return true;
    }

    // ============================================================
    // TASK PASSIVE HSPLIT MODE: Tmux horizontal split
    // ============================================================
    if args.len() >= 3 && args[1] == "--passive_hsplit_task_mode" {
        debug_log!("OPM: Detected --passive_hsplit_task_mode flag");

        let path = Path::new(&args[2]);
        debug_log!("OPM: Task board path (hsplit): {:?}", path);

        if let Err(e) = run_passive_task_mode(path) {
            eprintln!("Error in passive task hsplit mode: {}", e);
            debug_log!("OPM: Passive task hsplit mode failed: {}", e);
            process::exit(1);
        }

        debug_log!("OPM: Passive task hsplit mode completed");
        return true;
    }


    // ============================================================
    // NO PASSIVE MODE: Continue with normal Uma startup
    // ============================================================
    debug_log!("OPM: No passive mode flag detected, continuing normal startup");
    false
}

/*
An Appropriately Svelt Mainland:
*/
/// Initializes the UMA continue/halt signal by creating or resetting the
/// `continue_uma.txt` file and setting its value to "1" (continue).
/// set to hault by quit_set_continue_uma_to_false()
///
/// There is NO practical advantage
/// to using Arc<AtomicBool> over writing a "1" or "0" to a file.
/// The file method is simpler, more efficient,
/// and just as reliable in this context.
///
/// This also allows the user to manually set the halt signal.
fn main() {

    if optional_passive_mode() {
        return;
    };

    let _ = initialize_continue_uma_signal(); // set boolean flag for loops to hault
    let _ = initialize_hard_restart_signal(); // set boolean flag for uma restart

    let mut online_mode: bool;

    loop { // Main loop: let it fail, and try again

        if should_not_hard_restart() { // Check for restart
            debug_log("should_halt_uma(), exiting Uma in main()");
            break;
        }

        debug_log("boot...");
        match initialize_uma_application() {
            Ok(temp_online_val) => {
                online_mode = temp_online_val;
                if online_mode {
                    debug_log!("UMA initialized in online mode.");
                } else {
                    debug_log!("UMA initialized in offline mode.")
                }
            }
            Err(e) => {
                eprintln!("Initialization failed: {}", e);
                debug_log!("Initialization failed: {}", e);
                std::process::exit(1);
                // break;
            }
        }

        debug_log("Start!");

        // Thread 1: Executes the thread1_loop function
        let we_love_projects_loop = thread::spawn(move || {
            let _ = we_love_projects_loop();
        });

        // Thread 2: Executes the thread2_loop function
        if online_mode {
            let you_love_the_sync_team_office = thread::spawn(move || {
                let _ = you_love_the_sync_team_office();
            });
            you_love_the_sync_team_office.join().unwrap(); // Wait for finish
        };

        we_love_projects_loop.join().unwrap(); // Wait for finish
        // if online_mode {
        //     you_love_the_sync_team_office.join().unwrap();
        //     } // Wait for finish
        // End
        println!("All threads completed. The Uma says fare well and strive.");
        debug_log("All threads completed. The Uma says fare well and strive.");
        debug_log(">*< Halt signal received. Exiting The Uma. Closing... main() |o|");
    }
}



// /*
//  * Help Section
//  */

// /// ANSI color codes for terminal formatting
// ///
// /// These constants provide color and style formatting for terminal output.
// /// Using ANSI escape sequences for maximum compatibility.
// mod ansi_colors {
//     /// Reset all formatting to default
//     pub const RESET: &str = "\x1b[0m";

//     /// Bold text for headers
//     pub const BOLD: &str = "\x1b[1m";

//     /// Cyan color for commands
//     pub const CYAN: &str = "\x1b[36m";

//     /// Green color for examples
//     pub const GREEN: &str = "\x1b[32m";

//     /// Yellow color for warnings or important notes
//     pub const YELLOW: &str = "\x1b[33m";

//     /// Bright white for emphasis
//     pub const BRIGHT_WHITE: &str = "\x1b[97m";

//     /// Magenta for section numbers
//     pub const MAGENTA: &str = "\x1b[35m";
// }

// /// Help section identifiers for menu navigation
// ///
// /// Each variant represents a distinct help section that can be displayed
// /// independently to fit within 80x24 terminal constraints.
// #[derive(Debug, Clone, Copy, PartialEq)]
// enum HelpSection {
//     QuickStartBlurb,
//     TopbarLegend,
//     Navigation,
//     SortingFiltering,
//     SearchOptions,
//     FileOperations,
//     TerminalManagement,
//     GetSendModeBlurb,
//     ModularViewModes,
//     Configuration,
// }

// /// Main help menu header text
// ///
// /// Displayed at the top of the help menu selection screen
// const HELP_MENU_HEADER: &str = r#"
//   
//    ff is a minimal file manager. It's File Fantastic! ...it's a File Fantasy.
//   https://github.com/lineality/ff_file_manager_minimal_rust
//                          get source code -> ff --source

//   Goal: Best of both worlds between raw terminal and file manager:
//         GUI features in a TUI. Switch easily between terminal and ff.
//  "#;

// /// Quick start and examples help section content
// const HELP_SECTION_QUICK_START: &str = r#"
//  QUICK START & EXAMPLES      Press Enter to return to help menu
//  USAGE in terminal:      ff [OPTIONS] [DIRECTORY]
//  OPTIONS:
//    -h, --help            Show this help menu
//    --source              Get ff source code, Rust 'crate'

//  EXAMPLES:
//    ff                    Open ff in current directory
//    ff /path/to/dir       Open ff in specific directory
//    ff ~/Documents        Open ff in Documents folder
//    ff -h                 View ff help menu
//    ff --help             View ff help menu (Alternative)
//    ff /path/to/file.txt --line 42    Open file (to line, optional)
//    ff --session /path/to/session     User existing Lines-Session

//  BASIC WORKFLOW:
//    1. Launch ff in/to any directory
//    2. Navigate TO files/directories with selection numbers
//    3. Navigate backwards to parent directory with 'b'
//    4. Sort with 'n' (name), 's' (size), 'm' (modified)
//    5. Filter with 'd' (dirs only), 'f' (files only)
//    6. Search by typing a search term (and hitting enter)
//    7. 'q' to quit"#;

// const HELP_SECTION_TOPBAR_LEGEND: &str = r#"
// quit back|term|dir file|name size mod|get-send file v,y,p|str>search|enter>reset

//   THE LEGEND OF TOP-BAR 
//  quit back...........q for quite ff, b for go-back

//  term................t for open a new terminal
//                      vsplit for new tmux split vertical
//                      hsplit for new tmux split horizontal

//  dir file............d/f for view only directories/files

//  name size mod.......n/s/m to sort name, size, time-modified

//  get-send file v,y,p.....c,v,y,p,g for Enter Get-Send Mode
//                          a is a shortcut to archive-menu

//  str>search..........enter string for fuzzy directory search
//                      -r for recursive directory search
//                      or --recursive
//                      -g for to string search text files
//                      or --grep
//  enter>reset.........empty enter to reset view
//     Press Enter to return to help menu..."#;

// /// Navigation commands help section content
// const HELP_SECTION_NAVIGATION: &str = r#"
//   NAVIGATION COMMANDS 

//  BASIC NAVIGATION:
//    [number]              Enter item number to open file/directory
//    b                     Go back to parent directory
//    q                     Quit File Fantastic
//    [Enter]               Reset view and refresh

//  PAGINATION:
//    When viewing long lists:
//    - Items are automatically paginated
//    - Navigate pages with standard controls
//        up/down = j/k, </>, w/x, +/- arrows keys, etc
//    - Current page shown in status

//  POCKET DIMENSIONS: saved locations in Get-Send Mode
//    Often you want to navigate somewhere, but then come back!
//    - Save current location as a "Pocket Dimension"
//    - Jump between any saved 'pocket dimensions.'
//    - Pocket Dimentions should retain all your filters & sorts.

//  Press Enter to return to help menu..."#;

// /// Sorting and filtering help section content
// const HELP_SECTION_SORTING_FILTERING: &str = r#"
//   SORTING & FILTERING     Press Enter to return to help menu...

// One thing that makes raw terminal 'ls' tricky is when there are a
// lot of items and you are looking for... the most recent, or want to
// see only files. With ff you can have these file-manager features
// in your native terminal. Getting a reverse 'modified' 'size' 'name'
// sort is easy: toggle! (And use --count-rows to view/sort data-lines!)

//  SORTING COMMANDS:       [row-count: (n)ame sort, (c)ount sort)]
//    n                     Sort by name (toggle ascending/descending)
//    s                     Sort by size (toggle ascending/descending)
//    m                     Sort by last-modified date-time (toggle asc/desc)

//  FILTERING COMMANDS:     [row-count: (h) to remove headers from counts]
//    d                     Show only directories
//    f                     Show only files
//    [Enter]               Reset filter (show all items)

//  SORT ORDER (reverse the order):
//    - First press: ascending order (A-Z, smallest-largest, oldest-newest)
//    - Second press: descending order! Yay!"#;

// /// Search options help section content
// const HELP_SECTION_SEARCH: &str = r#"
//   SEARCH OPTIONS 

//  BASIC SEARCH:
//    [search term]        Fuzzy search for files/directories
//                         Just start typing to search current directory

//  ADVANCED SEARCH:       Tip, combine flags: goodstuff -r -g
//    [term] -r            Recursive search in subdirectories
//    [term] --recursive   Alternative recursive search syntax
//    [term] -g            Grep: search INSIDE text file contents
//    [term] --grep        Alternative grep syntax
//    [term] -c            Case-sensitive string search
//    [term] --case-sensitive

//  SEARCH BEHAVIOR:
//    - Fuzzy matching: finds partial matches
//    - Case-insensitive by default
//    - Fuzzy Results shown with relevance scoring
//         Distance = Levinshtein-Distance

//  Press Enter to return to help menu... "#;

// /// File operations help section content
// const HELP_SECTION_FILE_OPERATIONS: &str = r#"
//   FILE OPERATIONS     Press  Enter to return to help menu...
//  Sometimes you will use a teminal and a GUI desktop.
//  Sometimes you will use a headless environment (like with ssh).
//  Maybe you use tmux or tiling/window managers.

//  FILE OPENING:           (after entering the file number)
//    Empty Enter	         Open file with default editor
//    {editor}              Open file with chosen editor
//    {editor} -h           Headless! Open in current terminal
//                            Alternative: -- headless
//    {editor} -vsplit      Open in tmux vertical split
//                            Alternative: --vertical-split-tmux
//    {editor} -hsplit      Open in tmux horizontal split
//                            Alternative: --horizontal-split-tmux
//  CSV ANALYSIS:
//     [number] -rc         Analyzes a CSV file (rows, columns, stats)
//                          Opens analysis in temporary file
//                            Alternative: --rows-and-columns
//  EXAMPLES:
//   hx                    Open file with Helix editor, in a new window
//   vi -h                 Headless: Open with vi editor in same terminal
//   hx -hsplit            Headless Tmux: Open with Helix in a new split
//   hx -rc -vsplit        Tmux split view of rows-cols .csv "#;

// /// Get-Send Mode
// const HELP_SECTION_GET_SEND_MODE: &str = r#"
//   GET-SEND MODE    Press Enter to return to help menu...

//  Moving (or copying) a file using only a raw terminal can
//  be tricky. In Get-Send mode you will find various features
//  to ease this process of jumping between locations, and copying
//  files or directories (stacks), or making time-stamped archives, and
//  tracking where you are jumping around (pocket-dimensions)!
//  To enter Get-Send mode, use any common 'copy paste yank' key.
//  For safety, ff only copies or archives, no delete or move.

//  GET-SEND MODE ACTIVATION:
//    v, c, y, p, g         Enter Get-Send Mode
//    a                     Archive mode shortcut (create zip archives)

//  GET-SEND MODE OPERATIONS: no deleting, only copying/archiving
//    1. Add item TO stack (file or dir)
//    2. Get: Save item here, FROM stack
//    3. Save current location as pocket dimension
//    4. Go to pocket dimension
//    5. View stacks & pocket dimensions
//    6. Archive file/directory 'a': zip/timestamp
//    7. Clear all stacks"#;

// /// Get-Send Mode
// const HELP_SECTION_VIEW_MODES: &str = r#"
//    ROW-COUNTS & MODULAR VIEW-MODES     Press Enter to return...

//   COUNT ROWS / LINES: See how many rows the files in a directory have.
//   Enter mode with '--row-counts' or '--line-counts'

//   Commands: (n)ame sort, (c)ount sort, (h)eader, (Enter) reset, (b/q)uit
//   Sort by name or count (toggle to reverse sort), and
//   'h' removes the header from the row count: Count only data rows


//   MAKE YOUR OWN DIRECTORY-VIEW MODULES:
//     Make your own custom views and add them to FF.
//     1. Modify line-count as an example:
//         NavigationAction::GoToFileLineCountMode => {
//             match show_minimal_linecount_tui(&path) <-(make your own fn)

//     2. Add your new NavigationAction:
//     match lowercase_input.as_str() {
//         "vsplit" => return Ok(NavigationAction::VsplitTmux),
//         "--help" => return Ok(NavigationAction::GoToHelpMenuMode),
//    -> ->"--new-stuff" => return OK(NavigationAction::NewStuff),"#;

// /// Terminal management help section content
// const HELP_SECTION_TERMINAL: &str = r#"
//   TERMINAL & DISPLAY MANAGEMENT   Press Enter to return

//  Your 'current working directory,' where you go, in ff, does not
//  carry over to your terminal after you exit. But you will want
//  to keep working where you are in ff:
//  - you can open a new terminal or split IN your current ff location.
//  - Note: Run tmux before you run ff to use the tmux splits.

//  TERMINAL OPERATIONS:
//    t                     Open new terminal in current directory
//    vsplit                Create vertical tmux split (current directory)
//    hsplit                Create horizontal tmux split (current directory)

//  DISPLAY RESIZING:       'N' here is whatever number you enter.
//    tall+N                Increase display height by N rows
//    tall-N                Decrease display height by N rows
//    wide+N                Increase display width by N chars
//    wide-N                Decrease display width by N chars

//  When ff exits, it will tell you where you last were,
//  and the ~bash line to run to go back there in a terminal.
//  e.g.   To continue from this location, run:
//         cd /home/oops/code/ff_file_manager_minimal_rust"#;

// /// Configuration help section content
// const HELP_SECTION_CONFIGURATION: &str = r#"
//   PARTNER PROGRAMS CONFIGURATION 

//  You may want to call your own applications or other applications
//  that are not fully 'installed' on your system. "Partner Programs"
//  allows you to tell File Fantastic where these binary-executible
//  files are, wherever they are. Just list each file-path in this file,
//  which FF will create:

//  CONFIGURATION FILE:
//    ~/.ff_data/absolute_paths_to_local_partner_fileopening_executables.txt

//  FILE FORMAT:
//    - One program path per line
//    - Use absolute paths
//    - Comments with #, and blank lines, are ignored

//  EXAMPLE CONFIGURATION:
//    /usr/bin/emacs
//    # This is a comment
//    /home/user/bin/custom-editor

//  Press Enter to return to help menu... "#;

// /// Display the main help menu and handle section selection
// ///
// /// This function presents the user with a numbered menu of help sections
// /// and processes their selection. It returns to the caller when the user
// /// chooses to quit.
// ///
// /// # Returns
// /// * `Result<()>` - Ok on successful completion, Err on I/O or other errors
// ///
// /// # Errors
// /// - I/O errors when reading user input
// /// - Terminal display errors
// pub fn display_help_menu_system() -> Result<()> {
//     loop {
//         // Clear screen for clean display
//         clear_terminal_screen()?;

//         // Display header with colors
//         print!("{}{}", ansi_colors::BOLD, ansi_colors::BRIGHT_WHITE);
//         println!("{}", HELP_MENU_HEADER);
//         print!("{}", ansi_colors::RESET);

//         // Quit instructions (...learning from the vim nightmare...)
//         println!(
//             "  {}q.{} Type 'q' & hit Enter to quit help menu / File Fantastic",
//             ansi_colors::YELLOW,
//             ansi_colors::RESET
//         );
//         println!();

//         // Display menu options
//         println!(
//             "{} Select a help section:{}",
//             ansi_colors::CYAN,
//             ansi_colors::RESET
//         );

//         // Menu items with colored numbers
//         println!(
//             "  {}1.{} Quick Start & Examples",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}2.{} Top Bar Legend Tips",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}3.{} Navigation Commands",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}4.{} Sorting & Filtering",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}5.{} Search Options",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}6.{} Go To File: Opening / Processing a File",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}7.{} Get-Send Mode (Get/Send/Move files & directories)",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}8.{} See All Files' Row Counts in a Directory (Modular View Modes)",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}9.{} Terminal & Display Management",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}10.{} 'Partner Programs' Configuration",
//             ansi_colors::MAGENTA,
//             ansi_colors::RESET
//         );
//         println!(
//             "  {}11.{} View help menu doc in editor (vi/nano)",
//             ansi_colors::GREEN,
//             ansi_colors::RESET
//         );
//         println!();
//         print!(
//             "{}Enter section number (1-10) or 'q' to quit: {}",
//             ansi_colors::BOLD,
//             ansi_colors::RESET
//         );

//         // Flush to ensure prompt appears
//         io::stdout().flush().map_err(FileFantasticError::Io)?;

//         // Read user input
//         let mut input = String::new();
//         io::stdin()
//             .read_line(&mut input)
//             .map_err(FileFantasticError::Io)?;
//         let input = input.trim().to_lowercase();

//         // Process user selection
//         match input.as_str() {
//             "1" => display_help_section_content(HelpSection::QuickStartBlurb)?,
//             "2" => display_help_section_content(HelpSection::TopbarLegend)?,
//             "3" => display_help_section_content(HelpSection::Navigation)?,
//             "4" => display_help_section_content(HelpSection::SortingFiltering)?,
//             "5" => display_help_section_content(HelpSection::SearchOptions)?,
//             "6" => display_help_section_content(HelpSection::FileOperations)?,
//             "7" => display_help_section_content(HelpSection::GetSendModeBlurb)?,
//             "8" => display_help_section_content(HelpSection::ModularViewModes)?,
//             "9" => display_help_section_content(HelpSection::TerminalManagement)?,
//             "10" => display_help_section_content(HelpSection::Configuration)?,
//             "11" => open_complete_help_in_editor()?,
//             "q" | "quit" | "exit" => {
//                 println!(
//                     "{}Exiting help system...{}",
//                     ansi_colors::GREEN,
//                     ansi_colors::RESET
//                 );
//                 return Ok(());
//             }
//             _ => {
//                 println!(
//                     "{}Try again...Please enter 1-10 or 'q'.{}",
//                     ansi_colors::YELLOW,
//                     ansi_colors::RESET
//                 );
//                 wait_for_enter_keypress()?;
//             }
//         }
//     }
// }

// /// Display a specific help section with proper formatting
// ///
// /// This function clears the screen and displays the content for the
// /// selected help section, waiting for user input before returning.
// ///
// /// # Arguments
// /// * `section` - The help section to display
// ///
// /// # Returns
// /// * `Result<()>` - Ok on successful display, Err on I/O errors
// fn display_help_section_content(section: HelpSection) -> Result<()> {
//     clear_terminal_screen()?;

//     // Select and display appropriate section content
//     let content = match section {
//         HelpSection::QuickStartBlurb => HELP_SECTION_QUICK_START,
//         HelpSection::TopbarLegend => HELP_SECTION_TOPBAR_LEGEND,
//         HelpSection::Navigation => HELP_SECTION_NAVIGATION,
//         HelpSection::SortingFiltering => HELP_SECTION_SORTING_FILTERING,
//         HelpSection::SearchOptions => HELP_SECTION_SEARCH,
//         HelpSection::FileOperations => HELP_SECTION_FILE_OPERATIONS,
//         HelpSection::GetSendModeBlurb => HELP_SECTION_GET_SEND_MODE,
//         HelpSection::ModularViewModes => HELP_SECTION_VIEW_MODES,
//         HelpSection::TerminalManagement => HELP_SECTION_TERMINAL,
//         HelpSection::Configuration => HELP_SECTION_CONFIGURATION,
//     };

//     // Display with color formatting
//     print!("{}{}", ansi_colors::BOLD, ansi_colors::CYAN);
//     println!("{}", content);
//     print!("{}", ansi_colors::RESET);

//     // Wait for user to read
//     wait_for_enter_keypress()?;

//     Ok(())
// }

// /// Open complete help documentation in external editor
// ///
// /// This function compiles all help sections into a single document
// /// and opens it in the user's preferred editor (vi or nano).
// ///
// /// # Returns
// /// * `Result<()>` - Ok if editor opened successfully, Err otherwise
// ///
// /// # Errors
// /// - Failed to create temp file
// /// - Editor not found or failed to launch
// fn open_complete_help_in_editor() -> Result<()> {
//     // Create complete help content
//     let mut complete_help = String::new();

//     // Add header
//     complete_help.push_str("FILE FANTASTIC (ff) - COMPLETE HELP DOCUMENTATION\n");
//     complete_help.push_str("=".repeat(78).as_str());
//     complete_help.push_str("\n\n");

//     // Add all sections without ANSI codes for editor viewing
//     complete_help.push_str("QUICK START & EXAMPLES\n");
//     complete_help.push_str("-".repeat(78).as_str());
//     complete_help.push_str("\n");
//     complete_help.push_str(strip_ansi_codes(HELP_SECTION_QUICK_START).as_str());
//     complete_help.push_str("\n\n");

//     complete_help.push_str("NAVIGATION COMMANDS\n");
//     complete_help.push_str("-".repeat(78).as_str());
//     complete_help.push_str("\n");
//     complete_help.push_str(strip_ansi_codes(HELP_SECTION_NAVIGATION).as_str());
//     complete_help.push_str("\n\n");

//     complete_help.push_str("SORTING & FILTERING\n");
//     complete_help.push_str("-".repeat(78).as_str());
//     complete_help.push_str("\n");
//     complete_help.push_str(strip_ansi_codes(HELP_SECTION_SORTING_FILTERING).as_str());
//     complete_help.push_str("\n\n");

//     complete_help.push_str("SEARCH OPTIONS\n");
//     complete_help.push_str("-".repeat(78).as_str());
//     complete_help.push_str("\n");
//     complete_help.push_str(strip_ansi_codes(HELP_SECTION_SEARCH).as_str());
//     complete_help.push_str("\n\n");

//     complete_help.push_str("FILE OPERATIONS (GET-SEND MODE)\n");
//     complete_help.push_str("-".repeat(78).as_str());
//     complete_help.push_str("\n");
//     complete_help.push_str(strip_ansi_codes(HELP_SECTION_FILE_OPERATIONS).as_str());
//     complete_help.push_str("\n\n");

//     complete_help.push_str("TERMINAL & DISPLAY MANAGEMENT\n");
//     complete_help.push_str("-".repeat(78).as_str());
//     complete_help.push_str("\n");
//     complete_help.push_str(strip_ansi_codes(HELP_SECTION_TERMINAL).as_str());
//     complete_help.push_str("\n\n");

//     complete_help.push_str("PARTNER PROGRAMS CONFIGURATION\n");
//     complete_help.push_str("-".repeat(78).as_str());
//     complete_help.push_str("\n");
//     complete_help.push_str(strip_ansi_codes(HELP_SECTION_CONFIGURATION).as_str());

//     // Create temp file
//     let temp_dir = env::temp_dir();
//     let temp_file_path = temp_dir.join("ff_help_documentation.txt");

//     // Write content to temp file
//     fs::write(&temp_file_path, complete_help)?;

//     // Try to open in vi first, then nano
//     let editor_result = Command::new("vi").arg(&temp_file_path).status();

//     match editor_result {
//         Ok(status) if status.success() => {
//             // Successfully opened in vi
//             println!(
//                 "{}Help documentation closed.{}",
//                 ansi_colors::GREEN,
//                 ansi_colors::RESET
//             );
//         }
//         _ => {
//             // Try nano as fallback
//             let nano_result = Command::new("nano").arg(&temp_file_path).status();

//             match nano_result {
//                 Ok(status) if status.success() => {
//                     println!(
//                         "{}Help documentation closed.{}",
//                         ansi_colors::GREEN,
//                         ansi_colors::RESET
//                     );
//                 }
//                 _ => {
//                     // Neither editor worked
//                     eprintln!(
//                         "{}Error: Could not open help in vi or nano.{}",
//                         ansi_colors::YELLOW,
//                         ansi_colors::RESET
//                     );
//                     eprintln!("Help file saved to: {}", temp_file_path.display());
//                     wait_for_enter_keypress()?;
//                 }
//             }
//         }
//     }

//     // Note: We don't delete the temp file immediately in case user wants to reference it
//     // OS will clean up temp directory eventually

//     Ok(())
// }


// /// Clear the terminal screen using ANSI escape codes
// ///
// /// This function uses ANSI escape sequences to clear the terminal
// /// and reset the cursor to the top-left position.
// ///
// /// # Returns
// /// * `Result<()>` - Ok on success, Err on I/O error
// fn clear_terminal_screen() -> Result<()> {
//     // ANSI escape codes: clear screen and move cursor to top-left
//     print!("\x1b[2J\x1b[1;1H");
//     io::stdout().flush().map_err(FileFantasticError::Io)?;
//     Ok(())
// }

// /// Wait for user to press Enter key
// ///
// /// Simple utility function to pause execution until the user
// /// presses the Enter key. Used between help sections.
// ///
// /// # Returns
// /// * `Result<()>` - Ok when Enter pressed, Err on I/O error
// fn wait_for_enter_keypress() -> Result<()> {
//     let mut buffer = String::new();
//     io::stdin()
//         .read_line(&mut buffer)
//         .map_err(FileFantasticError::Io)?;
//     Ok(())
// }

// /// Strip ANSI color codes from a string
// ///
// /// Removes all ANSI escape sequences from text for clean display
// /// in external editors that don't support color codes.
// ///
// /// # Arguments
// /// * `text` - Text potentially containing ANSI codes
// ///
// /// # Returns
// /// * `String` - Text with all ANSI codes removed
// fn strip_ansi_codes(text: &str) -> String {
//     // Simple regex-like replacement without external dependencies
//     let mut result = String::new();
//     let mut chars = text.chars().peekable();

//     while let Some(ch) = chars.next() {
//         if ch == '\x1b' {
//             // Skip ANSI escape sequence
//             // Format: ESC [ ... m
//             if chars.peek() == Some(&'[') {
//                 chars.next(); // Skip '['
//                 // Skip until 'm'
//                 while let Some(next_ch) = chars.next() {
//                     if next_ch == 'm' {
//                         break;
//                     }
//                 }
//             }
//         } else {
//             result.push(ch);
//         }
//     }

//     result
// }

// /// Check if help flag is present in command line arguments
// ///
// /// This function checks if the user has requested help via
// /// -h or --help command line flags.
// ///
// /// # Arguments
// /// * `args` - Command line arguments iterator
// ///
// /// # Returns
// /// * `bool` - true if help flag found, false otherwise
// pub fn check_for_help_flag_in_args(args: &[String]) -> bool {
//     // args.iter().any(|arg| arg == "-h" || arg == "--help")
//     args.iter()
//         // .skip(1)
//         .any(|arg| arg == "-h" || arg == "--help")
// }
